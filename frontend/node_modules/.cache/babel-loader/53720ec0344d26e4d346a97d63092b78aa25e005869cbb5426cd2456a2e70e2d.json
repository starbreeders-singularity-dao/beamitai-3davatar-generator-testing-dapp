{"ast":null,"code":"/**\n * @license\n * Copyright 2017 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nconst i$2 = (i, e) => \"method\" === e.kind && e.descriptor && !(\"value\" in e.descriptor) ? {\n    ...e,\n    finisher(n) {\n      n.createProperty(e.key, i);\n    }\n  } : {\n    kind: \"field\",\n    key: Symbol(),\n    placement: \"own\",\n    descriptor: {},\n    originalKey: e.key,\n    initializer() {\n      \"function\" == typeof e.initializer && (this[e.key] = e.initializer.call(this));\n    },\n    finisher(n) {\n      n.createProperty(e.key, i);\n    }\n  },\n  e$5 = (i, e, n) => {\n    e.constructor.createProperty(n, i);\n  };\nfunction n$8(n) {\n  return (t, o) => void 0 !== o ? e$5(n, t, o) : i$2(n, t);\n}\n\n/**\n * @license\n * Copyright 2021 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nvar n$7;\nnull != (null === (n$7 = window.HTMLSlotElement) || void 0 === n$7 ? void 0 : n$7.prototype.assignedElements) ? (o, n) => o.assignedElements(n) : (o, n) => o.assignedNodes(n).filter(o => o.nodeType === Node.ELEMENT_NODE);\n\n/**\n * @license\n * Copyright 2010-2024 Three.js Authors\n * SPDX-License-Identifier: MIT\n */\nconst REVISION = '169';\nconst CullFaceNone = 0;\nconst CullFaceBack = 1;\nconst CullFaceFront = 2;\nconst PCFShadowMap = 1;\nconst PCFSoftShadowMap = 2;\nconst VSMShadowMap = 3;\nconst FrontSide = 0;\nconst BackSide = 1;\nconst DoubleSide = 2;\nconst NoBlending = 0;\nconst NormalBlending = 1;\nconst AdditiveBlending = 2;\nconst SubtractiveBlending = 3;\nconst MultiplyBlending = 4;\nconst CustomBlending = 5;\nconst AddEquation = 100;\nconst SubtractEquation = 101;\nconst ReverseSubtractEquation = 102;\nconst MinEquation = 103;\nconst MaxEquation = 104;\nconst ZeroFactor = 200;\nconst OneFactor = 201;\nconst SrcColorFactor = 202;\nconst OneMinusSrcColorFactor = 203;\nconst SrcAlphaFactor = 204;\nconst OneMinusSrcAlphaFactor = 205;\nconst DstAlphaFactor = 206;\nconst OneMinusDstAlphaFactor = 207;\nconst DstColorFactor = 208;\nconst OneMinusDstColorFactor = 209;\nconst SrcAlphaSaturateFactor = 210;\nconst ConstantColorFactor = 211;\nconst OneMinusConstantColorFactor = 212;\nconst ConstantAlphaFactor = 213;\nconst OneMinusConstantAlphaFactor = 214;\nconst NeverDepth = 0;\nconst AlwaysDepth = 1;\nconst LessDepth = 2;\nconst LessEqualDepth = 3;\nconst EqualDepth = 4;\nconst GreaterEqualDepth = 5;\nconst GreaterDepth = 6;\nconst NotEqualDepth = 7;\nconst MultiplyOperation = 0;\nconst MixOperation = 1;\nconst AddOperation = 2;\nconst NoToneMapping = 0;\nconst LinearToneMapping = 1;\nconst ReinhardToneMapping = 2;\nconst CineonToneMapping = 3;\nconst ACESFilmicToneMapping = 4;\nconst CustomToneMapping = 5;\nconst AgXToneMapping = 6;\nconst NeutralToneMapping = 7;\nconst AttachedBindMode = 'attached';\nconst DetachedBindMode = 'detached';\nconst UVMapping = 300;\nconst CubeReflectionMapping = 301;\nconst CubeRefractionMapping = 302;\nconst EquirectangularReflectionMapping = 303;\nconst EquirectangularRefractionMapping = 304;\nconst CubeUVReflectionMapping = 306;\nconst RepeatWrapping = 1000;\nconst ClampToEdgeWrapping = 1001;\nconst MirroredRepeatWrapping = 1002;\nconst NearestFilter = 1003;\nconst NearestMipmapNearestFilter = 1004;\nconst NearestMipmapLinearFilter = 1005;\nconst LinearFilter = 1006;\nconst LinearMipmapNearestFilter = 1007;\nconst LinearMipmapLinearFilter = 1008;\nconst LinearMipMapLinearFilter = 1008;\nconst UnsignedByteType = 1009;\nconst ByteType = 1010;\nconst ShortType = 1011;\nconst UnsignedShortType = 1012;\nconst IntType = 1013;\nconst UnsignedIntType = 1014;\nconst FloatType = 1015;\nconst HalfFloatType = 1016;\nconst UnsignedShort4444Type = 1017;\nconst UnsignedShort5551Type = 1018;\nconst UnsignedInt248Type = 1020;\nconst UnsignedInt5999Type = 35902;\nconst AlphaFormat = 1021;\nconst RGBFormat = 1022;\nconst RGBAFormat = 1023;\nconst LuminanceFormat = 1024;\nconst LuminanceAlphaFormat = 1025;\nconst DepthFormat = 1026;\nconst DepthStencilFormat = 1027;\nconst RedFormat = 1028;\nconst RedIntegerFormat = 1029;\nconst RGFormat = 1030;\nconst RGIntegerFormat = 1031;\nconst RGBAIntegerFormat = 1033;\nconst RGB_S3TC_DXT1_Format = 33776;\nconst RGBA_S3TC_DXT1_Format = 33777;\nconst RGBA_S3TC_DXT3_Format = 33778;\nconst RGBA_S3TC_DXT5_Format = 33779;\nconst RGB_PVRTC_4BPPV1_Format = 35840;\nconst RGB_PVRTC_2BPPV1_Format = 35841;\nconst RGBA_PVRTC_4BPPV1_Format = 35842;\nconst RGBA_PVRTC_2BPPV1_Format = 35843;\nconst RGB_ETC1_Format = 36196;\nconst RGB_ETC2_Format = 37492;\nconst RGBA_ETC2_EAC_Format = 37496;\nconst RGBA_ASTC_4x4_Format = 37808;\nconst RGBA_ASTC_5x4_Format = 37809;\nconst RGBA_ASTC_5x5_Format = 37810;\nconst RGBA_ASTC_6x5_Format = 37811;\nconst RGBA_ASTC_6x6_Format = 37812;\nconst RGBA_ASTC_8x5_Format = 37813;\nconst RGBA_ASTC_8x6_Format = 37814;\nconst RGBA_ASTC_8x8_Format = 37815;\nconst RGBA_ASTC_10x5_Format = 37816;\nconst RGBA_ASTC_10x6_Format = 37817;\nconst RGBA_ASTC_10x8_Format = 37818;\nconst RGBA_ASTC_10x10_Format = 37819;\nconst RGBA_ASTC_12x10_Format = 37820;\nconst RGBA_ASTC_12x12_Format = 37821;\nconst RGBA_BPTC_Format = 36492;\nconst RGB_BPTC_SIGNED_Format = 36494;\nconst RGB_BPTC_UNSIGNED_Format = 36495;\nconst RED_RGTC1_Format = 36283;\nconst SIGNED_RED_RGTC1_Format = 36284;\nconst RED_GREEN_RGTC2_Format = 36285;\nconst SIGNED_RED_GREEN_RGTC2_Format = 36286;\nconst LoopOnce = 2200;\nconst LoopRepeat = 2201;\nconst LoopPingPong = 2202;\nconst InterpolateDiscrete = 2300;\nconst InterpolateLinear = 2301;\nconst InterpolateSmooth = 2302;\nconst ZeroCurvatureEnding = 2400;\nconst ZeroSlopeEnding = 2401;\nconst WrapAroundEnding = 2402;\nconst NormalAnimationBlendMode = 2500;\nconst AdditiveAnimationBlendMode = 2501;\nconst TrianglesDrawMode = 0;\nconst TriangleStripDrawMode = 1;\nconst TriangleFanDrawMode = 2;\nconst BasicDepthPacking = 3200;\nconst RGBADepthPacking = 3201;\nconst TangentSpaceNormalMap = 0;\nconst ObjectSpaceNormalMap = 1;\n\n// Color space string identifiers, matching CSS Color Module Level 4 and WebGPU names where available.\nconst NoColorSpace = '';\nconst SRGBColorSpace = 'srgb';\nconst LinearSRGBColorSpace = 'srgb-linear';\nconst DisplayP3ColorSpace = 'display-p3';\nconst LinearDisplayP3ColorSpace = 'display-p3-linear';\nconst LinearTransfer = 'linear';\nconst SRGBTransfer = 'srgb';\nconst Rec709Primaries = 'rec709';\nconst P3Primaries = 'p3';\nconst KeepStencilOp = 7680;\nconst AlwaysStencilFunc = 519;\nconst NeverCompare = 512;\nconst LessCompare = 513;\nconst EqualCompare = 514;\nconst LessEqualCompare = 515;\nconst GreaterCompare = 516;\nconst NotEqualCompare = 517;\nconst GreaterEqualCompare = 518;\nconst AlwaysCompare = 519;\nconst StaticDrawUsage = 35044;\nconst GLSL3 = '300 es';\nconst WebGLCoordinateSystem = 2000;\nconst WebGPUCoordinateSystem = 2001;\n\n/**\n * https://github.com/mrdoob/eventdispatcher.js/\n */\n\nclass EventDispatcher {\n  addEventListener(type, listener) {\n    if (this._listeners === undefined) this._listeners = {};\n    const listeners = this._listeners;\n    if (listeners[type] === undefined) {\n      listeners[type] = [];\n    }\n    if (listeners[type].indexOf(listener) === -1) {\n      listeners[type].push(listener);\n    }\n  }\n  hasEventListener(type, listener) {\n    if (this._listeners === undefined) return false;\n    const listeners = this._listeners;\n    return listeners[type] !== undefined && listeners[type].indexOf(listener) !== -1;\n  }\n  removeEventListener(type, listener) {\n    if (this._listeners === undefined) return;\n    const listeners = this._listeners;\n    const listenerArray = listeners[type];\n    if (listenerArray !== undefined) {\n      const index = listenerArray.indexOf(listener);\n      if (index !== -1) {\n        listenerArray.splice(index, 1);\n      }\n    }\n  }\n  dispatchEvent(event) {\n    if (this._listeners === undefined) return;\n    const listeners = this._listeners;\n    const listenerArray = listeners[event.type];\n    if (listenerArray !== undefined) {\n      event.target = this;\n\n      // Make a copy, in case listeners are removed while iterating.\n      const array = listenerArray.slice(0);\n      for (let i = 0, l = array.length; i < l; i++) {\n        array[i].call(this, event);\n      }\n      event.target = null;\n    }\n  }\n}\nconst _lut = ['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '0a', '0b', '0c', '0d', '0e', '0f', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '1a', '1b', '1c', '1d', '1e', '1f', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '2a', '2b', '2c', '2d', '2e', '2f', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '3a', '3b', '3c', '3d', '3e', '3f', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '4a', '4b', '4c', '4d', '4e', '4f', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '5a', '5b', '5c', '5d', '5e', '5f', '60', '61', '62', '63', '64', '65', '66', '67', '68', '69', '6a', '6b', '6c', '6d', '6e', '6f', '70', '71', '72', '73', '74', '75', '76', '77', '78', '79', '7a', '7b', '7c', '7d', '7e', '7f', '80', '81', '82', '83', '84', '85', '86', '87', '88', '89', '8a', '8b', '8c', '8d', '8e', '8f', '90', '91', '92', '93', '94', '95', '96', '97', '98', '99', '9a', '9b', '9c', '9d', '9e', '9f', 'a0', 'a1', 'a2', 'a3', 'a4', 'a5', 'a6', 'a7', 'a8', 'a9', 'aa', 'ab', 'ac', 'ad', 'ae', 'af', 'b0', 'b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9', 'ba', 'bb', 'bc', 'bd', 'be', 'bf', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'ca', 'cb', 'cc', 'cd', 'ce', 'cf', 'd0', 'd1', 'd2', 'd3', 'd4', 'd5', 'd6', 'd7', 'd8', 'd9', 'da', 'db', 'dc', 'dd', 'de', 'df', 'e0', 'e1', 'e2', 'e3', 'e4', 'e5', 'e6', 'e7', 'e8', 'e9', 'ea', 'eb', 'ec', 'ed', 'ee', 'ef', 'f0', 'f1', 'f2', 'f3', 'f4', 'f5', 'f6', 'f7', 'f8', 'f9', 'fa', 'fb', 'fc', 'fd', 'fe', 'ff'];\nlet _seed = 1234567;\nconst DEG2RAD = Math.PI / 180;\nconst RAD2DEG = 180 / Math.PI;\n\n// http://stackoverflow.com/questions/105034/how-to-create-a-guid-uuid-in-javascript/21963136#21963136\nfunction generateUUID() {\n  const d0 = Math.random() * 0xffffffff | 0;\n  const d1 = Math.random() * 0xffffffff | 0;\n  const d2 = Math.random() * 0xffffffff | 0;\n  const d3 = Math.random() * 0xffffffff | 0;\n  const uuid = _lut[d0 & 0xff] + _lut[d0 >> 8 & 0xff] + _lut[d0 >> 16 & 0xff] + _lut[d0 >> 24 & 0xff] + '-' + _lut[d1 & 0xff] + _lut[d1 >> 8 & 0xff] + '-' + _lut[d1 >> 16 & 0x0f | 0x40] + _lut[d1 >> 24 & 0xff] + '-' + _lut[d2 & 0x3f | 0x80] + _lut[d2 >> 8 & 0xff] + '-' + _lut[d2 >> 16 & 0xff] + _lut[d2 >> 24 & 0xff] + _lut[d3 & 0xff] + _lut[d3 >> 8 & 0xff] + _lut[d3 >> 16 & 0xff] + _lut[d3 >> 24 & 0xff];\n\n  // .toLowerCase() here flattens concatenated strings to save heap memory space.\n  return uuid.toLowerCase();\n}\nfunction clamp$1(value, min, max) {\n  return Math.max(min, Math.min(max, value));\n}\n\n// compute euclidean modulo of m % n\n// https://en.wikipedia.org/wiki/Modulo_operation\nfunction euclideanModulo(n, m) {\n  return (n % m + m) % m;\n}\n\n// Linear mapping from range <a1, a2> to range <b1, b2>\nfunction mapLinear(x, a1, a2, b1, b2) {\n  return b1 + (x - a1) * (b2 - b1) / (a2 - a1);\n}\n\n// https://www.gamedev.net/tutorials/programming/general-and-gameplay-programming/inverse-lerp-a-super-useful-yet-often-overlooked-function-r5230/\nfunction inverseLerp(x, y, value) {\n  if (x !== y) {\n    return (value - x) / (y - x);\n  } else {\n    return 0;\n  }\n}\n\n// https://en.wikipedia.org/wiki/Linear_interpolation\nfunction lerp$1(x, y, t) {\n  return (1 - t) * x + t * y;\n}\n\n// http://www.rorydriscoll.com/2016/03/07/frame-rate-independent-damping-using-lerp/\nfunction damp(x, y, lambda, dt) {\n  return lerp$1(x, y, 1 - Math.exp(-lambda * dt));\n}\n\n// https://www.desmos.com/calculator/vcsjnyz7x4\nfunction pingpong(x, length = 1) {\n  return length - Math.abs(euclideanModulo(x, length * 2) - length);\n}\n\n// http://en.wikipedia.org/wiki/Smoothstep\nfunction smoothstep(x, min, max) {\n  if (x <= min) return 0;\n  if (x >= max) return 1;\n  x = (x - min) / (max - min);\n  return x * x * (3 - 2 * x);\n}\nfunction smootherstep(x, min, max) {\n  if (x <= min) return 0;\n  if (x >= max) return 1;\n  x = (x - min) / (max - min);\n  return x * x * x * (x * (x * 6 - 15) + 10);\n}\n\n// Random integer from <low, high> interval\nfunction randInt(low, high) {\n  return low + Math.floor(Math.random() * (high - low + 1));\n}\n\n// Random float from <low, high> interval\nfunction randFloat(low, high) {\n  return low + Math.random() * (high - low);\n}\n\n// Random float from <-range/2, range/2> interval\nfunction randFloatSpread(range) {\n  return range * (0.5 - Math.random());\n}\n\n// Deterministic pseudo-random float in the interval [ 0, 1 ]\nfunction seededRandom(s) {\n  if (s !== undefined) _seed = s;\n\n  // Mulberry32 generator\n\n  let t = _seed += 0x6D2B79F5;\n  t = Math.imul(t ^ t >>> 15, t | 1);\n  t ^= t + Math.imul(t ^ t >>> 7, t | 61);\n  return ((t ^ t >>> 14) >>> 0) / 4294967296;\n}\nfunction degToRad(degrees) {\n  return degrees * DEG2RAD;\n}\nfunction radToDeg(radians) {\n  return radians * RAD2DEG;\n}\nfunction isPowerOfTwo(value) {\n  return (value & value - 1) === 0 && value !== 0;\n}\nfunction ceilPowerOfTwo(value) {\n  return Math.pow(2, Math.ceil(Math.log(value) / Math.LN2));\n}\nfunction floorPowerOfTwo(value) {\n  return Math.pow(2, Math.floor(Math.log(value) / Math.LN2));\n}\nfunction setQuaternionFromProperEuler(q, a, b, c, order) {\n  // Intrinsic Proper Euler Angles - see https://en.wikipedia.org/wiki/Euler_angles\n\n  // rotations are applied to the axes in the order specified by 'order'\n  // rotation by angle 'a' is applied first, then by angle 'b', then by angle 'c'\n  // angles are in radians\n\n  const cos = Math.cos;\n  const sin = Math.sin;\n  const c2 = cos(b / 2);\n  const s2 = sin(b / 2);\n  const c13 = cos((a + c) / 2);\n  const s13 = sin((a + c) / 2);\n  const c1_3 = cos((a - c) / 2);\n  const s1_3 = sin((a - c) / 2);\n  const c3_1 = cos((c - a) / 2);\n  const s3_1 = sin((c - a) / 2);\n  switch (order) {\n    case 'XYX':\n      q.set(c2 * s13, s2 * c1_3, s2 * s1_3, c2 * c13);\n      break;\n    case 'YZY':\n      q.set(s2 * s1_3, c2 * s13, s2 * c1_3, c2 * c13);\n      break;\n    case 'ZXZ':\n      q.set(s2 * c1_3, s2 * s1_3, c2 * s13, c2 * c13);\n      break;\n    case 'XZX':\n      q.set(c2 * s13, s2 * s3_1, s2 * c3_1, c2 * c13);\n      break;\n    case 'YXY':\n      q.set(s2 * c3_1, c2 * s13, s2 * s3_1, c2 * c13);\n      break;\n    case 'ZYZ':\n      q.set(s2 * s3_1, s2 * c3_1, c2 * s13, c2 * c13);\n      break;\n    default:\n      console.warn('THREE.MathUtils: .setQuaternionFromProperEuler() encountered an unknown order: ' + order);\n  }\n}\nfunction denormalize(value, array) {\n  switch (array.constructor) {\n    case Float32Array:\n      return value;\n    case Uint32Array:\n      return value / 4294967295.0;\n    case Uint16Array:\n      return value / 65535.0;\n    case Uint8Array:\n      return value / 255.0;\n    case Int32Array:\n      return Math.max(value / 2147483647.0, -1.0);\n    case Int16Array:\n      return Math.max(value / 32767.0, -1.0);\n    case Int8Array:\n      return Math.max(value / 127.0, -1.0);\n    default:\n      throw new Error('Invalid component type.');\n  }\n}\nfunction normalize(value, array) {\n  switch (array.constructor) {\n    case Float32Array:\n      return value;\n    case Uint32Array:\n      return Math.round(value * 4294967295.0);\n    case Uint16Array:\n      return Math.round(value * 65535.0);\n    case Uint8Array:\n      return Math.round(value * 255.0);\n    case Int32Array:\n      return Math.round(value * 2147483647.0);\n    case Int16Array:\n      return Math.round(value * 32767.0);\n    case Int8Array:\n      return Math.round(value * 127.0);\n    default:\n      throw new Error('Invalid component type.');\n  }\n}\nconst MathUtils = {\n  DEG2RAD: DEG2RAD,\n  RAD2DEG: RAD2DEG,\n  generateUUID: generateUUID,\n  clamp: clamp$1,\n  euclideanModulo: euclideanModulo,\n  mapLinear: mapLinear,\n  inverseLerp: inverseLerp,\n  lerp: lerp$1,\n  damp: damp,\n  pingpong: pingpong,\n  smoothstep: smoothstep,\n  smootherstep: smootherstep,\n  randInt: randInt,\n  randFloat: randFloat,\n  randFloatSpread: randFloatSpread,\n  seededRandom: seededRandom,\n  degToRad: degToRad,\n  radToDeg: radToDeg,\n  isPowerOfTwo: isPowerOfTwo,\n  ceilPowerOfTwo: ceilPowerOfTwo,\n  floorPowerOfTwo: floorPowerOfTwo,\n  setQuaternionFromProperEuler: setQuaternionFromProperEuler,\n  normalize: normalize,\n  denormalize: denormalize\n};\nclass Vector2 {\n  constructor(x = 0, y = 0) {\n    Vector2.prototype.isVector2 = true;\n    this.x = x;\n    this.y = y;\n  }\n  get width() {\n    return this.x;\n  }\n  set width(value) {\n    this.x = value;\n  }\n  get height() {\n    return this.y;\n  }\n  set height(value) {\n    this.y = value;\n  }\n  set(x, y) {\n    this.x = x;\n    this.y = y;\n    return this;\n  }\n  setScalar(scalar) {\n    this.x = scalar;\n    this.y = scalar;\n    return this;\n  }\n  setX(x) {\n    this.x = x;\n    return this;\n  }\n  setY(y) {\n    this.y = y;\n    return this;\n  }\n  setComponent(index, value) {\n    switch (index) {\n      case 0:\n        this.x = value;\n        break;\n      case 1:\n        this.y = value;\n        break;\n      default:\n        throw new Error('index is out of range: ' + index);\n    }\n    return this;\n  }\n  getComponent(index) {\n    switch (index) {\n      case 0:\n        return this.x;\n      case 1:\n        return this.y;\n      default:\n        throw new Error('index is out of range: ' + index);\n    }\n  }\n  clone() {\n    return new this.constructor(this.x, this.y);\n  }\n  copy(v) {\n    this.x = v.x;\n    this.y = v.y;\n    return this;\n  }\n  add(v) {\n    this.x += v.x;\n    this.y += v.y;\n    return this;\n  }\n  addScalar(s) {\n    this.x += s;\n    this.y += s;\n    return this;\n  }\n  addVectors(a, b) {\n    this.x = a.x + b.x;\n    this.y = a.y + b.y;\n    return this;\n  }\n  addScaledVector(v, s) {\n    this.x += v.x * s;\n    this.y += v.y * s;\n    return this;\n  }\n  sub(v) {\n    this.x -= v.x;\n    this.y -= v.y;\n    return this;\n  }\n  subScalar(s) {\n    this.x -= s;\n    this.y -= s;\n    return this;\n  }\n  subVectors(a, b) {\n    this.x = a.x - b.x;\n    this.y = a.y - b.y;\n    return this;\n  }\n  multiply(v) {\n    this.x *= v.x;\n    this.y *= v.y;\n    return this;\n  }\n  multiplyScalar(scalar) {\n    this.x *= scalar;\n    this.y *= scalar;\n    return this;\n  }\n  divide(v) {\n    this.x /= v.x;\n    this.y /= v.y;\n    return this;\n  }\n  divideScalar(scalar) {\n    return this.multiplyScalar(1 / scalar);\n  }\n  applyMatrix3(m) {\n    const x = this.x,\n      y = this.y;\n    const e = m.elements;\n    this.x = e[0] * x + e[3] * y + e[6];\n    this.y = e[1] * x + e[4] * y + e[7];\n    return this;\n  }\n  min(v) {\n    this.x = Math.min(this.x, v.x);\n    this.y = Math.min(this.y, v.y);\n    return this;\n  }\n  max(v) {\n    this.x = Math.max(this.x, v.x);\n    this.y = Math.max(this.y, v.y);\n    return this;\n  }\n  clamp(min, max) {\n    // assumes min < max, componentwise\n\n    this.x = Math.max(min.x, Math.min(max.x, this.x));\n    this.y = Math.max(min.y, Math.min(max.y, this.y));\n    return this;\n  }\n  clampScalar(minVal, maxVal) {\n    this.x = Math.max(minVal, Math.min(maxVal, this.x));\n    this.y = Math.max(minVal, Math.min(maxVal, this.y));\n    return this;\n  }\n  clampLength(min, max) {\n    const length = this.length();\n    return this.divideScalar(length || 1).multiplyScalar(Math.max(min, Math.min(max, length)));\n  }\n  floor() {\n    this.x = Math.floor(this.x);\n    this.y = Math.floor(this.y);\n    return this;\n  }\n  ceil() {\n    this.x = Math.ceil(this.x);\n    this.y = Math.ceil(this.y);\n    return this;\n  }\n  round() {\n    this.x = Math.round(this.x);\n    this.y = Math.round(this.y);\n    return this;\n  }\n  roundToZero() {\n    this.x = Math.trunc(this.x);\n    this.y = Math.trunc(this.y);\n    return this;\n  }\n  negate() {\n    this.x = -this.x;\n    this.y = -this.y;\n    return this;\n  }\n  dot(v) {\n    return this.x * v.x + this.y * v.y;\n  }\n  cross(v) {\n    return this.x * v.y - this.y * v.x;\n  }\n  lengthSq() {\n    return this.x * this.x + this.y * this.y;\n  }\n  length() {\n    return Math.sqrt(this.x * this.x + this.y * this.y);\n  }\n  manhattanLength() {\n    return Math.abs(this.x) + Math.abs(this.y);\n  }\n  normalize() {\n    return this.divideScalar(this.length() || 1);\n  }\n  angle() {\n    // computes the angle in radians with respect to the positive x-axis\n\n    const angle = Math.atan2(-this.y, -this.x) + Math.PI;\n    return angle;\n  }\n  angleTo(v) {\n    const denominator = Math.sqrt(this.lengthSq() * v.lengthSq());\n    if (denominator === 0) return Math.PI / 2;\n    const theta = this.dot(v) / denominator;\n\n    // clamp, to handle numerical problems\n\n    return Math.acos(clamp$1(theta, -1, 1));\n  }\n  distanceTo(v) {\n    return Math.sqrt(this.distanceToSquared(v));\n  }\n  distanceToSquared(v) {\n    const dx = this.x - v.x,\n      dy = this.y - v.y;\n    return dx * dx + dy * dy;\n  }\n  manhattanDistanceTo(v) {\n    return Math.abs(this.x - v.x) + Math.abs(this.y - v.y);\n  }\n  setLength(length) {\n    return this.normalize().multiplyScalar(length);\n  }\n  lerp(v, alpha) {\n    this.x += (v.x - this.x) * alpha;\n    this.y += (v.y - this.y) * alpha;\n    return this;\n  }\n  lerpVectors(v1, v2, alpha) {\n    this.x = v1.x + (v2.x - v1.x) * alpha;\n    this.y = v1.y + (v2.y - v1.y) * alpha;\n    return this;\n  }\n  equals(v) {\n    return v.x === this.x && v.y === this.y;\n  }\n  fromArray(array, offset = 0) {\n    this.x = array[offset];\n    this.y = array[offset + 1];\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    array[offset] = this.x;\n    array[offset + 1] = this.y;\n    return array;\n  }\n  fromBufferAttribute(attribute, index) {\n    this.x = attribute.getX(index);\n    this.y = attribute.getY(index);\n    return this;\n  }\n  rotateAround(center, angle) {\n    const c = Math.cos(angle),\n      s = Math.sin(angle);\n    const x = this.x - center.x;\n    const y = this.y - center.y;\n    this.x = x * c - y * s + center.x;\n    this.y = x * s + y * c + center.y;\n    return this;\n  }\n  random() {\n    this.x = Math.random();\n    this.y = Math.random();\n    return this;\n  }\n  *[Symbol.iterator]() {\n    yield this.x;\n    yield this.y;\n  }\n}\nclass Matrix3 {\n  constructor(n11, n12, n13, n21, n22, n23, n31, n32, n33) {\n    Matrix3.prototype.isMatrix3 = true;\n    this.elements = [1, 0, 0, 0, 1, 0, 0, 0, 1];\n    if (n11 !== undefined) {\n      this.set(n11, n12, n13, n21, n22, n23, n31, n32, n33);\n    }\n  }\n  set(n11, n12, n13, n21, n22, n23, n31, n32, n33) {\n    const te = this.elements;\n    te[0] = n11;\n    te[1] = n21;\n    te[2] = n31;\n    te[3] = n12;\n    te[4] = n22;\n    te[5] = n32;\n    te[6] = n13;\n    te[7] = n23;\n    te[8] = n33;\n    return this;\n  }\n  identity() {\n    this.set(1, 0, 0, 0, 1, 0, 0, 0, 1);\n    return this;\n  }\n  copy(m) {\n    const te = this.elements;\n    const me = m.elements;\n    te[0] = me[0];\n    te[1] = me[1];\n    te[2] = me[2];\n    te[3] = me[3];\n    te[4] = me[4];\n    te[5] = me[5];\n    te[6] = me[6];\n    te[7] = me[7];\n    te[8] = me[8];\n    return this;\n  }\n  extractBasis(xAxis, yAxis, zAxis) {\n    xAxis.setFromMatrix3Column(this, 0);\n    yAxis.setFromMatrix3Column(this, 1);\n    zAxis.setFromMatrix3Column(this, 2);\n    return this;\n  }\n  setFromMatrix4(m) {\n    const me = m.elements;\n    this.set(me[0], me[4], me[8], me[1], me[5], me[9], me[2], me[6], me[10]);\n    return this;\n  }\n  multiply(m) {\n    return this.multiplyMatrices(this, m);\n  }\n  premultiply(m) {\n    return this.multiplyMatrices(m, this);\n  }\n  multiplyMatrices(a, b) {\n    const ae = a.elements;\n    const be = b.elements;\n    const te = this.elements;\n    const a11 = ae[0],\n      a12 = ae[3],\n      a13 = ae[6];\n    const a21 = ae[1],\n      a22 = ae[4],\n      a23 = ae[7];\n    const a31 = ae[2],\n      a32 = ae[5],\n      a33 = ae[8];\n    const b11 = be[0],\n      b12 = be[3],\n      b13 = be[6];\n    const b21 = be[1],\n      b22 = be[4],\n      b23 = be[7];\n    const b31 = be[2],\n      b32 = be[5],\n      b33 = be[8];\n    te[0] = a11 * b11 + a12 * b21 + a13 * b31;\n    te[3] = a11 * b12 + a12 * b22 + a13 * b32;\n    te[6] = a11 * b13 + a12 * b23 + a13 * b33;\n    te[1] = a21 * b11 + a22 * b21 + a23 * b31;\n    te[4] = a21 * b12 + a22 * b22 + a23 * b32;\n    te[7] = a21 * b13 + a22 * b23 + a23 * b33;\n    te[2] = a31 * b11 + a32 * b21 + a33 * b31;\n    te[5] = a31 * b12 + a32 * b22 + a33 * b32;\n    te[8] = a31 * b13 + a32 * b23 + a33 * b33;\n    return this;\n  }\n  multiplyScalar(s) {\n    const te = this.elements;\n    te[0] *= s;\n    te[3] *= s;\n    te[6] *= s;\n    te[1] *= s;\n    te[4] *= s;\n    te[7] *= s;\n    te[2] *= s;\n    te[5] *= s;\n    te[8] *= s;\n    return this;\n  }\n  determinant() {\n    const te = this.elements;\n    const a = te[0],\n      b = te[1],\n      c = te[2],\n      d = te[3],\n      e = te[4],\n      f = te[5],\n      g = te[6],\n      h = te[7],\n      i = te[8];\n    return a * e * i - a * f * h - b * d * i + b * f * g + c * d * h - c * e * g;\n  }\n  invert() {\n    const te = this.elements,\n      n11 = te[0],\n      n21 = te[1],\n      n31 = te[2],\n      n12 = te[3],\n      n22 = te[4],\n      n32 = te[5],\n      n13 = te[6],\n      n23 = te[7],\n      n33 = te[8],\n      t11 = n33 * n22 - n32 * n23,\n      t12 = n32 * n13 - n33 * n12,\n      t13 = n23 * n12 - n22 * n13,\n      det = n11 * t11 + n21 * t12 + n31 * t13;\n    if (det === 0) return this.set(0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const detInv = 1 / det;\n    te[0] = t11 * detInv;\n    te[1] = (n31 * n23 - n33 * n21) * detInv;\n    te[2] = (n32 * n21 - n31 * n22) * detInv;\n    te[3] = t12 * detInv;\n    te[4] = (n33 * n11 - n31 * n13) * detInv;\n    te[5] = (n31 * n12 - n32 * n11) * detInv;\n    te[6] = t13 * detInv;\n    te[7] = (n21 * n13 - n23 * n11) * detInv;\n    te[8] = (n22 * n11 - n21 * n12) * detInv;\n    return this;\n  }\n  transpose() {\n    let tmp;\n    const m = this.elements;\n    tmp = m[1];\n    m[1] = m[3];\n    m[3] = tmp;\n    tmp = m[2];\n    m[2] = m[6];\n    m[6] = tmp;\n    tmp = m[5];\n    m[5] = m[7];\n    m[7] = tmp;\n    return this;\n  }\n  getNormalMatrix(matrix4) {\n    return this.setFromMatrix4(matrix4).invert().transpose();\n  }\n  transposeIntoArray(r) {\n    const m = this.elements;\n    r[0] = m[0];\n    r[1] = m[3];\n    r[2] = m[6];\n    r[3] = m[1];\n    r[4] = m[4];\n    r[5] = m[7];\n    r[6] = m[2];\n    r[7] = m[5];\n    r[8] = m[8];\n    return this;\n  }\n  setUvTransform(tx, ty, sx, sy, rotation, cx, cy) {\n    const c = Math.cos(rotation);\n    const s = Math.sin(rotation);\n    this.set(sx * c, sx * s, -sx * (c * cx + s * cy) + cx + tx, -sy * s, sy * c, -sy * (-s * cx + c * cy) + cy + ty, 0, 0, 1);\n    return this;\n  }\n\n  //\n\n  scale(sx, sy) {\n    this.premultiply(_m3.makeScale(sx, sy));\n    return this;\n  }\n  rotate(theta) {\n    this.premultiply(_m3.makeRotation(-theta));\n    return this;\n  }\n  translate(tx, ty) {\n    this.premultiply(_m3.makeTranslation(tx, ty));\n    return this;\n  }\n\n  // for 2D Transforms\n\n  makeTranslation(x, y) {\n    if (x.isVector2) {\n      this.set(1, 0, x.x, 0, 1, x.y, 0, 0, 1);\n    } else {\n      this.set(1, 0, x, 0, 1, y, 0, 0, 1);\n    }\n    return this;\n  }\n  makeRotation(theta) {\n    // counterclockwise\n\n    const c = Math.cos(theta);\n    const s = Math.sin(theta);\n    this.set(c, -s, 0, s, c, 0, 0, 0, 1);\n    return this;\n  }\n  makeScale(x, y) {\n    this.set(x, 0, 0, 0, y, 0, 0, 0, 1);\n    return this;\n  }\n\n  //\n\n  equals(matrix) {\n    const te = this.elements;\n    const me = matrix.elements;\n    for (let i = 0; i < 9; i++) {\n      if (te[i] !== me[i]) return false;\n    }\n    return true;\n  }\n  fromArray(array, offset = 0) {\n    for (let i = 0; i < 9; i++) {\n      this.elements[i] = array[i + offset];\n    }\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    const te = this.elements;\n    array[offset] = te[0];\n    array[offset + 1] = te[1];\n    array[offset + 2] = te[2];\n    array[offset + 3] = te[3];\n    array[offset + 4] = te[4];\n    array[offset + 5] = te[5];\n    array[offset + 6] = te[6];\n    array[offset + 7] = te[7];\n    array[offset + 8] = te[8];\n    return array;\n  }\n  clone() {\n    return new this.constructor().fromArray(this.elements);\n  }\n}\nconst _m3 = /*@__PURE__*/new Matrix3();\nfunction arrayNeedsUint32(array) {\n  // assumes larger values usually on last\n\n  for (let i = array.length - 1; i >= 0; --i) {\n    if (array[i] >= 65535) return true; // account for PRIMITIVE_RESTART_FIXED_INDEX, #24565\n  }\n  return false;\n}\nfunction createElementNS(name) {\n  return document.createElementNS('http://www.w3.org/1999/xhtml', name);\n}\nfunction createCanvasElement() {\n  const canvas = createElementNS('canvas');\n  canvas.style.display = 'block';\n  return canvas;\n}\nconst _cache = {};\nfunction warnOnce(message) {\n  if (message in _cache) return;\n  _cache[message] = true;\n  console.warn(message);\n}\nfunction probeAsync(gl, sync, interval) {\n  return new Promise(function (resolve, reject) {\n    function probe() {\n      switch (gl.clientWaitSync(sync, gl.SYNC_FLUSH_COMMANDS_BIT, 0)) {\n        case gl.WAIT_FAILED:\n          reject();\n          break;\n        case gl.TIMEOUT_EXPIRED:\n          setTimeout(probe, interval);\n          break;\n        default:\n          resolve();\n      }\n    }\n    setTimeout(probe, interval);\n  });\n}\nfunction toNormalizedProjectionMatrix(projectionMatrix) {\n  const m = projectionMatrix.elements;\n\n  // Convert [-1, 1] to [0, 1] projection matrix\n  m[2] = 0.5 * m[2] + 0.5 * m[3];\n  m[6] = 0.5 * m[6] + 0.5 * m[7];\n  m[10] = 0.5 * m[10] + 0.5 * m[11];\n  m[14] = 0.5 * m[14] + 0.5 * m[15];\n}\nfunction toReversedProjectionMatrix(projectionMatrix) {\n  const m = projectionMatrix.elements;\n  const isPerspectiveMatrix = m[11] === -1;\n\n  // Reverse [0, 1] projection matrix\n  if (isPerspectiveMatrix) {\n    m[10] = -m[10] - 1;\n    m[14] = -m[14];\n  } else {\n    m[10] = -m[10];\n    m[14] = -m[14] + 1;\n  }\n}\n\n/**\n * Matrices converting P3 <-> Rec. 709 primaries, without gamut mapping\n * or clipping. Based on W3C specifications for sRGB and Display P3,\n * and ICC specifications for the D50 connection space. Values in/out\n * are _linear_ sRGB and _linear_ Display P3.\n *\n * Note that both sRGB and Display P3 use the sRGB transfer functions.\n *\n * Reference:\n * - http://www.russellcottrell.com/photo/matrixCalculator.htm\n */\n\nconst LINEAR_SRGB_TO_LINEAR_DISPLAY_P3 = /*@__PURE__*/new Matrix3().set(0.8224621, 0.177538, 0.0, 0.0331941, 0.9668058, 0.0, 0.0170827, 0.0723974, 0.9105199);\nconst LINEAR_DISPLAY_P3_TO_LINEAR_SRGB = /*@__PURE__*/new Matrix3().set(1.2249401, -0.2249404, 0.0, -0.0420569, 1.0420571, 0.0, -0.0196376, -0.0786361, 1.0982735);\n\n/**\n * Defines supported color spaces by transfer function and primaries,\n * and provides conversions to/from the Linear-sRGB reference space.\n */\nconst COLOR_SPACES = {\n  [LinearSRGBColorSpace]: {\n    transfer: LinearTransfer,\n    primaries: Rec709Primaries,\n    luminanceCoefficients: [0.2126, 0.7152, 0.0722],\n    toReference: color => color,\n    fromReference: color => color\n  },\n  [SRGBColorSpace]: {\n    transfer: SRGBTransfer,\n    primaries: Rec709Primaries,\n    luminanceCoefficients: [0.2126, 0.7152, 0.0722],\n    toReference: color => color.convertSRGBToLinear(),\n    fromReference: color => color.convertLinearToSRGB()\n  },\n  [LinearDisplayP3ColorSpace]: {\n    transfer: LinearTransfer,\n    primaries: P3Primaries,\n    luminanceCoefficients: [0.2289, 0.6917, 0.0793],\n    toReference: color => color.applyMatrix3(LINEAR_DISPLAY_P3_TO_LINEAR_SRGB),\n    fromReference: color => color.applyMatrix3(LINEAR_SRGB_TO_LINEAR_DISPLAY_P3)\n  },\n  [DisplayP3ColorSpace]: {\n    transfer: SRGBTransfer,\n    primaries: P3Primaries,\n    luminanceCoefficients: [0.2289, 0.6917, 0.0793],\n    toReference: color => color.convertSRGBToLinear().applyMatrix3(LINEAR_DISPLAY_P3_TO_LINEAR_SRGB),\n    fromReference: color => color.applyMatrix3(LINEAR_SRGB_TO_LINEAR_DISPLAY_P3).convertLinearToSRGB()\n  }\n};\nconst SUPPORTED_WORKING_COLOR_SPACES = new Set([LinearSRGBColorSpace, LinearDisplayP3ColorSpace]);\nconst ColorManagement = {\n  enabled: true,\n  _workingColorSpace: LinearSRGBColorSpace,\n  get workingColorSpace() {\n    return this._workingColorSpace;\n  },\n  set workingColorSpace(colorSpace) {\n    if (!SUPPORTED_WORKING_COLOR_SPACES.has(colorSpace)) {\n      throw new Error(`Unsupported working color space, \"${colorSpace}\".`);\n    }\n    this._workingColorSpace = colorSpace;\n  },\n  convert: function (color, sourceColorSpace, targetColorSpace) {\n    if (this.enabled === false || sourceColorSpace === targetColorSpace || !sourceColorSpace || !targetColorSpace) {\n      return color;\n    }\n    const sourceToReference = COLOR_SPACES[sourceColorSpace].toReference;\n    const targetFromReference = COLOR_SPACES[targetColorSpace].fromReference;\n    return targetFromReference(sourceToReference(color));\n  },\n  fromWorkingColorSpace: function (color, targetColorSpace) {\n    return this.convert(color, this._workingColorSpace, targetColorSpace);\n  },\n  toWorkingColorSpace: function (color, sourceColorSpace) {\n    return this.convert(color, sourceColorSpace, this._workingColorSpace);\n  },\n  getPrimaries: function (colorSpace) {\n    return COLOR_SPACES[colorSpace].primaries;\n  },\n  getTransfer: function (colorSpace) {\n    if (colorSpace === NoColorSpace) return LinearTransfer;\n    return COLOR_SPACES[colorSpace].transfer;\n  },\n  getLuminanceCoefficients: function (target, colorSpace = this._workingColorSpace) {\n    return target.fromArray(COLOR_SPACES[colorSpace].luminanceCoefficients);\n  }\n};\nfunction SRGBToLinear(c) {\n  return c < 0.04045 ? c * 0.0773993808 : Math.pow(c * 0.9478672986 + 0.0521327014, 2.4);\n}\nfunction LinearToSRGB(c) {\n  return c < 0.0031308 ? c * 12.92 : 1.055 * Math.pow(c, 0.41666) - 0.055;\n}\nlet _canvas;\nclass ImageUtils {\n  static getDataURL(image) {\n    if (/^data:/i.test(image.src)) {\n      return image.src;\n    }\n    if (typeof HTMLCanvasElement === 'undefined') {\n      return image.src;\n    }\n    let canvas;\n    if (image instanceof HTMLCanvasElement) {\n      canvas = image;\n    } else {\n      if (_canvas === undefined) _canvas = createElementNS('canvas');\n      _canvas.width = image.width;\n      _canvas.height = image.height;\n      const context = _canvas.getContext('2d');\n      if (image instanceof ImageData) {\n        context.putImageData(image, 0, 0);\n      } else {\n        context.drawImage(image, 0, 0, image.width, image.height);\n      }\n      canvas = _canvas;\n    }\n    if (canvas.width > 2048 || canvas.height > 2048) {\n      console.warn('THREE.ImageUtils.getDataURL: Image converted to jpg for performance reasons', image);\n      return canvas.toDataURL('image/jpeg', 0.6);\n    } else {\n      return canvas.toDataURL('image/png');\n    }\n  }\n  static sRGBToLinear(image) {\n    if (typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement || typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap) {\n      const canvas = createElementNS('canvas');\n      canvas.width = image.width;\n      canvas.height = image.height;\n      const context = canvas.getContext('2d');\n      context.drawImage(image, 0, 0, image.width, image.height);\n      const imageData = context.getImageData(0, 0, image.width, image.height);\n      const data = imageData.data;\n      for (let i = 0; i < data.length; i++) {\n        data[i] = SRGBToLinear(data[i] / 255) * 255;\n      }\n      context.putImageData(imageData, 0, 0);\n      return canvas;\n    } else if (image.data) {\n      const data = image.data.slice(0);\n      for (let i = 0; i < data.length; i++) {\n        if (data instanceof Uint8Array || data instanceof Uint8ClampedArray) {\n          data[i] = Math.floor(SRGBToLinear(data[i] / 255) * 255);\n        } else {\n          // assuming float\n\n          data[i] = SRGBToLinear(data[i]);\n        }\n      }\n      return {\n        data: data,\n        width: image.width,\n        height: image.height\n      };\n    } else {\n      console.warn('THREE.ImageUtils.sRGBToLinear(): Unsupported image type. No color space conversion applied.');\n      return image;\n    }\n  }\n}\nlet _sourceId = 0;\nclass Source {\n  constructor(data = null) {\n    this.isSource = true;\n    Object.defineProperty(this, 'id', {\n      value: _sourceId++\n    });\n    this.uuid = generateUUID();\n    this.data = data;\n    this.dataReady = true;\n    this.version = 0;\n  }\n  set needsUpdate(value) {\n    if (value === true) this.version++;\n  }\n  toJSON(meta) {\n    const isRootObject = meta === undefined || typeof meta === 'string';\n    if (!isRootObject && meta.images[this.uuid] !== undefined) {\n      return meta.images[this.uuid];\n    }\n    const output = {\n      uuid: this.uuid,\n      url: ''\n    };\n    const data = this.data;\n    if (data !== null) {\n      let url;\n      if (Array.isArray(data)) {\n        // cube texture\n\n        url = [];\n        for (let i = 0, l = data.length; i < l; i++) {\n          if (data[i].isDataTexture) {\n            url.push(serializeImage(data[i].image));\n          } else {\n            url.push(serializeImage(data[i]));\n          }\n        }\n      } else {\n        // texture\n\n        url = serializeImage(data);\n      }\n      output.url = url;\n    }\n    if (!isRootObject) {\n      meta.images[this.uuid] = output;\n    }\n    return output;\n  }\n}\nfunction serializeImage(image) {\n  if (typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement || typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap) {\n    // default images\n\n    return ImageUtils.getDataURL(image);\n  } else {\n    if (image.data) {\n      // images of DataTexture\n\n      return {\n        data: Array.from(image.data),\n        width: image.width,\n        height: image.height,\n        type: image.data.constructor.name\n      };\n    } else {\n      console.warn('THREE.Texture: Unable to serialize Texture.');\n      return {};\n    }\n  }\n}\nlet _textureId = 0;\nclass Texture$1 extends EventDispatcher {\n  constructor(image = Texture$1.DEFAULT_IMAGE, mapping = Texture$1.DEFAULT_MAPPING, wrapS = ClampToEdgeWrapping, wrapT = ClampToEdgeWrapping, magFilter = LinearFilter, minFilter = LinearMipmapLinearFilter, format = RGBAFormat, type = UnsignedByteType, anisotropy = Texture$1.DEFAULT_ANISOTROPY, colorSpace = NoColorSpace) {\n    super();\n    this.isTexture = true;\n    Object.defineProperty(this, 'id', {\n      value: _textureId++\n    });\n    this.uuid = generateUUID();\n    this.name = '';\n    this.source = new Source(image);\n    this.mipmaps = [];\n    this.mapping = mapping;\n    this.channel = 0;\n    this.wrapS = wrapS;\n    this.wrapT = wrapT;\n    this.magFilter = magFilter;\n    this.minFilter = minFilter;\n    this.anisotropy = anisotropy;\n    this.format = format;\n    this.internalFormat = null;\n    this.type = type;\n    this.offset = new Vector2(0, 0);\n    this.repeat = new Vector2(1, 1);\n    this.center = new Vector2(0, 0);\n    this.rotation = 0;\n    this.matrixAutoUpdate = true;\n    this.matrix = new Matrix3();\n    this.generateMipmaps = true;\n    this.premultiplyAlpha = false;\n    this.flipY = true;\n    this.unpackAlignment = 4; // valid values: 1, 2, 4, 8 (see http://www.khronos.org/opengles/sdk/docs/man/xhtml/glPixelStorei.xml)\n\n    this.colorSpace = colorSpace;\n    this.userData = {};\n    this.version = 0;\n    this.onUpdate = null;\n    this.isRenderTargetTexture = false; // indicates whether a texture belongs to a render target or not\n    this.pmremVersion = 0; // indicates whether this texture should be processed by PMREMGenerator or not (only relevant for render target textures)\n  }\n  get image() {\n    return this.source.data;\n  }\n  set image(value = null) {\n    this.source.data = value;\n  }\n  updateMatrix() {\n    this.matrix.setUvTransform(this.offset.x, this.offset.y, this.repeat.x, this.repeat.y, this.rotation, this.center.x, this.center.y);\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  copy(source) {\n    this.name = source.name;\n    this.source = source.source;\n    this.mipmaps = source.mipmaps.slice(0);\n    this.mapping = source.mapping;\n    this.channel = source.channel;\n    this.wrapS = source.wrapS;\n    this.wrapT = source.wrapT;\n    this.magFilter = source.magFilter;\n    this.minFilter = source.minFilter;\n    this.anisotropy = source.anisotropy;\n    this.format = source.format;\n    this.internalFormat = source.internalFormat;\n    this.type = source.type;\n    this.offset.copy(source.offset);\n    this.repeat.copy(source.repeat);\n    this.center.copy(source.center);\n    this.rotation = source.rotation;\n    this.matrixAutoUpdate = source.matrixAutoUpdate;\n    this.matrix.copy(source.matrix);\n    this.generateMipmaps = source.generateMipmaps;\n    this.premultiplyAlpha = source.premultiplyAlpha;\n    this.flipY = source.flipY;\n    this.unpackAlignment = source.unpackAlignment;\n    this.colorSpace = source.colorSpace;\n    this.userData = JSON.parse(JSON.stringify(source.userData));\n    this.needsUpdate = true;\n    return this;\n  }\n  toJSON(meta) {\n    const isRootObject = meta === undefined || typeof meta === 'string';\n    if (!isRootObject && meta.textures[this.uuid] !== undefined) {\n      return meta.textures[this.uuid];\n    }\n    const output = {\n      metadata: {\n        version: 4.6,\n        type: 'Texture',\n        generator: 'Texture.toJSON'\n      },\n      uuid: this.uuid,\n      name: this.name,\n      image: this.source.toJSON(meta).uuid,\n      mapping: this.mapping,\n      channel: this.channel,\n      repeat: [this.repeat.x, this.repeat.y],\n      offset: [this.offset.x, this.offset.y],\n      center: [this.center.x, this.center.y],\n      rotation: this.rotation,\n      wrap: [this.wrapS, this.wrapT],\n      format: this.format,\n      internalFormat: this.internalFormat,\n      type: this.type,\n      colorSpace: this.colorSpace,\n      minFilter: this.minFilter,\n      magFilter: this.magFilter,\n      anisotropy: this.anisotropy,\n      flipY: this.flipY,\n      generateMipmaps: this.generateMipmaps,\n      premultiplyAlpha: this.premultiplyAlpha,\n      unpackAlignment: this.unpackAlignment\n    };\n    if (Object.keys(this.userData).length > 0) output.userData = this.userData;\n    if (!isRootObject) {\n      meta.textures[this.uuid] = output;\n    }\n    return output;\n  }\n  dispose() {\n    this.dispatchEvent({\n      type: 'dispose'\n    });\n  }\n  transformUv(uv) {\n    if (this.mapping !== UVMapping) return uv;\n    uv.applyMatrix3(this.matrix);\n    if (uv.x < 0 || uv.x > 1) {\n      switch (this.wrapS) {\n        case RepeatWrapping:\n          uv.x = uv.x - Math.floor(uv.x);\n          break;\n        case ClampToEdgeWrapping:\n          uv.x = uv.x < 0 ? 0 : 1;\n          break;\n        case MirroredRepeatWrapping:\n          if (Math.abs(Math.floor(uv.x) % 2) === 1) {\n            uv.x = Math.ceil(uv.x) - uv.x;\n          } else {\n            uv.x = uv.x - Math.floor(uv.x);\n          }\n          break;\n      }\n    }\n    if (uv.y < 0 || uv.y > 1) {\n      switch (this.wrapT) {\n        case RepeatWrapping:\n          uv.y = uv.y - Math.floor(uv.y);\n          break;\n        case ClampToEdgeWrapping:\n          uv.y = uv.y < 0 ? 0 : 1;\n          break;\n        case MirroredRepeatWrapping:\n          if (Math.abs(Math.floor(uv.y) % 2) === 1) {\n            uv.y = Math.ceil(uv.y) - uv.y;\n          } else {\n            uv.y = uv.y - Math.floor(uv.y);\n          }\n          break;\n      }\n    }\n    if (this.flipY) {\n      uv.y = 1 - uv.y;\n    }\n    return uv;\n  }\n  set needsUpdate(value) {\n    if (value === true) {\n      this.version++;\n      this.source.needsUpdate = true;\n    }\n  }\n  set needsPMREMUpdate(value) {\n    if (value === true) {\n      this.pmremVersion++;\n    }\n  }\n}\nTexture$1.DEFAULT_IMAGE = null;\nTexture$1.DEFAULT_MAPPING = UVMapping;\nTexture$1.DEFAULT_ANISOTROPY = 1;\nclass Vector4 {\n  constructor(x = 0, y = 0, z = 0, w = 1) {\n    Vector4.prototype.isVector4 = true;\n    this.x = x;\n    this.y = y;\n    this.z = z;\n    this.w = w;\n  }\n  get width() {\n    return this.z;\n  }\n  set width(value) {\n    this.z = value;\n  }\n  get height() {\n    return this.w;\n  }\n  set height(value) {\n    this.w = value;\n  }\n  set(x, y, z, w) {\n    this.x = x;\n    this.y = y;\n    this.z = z;\n    this.w = w;\n    return this;\n  }\n  setScalar(scalar) {\n    this.x = scalar;\n    this.y = scalar;\n    this.z = scalar;\n    this.w = scalar;\n    return this;\n  }\n  setX(x) {\n    this.x = x;\n    return this;\n  }\n  setY(y) {\n    this.y = y;\n    return this;\n  }\n  setZ(z) {\n    this.z = z;\n    return this;\n  }\n  setW(w) {\n    this.w = w;\n    return this;\n  }\n  setComponent(index, value) {\n    switch (index) {\n      case 0:\n        this.x = value;\n        break;\n      case 1:\n        this.y = value;\n        break;\n      case 2:\n        this.z = value;\n        break;\n      case 3:\n        this.w = value;\n        break;\n      default:\n        throw new Error('index is out of range: ' + index);\n    }\n    return this;\n  }\n  getComponent(index) {\n    switch (index) {\n      case 0:\n        return this.x;\n      case 1:\n        return this.y;\n      case 2:\n        return this.z;\n      case 3:\n        return this.w;\n      default:\n        throw new Error('index is out of range: ' + index);\n    }\n  }\n  clone() {\n    return new this.constructor(this.x, this.y, this.z, this.w);\n  }\n  copy(v) {\n    this.x = v.x;\n    this.y = v.y;\n    this.z = v.z;\n    this.w = v.w !== undefined ? v.w : 1;\n    return this;\n  }\n  add(v) {\n    this.x += v.x;\n    this.y += v.y;\n    this.z += v.z;\n    this.w += v.w;\n    return this;\n  }\n  addScalar(s) {\n    this.x += s;\n    this.y += s;\n    this.z += s;\n    this.w += s;\n    return this;\n  }\n  addVectors(a, b) {\n    this.x = a.x + b.x;\n    this.y = a.y + b.y;\n    this.z = a.z + b.z;\n    this.w = a.w + b.w;\n    return this;\n  }\n  addScaledVector(v, s) {\n    this.x += v.x * s;\n    this.y += v.y * s;\n    this.z += v.z * s;\n    this.w += v.w * s;\n    return this;\n  }\n  sub(v) {\n    this.x -= v.x;\n    this.y -= v.y;\n    this.z -= v.z;\n    this.w -= v.w;\n    return this;\n  }\n  subScalar(s) {\n    this.x -= s;\n    this.y -= s;\n    this.z -= s;\n    this.w -= s;\n    return this;\n  }\n  subVectors(a, b) {\n    this.x = a.x - b.x;\n    this.y = a.y - b.y;\n    this.z = a.z - b.z;\n    this.w = a.w - b.w;\n    return this;\n  }\n  multiply(v) {\n    this.x *= v.x;\n    this.y *= v.y;\n    this.z *= v.z;\n    this.w *= v.w;\n    return this;\n  }\n  multiplyScalar(scalar) {\n    this.x *= scalar;\n    this.y *= scalar;\n    this.z *= scalar;\n    this.w *= scalar;\n    return this;\n  }\n  applyMatrix4(m) {\n    const x = this.x,\n      y = this.y,\n      z = this.z,\n      w = this.w;\n    const e = m.elements;\n    this.x = e[0] * x + e[4] * y + e[8] * z + e[12] * w;\n    this.y = e[1] * x + e[5] * y + e[9] * z + e[13] * w;\n    this.z = e[2] * x + e[6] * y + e[10] * z + e[14] * w;\n    this.w = e[3] * x + e[7] * y + e[11] * z + e[15] * w;\n    return this;\n  }\n  divideScalar(scalar) {\n    return this.multiplyScalar(1 / scalar);\n  }\n  setAxisAngleFromQuaternion(q) {\n    // http://www.euclideanspace.com/maths/geometry/rotations/conversions/quaternionToAngle/index.htm\n\n    // q is assumed to be normalized\n\n    this.w = 2 * Math.acos(q.w);\n    const s = Math.sqrt(1 - q.w * q.w);\n    if (s < 0.0001) {\n      this.x = 1;\n      this.y = 0;\n      this.z = 0;\n    } else {\n      this.x = q.x / s;\n      this.y = q.y / s;\n      this.z = q.z / s;\n    }\n    return this;\n  }\n  setAxisAngleFromRotationMatrix(m) {\n    // http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToAngle/index.htm\n\n    // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n    let angle, x, y, z; // variables for result\n    const epsilon = 0.01,\n      // margin to allow for rounding errors\n      epsilon2 = 0.1,\n      // margin to distinguish between 0 and 180 degrees\n\n      te = m.elements,\n      m11 = te[0],\n      m12 = te[4],\n      m13 = te[8],\n      m21 = te[1],\n      m22 = te[5],\n      m23 = te[9],\n      m31 = te[2],\n      m32 = te[6],\n      m33 = te[10];\n    if (Math.abs(m12 - m21) < epsilon && Math.abs(m13 - m31) < epsilon && Math.abs(m23 - m32) < epsilon) {\n      // singularity found\n      // first check for identity matrix which must have +1 for all terms\n      // in leading diagonal and zero in other terms\n\n      if (Math.abs(m12 + m21) < epsilon2 && Math.abs(m13 + m31) < epsilon2 && Math.abs(m23 + m32) < epsilon2 && Math.abs(m11 + m22 + m33 - 3) < epsilon2) {\n        // this singularity is identity matrix so angle = 0\n\n        this.set(1, 0, 0, 0);\n        return this; // zero angle, arbitrary axis\n      }\n\n      // otherwise this singularity is angle = 180\n\n      angle = Math.PI;\n      const xx = (m11 + 1) / 2;\n      const yy = (m22 + 1) / 2;\n      const zz = (m33 + 1) / 2;\n      const xy = (m12 + m21) / 4;\n      const xz = (m13 + m31) / 4;\n      const yz = (m23 + m32) / 4;\n      if (xx > yy && xx > zz) {\n        // m11 is the largest diagonal term\n\n        if (xx < epsilon) {\n          x = 0;\n          y = 0.707106781;\n          z = 0.707106781;\n        } else {\n          x = Math.sqrt(xx);\n          y = xy / x;\n          z = xz / x;\n        }\n      } else if (yy > zz) {\n        // m22 is the largest diagonal term\n\n        if (yy < epsilon) {\n          x = 0.707106781;\n          y = 0;\n          z = 0.707106781;\n        } else {\n          y = Math.sqrt(yy);\n          x = xy / y;\n          z = yz / y;\n        }\n      } else {\n        // m33 is the largest diagonal term so base result on this\n\n        if (zz < epsilon) {\n          x = 0.707106781;\n          y = 0.707106781;\n          z = 0;\n        } else {\n          z = Math.sqrt(zz);\n          x = xz / z;\n          y = yz / z;\n        }\n      }\n      this.set(x, y, z, angle);\n      return this; // return 180 deg rotation\n    }\n\n    // as we have reached here there are no singularities so we can handle normally\n\n    let s = Math.sqrt((m32 - m23) * (m32 - m23) + (m13 - m31) * (m13 - m31) + (m21 - m12) * (m21 - m12)); // used to normalize\n\n    if (Math.abs(s) < 0.001) s = 1;\n\n    // prevent divide by zero, should not happen if matrix is orthogonal and should be\n    // caught by singularity test above, but I've left it in just in case\n\n    this.x = (m32 - m23) / s;\n    this.y = (m13 - m31) / s;\n    this.z = (m21 - m12) / s;\n    this.w = Math.acos((m11 + m22 + m33 - 1) / 2);\n    return this;\n  }\n  setFromMatrixPosition(m) {\n    const e = m.elements;\n    this.x = e[12];\n    this.y = e[13];\n    this.z = e[14];\n    this.w = e[15];\n    return this;\n  }\n  min(v) {\n    this.x = Math.min(this.x, v.x);\n    this.y = Math.min(this.y, v.y);\n    this.z = Math.min(this.z, v.z);\n    this.w = Math.min(this.w, v.w);\n    return this;\n  }\n  max(v) {\n    this.x = Math.max(this.x, v.x);\n    this.y = Math.max(this.y, v.y);\n    this.z = Math.max(this.z, v.z);\n    this.w = Math.max(this.w, v.w);\n    return this;\n  }\n  clamp(min, max) {\n    // assumes min < max, componentwise\n\n    this.x = Math.max(min.x, Math.min(max.x, this.x));\n    this.y = Math.max(min.y, Math.min(max.y, this.y));\n    this.z = Math.max(min.z, Math.min(max.z, this.z));\n    this.w = Math.max(min.w, Math.min(max.w, this.w));\n    return this;\n  }\n  clampScalar(minVal, maxVal) {\n    this.x = Math.max(minVal, Math.min(maxVal, this.x));\n    this.y = Math.max(minVal, Math.min(maxVal, this.y));\n    this.z = Math.max(minVal, Math.min(maxVal, this.z));\n    this.w = Math.max(minVal, Math.min(maxVal, this.w));\n    return this;\n  }\n  clampLength(min, max) {\n    const length = this.length();\n    return this.divideScalar(length || 1).multiplyScalar(Math.max(min, Math.min(max, length)));\n  }\n  floor() {\n    this.x = Math.floor(this.x);\n    this.y = Math.floor(this.y);\n    this.z = Math.floor(this.z);\n    this.w = Math.floor(this.w);\n    return this;\n  }\n  ceil() {\n    this.x = Math.ceil(this.x);\n    this.y = Math.ceil(this.y);\n    this.z = Math.ceil(this.z);\n    this.w = Math.ceil(this.w);\n    return this;\n  }\n  round() {\n    this.x = Math.round(this.x);\n    this.y = Math.round(this.y);\n    this.z = Math.round(this.z);\n    this.w = Math.round(this.w);\n    return this;\n  }\n  roundToZero() {\n    this.x = Math.trunc(this.x);\n    this.y = Math.trunc(this.y);\n    this.z = Math.trunc(this.z);\n    this.w = Math.trunc(this.w);\n    return this;\n  }\n  negate() {\n    this.x = -this.x;\n    this.y = -this.y;\n    this.z = -this.z;\n    this.w = -this.w;\n    return this;\n  }\n  dot(v) {\n    return this.x * v.x + this.y * v.y + this.z * v.z + this.w * v.w;\n  }\n  lengthSq() {\n    return this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w;\n  }\n  length() {\n    return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z + this.w * this.w);\n  }\n  manhattanLength() {\n    return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z) + Math.abs(this.w);\n  }\n  normalize() {\n    return this.divideScalar(this.length() || 1);\n  }\n  setLength(length) {\n    return this.normalize().multiplyScalar(length);\n  }\n  lerp(v, alpha) {\n    this.x += (v.x - this.x) * alpha;\n    this.y += (v.y - this.y) * alpha;\n    this.z += (v.z - this.z) * alpha;\n    this.w += (v.w - this.w) * alpha;\n    return this;\n  }\n  lerpVectors(v1, v2, alpha) {\n    this.x = v1.x + (v2.x - v1.x) * alpha;\n    this.y = v1.y + (v2.y - v1.y) * alpha;\n    this.z = v1.z + (v2.z - v1.z) * alpha;\n    this.w = v1.w + (v2.w - v1.w) * alpha;\n    return this;\n  }\n  equals(v) {\n    return v.x === this.x && v.y === this.y && v.z === this.z && v.w === this.w;\n  }\n  fromArray(array, offset = 0) {\n    this.x = array[offset];\n    this.y = array[offset + 1];\n    this.z = array[offset + 2];\n    this.w = array[offset + 3];\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    array[offset] = this.x;\n    array[offset + 1] = this.y;\n    array[offset + 2] = this.z;\n    array[offset + 3] = this.w;\n    return array;\n  }\n  fromBufferAttribute(attribute, index) {\n    this.x = attribute.getX(index);\n    this.y = attribute.getY(index);\n    this.z = attribute.getZ(index);\n    this.w = attribute.getW(index);\n    return this;\n  }\n  random() {\n    this.x = Math.random();\n    this.y = Math.random();\n    this.z = Math.random();\n    this.w = Math.random();\n    return this;\n  }\n  *[Symbol.iterator]() {\n    yield this.x;\n    yield this.y;\n    yield this.z;\n    yield this.w;\n  }\n}\n\n/*\n In options, we can specify:\n * Texture parameters for an auto-generated target texture\n * depthBuffer/stencilBuffer: Booleans to indicate if we should generate these buffers\n*/\nclass RenderTarget extends EventDispatcher {\n  constructor(width = 1, height = 1, options = {}) {\n    super();\n    this.isRenderTarget = true;\n    this.width = width;\n    this.height = height;\n    this.depth = 1;\n    this.scissor = new Vector4(0, 0, width, height);\n    this.scissorTest = false;\n    this.viewport = new Vector4(0, 0, width, height);\n    const image = {\n      width: width,\n      height: height,\n      depth: 1\n    };\n    options = Object.assign({\n      generateMipmaps: false,\n      internalFormat: null,\n      minFilter: LinearFilter,\n      depthBuffer: true,\n      stencilBuffer: false,\n      resolveDepthBuffer: true,\n      resolveStencilBuffer: true,\n      depthTexture: null,\n      samples: 0,\n      count: 1\n    }, options);\n    const texture = new Texture$1(image, options.mapping, options.wrapS, options.wrapT, options.magFilter, options.minFilter, options.format, options.type, options.anisotropy, options.colorSpace);\n    texture.flipY = false;\n    texture.generateMipmaps = options.generateMipmaps;\n    texture.internalFormat = options.internalFormat;\n    this.textures = [];\n    const count = options.count;\n    for (let i = 0; i < count; i++) {\n      this.textures[i] = texture.clone();\n      this.textures[i].isRenderTargetTexture = true;\n    }\n    this.depthBuffer = options.depthBuffer;\n    this.stencilBuffer = options.stencilBuffer;\n    this.resolveDepthBuffer = options.resolveDepthBuffer;\n    this.resolveStencilBuffer = options.resolveStencilBuffer;\n    this.depthTexture = options.depthTexture;\n    this.samples = options.samples;\n  }\n  get texture() {\n    return this.textures[0];\n  }\n  set texture(value) {\n    this.textures[0] = value;\n  }\n  setSize(width, height, depth = 1) {\n    if (this.width !== width || this.height !== height || this.depth !== depth) {\n      this.width = width;\n      this.height = height;\n      this.depth = depth;\n      for (let i = 0, il = this.textures.length; i < il; i++) {\n        this.textures[i].image.width = width;\n        this.textures[i].image.height = height;\n        this.textures[i].image.depth = depth;\n      }\n      this.dispose();\n    }\n    this.viewport.set(0, 0, width, height);\n    this.scissor.set(0, 0, width, height);\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  copy(source) {\n    this.width = source.width;\n    this.height = source.height;\n    this.depth = source.depth;\n    this.scissor.copy(source.scissor);\n    this.scissorTest = source.scissorTest;\n    this.viewport.copy(source.viewport);\n    this.textures.length = 0;\n    for (let i = 0, il = source.textures.length; i < il; i++) {\n      this.textures[i] = source.textures[i].clone();\n      this.textures[i].isRenderTargetTexture = true;\n    }\n\n    // ensure image object is not shared, see #20328\n\n    const image = Object.assign({}, source.texture.image);\n    this.texture.source = new Source(image);\n    this.depthBuffer = source.depthBuffer;\n    this.stencilBuffer = source.stencilBuffer;\n    this.resolveDepthBuffer = source.resolveDepthBuffer;\n    this.resolveStencilBuffer = source.resolveStencilBuffer;\n    if (source.depthTexture !== null) this.depthTexture = source.depthTexture.clone();\n    this.samples = source.samples;\n    return this;\n  }\n  dispose() {\n    this.dispatchEvent({\n      type: 'dispose'\n    });\n  }\n}\nclass WebGLRenderTarget extends RenderTarget {\n  constructor(width = 1, height = 1, options = {}) {\n    super(width, height, options);\n    this.isWebGLRenderTarget = true;\n  }\n}\nclass DataArrayTexture extends Texture$1 {\n  constructor(data = null, width = 1, height = 1, depth = 1) {\n    super(null);\n    this.isDataArrayTexture = true;\n    this.image = {\n      data,\n      width,\n      height,\n      depth\n    };\n    this.magFilter = NearestFilter;\n    this.minFilter = NearestFilter;\n    this.wrapR = ClampToEdgeWrapping;\n    this.generateMipmaps = false;\n    this.flipY = false;\n    this.unpackAlignment = 1;\n    this.layerUpdates = new Set();\n  }\n  addLayerUpdate(layerIndex) {\n    this.layerUpdates.add(layerIndex);\n  }\n  clearLayerUpdates() {\n    this.layerUpdates.clear();\n  }\n}\nclass Data3DTexture extends Texture$1 {\n  constructor(data = null, width = 1, height = 1, depth = 1) {\n    // We're going to add .setXXX() methods for setting properties later.\n    // Users can still set in DataTexture3D directly.\n    //\n    //\tconst texture = new THREE.DataTexture3D( data, width, height, depth );\n    // \ttexture.anisotropy = 16;\n    //\n    // See #14839\n\n    super(null);\n    this.isData3DTexture = true;\n    this.image = {\n      data,\n      width,\n      height,\n      depth\n    };\n    this.magFilter = NearestFilter;\n    this.minFilter = NearestFilter;\n    this.wrapR = ClampToEdgeWrapping;\n    this.generateMipmaps = false;\n    this.flipY = false;\n    this.unpackAlignment = 1;\n  }\n}\nclass Quaternion {\n  constructor(x = 0, y = 0, z = 0, w = 1) {\n    this.isQuaternion = true;\n    this._x = x;\n    this._y = y;\n    this._z = z;\n    this._w = w;\n  }\n  static slerpFlat(dst, dstOffset, src0, srcOffset0, src1, srcOffset1, t) {\n    // fuzz-free, array-based Quaternion SLERP operation\n\n    let x0 = src0[srcOffset0 + 0],\n      y0 = src0[srcOffset0 + 1],\n      z0 = src0[srcOffset0 + 2],\n      w0 = src0[srcOffset0 + 3];\n    const x1 = src1[srcOffset1 + 0],\n      y1 = src1[srcOffset1 + 1],\n      z1 = src1[srcOffset1 + 2],\n      w1 = src1[srcOffset1 + 3];\n    if (t === 0) {\n      dst[dstOffset + 0] = x0;\n      dst[dstOffset + 1] = y0;\n      dst[dstOffset + 2] = z0;\n      dst[dstOffset + 3] = w0;\n      return;\n    }\n    if (t === 1) {\n      dst[dstOffset + 0] = x1;\n      dst[dstOffset + 1] = y1;\n      dst[dstOffset + 2] = z1;\n      dst[dstOffset + 3] = w1;\n      return;\n    }\n    if (w0 !== w1 || x0 !== x1 || y0 !== y1 || z0 !== z1) {\n      let s = 1 - t;\n      const cos = x0 * x1 + y0 * y1 + z0 * z1 + w0 * w1,\n        dir = cos >= 0 ? 1 : -1,\n        sqrSin = 1 - cos * cos;\n\n      // Skip the Slerp for tiny steps to avoid numeric problems:\n      if (sqrSin > Number.EPSILON) {\n        const sin = Math.sqrt(sqrSin),\n          len = Math.atan2(sin, cos * dir);\n        s = Math.sin(s * len) / sin;\n        t = Math.sin(t * len) / sin;\n      }\n      const tDir = t * dir;\n      x0 = x0 * s + x1 * tDir;\n      y0 = y0 * s + y1 * tDir;\n      z0 = z0 * s + z1 * tDir;\n      w0 = w0 * s + w1 * tDir;\n\n      // Normalize in case we just did a lerp:\n      if (s === 1 - t) {\n        const f = 1 / Math.sqrt(x0 * x0 + y0 * y0 + z0 * z0 + w0 * w0);\n        x0 *= f;\n        y0 *= f;\n        z0 *= f;\n        w0 *= f;\n      }\n    }\n    dst[dstOffset] = x0;\n    dst[dstOffset + 1] = y0;\n    dst[dstOffset + 2] = z0;\n    dst[dstOffset + 3] = w0;\n  }\n  static multiplyQuaternionsFlat(dst, dstOffset, src0, srcOffset0, src1, srcOffset1) {\n    const x0 = src0[srcOffset0];\n    const y0 = src0[srcOffset0 + 1];\n    const z0 = src0[srcOffset0 + 2];\n    const w0 = src0[srcOffset0 + 3];\n    const x1 = src1[srcOffset1];\n    const y1 = src1[srcOffset1 + 1];\n    const z1 = src1[srcOffset1 + 2];\n    const w1 = src1[srcOffset1 + 3];\n    dst[dstOffset] = x0 * w1 + w0 * x1 + y0 * z1 - z0 * y1;\n    dst[dstOffset + 1] = y0 * w1 + w0 * y1 + z0 * x1 - x0 * z1;\n    dst[dstOffset + 2] = z0 * w1 + w0 * z1 + x0 * y1 - y0 * x1;\n    dst[dstOffset + 3] = w0 * w1 - x0 * x1 - y0 * y1 - z0 * z1;\n    return dst;\n  }\n  get x() {\n    return this._x;\n  }\n  set x(value) {\n    this._x = value;\n    this._onChangeCallback();\n  }\n  get y() {\n    return this._y;\n  }\n  set y(value) {\n    this._y = value;\n    this._onChangeCallback();\n  }\n  get z() {\n    return this._z;\n  }\n  set z(value) {\n    this._z = value;\n    this._onChangeCallback();\n  }\n  get w() {\n    return this._w;\n  }\n  set w(value) {\n    this._w = value;\n    this._onChangeCallback();\n  }\n  set(x, y, z, w) {\n    this._x = x;\n    this._y = y;\n    this._z = z;\n    this._w = w;\n    this._onChangeCallback();\n    return this;\n  }\n  clone() {\n    return new this.constructor(this._x, this._y, this._z, this._w);\n  }\n  copy(quaternion) {\n    this._x = quaternion.x;\n    this._y = quaternion.y;\n    this._z = quaternion.z;\n    this._w = quaternion.w;\n    this._onChangeCallback();\n    return this;\n  }\n  setFromEuler(euler, update = true) {\n    const x = euler._x,\n      y = euler._y,\n      z = euler._z,\n      order = euler._order;\n\n    // http://www.mathworks.com/matlabcentral/fileexchange/\n    // \t20696-function-to-convert-between-dcm-euler-angles-quaternions-and-euler-vectors/\n    //\tcontent/SpinCalc.m\n\n    const cos = Math.cos;\n    const sin = Math.sin;\n    const c1 = cos(x / 2);\n    const c2 = cos(y / 2);\n    const c3 = cos(z / 2);\n    const s1 = sin(x / 2);\n    const s2 = sin(y / 2);\n    const s3 = sin(z / 2);\n    switch (order) {\n      case 'XYZ':\n        this._x = s1 * c2 * c3 + c1 * s2 * s3;\n        this._y = c1 * s2 * c3 - s1 * c2 * s3;\n        this._z = c1 * c2 * s3 + s1 * s2 * c3;\n        this._w = c1 * c2 * c3 - s1 * s2 * s3;\n        break;\n      case 'YXZ':\n        this._x = s1 * c2 * c3 + c1 * s2 * s3;\n        this._y = c1 * s2 * c3 - s1 * c2 * s3;\n        this._z = c1 * c2 * s3 - s1 * s2 * c3;\n        this._w = c1 * c2 * c3 + s1 * s2 * s3;\n        break;\n      case 'ZXY':\n        this._x = s1 * c2 * c3 - c1 * s2 * s3;\n        this._y = c1 * s2 * c3 + s1 * c2 * s3;\n        this._z = c1 * c2 * s3 + s1 * s2 * c3;\n        this._w = c1 * c2 * c3 - s1 * s2 * s3;\n        break;\n      case 'ZYX':\n        this._x = s1 * c2 * c3 - c1 * s2 * s3;\n        this._y = c1 * s2 * c3 + s1 * c2 * s3;\n        this._z = c1 * c2 * s3 - s1 * s2 * c3;\n        this._w = c1 * c2 * c3 + s1 * s2 * s3;\n        break;\n      case 'YZX':\n        this._x = s1 * c2 * c3 + c1 * s2 * s3;\n        this._y = c1 * s2 * c3 + s1 * c2 * s3;\n        this._z = c1 * c2 * s3 - s1 * s2 * c3;\n        this._w = c1 * c2 * c3 - s1 * s2 * s3;\n        break;\n      case 'XZY':\n        this._x = s1 * c2 * c3 - c1 * s2 * s3;\n        this._y = c1 * s2 * c3 - s1 * c2 * s3;\n        this._z = c1 * c2 * s3 + s1 * s2 * c3;\n        this._w = c1 * c2 * c3 + s1 * s2 * s3;\n        break;\n      default:\n        console.warn('THREE.Quaternion: .setFromEuler() encountered an unknown order: ' + order);\n    }\n    if (update === true) this._onChangeCallback();\n    return this;\n  }\n  setFromAxisAngle(axis, angle) {\n    // http://www.euclideanspace.com/maths/geometry/rotations/conversions/angleToQuaternion/index.htm\n\n    // assumes axis is normalized\n\n    const halfAngle = angle / 2,\n      s = Math.sin(halfAngle);\n    this._x = axis.x * s;\n    this._y = axis.y * s;\n    this._z = axis.z * s;\n    this._w = Math.cos(halfAngle);\n    this._onChangeCallback();\n    return this;\n  }\n  setFromRotationMatrix(m) {\n    // http://www.euclideanspace.com/maths/geometry/rotations/conversions/matrixToQuaternion/index.htm\n\n    // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n    const te = m.elements,\n      m11 = te[0],\n      m12 = te[4],\n      m13 = te[8],\n      m21 = te[1],\n      m22 = te[5],\n      m23 = te[9],\n      m31 = te[2],\n      m32 = te[6],\n      m33 = te[10],\n      trace = m11 + m22 + m33;\n    if (trace > 0) {\n      const s = 0.5 / Math.sqrt(trace + 1.0);\n      this._w = 0.25 / s;\n      this._x = (m32 - m23) * s;\n      this._y = (m13 - m31) * s;\n      this._z = (m21 - m12) * s;\n    } else if (m11 > m22 && m11 > m33) {\n      const s = 2.0 * Math.sqrt(1.0 + m11 - m22 - m33);\n      this._w = (m32 - m23) / s;\n      this._x = 0.25 * s;\n      this._y = (m12 + m21) / s;\n      this._z = (m13 + m31) / s;\n    } else if (m22 > m33) {\n      const s = 2.0 * Math.sqrt(1.0 + m22 - m11 - m33);\n      this._w = (m13 - m31) / s;\n      this._x = (m12 + m21) / s;\n      this._y = 0.25 * s;\n      this._z = (m23 + m32) / s;\n    } else {\n      const s = 2.0 * Math.sqrt(1.0 + m33 - m11 - m22);\n      this._w = (m21 - m12) / s;\n      this._x = (m13 + m31) / s;\n      this._y = (m23 + m32) / s;\n      this._z = 0.25 * s;\n    }\n    this._onChangeCallback();\n    return this;\n  }\n  setFromUnitVectors(vFrom, vTo) {\n    // assumes direction vectors vFrom and vTo are normalized\n\n    let r = vFrom.dot(vTo) + 1;\n    if (r < Number.EPSILON) {\n      // vFrom and vTo point in opposite directions\n\n      r = 0;\n      if (Math.abs(vFrom.x) > Math.abs(vFrom.z)) {\n        this._x = -vFrom.y;\n        this._y = vFrom.x;\n        this._z = 0;\n        this._w = r;\n      } else {\n        this._x = 0;\n        this._y = -vFrom.z;\n        this._z = vFrom.y;\n        this._w = r;\n      }\n    } else {\n      // crossVectors( vFrom, vTo ); // inlined to avoid cyclic dependency on Vector3\n\n      this._x = vFrom.y * vTo.z - vFrom.z * vTo.y;\n      this._y = vFrom.z * vTo.x - vFrom.x * vTo.z;\n      this._z = vFrom.x * vTo.y - vFrom.y * vTo.x;\n      this._w = r;\n    }\n    return this.normalize();\n  }\n  angleTo(q) {\n    return 2 * Math.acos(Math.abs(clamp$1(this.dot(q), -1, 1)));\n  }\n  rotateTowards(q, step) {\n    const angle = this.angleTo(q);\n    if (angle === 0) return this;\n    const t = Math.min(1, step / angle);\n    this.slerp(q, t);\n    return this;\n  }\n  identity() {\n    return this.set(0, 0, 0, 1);\n  }\n  invert() {\n    // quaternion is assumed to have unit length\n\n    return this.conjugate();\n  }\n  conjugate() {\n    this._x *= -1;\n    this._y *= -1;\n    this._z *= -1;\n    this._onChangeCallback();\n    return this;\n  }\n  dot(v) {\n    return this._x * v._x + this._y * v._y + this._z * v._z + this._w * v._w;\n  }\n  lengthSq() {\n    return this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w;\n  }\n  length() {\n    return Math.sqrt(this._x * this._x + this._y * this._y + this._z * this._z + this._w * this._w);\n  }\n  normalize() {\n    let l = this.length();\n    if (l === 0) {\n      this._x = 0;\n      this._y = 0;\n      this._z = 0;\n      this._w = 1;\n    } else {\n      l = 1 / l;\n      this._x = this._x * l;\n      this._y = this._y * l;\n      this._z = this._z * l;\n      this._w = this._w * l;\n    }\n    this._onChangeCallback();\n    return this;\n  }\n  multiply(q) {\n    return this.multiplyQuaternions(this, q);\n  }\n  premultiply(q) {\n    return this.multiplyQuaternions(q, this);\n  }\n  multiplyQuaternions(a, b) {\n    // from http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/code/index.htm\n\n    const qax = a._x,\n      qay = a._y,\n      qaz = a._z,\n      qaw = a._w;\n    const qbx = b._x,\n      qby = b._y,\n      qbz = b._z,\n      qbw = b._w;\n    this._x = qax * qbw + qaw * qbx + qay * qbz - qaz * qby;\n    this._y = qay * qbw + qaw * qby + qaz * qbx - qax * qbz;\n    this._z = qaz * qbw + qaw * qbz + qax * qby - qay * qbx;\n    this._w = qaw * qbw - qax * qbx - qay * qby - qaz * qbz;\n    this._onChangeCallback();\n    return this;\n  }\n  slerp(qb, t) {\n    if (t === 0) return this;\n    if (t === 1) return this.copy(qb);\n    const x = this._x,\n      y = this._y,\n      z = this._z,\n      w = this._w;\n\n    // http://www.euclideanspace.com/maths/algebra/realNormedAlgebra/quaternions/slerp/\n\n    let cosHalfTheta = w * qb._w + x * qb._x + y * qb._y + z * qb._z;\n    if (cosHalfTheta < 0) {\n      this._w = -qb._w;\n      this._x = -qb._x;\n      this._y = -qb._y;\n      this._z = -qb._z;\n      cosHalfTheta = -cosHalfTheta;\n    } else {\n      this.copy(qb);\n    }\n    if (cosHalfTheta >= 1.0) {\n      this._w = w;\n      this._x = x;\n      this._y = y;\n      this._z = z;\n      return this;\n    }\n    const sqrSinHalfTheta = 1.0 - cosHalfTheta * cosHalfTheta;\n    if (sqrSinHalfTheta <= Number.EPSILON) {\n      const s = 1 - t;\n      this._w = s * w + t * this._w;\n      this._x = s * x + t * this._x;\n      this._y = s * y + t * this._y;\n      this._z = s * z + t * this._z;\n      this.normalize(); // normalize calls _onChangeCallback()\n\n      return this;\n    }\n    const sinHalfTheta = Math.sqrt(sqrSinHalfTheta);\n    const halfTheta = Math.atan2(sinHalfTheta, cosHalfTheta);\n    const ratioA = Math.sin((1 - t) * halfTheta) / sinHalfTheta,\n      ratioB = Math.sin(t * halfTheta) / sinHalfTheta;\n    this._w = w * ratioA + this._w * ratioB;\n    this._x = x * ratioA + this._x * ratioB;\n    this._y = y * ratioA + this._y * ratioB;\n    this._z = z * ratioA + this._z * ratioB;\n    this._onChangeCallback();\n    return this;\n  }\n  slerpQuaternions(qa, qb, t) {\n    return this.copy(qa).slerp(qb, t);\n  }\n  random() {\n    // sets this quaternion to a uniform random unit quaternnion\n\n    // Ken Shoemake\n    // Uniform random rotations\n    // D. Kirk, editor, Graphics Gems III, pages 124-132. Academic Press, New York, 1992.\n\n    const theta1 = 2 * Math.PI * Math.random();\n    const theta2 = 2 * Math.PI * Math.random();\n    const x0 = Math.random();\n    const r1 = Math.sqrt(1 - x0);\n    const r2 = Math.sqrt(x0);\n    return this.set(r1 * Math.sin(theta1), r1 * Math.cos(theta1), r2 * Math.sin(theta2), r2 * Math.cos(theta2));\n  }\n  equals(quaternion) {\n    return quaternion._x === this._x && quaternion._y === this._y && quaternion._z === this._z && quaternion._w === this._w;\n  }\n  fromArray(array, offset = 0) {\n    this._x = array[offset];\n    this._y = array[offset + 1];\n    this._z = array[offset + 2];\n    this._w = array[offset + 3];\n    this._onChangeCallback();\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    array[offset] = this._x;\n    array[offset + 1] = this._y;\n    array[offset + 2] = this._z;\n    array[offset + 3] = this._w;\n    return array;\n  }\n  fromBufferAttribute(attribute, index) {\n    this._x = attribute.getX(index);\n    this._y = attribute.getY(index);\n    this._z = attribute.getZ(index);\n    this._w = attribute.getW(index);\n    this._onChangeCallback();\n    return this;\n  }\n  toJSON() {\n    return this.toArray();\n  }\n  _onChange(callback) {\n    this._onChangeCallback = callback;\n    return this;\n  }\n  _onChangeCallback() {}\n  *[Symbol.iterator]() {\n    yield this._x;\n    yield this._y;\n    yield this._z;\n    yield this._w;\n  }\n}\nclass Vector3 {\n  constructor(x = 0, y = 0, z = 0) {\n    Vector3.prototype.isVector3 = true;\n    this.x = x;\n    this.y = y;\n    this.z = z;\n  }\n  set(x, y, z) {\n    if (z === undefined) z = this.z; // sprite.scale.set(x,y)\n\n    this.x = x;\n    this.y = y;\n    this.z = z;\n    return this;\n  }\n  setScalar(scalar) {\n    this.x = scalar;\n    this.y = scalar;\n    this.z = scalar;\n    return this;\n  }\n  setX(x) {\n    this.x = x;\n    return this;\n  }\n  setY(y) {\n    this.y = y;\n    return this;\n  }\n  setZ(z) {\n    this.z = z;\n    return this;\n  }\n  setComponent(index, value) {\n    switch (index) {\n      case 0:\n        this.x = value;\n        break;\n      case 1:\n        this.y = value;\n        break;\n      case 2:\n        this.z = value;\n        break;\n      default:\n        throw new Error('index is out of range: ' + index);\n    }\n    return this;\n  }\n  getComponent(index) {\n    switch (index) {\n      case 0:\n        return this.x;\n      case 1:\n        return this.y;\n      case 2:\n        return this.z;\n      default:\n        throw new Error('index is out of range: ' + index);\n    }\n  }\n  clone() {\n    return new this.constructor(this.x, this.y, this.z);\n  }\n  copy(v) {\n    this.x = v.x;\n    this.y = v.y;\n    this.z = v.z;\n    return this;\n  }\n  add(v) {\n    this.x += v.x;\n    this.y += v.y;\n    this.z += v.z;\n    return this;\n  }\n  addScalar(s) {\n    this.x += s;\n    this.y += s;\n    this.z += s;\n    return this;\n  }\n  addVectors(a, b) {\n    this.x = a.x + b.x;\n    this.y = a.y + b.y;\n    this.z = a.z + b.z;\n    return this;\n  }\n  addScaledVector(v, s) {\n    this.x += v.x * s;\n    this.y += v.y * s;\n    this.z += v.z * s;\n    return this;\n  }\n  sub(v) {\n    this.x -= v.x;\n    this.y -= v.y;\n    this.z -= v.z;\n    return this;\n  }\n  subScalar(s) {\n    this.x -= s;\n    this.y -= s;\n    this.z -= s;\n    return this;\n  }\n  subVectors(a, b) {\n    this.x = a.x - b.x;\n    this.y = a.y - b.y;\n    this.z = a.z - b.z;\n    return this;\n  }\n  multiply(v) {\n    this.x *= v.x;\n    this.y *= v.y;\n    this.z *= v.z;\n    return this;\n  }\n  multiplyScalar(scalar) {\n    this.x *= scalar;\n    this.y *= scalar;\n    this.z *= scalar;\n    return this;\n  }\n  multiplyVectors(a, b) {\n    this.x = a.x * b.x;\n    this.y = a.y * b.y;\n    this.z = a.z * b.z;\n    return this;\n  }\n  applyEuler(euler) {\n    return this.applyQuaternion(_quaternion$4.setFromEuler(euler));\n  }\n  applyAxisAngle(axis, angle) {\n    return this.applyQuaternion(_quaternion$4.setFromAxisAngle(axis, angle));\n  }\n  applyMatrix3(m) {\n    const x = this.x,\n      y = this.y,\n      z = this.z;\n    const e = m.elements;\n    this.x = e[0] * x + e[3] * y + e[6] * z;\n    this.y = e[1] * x + e[4] * y + e[7] * z;\n    this.z = e[2] * x + e[5] * y + e[8] * z;\n    return this;\n  }\n  applyNormalMatrix(m) {\n    return this.applyMatrix3(m).normalize();\n  }\n  applyMatrix4(m) {\n    const x = this.x,\n      y = this.y,\n      z = this.z;\n    const e = m.elements;\n    const w = 1 / (e[3] * x + e[7] * y + e[11] * z + e[15]);\n    this.x = (e[0] * x + e[4] * y + e[8] * z + e[12]) * w;\n    this.y = (e[1] * x + e[5] * y + e[9] * z + e[13]) * w;\n    this.z = (e[2] * x + e[6] * y + e[10] * z + e[14]) * w;\n    return this;\n  }\n  applyQuaternion(q) {\n    // quaternion q is assumed to have unit length\n\n    const vx = this.x,\n      vy = this.y,\n      vz = this.z;\n    const qx = q.x,\n      qy = q.y,\n      qz = q.z,\n      qw = q.w;\n\n    // t = 2 * cross( q.xyz, v );\n    const tx = 2 * (qy * vz - qz * vy);\n    const ty = 2 * (qz * vx - qx * vz);\n    const tz = 2 * (qx * vy - qy * vx);\n\n    // v + q.w * t + cross( q.xyz, t );\n    this.x = vx + qw * tx + qy * tz - qz * ty;\n    this.y = vy + qw * ty + qz * tx - qx * tz;\n    this.z = vz + qw * tz + qx * ty - qy * tx;\n    return this;\n  }\n  project(camera) {\n    return this.applyMatrix4(camera.matrixWorldInverse).applyMatrix4(camera.projectionMatrix);\n  }\n  unproject(camera) {\n    return this.applyMatrix4(camera.projectionMatrixInverse).applyMatrix4(camera.matrixWorld);\n  }\n  transformDirection(m) {\n    // input: THREE.Matrix4 affine matrix\n    // vector interpreted as a direction\n\n    const x = this.x,\n      y = this.y,\n      z = this.z;\n    const e = m.elements;\n    this.x = e[0] * x + e[4] * y + e[8] * z;\n    this.y = e[1] * x + e[5] * y + e[9] * z;\n    this.z = e[2] * x + e[6] * y + e[10] * z;\n    return this.normalize();\n  }\n  divide(v) {\n    this.x /= v.x;\n    this.y /= v.y;\n    this.z /= v.z;\n    return this;\n  }\n  divideScalar(scalar) {\n    return this.multiplyScalar(1 / scalar);\n  }\n  min(v) {\n    this.x = Math.min(this.x, v.x);\n    this.y = Math.min(this.y, v.y);\n    this.z = Math.min(this.z, v.z);\n    return this;\n  }\n  max(v) {\n    this.x = Math.max(this.x, v.x);\n    this.y = Math.max(this.y, v.y);\n    this.z = Math.max(this.z, v.z);\n    return this;\n  }\n  clamp(min, max) {\n    // assumes min < max, componentwise\n\n    this.x = Math.max(min.x, Math.min(max.x, this.x));\n    this.y = Math.max(min.y, Math.min(max.y, this.y));\n    this.z = Math.max(min.z, Math.min(max.z, this.z));\n    return this;\n  }\n  clampScalar(minVal, maxVal) {\n    this.x = Math.max(minVal, Math.min(maxVal, this.x));\n    this.y = Math.max(minVal, Math.min(maxVal, this.y));\n    this.z = Math.max(minVal, Math.min(maxVal, this.z));\n    return this;\n  }\n  clampLength(min, max) {\n    const length = this.length();\n    return this.divideScalar(length || 1).multiplyScalar(Math.max(min, Math.min(max, length)));\n  }\n  floor() {\n    this.x = Math.floor(this.x);\n    this.y = Math.floor(this.y);\n    this.z = Math.floor(this.z);\n    return this;\n  }\n  ceil() {\n    this.x = Math.ceil(this.x);\n    this.y = Math.ceil(this.y);\n    this.z = Math.ceil(this.z);\n    return this;\n  }\n  round() {\n    this.x = Math.round(this.x);\n    this.y = Math.round(this.y);\n    this.z = Math.round(this.z);\n    return this;\n  }\n  roundToZero() {\n    this.x = Math.trunc(this.x);\n    this.y = Math.trunc(this.y);\n    this.z = Math.trunc(this.z);\n    return this;\n  }\n  negate() {\n    this.x = -this.x;\n    this.y = -this.y;\n    this.z = -this.z;\n    return this;\n  }\n  dot(v) {\n    return this.x * v.x + this.y * v.y + this.z * v.z;\n  }\n\n  // TODO lengthSquared?\n\n  lengthSq() {\n    return this.x * this.x + this.y * this.y + this.z * this.z;\n  }\n  length() {\n    return Math.sqrt(this.x * this.x + this.y * this.y + this.z * this.z);\n  }\n  manhattanLength() {\n    return Math.abs(this.x) + Math.abs(this.y) + Math.abs(this.z);\n  }\n  normalize() {\n    return this.divideScalar(this.length() || 1);\n  }\n  setLength(length) {\n    return this.normalize().multiplyScalar(length);\n  }\n  lerp(v, alpha) {\n    this.x += (v.x - this.x) * alpha;\n    this.y += (v.y - this.y) * alpha;\n    this.z += (v.z - this.z) * alpha;\n    return this;\n  }\n  lerpVectors(v1, v2, alpha) {\n    this.x = v1.x + (v2.x - v1.x) * alpha;\n    this.y = v1.y + (v2.y - v1.y) * alpha;\n    this.z = v1.z + (v2.z - v1.z) * alpha;\n    return this;\n  }\n  cross(v) {\n    return this.crossVectors(this, v);\n  }\n  crossVectors(a, b) {\n    const ax = a.x,\n      ay = a.y,\n      az = a.z;\n    const bx = b.x,\n      by = b.y,\n      bz = b.z;\n    this.x = ay * bz - az * by;\n    this.y = az * bx - ax * bz;\n    this.z = ax * by - ay * bx;\n    return this;\n  }\n  projectOnVector(v) {\n    const denominator = v.lengthSq();\n    if (denominator === 0) return this.set(0, 0, 0);\n    const scalar = v.dot(this) / denominator;\n    return this.copy(v).multiplyScalar(scalar);\n  }\n  projectOnPlane(planeNormal) {\n    _vector$c.copy(this).projectOnVector(planeNormal);\n    return this.sub(_vector$c);\n  }\n  reflect(normal) {\n    // reflect incident vector off plane orthogonal to normal\n    // normal is assumed to have unit length\n\n    return this.sub(_vector$c.copy(normal).multiplyScalar(2 * this.dot(normal)));\n  }\n  angleTo(v) {\n    const denominator = Math.sqrt(this.lengthSq() * v.lengthSq());\n    if (denominator === 0) return Math.PI / 2;\n    const theta = this.dot(v) / denominator;\n\n    // clamp, to handle numerical problems\n\n    return Math.acos(clamp$1(theta, -1, 1));\n  }\n  distanceTo(v) {\n    return Math.sqrt(this.distanceToSquared(v));\n  }\n  distanceToSquared(v) {\n    const dx = this.x - v.x,\n      dy = this.y - v.y,\n      dz = this.z - v.z;\n    return dx * dx + dy * dy + dz * dz;\n  }\n  manhattanDistanceTo(v) {\n    return Math.abs(this.x - v.x) + Math.abs(this.y - v.y) + Math.abs(this.z - v.z);\n  }\n  setFromSpherical(s) {\n    return this.setFromSphericalCoords(s.radius, s.phi, s.theta);\n  }\n  setFromSphericalCoords(radius, phi, theta) {\n    const sinPhiRadius = Math.sin(phi) * radius;\n    this.x = sinPhiRadius * Math.sin(theta);\n    this.y = Math.cos(phi) * radius;\n    this.z = sinPhiRadius * Math.cos(theta);\n    return this;\n  }\n  setFromCylindrical(c) {\n    return this.setFromCylindricalCoords(c.radius, c.theta, c.y);\n  }\n  setFromCylindricalCoords(radius, theta, y) {\n    this.x = radius * Math.sin(theta);\n    this.y = y;\n    this.z = radius * Math.cos(theta);\n    return this;\n  }\n  setFromMatrixPosition(m) {\n    const e = m.elements;\n    this.x = e[12];\n    this.y = e[13];\n    this.z = e[14];\n    return this;\n  }\n  setFromMatrixScale(m) {\n    const sx = this.setFromMatrixColumn(m, 0).length();\n    const sy = this.setFromMatrixColumn(m, 1).length();\n    const sz = this.setFromMatrixColumn(m, 2).length();\n    this.x = sx;\n    this.y = sy;\n    this.z = sz;\n    return this;\n  }\n  setFromMatrixColumn(m, index) {\n    return this.fromArray(m.elements, index * 4);\n  }\n  setFromMatrix3Column(m, index) {\n    return this.fromArray(m.elements, index * 3);\n  }\n  setFromEuler(e) {\n    this.x = e._x;\n    this.y = e._y;\n    this.z = e._z;\n    return this;\n  }\n  setFromColor(c) {\n    this.x = c.r;\n    this.y = c.g;\n    this.z = c.b;\n    return this;\n  }\n  equals(v) {\n    return v.x === this.x && v.y === this.y && v.z === this.z;\n  }\n  fromArray(array, offset = 0) {\n    this.x = array[offset];\n    this.y = array[offset + 1];\n    this.z = array[offset + 2];\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    array[offset] = this.x;\n    array[offset + 1] = this.y;\n    array[offset + 2] = this.z;\n    return array;\n  }\n  fromBufferAttribute(attribute, index) {\n    this.x = attribute.getX(index);\n    this.y = attribute.getY(index);\n    this.z = attribute.getZ(index);\n    return this;\n  }\n  random() {\n    this.x = Math.random();\n    this.y = Math.random();\n    this.z = Math.random();\n    return this;\n  }\n  randomDirection() {\n    // https://mathworld.wolfram.com/SpherePointPicking.html\n\n    const theta = Math.random() * Math.PI * 2;\n    const u = Math.random() * 2 - 1;\n    const c = Math.sqrt(1 - u * u);\n    this.x = c * Math.cos(theta);\n    this.y = u;\n    this.z = c * Math.sin(theta);\n    return this;\n  }\n  *[Symbol.iterator]() {\n    yield this.x;\n    yield this.y;\n    yield this.z;\n  }\n}\nconst _vector$c = /*@__PURE__*/new Vector3();\nconst _quaternion$4 = /*@__PURE__*/new Quaternion();\nclass Box3 {\n  constructor(min = new Vector3(+Infinity, +Infinity, +Infinity), max = new Vector3(-Infinity, -Infinity, -Infinity)) {\n    this.isBox3 = true;\n    this.min = min;\n    this.max = max;\n  }\n  set(min, max) {\n    this.min.copy(min);\n    this.max.copy(max);\n    return this;\n  }\n  setFromArray(array) {\n    this.makeEmpty();\n    for (let i = 0, il = array.length; i < il; i += 3) {\n      this.expandByPoint(_vector$b.fromArray(array, i));\n    }\n    return this;\n  }\n  setFromBufferAttribute(attribute) {\n    this.makeEmpty();\n    for (let i = 0, il = attribute.count; i < il; i++) {\n      this.expandByPoint(_vector$b.fromBufferAttribute(attribute, i));\n    }\n    return this;\n  }\n  setFromPoints(points) {\n    this.makeEmpty();\n    for (let i = 0, il = points.length; i < il; i++) {\n      this.expandByPoint(points[i]);\n    }\n    return this;\n  }\n  setFromCenterAndSize(center, size) {\n    const halfSize = _vector$b.copy(size).multiplyScalar(0.5);\n    this.min.copy(center).sub(halfSize);\n    this.max.copy(center).add(halfSize);\n    return this;\n  }\n  setFromObject(object, precise = false) {\n    this.makeEmpty();\n    return this.expandByObject(object, precise);\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  copy(box) {\n    this.min.copy(box.min);\n    this.max.copy(box.max);\n    return this;\n  }\n  makeEmpty() {\n    this.min.x = this.min.y = this.min.z = +Infinity;\n    this.max.x = this.max.y = this.max.z = -Infinity;\n    return this;\n  }\n  isEmpty() {\n    // this is a more robust check for empty than ( volume <= 0 ) because volume can get positive with two negative axes\n\n    return this.max.x < this.min.x || this.max.y < this.min.y || this.max.z < this.min.z;\n  }\n  getCenter(target) {\n    return this.isEmpty() ? target.set(0, 0, 0) : target.addVectors(this.min, this.max).multiplyScalar(0.5);\n  }\n  getSize(target) {\n    return this.isEmpty() ? target.set(0, 0, 0) : target.subVectors(this.max, this.min);\n  }\n  expandByPoint(point) {\n    this.min.min(point);\n    this.max.max(point);\n    return this;\n  }\n  expandByVector(vector) {\n    this.min.sub(vector);\n    this.max.add(vector);\n    return this;\n  }\n  expandByScalar(scalar) {\n    this.min.addScalar(-scalar);\n    this.max.addScalar(scalar);\n    return this;\n  }\n  expandByObject(object, precise = false) {\n    // Computes the world-axis-aligned bounding box of an object (including its children),\n    // accounting for both the object's, and children's, world transforms\n\n    object.updateWorldMatrix(false, false);\n    const geometry = object.geometry;\n    if (geometry !== undefined) {\n      const positionAttribute = geometry.getAttribute('position');\n\n      // precise AABB computation based on vertex data requires at least a position attribute.\n      // instancing isn't supported so far and uses the normal (conservative) code path.\n\n      if (precise === true && positionAttribute !== undefined && object.isInstancedMesh !== true) {\n        for (let i = 0, l = positionAttribute.count; i < l; i++) {\n          if (object.isMesh === true) {\n            object.getVertexPosition(i, _vector$b);\n          } else {\n            _vector$b.fromBufferAttribute(positionAttribute, i);\n          }\n          _vector$b.applyMatrix4(object.matrixWorld);\n          this.expandByPoint(_vector$b);\n        }\n      } else {\n        if (object.boundingBox !== undefined) {\n          // object-level bounding box\n\n          if (object.boundingBox === null) {\n            object.computeBoundingBox();\n          }\n          _box$4.copy(object.boundingBox);\n        } else {\n          // geometry-level bounding box\n\n          if (geometry.boundingBox === null) {\n            geometry.computeBoundingBox();\n          }\n          _box$4.copy(geometry.boundingBox);\n        }\n        _box$4.applyMatrix4(object.matrixWorld);\n        this.union(_box$4);\n      }\n    }\n    const children = object.children;\n    for (let i = 0, l = children.length; i < l; i++) {\n      this.expandByObject(children[i], precise);\n    }\n    return this;\n  }\n  containsPoint(point) {\n    return point.x >= this.min.x && point.x <= this.max.x && point.y >= this.min.y && point.y <= this.max.y && point.z >= this.min.z && point.z <= this.max.z;\n  }\n  containsBox(box) {\n    return this.min.x <= box.min.x && box.max.x <= this.max.x && this.min.y <= box.min.y && box.max.y <= this.max.y && this.min.z <= box.min.z && box.max.z <= this.max.z;\n  }\n  getParameter(point, target) {\n    // This can potentially have a divide by zero if the box\n    // has a size dimension of 0.\n\n    return target.set((point.x - this.min.x) / (this.max.x - this.min.x), (point.y - this.min.y) / (this.max.y - this.min.y), (point.z - this.min.z) / (this.max.z - this.min.z));\n  }\n  intersectsBox(box) {\n    // using 6 splitting planes to rule out intersections.\n    return box.max.x >= this.min.x && box.min.x <= this.max.x && box.max.y >= this.min.y && box.min.y <= this.max.y && box.max.z >= this.min.z && box.min.z <= this.max.z;\n  }\n  intersectsSphere(sphere) {\n    // Find the point on the AABB closest to the sphere center.\n    this.clampPoint(sphere.center, _vector$b);\n\n    // If that point is inside the sphere, the AABB and sphere intersect.\n    return _vector$b.distanceToSquared(sphere.center) <= sphere.radius * sphere.radius;\n  }\n  intersectsPlane(plane) {\n    // We compute the minimum and maximum dot product values. If those values\n    // are on the same side (back or front) of the plane, then there is no intersection.\n\n    let min, max;\n    if (plane.normal.x > 0) {\n      min = plane.normal.x * this.min.x;\n      max = plane.normal.x * this.max.x;\n    } else {\n      min = plane.normal.x * this.max.x;\n      max = plane.normal.x * this.min.x;\n    }\n    if (plane.normal.y > 0) {\n      min += plane.normal.y * this.min.y;\n      max += plane.normal.y * this.max.y;\n    } else {\n      min += plane.normal.y * this.max.y;\n      max += plane.normal.y * this.min.y;\n    }\n    if (plane.normal.z > 0) {\n      min += plane.normal.z * this.min.z;\n      max += plane.normal.z * this.max.z;\n    } else {\n      min += plane.normal.z * this.max.z;\n      max += plane.normal.z * this.min.z;\n    }\n    return min <= -plane.constant && max >= -plane.constant;\n  }\n  intersectsTriangle(triangle) {\n    if (this.isEmpty()) {\n      return false;\n    }\n\n    // compute box center and extents\n    this.getCenter(_center);\n    _extents.subVectors(this.max, _center);\n\n    // translate triangle to aabb origin\n    _v0$3.subVectors(triangle.a, _center);\n    _v1$7.subVectors(triangle.b, _center);\n    _v2$4.subVectors(triangle.c, _center);\n\n    // compute edge vectors for triangle\n    _f0.subVectors(_v1$7, _v0$3);\n    _f1.subVectors(_v2$4, _v1$7);\n    _f2.subVectors(_v0$3, _v2$4);\n\n    // test against axes that are given by cross product combinations of the edges of the triangle and the edges of the aabb\n    // make an axis testing of each of the 3 sides of the aabb against each of the 3 sides of the triangle = 9 axis of separation\n    // axis_ij = u_i x f_j (u0, u1, u2 = face normals of aabb = x,y,z axes vectors since aabb is axis aligned)\n    let axes = [0, -_f0.z, _f0.y, 0, -_f1.z, _f1.y, 0, -_f2.z, _f2.y, _f0.z, 0, -_f0.x, _f1.z, 0, -_f1.x, _f2.z, 0, -_f2.x, -_f0.y, _f0.x, 0, -_f1.y, _f1.x, 0, -_f2.y, _f2.x, 0];\n    if (!satForAxes(axes, _v0$3, _v1$7, _v2$4, _extents)) {\n      return false;\n    }\n\n    // test 3 face normals from the aabb\n    axes = [1, 0, 0, 0, 1, 0, 0, 0, 1];\n    if (!satForAxes(axes, _v0$3, _v1$7, _v2$4, _extents)) {\n      return false;\n    }\n\n    // finally testing the face normal of the triangle\n    // use already existing triangle edge vectors here\n    _triangleNormal.crossVectors(_f0, _f1);\n    axes = [_triangleNormal.x, _triangleNormal.y, _triangleNormal.z];\n    return satForAxes(axes, _v0$3, _v1$7, _v2$4, _extents);\n  }\n  clampPoint(point, target) {\n    return target.copy(point).clamp(this.min, this.max);\n  }\n  distanceToPoint(point) {\n    return this.clampPoint(point, _vector$b).distanceTo(point);\n  }\n  getBoundingSphere(target) {\n    if (this.isEmpty()) {\n      target.makeEmpty();\n    } else {\n      this.getCenter(target.center);\n      target.radius = this.getSize(_vector$b).length() * 0.5;\n    }\n    return target;\n  }\n  intersect(box) {\n    this.min.max(box.min);\n    this.max.min(box.max);\n\n    // ensure that if there is no overlap, the result is fully empty, not slightly empty with non-inf/+inf values that will cause subsequence intersects to erroneously return valid values.\n    if (this.isEmpty()) this.makeEmpty();\n    return this;\n  }\n  union(box) {\n    this.min.min(box.min);\n    this.max.max(box.max);\n    return this;\n  }\n  applyMatrix4(matrix) {\n    // transform of empty box is an empty box.\n    if (this.isEmpty()) return this;\n\n    // NOTE: I am using a binary pattern to specify all 2^3 combinations below\n    _points[0].set(this.min.x, this.min.y, this.min.z).applyMatrix4(matrix); // 000\n    _points[1].set(this.min.x, this.min.y, this.max.z).applyMatrix4(matrix); // 001\n    _points[2].set(this.min.x, this.max.y, this.min.z).applyMatrix4(matrix); // 010\n    _points[3].set(this.min.x, this.max.y, this.max.z).applyMatrix4(matrix); // 011\n    _points[4].set(this.max.x, this.min.y, this.min.z).applyMatrix4(matrix); // 100\n    _points[5].set(this.max.x, this.min.y, this.max.z).applyMatrix4(matrix); // 101\n    _points[6].set(this.max.x, this.max.y, this.min.z).applyMatrix4(matrix); // 110\n    _points[7].set(this.max.x, this.max.y, this.max.z).applyMatrix4(matrix); // 111\n\n    this.setFromPoints(_points);\n    return this;\n  }\n  translate(offset) {\n    this.min.add(offset);\n    this.max.add(offset);\n    return this;\n  }\n  equals(box) {\n    return box.min.equals(this.min) && box.max.equals(this.max);\n  }\n}\nconst _points = [/*@__PURE__*/new Vector3(), /*@__PURE__*/new Vector3(), /*@__PURE__*/new Vector3(), /*@__PURE__*/new Vector3(), /*@__PURE__*/new Vector3(), /*@__PURE__*/new Vector3(), /*@__PURE__*/new Vector3(), /*@__PURE__*/new Vector3()];\nconst _vector$b = /*@__PURE__*/new Vector3();\nconst _box$4 = /*@__PURE__*/new Box3();\n\n// triangle centered vertices\n\nconst _v0$3 = /*@__PURE__*/new Vector3();\nconst _v1$7 = /*@__PURE__*/new Vector3();\nconst _v2$4 = /*@__PURE__*/new Vector3();\n\n// triangle edge vectors\n\nconst _f0 = /*@__PURE__*/new Vector3();\nconst _f1 = /*@__PURE__*/new Vector3();\nconst _f2 = /*@__PURE__*/new Vector3();\nconst _center = /*@__PURE__*/new Vector3();\nconst _extents = /*@__PURE__*/new Vector3();\nconst _triangleNormal = /*@__PURE__*/new Vector3();\nconst _testAxis = /*@__PURE__*/new Vector3();\nfunction satForAxes(axes, v0, v1, v2, extents) {\n  for (let i = 0, j = axes.length - 3; i <= j; i += 3) {\n    _testAxis.fromArray(axes, i);\n    // project the aabb onto the separating axis\n    const r = extents.x * Math.abs(_testAxis.x) + extents.y * Math.abs(_testAxis.y) + extents.z * Math.abs(_testAxis.z);\n    // project all 3 vertices of the triangle onto the separating axis\n    const p0 = v0.dot(_testAxis);\n    const p1 = v1.dot(_testAxis);\n    const p2 = v2.dot(_testAxis);\n    // actual test, basically see if either of the most extreme of the triangle points intersects r\n    if (Math.max(-Math.max(p0, p1, p2), Math.min(p0, p1, p2)) > r) {\n      // points of the projected triangle are outside the projected half-length of the aabb\n      // the axis is separating and we can exit\n      return false;\n    }\n  }\n  return true;\n}\nconst _box$3 = /*@__PURE__*/new Box3();\nconst _v1$6 = /*@__PURE__*/new Vector3();\nconst _v2$3 = /*@__PURE__*/new Vector3();\nclass Sphere {\n  constructor(center = new Vector3(), radius = -1) {\n    this.isSphere = true;\n    this.center = center;\n    this.radius = radius;\n  }\n  set(center, radius) {\n    this.center.copy(center);\n    this.radius = radius;\n    return this;\n  }\n  setFromPoints(points, optionalCenter) {\n    const center = this.center;\n    if (optionalCenter !== undefined) {\n      center.copy(optionalCenter);\n    } else {\n      _box$3.setFromPoints(points).getCenter(center);\n    }\n    let maxRadiusSq = 0;\n    for (let i = 0, il = points.length; i < il; i++) {\n      maxRadiusSq = Math.max(maxRadiusSq, center.distanceToSquared(points[i]));\n    }\n    this.radius = Math.sqrt(maxRadiusSq);\n    return this;\n  }\n  copy(sphere) {\n    this.center.copy(sphere.center);\n    this.radius = sphere.radius;\n    return this;\n  }\n  isEmpty() {\n    return this.radius < 0;\n  }\n  makeEmpty() {\n    this.center.set(0, 0, 0);\n    this.radius = -1;\n    return this;\n  }\n  containsPoint(point) {\n    return point.distanceToSquared(this.center) <= this.radius * this.radius;\n  }\n  distanceToPoint(point) {\n    return point.distanceTo(this.center) - this.radius;\n  }\n  intersectsSphere(sphere) {\n    const radiusSum = this.radius + sphere.radius;\n    return sphere.center.distanceToSquared(this.center) <= radiusSum * radiusSum;\n  }\n  intersectsBox(box) {\n    return box.intersectsSphere(this);\n  }\n  intersectsPlane(plane) {\n    return Math.abs(plane.distanceToPoint(this.center)) <= this.radius;\n  }\n  clampPoint(point, target) {\n    const deltaLengthSq = this.center.distanceToSquared(point);\n    target.copy(point);\n    if (deltaLengthSq > this.radius * this.radius) {\n      target.sub(this.center).normalize();\n      target.multiplyScalar(this.radius).add(this.center);\n    }\n    return target;\n  }\n  getBoundingBox(target) {\n    if (this.isEmpty()) {\n      // Empty sphere produces empty bounding box\n      target.makeEmpty();\n      return target;\n    }\n    target.set(this.center, this.center);\n    target.expandByScalar(this.radius);\n    return target;\n  }\n  applyMatrix4(matrix) {\n    this.center.applyMatrix4(matrix);\n    this.radius = this.radius * matrix.getMaxScaleOnAxis();\n    return this;\n  }\n  translate(offset) {\n    this.center.add(offset);\n    return this;\n  }\n  expandByPoint(point) {\n    if (this.isEmpty()) {\n      this.center.copy(point);\n      this.radius = 0;\n      return this;\n    }\n    _v1$6.subVectors(point, this.center);\n    const lengthSq = _v1$6.lengthSq();\n    if (lengthSq > this.radius * this.radius) {\n      // calculate the minimal sphere\n\n      const length = Math.sqrt(lengthSq);\n      const delta = (length - this.radius) * 0.5;\n      this.center.addScaledVector(_v1$6, delta / length);\n      this.radius += delta;\n    }\n    return this;\n  }\n  union(sphere) {\n    if (sphere.isEmpty()) {\n      return this;\n    }\n    if (this.isEmpty()) {\n      this.copy(sphere);\n      return this;\n    }\n    if (this.center.equals(sphere.center) === true) {\n      this.radius = Math.max(this.radius, sphere.radius);\n    } else {\n      _v2$3.subVectors(sphere.center, this.center).setLength(sphere.radius);\n      this.expandByPoint(_v1$6.copy(sphere.center).add(_v2$3));\n      this.expandByPoint(_v1$6.copy(sphere.center).sub(_v2$3));\n    }\n    return this;\n  }\n  equals(sphere) {\n    return sphere.center.equals(this.center) && sphere.radius === this.radius;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n}\nconst _vector$a = /*@__PURE__*/new Vector3();\nconst _segCenter = /*@__PURE__*/new Vector3();\nconst _segDir = /*@__PURE__*/new Vector3();\nconst _diff = /*@__PURE__*/new Vector3();\nconst _edge1 = /*@__PURE__*/new Vector3();\nconst _edge2 = /*@__PURE__*/new Vector3();\nconst _normal$1 = /*@__PURE__*/new Vector3();\nclass Ray {\n  constructor(origin = new Vector3(), direction = new Vector3(0, 0, -1)) {\n    this.origin = origin;\n    this.direction = direction;\n  }\n  set(origin, direction) {\n    this.origin.copy(origin);\n    this.direction.copy(direction);\n    return this;\n  }\n  copy(ray) {\n    this.origin.copy(ray.origin);\n    this.direction.copy(ray.direction);\n    return this;\n  }\n  at(t, target) {\n    return target.copy(this.origin).addScaledVector(this.direction, t);\n  }\n  lookAt(v) {\n    this.direction.copy(v).sub(this.origin).normalize();\n    return this;\n  }\n  recast(t) {\n    this.origin.copy(this.at(t, _vector$a));\n    return this;\n  }\n  closestPointToPoint(point, target) {\n    target.subVectors(point, this.origin);\n    const directionDistance = target.dot(this.direction);\n    if (directionDistance < 0) {\n      return target.copy(this.origin);\n    }\n    return target.copy(this.origin).addScaledVector(this.direction, directionDistance);\n  }\n  distanceToPoint(point) {\n    return Math.sqrt(this.distanceSqToPoint(point));\n  }\n  distanceSqToPoint(point) {\n    const directionDistance = _vector$a.subVectors(point, this.origin).dot(this.direction);\n\n    // point behind the ray\n\n    if (directionDistance < 0) {\n      return this.origin.distanceToSquared(point);\n    }\n    _vector$a.copy(this.origin).addScaledVector(this.direction, directionDistance);\n    return _vector$a.distanceToSquared(point);\n  }\n  distanceSqToSegment(v0, v1, optionalPointOnRay, optionalPointOnSegment) {\n    // from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteDistRaySegment.h\n    // It returns the min distance between the ray and the segment\n    // defined by v0 and v1\n    // It can also set two optional targets :\n    // - The closest point on the ray\n    // - The closest point on the segment\n\n    _segCenter.copy(v0).add(v1).multiplyScalar(0.5);\n    _segDir.copy(v1).sub(v0).normalize();\n    _diff.copy(this.origin).sub(_segCenter);\n    const segExtent = v0.distanceTo(v1) * 0.5;\n    const a01 = -this.direction.dot(_segDir);\n    const b0 = _diff.dot(this.direction);\n    const b1 = -_diff.dot(_segDir);\n    const c = _diff.lengthSq();\n    const det = Math.abs(1 - a01 * a01);\n    let s0, s1, sqrDist, extDet;\n    if (det > 0) {\n      // The ray and segment are not parallel.\n\n      s0 = a01 * b1 - b0;\n      s1 = a01 * b0 - b1;\n      extDet = segExtent * det;\n      if (s0 >= 0) {\n        if (s1 >= -extDet) {\n          if (s1 <= extDet) {\n            // region 0\n            // Minimum at interior points of ray and segment.\n\n            const invDet = 1 / det;\n            s0 *= invDet;\n            s1 *= invDet;\n            sqrDist = s0 * (s0 + a01 * s1 + 2 * b0) + s1 * (a01 * s0 + s1 + 2 * b1) + c;\n          } else {\n            // region 1\n\n            s1 = segExtent;\n            s0 = Math.max(0, -(a01 * s1 + b0));\n            sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;\n          }\n        } else {\n          // region 5\n\n          s1 = -segExtent;\n          s0 = Math.max(0, -(a01 * s1 + b0));\n          sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;\n        }\n      } else {\n        if (s1 <= -extDet) {\n          // region 4\n\n          s0 = Math.max(0, -(-a01 * segExtent + b0));\n          s1 = s0 > 0 ? -segExtent : Math.min(Math.max(-segExtent, -b1), segExtent);\n          sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;\n        } else if (s1 <= extDet) {\n          // region 3\n\n          s0 = 0;\n          s1 = Math.min(Math.max(-segExtent, -b1), segExtent);\n          sqrDist = s1 * (s1 + 2 * b1) + c;\n        } else {\n          // region 2\n\n          s0 = Math.max(0, -(a01 * segExtent + b0));\n          s1 = s0 > 0 ? segExtent : Math.min(Math.max(-segExtent, -b1), segExtent);\n          sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;\n        }\n      }\n    } else {\n      // Ray and segment are parallel.\n\n      s1 = a01 > 0 ? -segExtent : segExtent;\n      s0 = Math.max(0, -(a01 * s1 + b0));\n      sqrDist = -s0 * s0 + s1 * (s1 + 2 * b1) + c;\n    }\n    if (optionalPointOnRay) {\n      optionalPointOnRay.copy(this.origin).addScaledVector(this.direction, s0);\n    }\n    if (optionalPointOnSegment) {\n      optionalPointOnSegment.copy(_segCenter).addScaledVector(_segDir, s1);\n    }\n    return sqrDist;\n  }\n  intersectSphere(sphere, target) {\n    _vector$a.subVectors(sphere.center, this.origin);\n    const tca = _vector$a.dot(this.direction);\n    const d2 = _vector$a.dot(_vector$a) - tca * tca;\n    const radius2 = sphere.radius * sphere.radius;\n    if (d2 > radius2) return null;\n    const thc = Math.sqrt(radius2 - d2);\n\n    // t0 = first intersect point - entrance on front of sphere\n    const t0 = tca - thc;\n\n    // t1 = second intersect point - exit point on back of sphere\n    const t1 = tca + thc;\n\n    // test to see if t1 is behind the ray - if so, return null\n    if (t1 < 0) return null;\n\n    // test to see if t0 is behind the ray:\n    // if it is, the ray is inside the sphere, so return the second exit point scaled by t1,\n    // in order to always return an intersect point that is in front of the ray.\n    if (t0 < 0) return this.at(t1, target);\n\n    // else t0 is in front of the ray, so return the first collision point scaled by t0\n    return this.at(t0, target);\n  }\n  intersectsSphere(sphere) {\n    return this.distanceSqToPoint(sphere.center) <= sphere.radius * sphere.radius;\n  }\n  distanceToPlane(plane) {\n    const denominator = plane.normal.dot(this.direction);\n    if (denominator === 0) {\n      // line is coplanar, return origin\n      if (plane.distanceToPoint(this.origin) === 0) {\n        return 0;\n      }\n\n      // Null is preferable to undefined since undefined means.... it is undefined\n\n      return null;\n    }\n    const t = -(this.origin.dot(plane.normal) + plane.constant) / denominator;\n\n    // Return if the ray never intersects the plane\n\n    return t >= 0 ? t : null;\n  }\n  intersectPlane(plane, target) {\n    const t = this.distanceToPlane(plane);\n    if (t === null) {\n      return null;\n    }\n    return this.at(t, target);\n  }\n  intersectsPlane(plane) {\n    // check if the ray lies on the plane first\n\n    const distToPoint = plane.distanceToPoint(this.origin);\n    if (distToPoint === 0) {\n      return true;\n    }\n    const denominator = plane.normal.dot(this.direction);\n    if (denominator * distToPoint < 0) {\n      return true;\n    }\n\n    // ray origin is behind the plane (and is pointing behind it)\n\n    return false;\n  }\n  intersectBox(box, target) {\n    let tmin, tmax, tymin, tymax, tzmin, tzmax;\n    const invdirx = 1 / this.direction.x,\n      invdiry = 1 / this.direction.y,\n      invdirz = 1 / this.direction.z;\n    const origin = this.origin;\n    if (invdirx >= 0) {\n      tmin = (box.min.x - origin.x) * invdirx;\n      tmax = (box.max.x - origin.x) * invdirx;\n    } else {\n      tmin = (box.max.x - origin.x) * invdirx;\n      tmax = (box.min.x - origin.x) * invdirx;\n    }\n    if (invdiry >= 0) {\n      tymin = (box.min.y - origin.y) * invdiry;\n      tymax = (box.max.y - origin.y) * invdiry;\n    } else {\n      tymin = (box.max.y - origin.y) * invdiry;\n      tymax = (box.min.y - origin.y) * invdiry;\n    }\n    if (tmin > tymax || tymin > tmax) return null;\n    if (tymin > tmin || isNaN(tmin)) tmin = tymin;\n    if (tymax < tmax || isNaN(tmax)) tmax = tymax;\n    if (invdirz >= 0) {\n      tzmin = (box.min.z - origin.z) * invdirz;\n      tzmax = (box.max.z - origin.z) * invdirz;\n    } else {\n      tzmin = (box.max.z - origin.z) * invdirz;\n      tzmax = (box.min.z - origin.z) * invdirz;\n    }\n    if (tmin > tzmax || tzmin > tmax) return null;\n    if (tzmin > tmin || tmin !== tmin) tmin = tzmin;\n    if (tzmax < tmax || tmax !== tmax) tmax = tzmax;\n\n    //return point closest to the ray (positive side)\n\n    if (tmax < 0) return null;\n    return this.at(tmin >= 0 ? tmin : tmax, target);\n  }\n  intersectsBox(box) {\n    return this.intersectBox(box, _vector$a) !== null;\n  }\n  intersectTriangle(a, b, c, backfaceCulling, target) {\n    // Compute the offset origin, edges, and normal.\n\n    // from https://github.com/pmjoniak/GeometricTools/blob/master/GTEngine/Include/Mathematics/GteIntrRay3Triangle3.h\n\n    _edge1.subVectors(b, a);\n    _edge2.subVectors(c, a);\n    _normal$1.crossVectors(_edge1, _edge2);\n\n    // Solve Q + t*D = b1*E1 + b2*E2 (Q = kDiff, D = ray direction,\n    // E1 = kEdge1, E2 = kEdge2, N = Cross(E1,E2)) by\n    //   |Dot(D,N)|*b1 = sign(Dot(D,N))*Dot(D,Cross(Q,E2))\n    //   |Dot(D,N)|*b2 = sign(Dot(D,N))*Dot(D,Cross(E1,Q))\n    //   |Dot(D,N)|*t = -sign(Dot(D,N))*Dot(Q,N)\n    let DdN = this.direction.dot(_normal$1);\n    let sign;\n    if (DdN > 0) {\n      if (backfaceCulling) return null;\n      sign = 1;\n    } else if (DdN < 0) {\n      sign = -1;\n      DdN = -DdN;\n    } else {\n      return null;\n    }\n    _diff.subVectors(this.origin, a);\n    const DdQxE2 = sign * this.direction.dot(_edge2.crossVectors(_diff, _edge2));\n\n    // b1 < 0, no intersection\n    if (DdQxE2 < 0) {\n      return null;\n    }\n    const DdE1xQ = sign * this.direction.dot(_edge1.cross(_diff));\n\n    // b2 < 0, no intersection\n    if (DdE1xQ < 0) {\n      return null;\n    }\n\n    // b1+b2 > 1, no intersection\n    if (DdQxE2 + DdE1xQ > DdN) {\n      return null;\n    }\n\n    // Line intersects triangle, check if ray does.\n    const QdN = -sign * _diff.dot(_normal$1);\n\n    // t < 0, no intersection\n    if (QdN < 0) {\n      return null;\n    }\n\n    // Ray intersects triangle.\n    return this.at(QdN / DdN, target);\n  }\n  applyMatrix4(matrix4) {\n    this.origin.applyMatrix4(matrix4);\n    this.direction.transformDirection(matrix4);\n    return this;\n  }\n  equals(ray) {\n    return ray.origin.equals(this.origin) && ray.direction.equals(this.direction);\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n}\nclass Matrix4 {\n  constructor(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44) {\n    Matrix4.prototype.isMatrix4 = true;\n    this.elements = [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1];\n    if (n11 !== undefined) {\n      this.set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44);\n    }\n  }\n  set(n11, n12, n13, n14, n21, n22, n23, n24, n31, n32, n33, n34, n41, n42, n43, n44) {\n    const te = this.elements;\n    te[0] = n11;\n    te[4] = n12;\n    te[8] = n13;\n    te[12] = n14;\n    te[1] = n21;\n    te[5] = n22;\n    te[9] = n23;\n    te[13] = n24;\n    te[2] = n31;\n    te[6] = n32;\n    te[10] = n33;\n    te[14] = n34;\n    te[3] = n41;\n    te[7] = n42;\n    te[11] = n43;\n    te[15] = n44;\n    return this;\n  }\n  identity() {\n    this.set(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);\n    return this;\n  }\n  clone() {\n    return new Matrix4().fromArray(this.elements);\n  }\n  copy(m) {\n    const te = this.elements;\n    const me = m.elements;\n    te[0] = me[0];\n    te[1] = me[1];\n    te[2] = me[2];\n    te[3] = me[3];\n    te[4] = me[4];\n    te[5] = me[5];\n    te[6] = me[6];\n    te[7] = me[7];\n    te[8] = me[8];\n    te[9] = me[9];\n    te[10] = me[10];\n    te[11] = me[11];\n    te[12] = me[12];\n    te[13] = me[13];\n    te[14] = me[14];\n    te[15] = me[15];\n    return this;\n  }\n  copyPosition(m) {\n    const te = this.elements,\n      me = m.elements;\n    te[12] = me[12];\n    te[13] = me[13];\n    te[14] = me[14];\n    return this;\n  }\n  setFromMatrix3(m) {\n    const me = m.elements;\n    this.set(me[0], me[3], me[6], 0, me[1], me[4], me[7], 0, me[2], me[5], me[8], 0, 0, 0, 0, 1);\n    return this;\n  }\n  extractBasis(xAxis, yAxis, zAxis) {\n    xAxis.setFromMatrixColumn(this, 0);\n    yAxis.setFromMatrixColumn(this, 1);\n    zAxis.setFromMatrixColumn(this, 2);\n    return this;\n  }\n  makeBasis(xAxis, yAxis, zAxis) {\n    this.set(xAxis.x, yAxis.x, zAxis.x, 0, xAxis.y, yAxis.y, zAxis.y, 0, xAxis.z, yAxis.z, zAxis.z, 0, 0, 0, 0, 1);\n    return this;\n  }\n  extractRotation(m) {\n    // this method does not support reflection matrices\n\n    const te = this.elements;\n    const me = m.elements;\n    const scaleX = 1 / _v1$5.setFromMatrixColumn(m, 0).length();\n    const scaleY = 1 / _v1$5.setFromMatrixColumn(m, 1).length();\n    const scaleZ = 1 / _v1$5.setFromMatrixColumn(m, 2).length();\n    te[0] = me[0] * scaleX;\n    te[1] = me[1] * scaleX;\n    te[2] = me[2] * scaleX;\n    te[3] = 0;\n    te[4] = me[4] * scaleY;\n    te[5] = me[5] * scaleY;\n    te[6] = me[6] * scaleY;\n    te[7] = 0;\n    te[8] = me[8] * scaleZ;\n    te[9] = me[9] * scaleZ;\n    te[10] = me[10] * scaleZ;\n    te[11] = 0;\n    te[12] = 0;\n    te[13] = 0;\n    te[14] = 0;\n    te[15] = 1;\n    return this;\n  }\n  makeRotationFromEuler(euler) {\n    const te = this.elements;\n    const x = euler.x,\n      y = euler.y,\n      z = euler.z;\n    const a = Math.cos(x),\n      b = Math.sin(x);\n    const c = Math.cos(y),\n      d = Math.sin(y);\n    const e = Math.cos(z),\n      f = Math.sin(z);\n    if (euler.order === 'XYZ') {\n      const ae = a * e,\n        af = a * f,\n        be = b * e,\n        bf = b * f;\n      te[0] = c * e;\n      te[4] = -c * f;\n      te[8] = d;\n      te[1] = af + be * d;\n      te[5] = ae - bf * d;\n      te[9] = -b * c;\n      te[2] = bf - ae * d;\n      te[6] = be + af * d;\n      te[10] = a * c;\n    } else if (euler.order === 'YXZ') {\n      const ce = c * e,\n        cf = c * f,\n        de = d * e,\n        df = d * f;\n      te[0] = ce + df * b;\n      te[4] = de * b - cf;\n      te[8] = a * d;\n      te[1] = a * f;\n      te[5] = a * e;\n      te[9] = -b;\n      te[2] = cf * b - de;\n      te[6] = df + ce * b;\n      te[10] = a * c;\n    } else if (euler.order === 'ZXY') {\n      const ce = c * e,\n        cf = c * f,\n        de = d * e,\n        df = d * f;\n      te[0] = ce - df * b;\n      te[4] = -a * f;\n      te[8] = de + cf * b;\n      te[1] = cf + de * b;\n      te[5] = a * e;\n      te[9] = df - ce * b;\n      te[2] = -a * d;\n      te[6] = b;\n      te[10] = a * c;\n    } else if (euler.order === 'ZYX') {\n      const ae = a * e,\n        af = a * f,\n        be = b * e,\n        bf = b * f;\n      te[0] = c * e;\n      te[4] = be * d - af;\n      te[8] = ae * d + bf;\n      te[1] = c * f;\n      te[5] = bf * d + ae;\n      te[9] = af * d - be;\n      te[2] = -d;\n      te[6] = b * c;\n      te[10] = a * c;\n    } else if (euler.order === 'YZX') {\n      const ac = a * c,\n        ad = a * d,\n        bc = b * c,\n        bd = b * d;\n      te[0] = c * e;\n      te[4] = bd - ac * f;\n      te[8] = bc * f + ad;\n      te[1] = f;\n      te[5] = a * e;\n      te[9] = -b * e;\n      te[2] = -d * e;\n      te[6] = ad * f + bc;\n      te[10] = ac - bd * f;\n    } else if (euler.order === 'XZY') {\n      const ac = a * c,\n        ad = a * d,\n        bc = b * c,\n        bd = b * d;\n      te[0] = c * e;\n      te[4] = -f;\n      te[8] = d * e;\n      te[1] = ac * f + bd;\n      te[5] = a * e;\n      te[9] = ad * f - bc;\n      te[2] = bc * f - ad;\n      te[6] = b * e;\n      te[10] = bd * f + ac;\n    }\n\n    // bottom row\n    te[3] = 0;\n    te[7] = 0;\n    te[11] = 0;\n\n    // last column\n    te[12] = 0;\n    te[13] = 0;\n    te[14] = 0;\n    te[15] = 1;\n    return this;\n  }\n  makeRotationFromQuaternion(q) {\n    return this.compose(_zero, q, _one);\n  }\n  lookAt(eye, target, up) {\n    const te = this.elements;\n    _z.subVectors(eye, target);\n    if (_z.lengthSq() === 0) {\n      // eye and target are in the same position\n\n      _z.z = 1;\n    }\n    _z.normalize();\n    _x.crossVectors(up, _z);\n    if (_x.lengthSq() === 0) {\n      // up and z are parallel\n\n      if (Math.abs(up.z) === 1) {\n        _z.x += 0.0001;\n      } else {\n        _z.z += 0.0001;\n      }\n      _z.normalize();\n      _x.crossVectors(up, _z);\n    }\n    _x.normalize();\n    _y.crossVectors(_z, _x);\n    te[0] = _x.x;\n    te[4] = _y.x;\n    te[8] = _z.x;\n    te[1] = _x.y;\n    te[5] = _y.y;\n    te[9] = _z.y;\n    te[2] = _x.z;\n    te[6] = _y.z;\n    te[10] = _z.z;\n    return this;\n  }\n  multiply(m) {\n    return this.multiplyMatrices(this, m);\n  }\n  premultiply(m) {\n    return this.multiplyMatrices(m, this);\n  }\n  multiplyMatrices(a, b) {\n    const ae = a.elements;\n    const be = b.elements;\n    const te = this.elements;\n    const a11 = ae[0],\n      a12 = ae[4],\n      a13 = ae[8],\n      a14 = ae[12];\n    const a21 = ae[1],\n      a22 = ae[5],\n      a23 = ae[9],\n      a24 = ae[13];\n    const a31 = ae[2],\n      a32 = ae[6],\n      a33 = ae[10],\n      a34 = ae[14];\n    const a41 = ae[3],\n      a42 = ae[7],\n      a43 = ae[11],\n      a44 = ae[15];\n    const b11 = be[0],\n      b12 = be[4],\n      b13 = be[8],\n      b14 = be[12];\n    const b21 = be[1],\n      b22 = be[5],\n      b23 = be[9],\n      b24 = be[13];\n    const b31 = be[2],\n      b32 = be[6],\n      b33 = be[10],\n      b34 = be[14];\n    const b41 = be[3],\n      b42 = be[7],\n      b43 = be[11],\n      b44 = be[15];\n    te[0] = a11 * b11 + a12 * b21 + a13 * b31 + a14 * b41;\n    te[4] = a11 * b12 + a12 * b22 + a13 * b32 + a14 * b42;\n    te[8] = a11 * b13 + a12 * b23 + a13 * b33 + a14 * b43;\n    te[12] = a11 * b14 + a12 * b24 + a13 * b34 + a14 * b44;\n    te[1] = a21 * b11 + a22 * b21 + a23 * b31 + a24 * b41;\n    te[5] = a21 * b12 + a22 * b22 + a23 * b32 + a24 * b42;\n    te[9] = a21 * b13 + a22 * b23 + a23 * b33 + a24 * b43;\n    te[13] = a21 * b14 + a22 * b24 + a23 * b34 + a24 * b44;\n    te[2] = a31 * b11 + a32 * b21 + a33 * b31 + a34 * b41;\n    te[6] = a31 * b12 + a32 * b22 + a33 * b32 + a34 * b42;\n    te[10] = a31 * b13 + a32 * b23 + a33 * b33 + a34 * b43;\n    te[14] = a31 * b14 + a32 * b24 + a33 * b34 + a34 * b44;\n    te[3] = a41 * b11 + a42 * b21 + a43 * b31 + a44 * b41;\n    te[7] = a41 * b12 + a42 * b22 + a43 * b32 + a44 * b42;\n    te[11] = a41 * b13 + a42 * b23 + a43 * b33 + a44 * b43;\n    te[15] = a41 * b14 + a42 * b24 + a43 * b34 + a44 * b44;\n    return this;\n  }\n  multiplyScalar(s) {\n    const te = this.elements;\n    te[0] *= s;\n    te[4] *= s;\n    te[8] *= s;\n    te[12] *= s;\n    te[1] *= s;\n    te[5] *= s;\n    te[9] *= s;\n    te[13] *= s;\n    te[2] *= s;\n    te[6] *= s;\n    te[10] *= s;\n    te[14] *= s;\n    te[3] *= s;\n    te[7] *= s;\n    te[11] *= s;\n    te[15] *= s;\n    return this;\n  }\n  determinant() {\n    const te = this.elements;\n    const n11 = te[0],\n      n12 = te[4],\n      n13 = te[8],\n      n14 = te[12];\n    const n21 = te[1],\n      n22 = te[5],\n      n23 = te[9],\n      n24 = te[13];\n    const n31 = te[2],\n      n32 = te[6],\n      n33 = te[10],\n      n34 = te[14];\n    const n41 = te[3],\n      n42 = te[7],\n      n43 = te[11],\n      n44 = te[15];\n\n    //TODO: make this more efficient\n    //( based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm )\n\n    return n41 * (+n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34) + n42 * (+n11 * n23 * n34 - n11 * n24 * n33 + n14 * n21 * n33 - n13 * n21 * n34 + n13 * n24 * n31 - n14 * n23 * n31) + n43 * (+n11 * n24 * n32 - n11 * n22 * n34 - n14 * n21 * n32 + n12 * n21 * n34 + n14 * n22 * n31 - n12 * n24 * n31) + n44 * (-n13 * n22 * n31 - n11 * n23 * n32 + n11 * n22 * n33 + n13 * n21 * n32 - n12 * n21 * n33 + n12 * n23 * n31);\n  }\n  transpose() {\n    const te = this.elements;\n    let tmp;\n    tmp = te[1];\n    te[1] = te[4];\n    te[4] = tmp;\n    tmp = te[2];\n    te[2] = te[8];\n    te[8] = tmp;\n    tmp = te[6];\n    te[6] = te[9];\n    te[9] = tmp;\n    tmp = te[3];\n    te[3] = te[12];\n    te[12] = tmp;\n    tmp = te[7];\n    te[7] = te[13];\n    te[13] = tmp;\n    tmp = te[11];\n    te[11] = te[14];\n    te[14] = tmp;\n    return this;\n  }\n  setPosition(x, y, z) {\n    const te = this.elements;\n    if (x.isVector3) {\n      te[12] = x.x;\n      te[13] = x.y;\n      te[14] = x.z;\n    } else {\n      te[12] = x;\n      te[13] = y;\n      te[14] = z;\n    }\n    return this;\n  }\n  invert() {\n    // based on http://www.euclideanspace.com/maths/algebra/matrix/functions/inverse/fourD/index.htm\n    const te = this.elements,\n      n11 = te[0],\n      n21 = te[1],\n      n31 = te[2],\n      n41 = te[3],\n      n12 = te[4],\n      n22 = te[5],\n      n32 = te[6],\n      n42 = te[7],\n      n13 = te[8],\n      n23 = te[9],\n      n33 = te[10],\n      n43 = te[11],\n      n14 = te[12],\n      n24 = te[13],\n      n34 = te[14],\n      n44 = te[15],\n      t11 = n23 * n34 * n42 - n24 * n33 * n42 + n24 * n32 * n43 - n22 * n34 * n43 - n23 * n32 * n44 + n22 * n33 * n44,\n      t12 = n14 * n33 * n42 - n13 * n34 * n42 - n14 * n32 * n43 + n12 * n34 * n43 + n13 * n32 * n44 - n12 * n33 * n44,\n      t13 = n13 * n24 * n42 - n14 * n23 * n42 + n14 * n22 * n43 - n12 * n24 * n43 - n13 * n22 * n44 + n12 * n23 * n44,\n      t14 = n14 * n23 * n32 - n13 * n24 * n32 - n14 * n22 * n33 + n12 * n24 * n33 + n13 * n22 * n34 - n12 * n23 * n34;\n    const det = n11 * t11 + n21 * t12 + n31 * t13 + n41 * t14;\n    if (det === 0) return this.set(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0);\n    const detInv = 1 / det;\n    te[0] = t11 * detInv;\n    te[1] = (n24 * n33 * n41 - n23 * n34 * n41 - n24 * n31 * n43 + n21 * n34 * n43 + n23 * n31 * n44 - n21 * n33 * n44) * detInv;\n    te[2] = (n22 * n34 * n41 - n24 * n32 * n41 + n24 * n31 * n42 - n21 * n34 * n42 - n22 * n31 * n44 + n21 * n32 * n44) * detInv;\n    te[3] = (n23 * n32 * n41 - n22 * n33 * n41 - n23 * n31 * n42 + n21 * n33 * n42 + n22 * n31 * n43 - n21 * n32 * n43) * detInv;\n    te[4] = t12 * detInv;\n    te[5] = (n13 * n34 * n41 - n14 * n33 * n41 + n14 * n31 * n43 - n11 * n34 * n43 - n13 * n31 * n44 + n11 * n33 * n44) * detInv;\n    te[6] = (n14 * n32 * n41 - n12 * n34 * n41 - n14 * n31 * n42 + n11 * n34 * n42 + n12 * n31 * n44 - n11 * n32 * n44) * detInv;\n    te[7] = (n12 * n33 * n41 - n13 * n32 * n41 + n13 * n31 * n42 - n11 * n33 * n42 - n12 * n31 * n43 + n11 * n32 * n43) * detInv;\n    te[8] = t13 * detInv;\n    te[9] = (n14 * n23 * n41 - n13 * n24 * n41 - n14 * n21 * n43 + n11 * n24 * n43 + n13 * n21 * n44 - n11 * n23 * n44) * detInv;\n    te[10] = (n12 * n24 * n41 - n14 * n22 * n41 + n14 * n21 * n42 - n11 * n24 * n42 - n12 * n21 * n44 + n11 * n22 * n44) * detInv;\n    te[11] = (n13 * n22 * n41 - n12 * n23 * n41 - n13 * n21 * n42 + n11 * n23 * n42 + n12 * n21 * n43 - n11 * n22 * n43) * detInv;\n    te[12] = t14 * detInv;\n    te[13] = (n13 * n24 * n31 - n14 * n23 * n31 + n14 * n21 * n33 - n11 * n24 * n33 - n13 * n21 * n34 + n11 * n23 * n34) * detInv;\n    te[14] = (n14 * n22 * n31 - n12 * n24 * n31 - n14 * n21 * n32 + n11 * n24 * n32 + n12 * n21 * n34 - n11 * n22 * n34) * detInv;\n    te[15] = (n12 * n23 * n31 - n13 * n22 * n31 + n13 * n21 * n32 - n11 * n23 * n32 - n12 * n21 * n33 + n11 * n22 * n33) * detInv;\n    return this;\n  }\n  scale(v) {\n    const te = this.elements;\n    const x = v.x,\n      y = v.y,\n      z = v.z;\n    te[0] *= x;\n    te[4] *= y;\n    te[8] *= z;\n    te[1] *= x;\n    te[5] *= y;\n    te[9] *= z;\n    te[2] *= x;\n    te[6] *= y;\n    te[10] *= z;\n    te[3] *= x;\n    te[7] *= y;\n    te[11] *= z;\n    return this;\n  }\n  getMaxScaleOnAxis() {\n    const te = this.elements;\n    const scaleXSq = te[0] * te[0] + te[1] * te[1] + te[2] * te[2];\n    const scaleYSq = te[4] * te[4] + te[5] * te[5] + te[6] * te[6];\n    const scaleZSq = te[8] * te[8] + te[9] * te[9] + te[10] * te[10];\n    return Math.sqrt(Math.max(scaleXSq, scaleYSq, scaleZSq));\n  }\n  makeTranslation(x, y, z) {\n    if (x.isVector3) {\n      this.set(1, 0, 0, x.x, 0, 1, 0, x.y, 0, 0, 1, x.z, 0, 0, 0, 1);\n    } else {\n      this.set(1, 0, 0, x, 0, 1, 0, y, 0, 0, 1, z, 0, 0, 0, 1);\n    }\n    return this;\n  }\n  makeRotationX(theta) {\n    const c = Math.cos(theta),\n      s = Math.sin(theta);\n    this.set(1, 0, 0, 0, 0, c, -s, 0, 0, s, c, 0, 0, 0, 0, 1);\n    return this;\n  }\n  makeRotationY(theta) {\n    const c = Math.cos(theta),\n      s = Math.sin(theta);\n    this.set(c, 0, s, 0, 0, 1, 0, 0, -s, 0, c, 0, 0, 0, 0, 1);\n    return this;\n  }\n  makeRotationZ(theta) {\n    const c = Math.cos(theta),\n      s = Math.sin(theta);\n    this.set(c, -s, 0, 0, s, c, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1);\n    return this;\n  }\n  makeRotationAxis(axis, angle) {\n    // Based on http://www.gamedev.net/reference/articles/article1199.asp\n\n    const c = Math.cos(angle);\n    const s = Math.sin(angle);\n    const t = 1 - c;\n    const x = axis.x,\n      y = axis.y,\n      z = axis.z;\n    const tx = t * x,\n      ty = t * y;\n    this.set(tx * x + c, tx * y - s * z, tx * z + s * y, 0, tx * y + s * z, ty * y + c, ty * z - s * x, 0, tx * z - s * y, ty * z + s * x, t * z * z + c, 0, 0, 0, 0, 1);\n    return this;\n  }\n  makeScale(x, y, z) {\n    this.set(x, 0, 0, 0, 0, y, 0, 0, 0, 0, z, 0, 0, 0, 0, 1);\n    return this;\n  }\n  makeShear(xy, xz, yx, yz, zx, zy) {\n    this.set(1, yx, zx, 0, xy, 1, zy, 0, xz, yz, 1, 0, 0, 0, 0, 1);\n    return this;\n  }\n  compose(position, quaternion, scale) {\n    const te = this.elements;\n    const x = quaternion._x,\n      y = quaternion._y,\n      z = quaternion._z,\n      w = quaternion._w;\n    const x2 = x + x,\n      y2 = y + y,\n      z2 = z + z;\n    const xx = x * x2,\n      xy = x * y2,\n      xz = x * z2;\n    const yy = y * y2,\n      yz = y * z2,\n      zz = z * z2;\n    const wx = w * x2,\n      wy = w * y2,\n      wz = w * z2;\n    const sx = scale.x,\n      sy = scale.y,\n      sz = scale.z;\n    te[0] = (1 - (yy + zz)) * sx;\n    te[1] = (xy + wz) * sx;\n    te[2] = (xz - wy) * sx;\n    te[3] = 0;\n    te[4] = (xy - wz) * sy;\n    te[5] = (1 - (xx + zz)) * sy;\n    te[6] = (yz + wx) * sy;\n    te[7] = 0;\n    te[8] = (xz + wy) * sz;\n    te[9] = (yz - wx) * sz;\n    te[10] = (1 - (xx + yy)) * sz;\n    te[11] = 0;\n    te[12] = position.x;\n    te[13] = position.y;\n    te[14] = position.z;\n    te[15] = 1;\n    return this;\n  }\n  decompose(position, quaternion, scale) {\n    const te = this.elements;\n    let sx = _v1$5.set(te[0], te[1], te[2]).length();\n    const sy = _v1$5.set(te[4], te[5], te[6]).length();\n    const sz = _v1$5.set(te[8], te[9], te[10]).length();\n\n    // if determine is negative, we need to invert one scale\n    const det = this.determinant();\n    if (det < 0) sx = -sx;\n    position.x = te[12];\n    position.y = te[13];\n    position.z = te[14];\n\n    // scale the rotation part\n    _m1$4.copy(this);\n    const invSX = 1 / sx;\n    const invSY = 1 / sy;\n    const invSZ = 1 / sz;\n    _m1$4.elements[0] *= invSX;\n    _m1$4.elements[1] *= invSX;\n    _m1$4.elements[2] *= invSX;\n    _m1$4.elements[4] *= invSY;\n    _m1$4.elements[5] *= invSY;\n    _m1$4.elements[6] *= invSY;\n    _m1$4.elements[8] *= invSZ;\n    _m1$4.elements[9] *= invSZ;\n    _m1$4.elements[10] *= invSZ;\n    quaternion.setFromRotationMatrix(_m1$4);\n    scale.x = sx;\n    scale.y = sy;\n    scale.z = sz;\n    return this;\n  }\n  makePerspective(left, right, top, bottom, near, far, coordinateSystem = WebGLCoordinateSystem) {\n    const te = this.elements;\n    const x = 2 * near / (right - left);\n    const y = 2 * near / (top - bottom);\n    const a = (right + left) / (right - left);\n    const b = (top + bottom) / (top - bottom);\n    let c, d;\n    if (coordinateSystem === WebGLCoordinateSystem) {\n      c = -(far + near) / (far - near);\n      d = -2 * far * near / (far - near);\n    } else if (coordinateSystem === WebGPUCoordinateSystem) {\n      c = -far / (far - near);\n      d = -far * near / (far - near);\n    } else {\n      throw new Error('THREE.Matrix4.makePerspective(): Invalid coordinate system: ' + coordinateSystem);\n    }\n    te[0] = x;\n    te[4] = 0;\n    te[8] = a;\n    te[12] = 0;\n    te[1] = 0;\n    te[5] = y;\n    te[9] = b;\n    te[13] = 0;\n    te[2] = 0;\n    te[6] = 0;\n    te[10] = c;\n    te[14] = d;\n    te[3] = 0;\n    te[7] = 0;\n    te[11] = -1;\n    te[15] = 0;\n    return this;\n  }\n  makeOrthographic(left, right, top, bottom, near, far, coordinateSystem = WebGLCoordinateSystem) {\n    const te = this.elements;\n    const w = 1.0 / (right - left);\n    const h = 1.0 / (top - bottom);\n    const p = 1.0 / (far - near);\n    const x = (right + left) * w;\n    const y = (top + bottom) * h;\n    let z, zInv;\n    if (coordinateSystem === WebGLCoordinateSystem) {\n      z = (far + near) * p;\n      zInv = -2 * p;\n    } else if (coordinateSystem === WebGPUCoordinateSystem) {\n      z = near * p;\n      zInv = -1 * p;\n    } else {\n      throw new Error('THREE.Matrix4.makeOrthographic(): Invalid coordinate system: ' + coordinateSystem);\n    }\n    te[0] = 2 * w;\n    te[4] = 0;\n    te[8] = 0;\n    te[12] = -x;\n    te[1] = 0;\n    te[5] = 2 * h;\n    te[9] = 0;\n    te[13] = -y;\n    te[2] = 0;\n    te[6] = 0;\n    te[10] = zInv;\n    te[14] = -z;\n    te[3] = 0;\n    te[7] = 0;\n    te[11] = 0;\n    te[15] = 1;\n    return this;\n  }\n  equals(matrix) {\n    const te = this.elements;\n    const me = matrix.elements;\n    for (let i = 0; i < 16; i++) {\n      if (te[i] !== me[i]) return false;\n    }\n    return true;\n  }\n  fromArray(array, offset = 0) {\n    for (let i = 0; i < 16; i++) {\n      this.elements[i] = array[i + offset];\n    }\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    const te = this.elements;\n    array[offset] = te[0];\n    array[offset + 1] = te[1];\n    array[offset + 2] = te[2];\n    array[offset + 3] = te[3];\n    array[offset + 4] = te[4];\n    array[offset + 5] = te[5];\n    array[offset + 6] = te[6];\n    array[offset + 7] = te[7];\n    array[offset + 8] = te[8];\n    array[offset + 9] = te[9];\n    array[offset + 10] = te[10];\n    array[offset + 11] = te[11];\n    array[offset + 12] = te[12];\n    array[offset + 13] = te[13];\n    array[offset + 14] = te[14];\n    array[offset + 15] = te[15];\n    return array;\n  }\n}\nconst _v1$5 = /*@__PURE__*/new Vector3();\nconst _m1$4 = /*@__PURE__*/new Matrix4();\nconst _zero = /*@__PURE__*/new Vector3(0, 0, 0);\nconst _one = /*@__PURE__*/new Vector3(1, 1, 1);\nconst _x = /*@__PURE__*/new Vector3();\nconst _y = /*@__PURE__*/new Vector3();\nconst _z = /*@__PURE__*/new Vector3();\nconst _matrix$2 = /*@__PURE__*/new Matrix4();\nconst _quaternion$3 = /*@__PURE__*/new Quaternion();\nclass Euler {\n  constructor(x = 0, y = 0, z = 0, order = Euler.DEFAULT_ORDER) {\n    this.isEuler = true;\n    this._x = x;\n    this._y = y;\n    this._z = z;\n    this._order = order;\n  }\n  get x() {\n    return this._x;\n  }\n  set x(value) {\n    this._x = value;\n    this._onChangeCallback();\n  }\n  get y() {\n    return this._y;\n  }\n  set y(value) {\n    this._y = value;\n    this._onChangeCallback();\n  }\n  get z() {\n    return this._z;\n  }\n  set z(value) {\n    this._z = value;\n    this._onChangeCallback();\n  }\n  get order() {\n    return this._order;\n  }\n  set order(value) {\n    this._order = value;\n    this._onChangeCallback();\n  }\n  set(x, y, z, order = this._order) {\n    this._x = x;\n    this._y = y;\n    this._z = z;\n    this._order = order;\n    this._onChangeCallback();\n    return this;\n  }\n  clone() {\n    return new this.constructor(this._x, this._y, this._z, this._order);\n  }\n  copy(euler) {\n    this._x = euler._x;\n    this._y = euler._y;\n    this._z = euler._z;\n    this._order = euler._order;\n    this._onChangeCallback();\n    return this;\n  }\n  setFromRotationMatrix(m, order = this._order, update = true) {\n    // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n    const te = m.elements;\n    const m11 = te[0],\n      m12 = te[4],\n      m13 = te[8];\n    const m21 = te[1],\n      m22 = te[5],\n      m23 = te[9];\n    const m31 = te[2],\n      m32 = te[6],\n      m33 = te[10];\n    switch (order) {\n      case 'XYZ':\n        this._y = Math.asin(clamp$1(m13, -1, 1));\n        if (Math.abs(m13) < 0.9999999) {\n          this._x = Math.atan2(-m23, m33);\n          this._z = Math.atan2(-m12, m11);\n        } else {\n          this._x = Math.atan2(m32, m22);\n          this._z = 0;\n        }\n        break;\n      case 'YXZ':\n        this._x = Math.asin(-clamp$1(m23, -1, 1));\n        if (Math.abs(m23) < 0.9999999) {\n          this._y = Math.atan2(m13, m33);\n          this._z = Math.atan2(m21, m22);\n        } else {\n          this._y = Math.atan2(-m31, m11);\n          this._z = 0;\n        }\n        break;\n      case 'ZXY':\n        this._x = Math.asin(clamp$1(m32, -1, 1));\n        if (Math.abs(m32) < 0.9999999) {\n          this._y = Math.atan2(-m31, m33);\n          this._z = Math.atan2(-m12, m22);\n        } else {\n          this._y = 0;\n          this._z = Math.atan2(m21, m11);\n        }\n        break;\n      case 'ZYX':\n        this._y = Math.asin(-clamp$1(m31, -1, 1));\n        if (Math.abs(m31) < 0.9999999) {\n          this._x = Math.atan2(m32, m33);\n          this._z = Math.atan2(m21, m11);\n        } else {\n          this._x = 0;\n          this._z = Math.atan2(-m12, m22);\n        }\n        break;\n      case 'YZX':\n        this._z = Math.asin(clamp$1(m21, -1, 1));\n        if (Math.abs(m21) < 0.9999999) {\n          this._x = Math.atan2(-m23, m22);\n          this._y = Math.atan2(-m31, m11);\n        } else {\n          this._x = 0;\n          this._y = Math.atan2(m13, m33);\n        }\n        break;\n      case 'XZY':\n        this._z = Math.asin(-clamp$1(m12, -1, 1));\n        if (Math.abs(m12) < 0.9999999) {\n          this._x = Math.atan2(m32, m22);\n          this._y = Math.atan2(m13, m11);\n        } else {\n          this._x = Math.atan2(-m23, m33);\n          this._y = 0;\n        }\n        break;\n      default:\n        console.warn('THREE.Euler: .setFromRotationMatrix() encountered an unknown order: ' + order);\n    }\n    this._order = order;\n    if (update === true) this._onChangeCallback();\n    return this;\n  }\n  setFromQuaternion(q, order, update) {\n    _matrix$2.makeRotationFromQuaternion(q);\n    return this.setFromRotationMatrix(_matrix$2, order, update);\n  }\n  setFromVector3(v, order = this._order) {\n    return this.set(v.x, v.y, v.z, order);\n  }\n  reorder(newOrder) {\n    // WARNING: this discards revolution information -bhouston\n\n    _quaternion$3.setFromEuler(this);\n    return this.setFromQuaternion(_quaternion$3, newOrder);\n  }\n  equals(euler) {\n    return euler._x === this._x && euler._y === this._y && euler._z === this._z && euler._order === this._order;\n  }\n  fromArray(array) {\n    this._x = array[0];\n    this._y = array[1];\n    this._z = array[2];\n    if (array[3] !== undefined) this._order = array[3];\n    this._onChangeCallback();\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    array[offset] = this._x;\n    array[offset + 1] = this._y;\n    array[offset + 2] = this._z;\n    array[offset + 3] = this._order;\n    return array;\n  }\n  _onChange(callback) {\n    this._onChangeCallback = callback;\n    return this;\n  }\n  _onChangeCallback() {}\n  *[Symbol.iterator]() {\n    yield this._x;\n    yield this._y;\n    yield this._z;\n    yield this._order;\n  }\n}\nEuler.DEFAULT_ORDER = 'XYZ';\nclass Layers {\n  constructor() {\n    this.mask = 1 | 0;\n  }\n  set(channel) {\n    this.mask = (1 << channel | 0) >>> 0;\n  }\n  enable(channel) {\n    this.mask |= 1 << channel | 0;\n  }\n  enableAll() {\n    this.mask = 0xffffffff | 0;\n  }\n  toggle(channel) {\n    this.mask ^= 1 << channel | 0;\n  }\n  disable(channel) {\n    this.mask &= ~(1 << channel | 0);\n  }\n  disableAll() {\n    this.mask = 0;\n  }\n  test(layers) {\n    return (this.mask & layers.mask) !== 0;\n  }\n  isEnabled(channel) {\n    return (this.mask & (1 << channel | 0)) !== 0;\n  }\n}\nlet _object3DId = 0;\nconst _v1$4 = /*@__PURE__*/new Vector3();\nconst _q1 = /*@__PURE__*/new Quaternion();\nconst _m1$3 = /*@__PURE__*/new Matrix4();\nconst _target = /*@__PURE__*/new Vector3();\nconst _position$3 = /*@__PURE__*/new Vector3();\nconst _scale$2 = /*@__PURE__*/new Vector3();\nconst _quaternion$2 = /*@__PURE__*/new Quaternion();\nconst _xAxis = /*@__PURE__*/new Vector3(1, 0, 0);\nconst _yAxis = /*@__PURE__*/new Vector3(0, 1, 0);\nconst _zAxis = /*@__PURE__*/new Vector3(0, 0, 1);\nconst _addedEvent = {\n  type: 'added'\n};\nconst _removedEvent = {\n  type: 'removed'\n};\nconst _childaddedEvent = {\n  type: 'childadded',\n  child: null\n};\nconst _childremovedEvent = {\n  type: 'childremoved',\n  child: null\n};\nclass Object3D extends EventDispatcher {\n  constructor() {\n    super();\n    this.isObject3D = true;\n    Object.defineProperty(this, 'id', {\n      value: _object3DId++\n    });\n    this.uuid = generateUUID();\n    this.name = '';\n    this.type = 'Object3D';\n    this.parent = null;\n    this.children = [];\n    this.up = Object3D.DEFAULT_UP.clone();\n    const position = new Vector3();\n    const rotation = new Euler();\n    const quaternion = new Quaternion();\n    const scale = new Vector3(1, 1, 1);\n    function onRotationChange() {\n      quaternion.setFromEuler(rotation, false);\n    }\n    function onQuaternionChange() {\n      rotation.setFromQuaternion(quaternion, undefined, false);\n    }\n    rotation._onChange(onRotationChange);\n    quaternion._onChange(onQuaternionChange);\n    Object.defineProperties(this, {\n      position: {\n        configurable: true,\n        enumerable: true,\n        value: position\n      },\n      rotation: {\n        configurable: true,\n        enumerable: true,\n        value: rotation\n      },\n      quaternion: {\n        configurable: true,\n        enumerable: true,\n        value: quaternion\n      },\n      scale: {\n        configurable: true,\n        enumerable: true,\n        value: scale\n      },\n      modelViewMatrix: {\n        value: new Matrix4()\n      },\n      normalMatrix: {\n        value: new Matrix3()\n      }\n    });\n    this.matrix = new Matrix4();\n    this.matrixWorld = new Matrix4();\n    this.matrixAutoUpdate = Object3D.DEFAULT_MATRIX_AUTO_UPDATE;\n    this.matrixWorldAutoUpdate = Object3D.DEFAULT_MATRIX_WORLD_AUTO_UPDATE; // checked by the renderer\n    this.matrixWorldNeedsUpdate = false;\n    this.layers = new Layers();\n    this.visible = true;\n    this.castShadow = false;\n    this.receiveShadow = false;\n    this.frustumCulled = true;\n    this.renderOrder = 0;\n    this.animations = [];\n    this.userData = {};\n  }\n  onBeforeShadow(/* renderer, object, camera, shadowCamera, geometry, depthMaterial, group */) {}\n  onAfterShadow(/* renderer, object, camera, shadowCamera, geometry, depthMaterial, group */) {}\n  onBeforeRender(/* renderer, scene, camera, geometry, material, group */) {}\n  onAfterRender(/* renderer, scene, camera, geometry, material, group */) {}\n  applyMatrix4(matrix) {\n    if (this.matrixAutoUpdate) this.updateMatrix();\n    this.matrix.premultiply(matrix);\n    this.matrix.decompose(this.position, this.quaternion, this.scale);\n  }\n  applyQuaternion(q) {\n    this.quaternion.premultiply(q);\n    return this;\n  }\n  setRotationFromAxisAngle(axis, angle) {\n    // assumes axis is normalized\n\n    this.quaternion.setFromAxisAngle(axis, angle);\n  }\n  setRotationFromEuler(euler) {\n    this.quaternion.setFromEuler(euler, true);\n  }\n  setRotationFromMatrix(m) {\n    // assumes the upper 3x3 of m is a pure rotation matrix (i.e, unscaled)\n\n    this.quaternion.setFromRotationMatrix(m);\n  }\n  setRotationFromQuaternion(q) {\n    // assumes q is normalized\n\n    this.quaternion.copy(q);\n  }\n  rotateOnAxis(axis, angle) {\n    // rotate object on axis in object space\n    // axis is assumed to be normalized\n\n    _q1.setFromAxisAngle(axis, angle);\n    this.quaternion.multiply(_q1);\n    return this;\n  }\n  rotateOnWorldAxis(axis, angle) {\n    // rotate object on axis in world space\n    // axis is assumed to be normalized\n    // method assumes no rotated parent\n\n    _q1.setFromAxisAngle(axis, angle);\n    this.quaternion.premultiply(_q1);\n    return this;\n  }\n  rotateX(angle) {\n    return this.rotateOnAxis(_xAxis, angle);\n  }\n  rotateY(angle) {\n    return this.rotateOnAxis(_yAxis, angle);\n  }\n  rotateZ(angle) {\n    return this.rotateOnAxis(_zAxis, angle);\n  }\n  translateOnAxis(axis, distance) {\n    // translate object by distance along axis in object space\n    // axis is assumed to be normalized\n\n    _v1$4.copy(axis).applyQuaternion(this.quaternion);\n    this.position.add(_v1$4.multiplyScalar(distance));\n    return this;\n  }\n  translateX(distance) {\n    return this.translateOnAxis(_xAxis, distance);\n  }\n  translateY(distance) {\n    return this.translateOnAxis(_yAxis, distance);\n  }\n  translateZ(distance) {\n    return this.translateOnAxis(_zAxis, distance);\n  }\n  localToWorld(vector) {\n    this.updateWorldMatrix(true, false);\n    return vector.applyMatrix4(this.matrixWorld);\n  }\n  worldToLocal(vector) {\n    this.updateWorldMatrix(true, false);\n    return vector.applyMatrix4(_m1$3.copy(this.matrixWorld).invert());\n  }\n  lookAt(x, y, z) {\n    // This method does not support objects having non-uniformly-scaled parent(s)\n\n    if (x.isVector3) {\n      _target.copy(x);\n    } else {\n      _target.set(x, y, z);\n    }\n    const parent = this.parent;\n    this.updateWorldMatrix(true, false);\n    _position$3.setFromMatrixPosition(this.matrixWorld);\n    if (this.isCamera || this.isLight) {\n      _m1$3.lookAt(_position$3, _target, this.up);\n    } else {\n      _m1$3.lookAt(_target, _position$3, this.up);\n    }\n    this.quaternion.setFromRotationMatrix(_m1$3);\n    if (parent) {\n      _m1$3.extractRotation(parent.matrixWorld);\n      _q1.setFromRotationMatrix(_m1$3);\n      this.quaternion.premultiply(_q1.invert());\n    }\n  }\n  add(object) {\n    if (arguments.length > 1) {\n      for (let i = 0; i < arguments.length; i++) {\n        this.add(arguments[i]);\n      }\n      return this;\n    }\n    if (object === this) {\n      console.error('THREE.Object3D.add: object can\\'t be added as a child of itself.', object);\n      return this;\n    }\n    if (object && object.isObject3D) {\n      object.removeFromParent();\n      object.parent = this;\n      this.children.push(object);\n      object.dispatchEvent(_addedEvent);\n      _childaddedEvent.child = object;\n      this.dispatchEvent(_childaddedEvent);\n      _childaddedEvent.child = null;\n    } else {\n      console.error('THREE.Object3D.add: object not an instance of THREE.Object3D.', object);\n    }\n    return this;\n  }\n  remove(object) {\n    if (arguments.length > 1) {\n      for (let i = 0; i < arguments.length; i++) {\n        this.remove(arguments[i]);\n      }\n      return this;\n    }\n    const index = this.children.indexOf(object);\n    if (index !== -1) {\n      object.parent = null;\n      this.children.splice(index, 1);\n      object.dispatchEvent(_removedEvent);\n      _childremovedEvent.child = object;\n      this.dispatchEvent(_childremovedEvent);\n      _childremovedEvent.child = null;\n    }\n    return this;\n  }\n  removeFromParent() {\n    const parent = this.parent;\n    if (parent !== null) {\n      parent.remove(this);\n    }\n    return this;\n  }\n  clear() {\n    return this.remove(...this.children);\n  }\n  attach(object) {\n    // adds object as a child of this, while maintaining the object's world transform\n\n    // Note: This method does not support scene graphs having non-uniformly-scaled nodes(s)\n\n    this.updateWorldMatrix(true, false);\n    _m1$3.copy(this.matrixWorld).invert();\n    if (object.parent !== null) {\n      object.parent.updateWorldMatrix(true, false);\n      _m1$3.multiply(object.parent.matrixWorld);\n    }\n    object.applyMatrix4(_m1$3);\n    object.removeFromParent();\n    object.parent = this;\n    this.children.push(object);\n    object.updateWorldMatrix(false, true);\n    object.dispatchEvent(_addedEvent);\n    _childaddedEvent.child = object;\n    this.dispatchEvent(_childaddedEvent);\n    _childaddedEvent.child = null;\n    return this;\n  }\n  getObjectById(id) {\n    return this.getObjectByProperty('id', id);\n  }\n  getObjectByName(name) {\n    return this.getObjectByProperty('name', name);\n  }\n  getObjectByProperty(name, value) {\n    if (this[name] === value) return this;\n    for (let i = 0, l = this.children.length; i < l; i++) {\n      const child = this.children[i];\n      const object = child.getObjectByProperty(name, value);\n      if (object !== undefined) {\n        return object;\n      }\n    }\n    return undefined;\n  }\n  getObjectsByProperty(name, value, result = []) {\n    if (this[name] === value) result.push(this);\n    const children = this.children;\n    for (let i = 0, l = children.length; i < l; i++) {\n      children[i].getObjectsByProperty(name, value, result);\n    }\n    return result;\n  }\n  getWorldPosition(target) {\n    this.updateWorldMatrix(true, false);\n    return target.setFromMatrixPosition(this.matrixWorld);\n  }\n  getWorldQuaternion(target) {\n    this.updateWorldMatrix(true, false);\n    this.matrixWorld.decompose(_position$3, target, _scale$2);\n    return target;\n  }\n  getWorldScale(target) {\n    this.updateWorldMatrix(true, false);\n    this.matrixWorld.decompose(_position$3, _quaternion$2, target);\n    return target;\n  }\n  getWorldDirection(target) {\n    this.updateWorldMatrix(true, false);\n    const e = this.matrixWorld.elements;\n    return target.set(e[8], e[9], e[10]).normalize();\n  }\n  raycast(/* raycaster, intersects */) {}\n  traverse(callback) {\n    callback(this);\n    const children = this.children;\n    for (let i = 0, l = children.length; i < l; i++) {\n      children[i].traverse(callback);\n    }\n  }\n  traverseVisible(callback) {\n    if (this.visible === false) return;\n    callback(this);\n    const children = this.children;\n    for (let i = 0, l = children.length; i < l; i++) {\n      children[i].traverseVisible(callback);\n    }\n  }\n  traverseAncestors(callback) {\n    const parent = this.parent;\n    if (parent !== null) {\n      callback(parent);\n      parent.traverseAncestors(callback);\n    }\n  }\n  updateMatrix() {\n    this.matrix.compose(this.position, this.quaternion, this.scale);\n    this.matrixWorldNeedsUpdate = true;\n  }\n  updateMatrixWorld(force) {\n    if (this.matrixAutoUpdate) this.updateMatrix();\n    if (this.matrixWorldNeedsUpdate || force) {\n      if (this.matrixWorldAutoUpdate === true) {\n        if (this.parent === null) {\n          this.matrixWorld.copy(this.matrix);\n        } else {\n          this.matrixWorld.multiplyMatrices(this.parent.matrixWorld, this.matrix);\n        }\n      }\n      this.matrixWorldNeedsUpdate = false;\n      force = true;\n    }\n\n    // make sure descendants are updated if required\n\n    const children = this.children;\n    for (let i = 0, l = children.length; i < l; i++) {\n      const child = children[i];\n      child.updateMatrixWorld(force);\n    }\n  }\n  updateWorldMatrix(updateParents, updateChildren) {\n    const parent = this.parent;\n    if (updateParents === true && parent !== null) {\n      parent.updateWorldMatrix(true, false);\n    }\n    if (this.matrixAutoUpdate) this.updateMatrix();\n    if (this.matrixWorldAutoUpdate === true) {\n      if (this.parent === null) {\n        this.matrixWorld.copy(this.matrix);\n      } else {\n        this.matrixWorld.multiplyMatrices(this.parent.matrixWorld, this.matrix);\n      }\n    }\n\n    // make sure descendants are updated\n\n    if (updateChildren === true) {\n      const children = this.children;\n      for (let i = 0, l = children.length; i < l; i++) {\n        const child = children[i];\n        child.updateWorldMatrix(false, true);\n      }\n    }\n  }\n  toJSON(meta) {\n    // meta is a string when called from JSON.stringify\n    const isRootObject = meta === undefined || typeof meta === 'string';\n    const output = {};\n\n    // meta is a hash used to collect geometries, materials.\n    // not providing it implies that this is the root object\n    // being serialized.\n    if (isRootObject) {\n      // initialize meta obj\n      meta = {\n        geometries: {},\n        materials: {},\n        textures: {},\n        images: {},\n        shapes: {},\n        skeletons: {},\n        animations: {},\n        nodes: {}\n      };\n      output.metadata = {\n        version: 4.6,\n        type: 'Object',\n        generator: 'Object3D.toJSON'\n      };\n    }\n\n    // standard Object3D serialization\n\n    const object = {};\n    object.uuid = this.uuid;\n    object.type = this.type;\n    if (this.name !== '') object.name = this.name;\n    if (this.castShadow === true) object.castShadow = true;\n    if (this.receiveShadow === true) object.receiveShadow = true;\n    if (this.visible === false) object.visible = false;\n    if (this.frustumCulled === false) object.frustumCulled = false;\n    if (this.renderOrder !== 0) object.renderOrder = this.renderOrder;\n    if (Object.keys(this.userData).length > 0) object.userData = this.userData;\n    object.layers = this.layers.mask;\n    object.matrix = this.matrix.toArray();\n    object.up = this.up.toArray();\n    if (this.matrixAutoUpdate === false) object.matrixAutoUpdate = false;\n\n    // object specific properties\n\n    if (this.isInstancedMesh) {\n      object.type = 'InstancedMesh';\n      object.count = this.count;\n      object.instanceMatrix = this.instanceMatrix.toJSON();\n      if (this.instanceColor !== null) object.instanceColor = this.instanceColor.toJSON();\n    }\n    if (this.isBatchedMesh) {\n      object.type = 'BatchedMesh';\n      object.perObjectFrustumCulled = this.perObjectFrustumCulled;\n      object.sortObjects = this.sortObjects;\n      object.drawRanges = this._drawRanges;\n      object.reservedRanges = this._reservedRanges;\n      object.visibility = this._visibility;\n      object.active = this._active;\n      object.bounds = this._bounds.map(bound => ({\n        boxInitialized: bound.boxInitialized,\n        boxMin: bound.box.min.toArray(),\n        boxMax: bound.box.max.toArray(),\n        sphereInitialized: bound.sphereInitialized,\n        sphereRadius: bound.sphere.radius,\n        sphereCenter: bound.sphere.center.toArray()\n      }));\n      object.maxInstanceCount = this._maxInstanceCount;\n      object.maxVertexCount = this._maxVertexCount;\n      object.maxIndexCount = this._maxIndexCount;\n      object.geometryInitialized = this._geometryInitialized;\n      object.geometryCount = this._geometryCount;\n      object.matricesTexture = this._matricesTexture.toJSON(meta);\n      if (this._colorsTexture !== null) object.colorsTexture = this._colorsTexture.toJSON(meta);\n      if (this.boundingSphere !== null) {\n        object.boundingSphere = {\n          center: object.boundingSphere.center.toArray(),\n          radius: object.boundingSphere.radius\n        };\n      }\n      if (this.boundingBox !== null) {\n        object.boundingBox = {\n          min: object.boundingBox.min.toArray(),\n          max: object.boundingBox.max.toArray()\n        };\n      }\n    }\n\n    //\n\n    function serialize(library, element) {\n      if (library[element.uuid] === undefined) {\n        library[element.uuid] = element.toJSON(meta);\n      }\n      return element.uuid;\n    }\n    if (this.isScene) {\n      if (this.background) {\n        if (this.background.isColor) {\n          object.background = this.background.toJSON();\n        } else if (this.background.isTexture) {\n          object.background = this.background.toJSON(meta).uuid;\n        }\n      }\n      if (this.environment && this.environment.isTexture && this.environment.isRenderTargetTexture !== true) {\n        object.environment = this.environment.toJSON(meta).uuid;\n      }\n    } else if (this.isMesh || this.isLine || this.isPoints) {\n      object.geometry = serialize(meta.geometries, this.geometry);\n      const parameters = this.geometry.parameters;\n      if (parameters !== undefined && parameters.shapes !== undefined) {\n        const shapes = parameters.shapes;\n        if (Array.isArray(shapes)) {\n          for (let i = 0, l = shapes.length; i < l; i++) {\n            const shape = shapes[i];\n            serialize(meta.shapes, shape);\n          }\n        } else {\n          serialize(meta.shapes, shapes);\n        }\n      }\n    }\n    if (this.isSkinnedMesh) {\n      object.bindMode = this.bindMode;\n      object.bindMatrix = this.bindMatrix.toArray();\n      if (this.skeleton !== undefined) {\n        serialize(meta.skeletons, this.skeleton);\n        object.skeleton = this.skeleton.uuid;\n      }\n    }\n    if (this.material !== undefined) {\n      if (Array.isArray(this.material)) {\n        const uuids = [];\n        for (let i = 0, l = this.material.length; i < l; i++) {\n          uuids.push(serialize(meta.materials, this.material[i]));\n        }\n        object.material = uuids;\n      } else {\n        object.material = serialize(meta.materials, this.material);\n      }\n    }\n\n    //\n\n    if (this.children.length > 0) {\n      object.children = [];\n      for (let i = 0; i < this.children.length; i++) {\n        object.children.push(this.children[i].toJSON(meta).object);\n      }\n    }\n\n    //\n\n    if (this.animations.length > 0) {\n      object.animations = [];\n      for (let i = 0; i < this.animations.length; i++) {\n        const animation = this.animations[i];\n        object.animations.push(serialize(meta.animations, animation));\n      }\n    }\n    if (isRootObject) {\n      const geometries = extractFromCache(meta.geometries);\n      const materials = extractFromCache(meta.materials);\n      const textures = extractFromCache(meta.textures);\n      const images = extractFromCache(meta.images);\n      const shapes = extractFromCache(meta.shapes);\n      const skeletons = extractFromCache(meta.skeletons);\n      const animations = extractFromCache(meta.animations);\n      const nodes = extractFromCache(meta.nodes);\n      if (geometries.length > 0) output.geometries = geometries;\n      if (materials.length > 0) output.materials = materials;\n      if (textures.length > 0) output.textures = textures;\n      if (images.length > 0) output.images = images;\n      if (shapes.length > 0) output.shapes = shapes;\n      if (skeletons.length > 0) output.skeletons = skeletons;\n      if (animations.length > 0) output.animations = animations;\n      if (nodes.length > 0) output.nodes = nodes;\n    }\n    output.object = object;\n    return output;\n\n    // extract data from the cache hash\n    // remove metadata on each item\n    // and return as array\n    function extractFromCache(cache) {\n      const values = [];\n      for (const key in cache) {\n        const data = cache[key];\n        delete data.metadata;\n        values.push(data);\n      }\n      return values;\n    }\n  }\n  clone(recursive) {\n    return new this.constructor().copy(this, recursive);\n  }\n  copy(source, recursive = true) {\n    this.name = source.name;\n    this.up.copy(source.up);\n    this.position.copy(source.position);\n    this.rotation.order = source.rotation.order;\n    this.quaternion.copy(source.quaternion);\n    this.scale.copy(source.scale);\n    this.matrix.copy(source.matrix);\n    this.matrixWorld.copy(source.matrixWorld);\n    this.matrixAutoUpdate = source.matrixAutoUpdate;\n    this.matrixWorldAutoUpdate = source.matrixWorldAutoUpdate;\n    this.matrixWorldNeedsUpdate = source.matrixWorldNeedsUpdate;\n    this.layers.mask = source.layers.mask;\n    this.visible = source.visible;\n    this.castShadow = source.castShadow;\n    this.receiveShadow = source.receiveShadow;\n    this.frustumCulled = source.frustumCulled;\n    this.renderOrder = source.renderOrder;\n    this.animations = source.animations.slice();\n    this.userData = JSON.parse(JSON.stringify(source.userData));\n    if (recursive === true) {\n      for (let i = 0; i < source.children.length; i++) {\n        const child = source.children[i];\n        this.add(child.clone());\n      }\n    }\n    return this;\n  }\n}\nObject3D.DEFAULT_UP = /*@__PURE__*/new Vector3(0, 1, 0);\nObject3D.DEFAULT_MATRIX_AUTO_UPDATE = true;\nObject3D.DEFAULT_MATRIX_WORLD_AUTO_UPDATE = true;\nconst _v0$2 = /*@__PURE__*/new Vector3();\nconst _v1$3 = /*@__PURE__*/new Vector3();\nconst _v2$2 = /*@__PURE__*/new Vector3();\nconst _v3$2 = /*@__PURE__*/new Vector3();\nconst _vab = /*@__PURE__*/new Vector3();\nconst _vac = /*@__PURE__*/new Vector3();\nconst _vbc = /*@__PURE__*/new Vector3();\nconst _vap = /*@__PURE__*/new Vector3();\nconst _vbp = /*@__PURE__*/new Vector3();\nconst _vcp = /*@__PURE__*/new Vector3();\nconst _v40 = /*@__PURE__*/new Vector4();\nconst _v41 = /*@__PURE__*/new Vector4();\nconst _v42 = /*@__PURE__*/new Vector4();\nclass Triangle {\n  constructor(a = new Vector3(), b = new Vector3(), c = new Vector3()) {\n    this.a = a;\n    this.b = b;\n    this.c = c;\n  }\n  static getNormal(a, b, c, target) {\n    target.subVectors(c, b);\n    _v0$2.subVectors(a, b);\n    target.cross(_v0$2);\n    const targetLengthSq = target.lengthSq();\n    if (targetLengthSq > 0) {\n      return target.multiplyScalar(1 / Math.sqrt(targetLengthSq));\n    }\n    return target.set(0, 0, 0);\n  }\n\n  // static/instance method to calculate barycentric coordinates\n  // based on: http://www.blackpawn.com/texts/pointinpoly/default.html\n  static getBarycoord(point, a, b, c, target) {\n    _v0$2.subVectors(c, a);\n    _v1$3.subVectors(b, a);\n    _v2$2.subVectors(point, a);\n    const dot00 = _v0$2.dot(_v0$2);\n    const dot01 = _v0$2.dot(_v1$3);\n    const dot02 = _v0$2.dot(_v2$2);\n    const dot11 = _v1$3.dot(_v1$3);\n    const dot12 = _v1$3.dot(_v2$2);\n    const denom = dot00 * dot11 - dot01 * dot01;\n\n    // collinear or singular triangle\n    if (denom === 0) {\n      target.set(0, 0, 0);\n      return null;\n    }\n    const invDenom = 1 / denom;\n    const u = (dot11 * dot02 - dot01 * dot12) * invDenom;\n    const v = (dot00 * dot12 - dot01 * dot02) * invDenom;\n\n    // barycentric coordinates must always sum to 1\n    return target.set(1 - u - v, v, u);\n  }\n  static containsPoint(point, a, b, c) {\n    // if the triangle is degenerate then we can't contain a point\n    if (this.getBarycoord(point, a, b, c, _v3$2) === null) {\n      return false;\n    }\n    return _v3$2.x >= 0 && _v3$2.y >= 0 && _v3$2.x + _v3$2.y <= 1;\n  }\n  static getInterpolation(point, p1, p2, p3, v1, v2, v3, target) {\n    if (this.getBarycoord(point, p1, p2, p3, _v3$2) === null) {\n      target.x = 0;\n      target.y = 0;\n      if ('z' in target) target.z = 0;\n      if ('w' in target) target.w = 0;\n      return null;\n    }\n    target.setScalar(0);\n    target.addScaledVector(v1, _v3$2.x);\n    target.addScaledVector(v2, _v3$2.y);\n    target.addScaledVector(v3, _v3$2.z);\n    return target;\n  }\n  static getInterpolatedAttribute(attr, i1, i2, i3, barycoord, target) {\n    _v40.setScalar(0);\n    _v41.setScalar(0);\n    _v42.setScalar(0);\n    _v40.fromBufferAttribute(attr, i1);\n    _v41.fromBufferAttribute(attr, i2);\n    _v42.fromBufferAttribute(attr, i3);\n    target.setScalar(0);\n    target.addScaledVector(_v40, barycoord.x);\n    target.addScaledVector(_v41, barycoord.y);\n    target.addScaledVector(_v42, barycoord.z);\n    return target;\n  }\n  static isFrontFacing(a, b, c, direction) {\n    _v0$2.subVectors(c, b);\n    _v1$3.subVectors(a, b);\n\n    // strictly front facing\n    return _v0$2.cross(_v1$3).dot(direction) < 0 ? true : false;\n  }\n  set(a, b, c) {\n    this.a.copy(a);\n    this.b.copy(b);\n    this.c.copy(c);\n    return this;\n  }\n  setFromPointsAndIndices(points, i0, i1, i2) {\n    this.a.copy(points[i0]);\n    this.b.copy(points[i1]);\n    this.c.copy(points[i2]);\n    return this;\n  }\n  setFromAttributeAndIndices(attribute, i0, i1, i2) {\n    this.a.fromBufferAttribute(attribute, i0);\n    this.b.fromBufferAttribute(attribute, i1);\n    this.c.fromBufferAttribute(attribute, i2);\n    return this;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  copy(triangle) {\n    this.a.copy(triangle.a);\n    this.b.copy(triangle.b);\n    this.c.copy(triangle.c);\n    return this;\n  }\n  getArea() {\n    _v0$2.subVectors(this.c, this.b);\n    _v1$3.subVectors(this.a, this.b);\n    return _v0$2.cross(_v1$3).length() * 0.5;\n  }\n  getMidpoint(target) {\n    return target.addVectors(this.a, this.b).add(this.c).multiplyScalar(1 / 3);\n  }\n  getNormal(target) {\n    return Triangle.getNormal(this.a, this.b, this.c, target);\n  }\n  getPlane(target) {\n    return target.setFromCoplanarPoints(this.a, this.b, this.c);\n  }\n  getBarycoord(point, target) {\n    return Triangle.getBarycoord(point, this.a, this.b, this.c, target);\n  }\n  getInterpolation(point, v1, v2, v3, target) {\n    return Triangle.getInterpolation(point, this.a, this.b, this.c, v1, v2, v3, target);\n  }\n  containsPoint(point) {\n    return Triangle.containsPoint(point, this.a, this.b, this.c);\n  }\n  isFrontFacing(direction) {\n    return Triangle.isFrontFacing(this.a, this.b, this.c, direction);\n  }\n  intersectsBox(box) {\n    return box.intersectsTriangle(this);\n  }\n  closestPointToPoint(p, target) {\n    const a = this.a,\n      b = this.b,\n      c = this.c;\n    let v, w;\n\n    // algorithm thanks to Real-Time Collision Detection by Christer Ericson,\n    // published by Morgan Kaufmann Publishers, (c) 2005 Elsevier Inc.,\n    // under the accompanying license; see chapter 5.1.5 for detailed explanation.\n    // basically, we're distinguishing which of the voronoi regions of the triangle\n    // the point lies in with the minimum amount of redundant computation.\n\n    _vab.subVectors(b, a);\n    _vac.subVectors(c, a);\n    _vap.subVectors(p, a);\n    const d1 = _vab.dot(_vap);\n    const d2 = _vac.dot(_vap);\n    if (d1 <= 0 && d2 <= 0) {\n      // vertex region of A; barycentric coords (1, 0, 0)\n      return target.copy(a);\n    }\n    _vbp.subVectors(p, b);\n    const d3 = _vab.dot(_vbp);\n    const d4 = _vac.dot(_vbp);\n    if (d3 >= 0 && d4 <= d3) {\n      // vertex region of B; barycentric coords (0, 1, 0)\n      return target.copy(b);\n    }\n    const vc = d1 * d4 - d3 * d2;\n    if (vc <= 0 && d1 >= 0 && d3 <= 0) {\n      v = d1 / (d1 - d3);\n      // edge region of AB; barycentric coords (1-v, v, 0)\n      return target.copy(a).addScaledVector(_vab, v);\n    }\n    _vcp.subVectors(p, c);\n    const d5 = _vab.dot(_vcp);\n    const d6 = _vac.dot(_vcp);\n    if (d6 >= 0 && d5 <= d6) {\n      // vertex region of C; barycentric coords (0, 0, 1)\n      return target.copy(c);\n    }\n    const vb = d5 * d2 - d1 * d6;\n    if (vb <= 0 && d2 >= 0 && d6 <= 0) {\n      w = d2 / (d2 - d6);\n      // edge region of AC; barycentric coords (1-w, 0, w)\n      return target.copy(a).addScaledVector(_vac, w);\n    }\n    const va = d3 * d6 - d5 * d4;\n    if (va <= 0 && d4 - d3 >= 0 && d5 - d6 >= 0) {\n      _vbc.subVectors(c, b);\n      w = (d4 - d3) / (d4 - d3 + (d5 - d6));\n      // edge region of BC; barycentric coords (0, 1-w, w)\n      return target.copy(b).addScaledVector(_vbc, w); // edge region of BC\n    }\n\n    // face region\n    const denom = 1 / (va + vb + vc);\n    // u = va * denom\n    v = vb * denom;\n    w = vc * denom;\n    return target.copy(a).addScaledVector(_vab, v).addScaledVector(_vac, w);\n  }\n  equals(triangle) {\n    return triangle.a.equals(this.a) && triangle.b.equals(this.b) && triangle.c.equals(this.c);\n  }\n}\nconst _colorKeywords = {\n  'aliceblue': 0xF0F8FF,\n  'antiquewhite': 0xFAEBD7,\n  'aqua': 0x00FFFF,\n  'aquamarine': 0x7FFFD4,\n  'azure': 0xF0FFFF,\n  'beige': 0xF5F5DC,\n  'bisque': 0xFFE4C4,\n  'black': 0x000000,\n  'blanchedalmond': 0xFFEBCD,\n  'blue': 0x0000FF,\n  'blueviolet': 0x8A2BE2,\n  'brown': 0xA52A2A,\n  'burlywood': 0xDEB887,\n  'cadetblue': 0x5F9EA0,\n  'chartreuse': 0x7FFF00,\n  'chocolate': 0xD2691E,\n  'coral': 0xFF7F50,\n  'cornflowerblue': 0x6495ED,\n  'cornsilk': 0xFFF8DC,\n  'crimson': 0xDC143C,\n  'cyan': 0x00FFFF,\n  'darkblue': 0x00008B,\n  'darkcyan': 0x008B8B,\n  'darkgoldenrod': 0xB8860B,\n  'darkgray': 0xA9A9A9,\n  'darkgreen': 0x006400,\n  'darkgrey': 0xA9A9A9,\n  'darkkhaki': 0xBDB76B,\n  'darkmagenta': 0x8B008B,\n  'darkolivegreen': 0x556B2F,\n  'darkorange': 0xFF8C00,\n  'darkorchid': 0x9932CC,\n  'darkred': 0x8B0000,\n  'darksalmon': 0xE9967A,\n  'darkseagreen': 0x8FBC8F,\n  'darkslateblue': 0x483D8B,\n  'darkslategray': 0x2F4F4F,\n  'darkslategrey': 0x2F4F4F,\n  'darkturquoise': 0x00CED1,\n  'darkviolet': 0x9400D3,\n  'deeppink': 0xFF1493,\n  'deepskyblue': 0x00BFFF,\n  'dimgray': 0x696969,\n  'dimgrey': 0x696969,\n  'dodgerblue': 0x1E90FF,\n  'firebrick': 0xB22222,\n  'floralwhite': 0xFFFAF0,\n  'forestgreen': 0x228B22,\n  'fuchsia': 0xFF00FF,\n  'gainsboro': 0xDCDCDC,\n  'ghostwhite': 0xF8F8FF,\n  'gold': 0xFFD700,\n  'goldenrod': 0xDAA520,\n  'gray': 0x808080,\n  'green': 0x008000,\n  'greenyellow': 0xADFF2F,\n  'grey': 0x808080,\n  'honeydew': 0xF0FFF0,\n  'hotpink': 0xFF69B4,\n  'indianred': 0xCD5C5C,\n  'indigo': 0x4B0082,\n  'ivory': 0xFFFFF0,\n  'khaki': 0xF0E68C,\n  'lavender': 0xE6E6FA,\n  'lavenderblush': 0xFFF0F5,\n  'lawngreen': 0x7CFC00,\n  'lemonchiffon': 0xFFFACD,\n  'lightblue': 0xADD8E6,\n  'lightcoral': 0xF08080,\n  'lightcyan': 0xE0FFFF,\n  'lightgoldenrodyellow': 0xFAFAD2,\n  'lightgray': 0xD3D3D3,\n  'lightgreen': 0x90EE90,\n  'lightgrey': 0xD3D3D3,\n  'lightpink': 0xFFB6C1,\n  'lightsalmon': 0xFFA07A,\n  'lightseagreen': 0x20B2AA,\n  'lightskyblue': 0x87CEFA,\n  'lightslategray': 0x778899,\n  'lightslategrey': 0x778899,\n  'lightsteelblue': 0xB0C4DE,\n  'lightyellow': 0xFFFFE0,\n  'lime': 0x00FF00,\n  'limegreen': 0x32CD32,\n  'linen': 0xFAF0E6,\n  'magenta': 0xFF00FF,\n  'maroon': 0x800000,\n  'mediumaquamarine': 0x66CDAA,\n  'mediumblue': 0x0000CD,\n  'mediumorchid': 0xBA55D3,\n  'mediumpurple': 0x9370DB,\n  'mediumseagreen': 0x3CB371,\n  'mediumslateblue': 0x7B68EE,\n  'mediumspringgreen': 0x00FA9A,\n  'mediumturquoise': 0x48D1CC,\n  'mediumvioletred': 0xC71585,\n  'midnightblue': 0x191970,\n  'mintcream': 0xF5FFFA,\n  'mistyrose': 0xFFE4E1,\n  'moccasin': 0xFFE4B5,\n  'navajowhite': 0xFFDEAD,\n  'navy': 0x000080,\n  'oldlace': 0xFDF5E6,\n  'olive': 0x808000,\n  'olivedrab': 0x6B8E23,\n  'orange': 0xFFA500,\n  'orangered': 0xFF4500,\n  'orchid': 0xDA70D6,\n  'palegoldenrod': 0xEEE8AA,\n  'palegreen': 0x98FB98,\n  'paleturquoise': 0xAFEEEE,\n  'palevioletred': 0xDB7093,\n  'papayawhip': 0xFFEFD5,\n  'peachpuff': 0xFFDAB9,\n  'peru': 0xCD853F,\n  'pink': 0xFFC0CB,\n  'plum': 0xDDA0DD,\n  'powderblue': 0xB0E0E6,\n  'purple': 0x800080,\n  'rebeccapurple': 0x663399,\n  'red': 0xFF0000,\n  'rosybrown': 0xBC8F8F,\n  'royalblue': 0x4169E1,\n  'saddlebrown': 0x8B4513,\n  'salmon': 0xFA8072,\n  'sandybrown': 0xF4A460,\n  'seagreen': 0x2E8B57,\n  'seashell': 0xFFF5EE,\n  'sienna': 0xA0522D,\n  'silver': 0xC0C0C0,\n  'skyblue': 0x87CEEB,\n  'slateblue': 0x6A5ACD,\n  'slategray': 0x708090,\n  'slategrey': 0x708090,\n  'snow': 0xFFFAFA,\n  'springgreen': 0x00FF7F,\n  'steelblue': 0x4682B4,\n  'tan': 0xD2B48C,\n  'teal': 0x008080,\n  'thistle': 0xD8BFD8,\n  'tomato': 0xFF6347,\n  'turquoise': 0x40E0D0,\n  'violet': 0xEE82EE,\n  'wheat': 0xF5DEB3,\n  'white': 0xFFFFFF,\n  'whitesmoke': 0xF5F5F5,\n  'yellow': 0xFFFF00,\n  'yellowgreen': 0x9ACD32\n};\nconst _hslA = {\n  h: 0,\n  s: 0,\n  l: 0\n};\nconst _hslB = {\n  h: 0,\n  s: 0,\n  l: 0\n};\nfunction hue2rgb(p, q, t) {\n  if (t < 0) t += 1;\n  if (t > 1) t -= 1;\n  if (t < 1 / 6) return p + (q - p) * 6 * t;\n  if (t < 1 / 2) return q;\n  if (t < 2 / 3) return p + (q - p) * 6 * (2 / 3 - t);\n  return p;\n}\nclass Color {\n  constructor(r, g, b) {\n    this.isColor = true;\n    this.r = 1;\n    this.g = 1;\n    this.b = 1;\n    return this.set(r, g, b);\n  }\n  set(r, g, b) {\n    if (g === undefined && b === undefined) {\n      // r is THREE.Color, hex or string\n\n      const value = r;\n      if (value && value.isColor) {\n        this.copy(value);\n      } else if (typeof value === 'number') {\n        this.setHex(value);\n      } else if (typeof value === 'string') {\n        this.setStyle(value);\n      }\n    } else {\n      this.setRGB(r, g, b);\n    }\n    return this;\n  }\n  setScalar(scalar) {\n    this.r = scalar;\n    this.g = scalar;\n    this.b = scalar;\n    return this;\n  }\n  setHex(hex, colorSpace = SRGBColorSpace) {\n    hex = Math.floor(hex);\n    this.r = (hex >> 16 & 255) / 255;\n    this.g = (hex >> 8 & 255) / 255;\n    this.b = (hex & 255) / 255;\n    ColorManagement.toWorkingColorSpace(this, colorSpace);\n    return this;\n  }\n  setRGB(r, g, b, colorSpace = ColorManagement.workingColorSpace) {\n    this.r = r;\n    this.g = g;\n    this.b = b;\n    ColorManagement.toWorkingColorSpace(this, colorSpace);\n    return this;\n  }\n  setHSL(h, s, l, colorSpace = ColorManagement.workingColorSpace) {\n    // h,s,l ranges are in 0.0 - 1.0\n    h = euclideanModulo(h, 1);\n    s = clamp$1(s, 0, 1);\n    l = clamp$1(l, 0, 1);\n    if (s === 0) {\n      this.r = this.g = this.b = l;\n    } else {\n      const p = l <= 0.5 ? l * (1 + s) : l + s - l * s;\n      const q = 2 * l - p;\n      this.r = hue2rgb(q, p, h + 1 / 3);\n      this.g = hue2rgb(q, p, h);\n      this.b = hue2rgb(q, p, h - 1 / 3);\n    }\n    ColorManagement.toWorkingColorSpace(this, colorSpace);\n    return this;\n  }\n  setStyle(style, colorSpace = SRGBColorSpace) {\n    function handleAlpha(string) {\n      if (string === undefined) return;\n      if (parseFloat(string) < 1) {\n        console.warn('THREE.Color: Alpha component of ' + style + ' will be ignored.');\n      }\n    }\n    let m;\n    if (m = /^(\\w+)\\(([^\\)]*)\\)/.exec(style)) {\n      // rgb / hsl\n\n      let color;\n      const name = m[1];\n      const components = m[2];\n      switch (name) {\n        case 'rgb':\n        case 'rgba':\n          if (color = /^\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec(components)) {\n            // rgb(255,0,0) rgba(255,0,0,0.5)\n\n            handleAlpha(color[4]);\n            return this.setRGB(Math.min(255, parseInt(color[1], 10)) / 255, Math.min(255, parseInt(color[2], 10)) / 255, Math.min(255, parseInt(color[3], 10)) / 255, colorSpace);\n          }\n          if (color = /^\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*,\\s*(\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec(components)) {\n            // rgb(100%,0%,0%) rgba(100%,0%,0%,0.5)\n\n            handleAlpha(color[4]);\n            return this.setRGB(Math.min(100, parseInt(color[1], 10)) / 100, Math.min(100, parseInt(color[2], 10)) / 100, Math.min(100, parseInt(color[3], 10)) / 100, colorSpace);\n          }\n          break;\n        case 'hsl':\n        case 'hsla':\n          if (color = /^\\s*(\\d*\\.?\\d+)\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*,\\s*(\\d*\\.?\\d+)\\%\\s*(?:,\\s*(\\d*\\.?\\d+)\\s*)?$/.exec(components)) {\n            // hsl(120,50%,50%) hsla(120,50%,50%,0.5)\n\n            handleAlpha(color[4]);\n            return this.setHSL(parseFloat(color[1]) / 360, parseFloat(color[2]) / 100, parseFloat(color[3]) / 100, colorSpace);\n          }\n          break;\n        default:\n          console.warn('THREE.Color: Unknown color model ' + style);\n      }\n    } else if (m = /^\\#([A-Fa-f\\d]+)$/.exec(style)) {\n      // hex color\n\n      const hex = m[1];\n      const size = hex.length;\n      if (size === 3) {\n        // #ff0\n        return this.setRGB(parseInt(hex.charAt(0), 16) / 15, parseInt(hex.charAt(1), 16) / 15, parseInt(hex.charAt(2), 16) / 15, colorSpace);\n      } else if (size === 6) {\n        // #ff0000\n        return this.setHex(parseInt(hex, 16), colorSpace);\n      } else {\n        console.warn('THREE.Color: Invalid hex color ' + style);\n      }\n    } else if (style && style.length > 0) {\n      return this.setColorName(style, colorSpace);\n    }\n    return this;\n  }\n  setColorName(style, colorSpace = SRGBColorSpace) {\n    // color keywords\n    const hex = _colorKeywords[style.toLowerCase()];\n    if (hex !== undefined) {\n      // red\n      this.setHex(hex, colorSpace);\n    } else {\n      // unknown color\n      console.warn('THREE.Color: Unknown color ' + style);\n    }\n    return this;\n  }\n  clone() {\n    return new this.constructor(this.r, this.g, this.b);\n  }\n  copy(color) {\n    this.r = color.r;\n    this.g = color.g;\n    this.b = color.b;\n    return this;\n  }\n  copySRGBToLinear(color) {\n    this.r = SRGBToLinear(color.r);\n    this.g = SRGBToLinear(color.g);\n    this.b = SRGBToLinear(color.b);\n    return this;\n  }\n  copyLinearToSRGB(color) {\n    this.r = LinearToSRGB(color.r);\n    this.g = LinearToSRGB(color.g);\n    this.b = LinearToSRGB(color.b);\n    return this;\n  }\n  convertSRGBToLinear() {\n    this.copySRGBToLinear(this);\n    return this;\n  }\n  convertLinearToSRGB() {\n    this.copyLinearToSRGB(this);\n    return this;\n  }\n  getHex(colorSpace = SRGBColorSpace) {\n    ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace);\n    return Math.round(clamp$1(_color.r * 255, 0, 255)) * 65536 + Math.round(clamp$1(_color.g * 255, 0, 255)) * 256 + Math.round(clamp$1(_color.b * 255, 0, 255));\n  }\n  getHexString(colorSpace = SRGBColorSpace) {\n    return ('000000' + this.getHex(colorSpace).toString(16)).slice(-6);\n  }\n  getHSL(target, colorSpace = ColorManagement.workingColorSpace) {\n    // h,s,l ranges are in 0.0 - 1.0\n\n    ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace);\n    const r = _color.r,\n      g = _color.g,\n      b = _color.b;\n    const max = Math.max(r, g, b);\n    const min = Math.min(r, g, b);\n    let hue, saturation;\n    const lightness = (min + max) / 2.0;\n    if (min === max) {\n      hue = 0;\n      saturation = 0;\n    } else {\n      const delta = max - min;\n      saturation = lightness <= 0.5 ? delta / (max + min) : delta / (2 - max - min);\n      switch (max) {\n        case r:\n          hue = (g - b) / delta + (g < b ? 6 : 0);\n          break;\n        case g:\n          hue = (b - r) / delta + 2;\n          break;\n        case b:\n          hue = (r - g) / delta + 4;\n          break;\n      }\n      hue /= 6;\n    }\n    target.h = hue;\n    target.s = saturation;\n    target.l = lightness;\n    return target;\n  }\n  getRGB(target, colorSpace = ColorManagement.workingColorSpace) {\n    ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace);\n    target.r = _color.r;\n    target.g = _color.g;\n    target.b = _color.b;\n    return target;\n  }\n  getStyle(colorSpace = SRGBColorSpace) {\n    ColorManagement.fromWorkingColorSpace(_color.copy(this), colorSpace);\n    const r = _color.r,\n      g = _color.g,\n      b = _color.b;\n    if (colorSpace !== SRGBColorSpace) {\n      // Requires CSS Color Module Level 4 (https://www.w3.org/TR/css-color-4/).\n      return `color(${colorSpace} ${r.toFixed(3)} ${g.toFixed(3)} ${b.toFixed(3)})`;\n    }\n    return `rgb(${Math.round(r * 255)},${Math.round(g * 255)},${Math.round(b * 255)})`;\n  }\n  offsetHSL(h, s, l) {\n    this.getHSL(_hslA);\n    return this.setHSL(_hslA.h + h, _hslA.s + s, _hslA.l + l);\n  }\n  add(color) {\n    this.r += color.r;\n    this.g += color.g;\n    this.b += color.b;\n    return this;\n  }\n  addColors(color1, color2) {\n    this.r = color1.r + color2.r;\n    this.g = color1.g + color2.g;\n    this.b = color1.b + color2.b;\n    return this;\n  }\n  addScalar(s) {\n    this.r += s;\n    this.g += s;\n    this.b += s;\n    return this;\n  }\n  sub(color) {\n    this.r = Math.max(0, this.r - color.r);\n    this.g = Math.max(0, this.g - color.g);\n    this.b = Math.max(0, this.b - color.b);\n    return this;\n  }\n  multiply(color) {\n    this.r *= color.r;\n    this.g *= color.g;\n    this.b *= color.b;\n    return this;\n  }\n  multiplyScalar(s) {\n    this.r *= s;\n    this.g *= s;\n    this.b *= s;\n    return this;\n  }\n  lerp(color, alpha) {\n    this.r += (color.r - this.r) * alpha;\n    this.g += (color.g - this.g) * alpha;\n    this.b += (color.b - this.b) * alpha;\n    return this;\n  }\n  lerpColors(color1, color2, alpha) {\n    this.r = color1.r + (color2.r - color1.r) * alpha;\n    this.g = color1.g + (color2.g - color1.g) * alpha;\n    this.b = color1.b + (color2.b - color1.b) * alpha;\n    return this;\n  }\n  lerpHSL(color, alpha) {\n    this.getHSL(_hslA);\n    color.getHSL(_hslB);\n    const h = lerp$1(_hslA.h, _hslB.h, alpha);\n    const s = lerp$1(_hslA.s, _hslB.s, alpha);\n    const l = lerp$1(_hslA.l, _hslB.l, alpha);\n    this.setHSL(h, s, l);\n    return this;\n  }\n  setFromVector3(v) {\n    this.r = v.x;\n    this.g = v.y;\n    this.b = v.z;\n    return this;\n  }\n  applyMatrix3(m) {\n    const r = this.r,\n      g = this.g,\n      b = this.b;\n    const e = m.elements;\n    this.r = e[0] * r + e[3] * g + e[6] * b;\n    this.g = e[1] * r + e[4] * g + e[7] * b;\n    this.b = e[2] * r + e[5] * g + e[8] * b;\n    return this;\n  }\n  equals(c) {\n    return c.r === this.r && c.g === this.g && c.b === this.b;\n  }\n  fromArray(array, offset = 0) {\n    this.r = array[offset];\n    this.g = array[offset + 1];\n    this.b = array[offset + 2];\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    array[offset] = this.r;\n    array[offset + 1] = this.g;\n    array[offset + 2] = this.b;\n    return array;\n  }\n  fromBufferAttribute(attribute, index) {\n    this.r = attribute.getX(index);\n    this.g = attribute.getY(index);\n    this.b = attribute.getZ(index);\n    return this;\n  }\n  toJSON() {\n    return this.getHex();\n  }\n  *[Symbol.iterator]() {\n    yield this.r;\n    yield this.g;\n    yield this.b;\n  }\n}\nconst _color = /*@__PURE__*/new Color();\nColor.NAMES = _colorKeywords;\nlet _materialId = 0;\nclass Material$1 extends EventDispatcher {\n  constructor() {\n    super();\n    this.isMaterial = true;\n    Object.defineProperty(this, 'id', {\n      value: _materialId++\n    });\n    this.uuid = generateUUID();\n    this.name = '';\n    this.type = 'Material';\n    this.blending = NormalBlending;\n    this.side = FrontSide;\n    this.vertexColors = false;\n    this.opacity = 1;\n    this.transparent = false;\n    this.alphaHash = false;\n    this.blendSrc = SrcAlphaFactor;\n    this.blendDst = OneMinusSrcAlphaFactor;\n    this.blendEquation = AddEquation;\n    this.blendSrcAlpha = null;\n    this.blendDstAlpha = null;\n    this.blendEquationAlpha = null;\n    this.blendColor = new Color(0, 0, 0);\n    this.blendAlpha = 0;\n    this.depthFunc = LessEqualDepth;\n    this.depthTest = true;\n    this.depthWrite = true;\n    this.stencilWriteMask = 0xff;\n    this.stencilFunc = AlwaysStencilFunc;\n    this.stencilRef = 0;\n    this.stencilFuncMask = 0xff;\n    this.stencilFail = KeepStencilOp;\n    this.stencilZFail = KeepStencilOp;\n    this.stencilZPass = KeepStencilOp;\n    this.stencilWrite = false;\n    this.clippingPlanes = null;\n    this.clipIntersection = false;\n    this.clipShadows = false;\n    this.shadowSide = null;\n    this.colorWrite = true;\n    this.precision = null; // override the renderer's default precision for this material\n\n    this.polygonOffset = false;\n    this.polygonOffsetFactor = 0;\n    this.polygonOffsetUnits = 0;\n    this.dithering = false;\n    this.alphaToCoverage = false;\n    this.premultipliedAlpha = false;\n    this.forceSinglePass = false;\n    this.visible = true;\n    this.toneMapped = true;\n    this.userData = {};\n    this.version = 0;\n    this._alphaTest = 0;\n  }\n  get alphaTest() {\n    return this._alphaTest;\n  }\n  set alphaTest(value) {\n    if (this._alphaTest > 0 !== value > 0) {\n      this.version++;\n    }\n    this._alphaTest = value;\n  }\n\n  // onBeforeRender and onBeforeCompile only supported in WebGLRenderer\n\n  onBeforeRender(/* renderer, scene, camera, geometry, object, group */) {}\n  onBeforeCompile(/* shaderobject, renderer */) {}\n  customProgramCacheKey() {\n    return this.onBeforeCompile.toString();\n  }\n  setValues(values) {\n    if (values === undefined) return;\n    for (const key in values) {\n      const newValue = values[key];\n      if (newValue === undefined) {\n        console.warn(`THREE.Material: parameter '${key}' has value of undefined.`);\n        continue;\n      }\n      const currentValue = this[key];\n      if (currentValue === undefined) {\n        console.warn(`THREE.Material: '${key}' is not a property of THREE.${this.type}.`);\n        continue;\n      }\n      if (currentValue && currentValue.isColor) {\n        currentValue.set(newValue);\n      } else if (currentValue && currentValue.isVector3 && newValue && newValue.isVector3) {\n        currentValue.copy(newValue);\n      } else {\n        this[key] = newValue;\n      }\n    }\n  }\n  toJSON(meta) {\n    const isRootObject = meta === undefined || typeof meta === 'string';\n    if (isRootObject) {\n      meta = {\n        textures: {},\n        images: {}\n      };\n    }\n    const data = {\n      metadata: {\n        version: 4.6,\n        type: 'Material',\n        generator: 'Material.toJSON'\n      }\n    };\n\n    // standard Material serialization\n    data.uuid = this.uuid;\n    data.type = this.type;\n    if (this.name !== '') data.name = this.name;\n    if (this.color && this.color.isColor) data.color = this.color.getHex();\n    if (this.roughness !== undefined) data.roughness = this.roughness;\n    if (this.metalness !== undefined) data.metalness = this.metalness;\n    if (this.sheen !== undefined) data.sheen = this.sheen;\n    if (this.sheenColor && this.sheenColor.isColor) data.sheenColor = this.sheenColor.getHex();\n    if (this.sheenRoughness !== undefined) data.sheenRoughness = this.sheenRoughness;\n    if (this.emissive && this.emissive.isColor) data.emissive = this.emissive.getHex();\n    if (this.emissiveIntensity !== undefined && this.emissiveIntensity !== 1) data.emissiveIntensity = this.emissiveIntensity;\n    if (this.specular && this.specular.isColor) data.specular = this.specular.getHex();\n    if (this.specularIntensity !== undefined) data.specularIntensity = this.specularIntensity;\n    if (this.specularColor && this.specularColor.isColor) data.specularColor = this.specularColor.getHex();\n    if (this.shininess !== undefined) data.shininess = this.shininess;\n    if (this.clearcoat !== undefined) data.clearcoat = this.clearcoat;\n    if (this.clearcoatRoughness !== undefined) data.clearcoatRoughness = this.clearcoatRoughness;\n    if (this.clearcoatMap && this.clearcoatMap.isTexture) {\n      data.clearcoatMap = this.clearcoatMap.toJSON(meta).uuid;\n    }\n    if (this.clearcoatRoughnessMap && this.clearcoatRoughnessMap.isTexture) {\n      data.clearcoatRoughnessMap = this.clearcoatRoughnessMap.toJSON(meta).uuid;\n    }\n    if (this.clearcoatNormalMap && this.clearcoatNormalMap.isTexture) {\n      data.clearcoatNormalMap = this.clearcoatNormalMap.toJSON(meta).uuid;\n      data.clearcoatNormalScale = this.clearcoatNormalScale.toArray();\n    }\n    if (this.dispersion !== undefined) data.dispersion = this.dispersion;\n    if (this.iridescence !== undefined) data.iridescence = this.iridescence;\n    if (this.iridescenceIOR !== undefined) data.iridescenceIOR = this.iridescenceIOR;\n    if (this.iridescenceThicknessRange !== undefined) data.iridescenceThicknessRange = this.iridescenceThicknessRange;\n    if (this.iridescenceMap && this.iridescenceMap.isTexture) {\n      data.iridescenceMap = this.iridescenceMap.toJSON(meta).uuid;\n    }\n    if (this.iridescenceThicknessMap && this.iridescenceThicknessMap.isTexture) {\n      data.iridescenceThicknessMap = this.iridescenceThicknessMap.toJSON(meta).uuid;\n    }\n    if (this.anisotropy !== undefined) data.anisotropy = this.anisotropy;\n    if (this.anisotropyRotation !== undefined) data.anisotropyRotation = this.anisotropyRotation;\n    if (this.anisotropyMap && this.anisotropyMap.isTexture) {\n      data.anisotropyMap = this.anisotropyMap.toJSON(meta).uuid;\n    }\n    if (this.map && this.map.isTexture) data.map = this.map.toJSON(meta).uuid;\n    if (this.matcap && this.matcap.isTexture) data.matcap = this.matcap.toJSON(meta).uuid;\n    if (this.alphaMap && this.alphaMap.isTexture) data.alphaMap = this.alphaMap.toJSON(meta).uuid;\n    if (this.lightMap && this.lightMap.isTexture) {\n      data.lightMap = this.lightMap.toJSON(meta).uuid;\n      data.lightMapIntensity = this.lightMapIntensity;\n    }\n    if (this.aoMap && this.aoMap.isTexture) {\n      data.aoMap = this.aoMap.toJSON(meta).uuid;\n      data.aoMapIntensity = this.aoMapIntensity;\n    }\n    if (this.bumpMap && this.bumpMap.isTexture) {\n      data.bumpMap = this.bumpMap.toJSON(meta).uuid;\n      data.bumpScale = this.bumpScale;\n    }\n    if (this.normalMap && this.normalMap.isTexture) {\n      data.normalMap = this.normalMap.toJSON(meta).uuid;\n      data.normalMapType = this.normalMapType;\n      data.normalScale = this.normalScale.toArray();\n    }\n    if (this.displacementMap && this.displacementMap.isTexture) {\n      data.displacementMap = this.displacementMap.toJSON(meta).uuid;\n      data.displacementScale = this.displacementScale;\n      data.displacementBias = this.displacementBias;\n    }\n    if (this.roughnessMap && this.roughnessMap.isTexture) data.roughnessMap = this.roughnessMap.toJSON(meta).uuid;\n    if (this.metalnessMap && this.metalnessMap.isTexture) data.metalnessMap = this.metalnessMap.toJSON(meta).uuid;\n    if (this.emissiveMap && this.emissiveMap.isTexture) data.emissiveMap = this.emissiveMap.toJSON(meta).uuid;\n    if (this.specularMap && this.specularMap.isTexture) data.specularMap = this.specularMap.toJSON(meta).uuid;\n    if (this.specularIntensityMap && this.specularIntensityMap.isTexture) data.specularIntensityMap = this.specularIntensityMap.toJSON(meta).uuid;\n    if (this.specularColorMap && this.specularColorMap.isTexture) data.specularColorMap = this.specularColorMap.toJSON(meta).uuid;\n    if (this.envMap && this.envMap.isTexture) {\n      data.envMap = this.envMap.toJSON(meta).uuid;\n      if (this.combine !== undefined) data.combine = this.combine;\n    }\n    if (this.envMapRotation !== undefined) data.envMapRotation = this.envMapRotation.toArray();\n    if (this.envMapIntensity !== undefined) data.envMapIntensity = this.envMapIntensity;\n    if (this.reflectivity !== undefined) data.reflectivity = this.reflectivity;\n    if (this.refractionRatio !== undefined) data.refractionRatio = this.refractionRatio;\n    if (this.gradientMap && this.gradientMap.isTexture) {\n      data.gradientMap = this.gradientMap.toJSON(meta).uuid;\n    }\n    if (this.transmission !== undefined) data.transmission = this.transmission;\n    if (this.transmissionMap && this.transmissionMap.isTexture) data.transmissionMap = this.transmissionMap.toJSON(meta).uuid;\n    if (this.thickness !== undefined) data.thickness = this.thickness;\n    if (this.thicknessMap && this.thicknessMap.isTexture) data.thicknessMap = this.thicknessMap.toJSON(meta).uuid;\n    if (this.attenuationDistance !== undefined && this.attenuationDistance !== Infinity) data.attenuationDistance = this.attenuationDistance;\n    if (this.attenuationColor !== undefined) data.attenuationColor = this.attenuationColor.getHex();\n    if (this.size !== undefined) data.size = this.size;\n    if (this.shadowSide !== null) data.shadowSide = this.shadowSide;\n    if (this.sizeAttenuation !== undefined) data.sizeAttenuation = this.sizeAttenuation;\n    if (this.blending !== NormalBlending) data.blending = this.blending;\n    if (this.side !== FrontSide) data.side = this.side;\n    if (this.vertexColors === true) data.vertexColors = true;\n    if (this.opacity < 1) data.opacity = this.opacity;\n    if (this.transparent === true) data.transparent = true;\n    if (this.blendSrc !== SrcAlphaFactor) data.blendSrc = this.blendSrc;\n    if (this.blendDst !== OneMinusSrcAlphaFactor) data.blendDst = this.blendDst;\n    if (this.blendEquation !== AddEquation) data.blendEquation = this.blendEquation;\n    if (this.blendSrcAlpha !== null) data.blendSrcAlpha = this.blendSrcAlpha;\n    if (this.blendDstAlpha !== null) data.blendDstAlpha = this.blendDstAlpha;\n    if (this.blendEquationAlpha !== null) data.blendEquationAlpha = this.blendEquationAlpha;\n    if (this.blendColor && this.blendColor.isColor) data.blendColor = this.blendColor.getHex();\n    if (this.blendAlpha !== 0) data.blendAlpha = this.blendAlpha;\n    if (this.depthFunc !== LessEqualDepth) data.depthFunc = this.depthFunc;\n    if (this.depthTest === false) data.depthTest = this.depthTest;\n    if (this.depthWrite === false) data.depthWrite = this.depthWrite;\n    if (this.colorWrite === false) data.colorWrite = this.colorWrite;\n    if (this.stencilWriteMask !== 0xff) data.stencilWriteMask = this.stencilWriteMask;\n    if (this.stencilFunc !== AlwaysStencilFunc) data.stencilFunc = this.stencilFunc;\n    if (this.stencilRef !== 0) data.stencilRef = this.stencilRef;\n    if (this.stencilFuncMask !== 0xff) data.stencilFuncMask = this.stencilFuncMask;\n    if (this.stencilFail !== KeepStencilOp) data.stencilFail = this.stencilFail;\n    if (this.stencilZFail !== KeepStencilOp) data.stencilZFail = this.stencilZFail;\n    if (this.stencilZPass !== KeepStencilOp) data.stencilZPass = this.stencilZPass;\n    if (this.stencilWrite === true) data.stencilWrite = this.stencilWrite;\n\n    // rotation (SpriteMaterial)\n    if (this.rotation !== undefined && this.rotation !== 0) data.rotation = this.rotation;\n    if (this.polygonOffset === true) data.polygonOffset = true;\n    if (this.polygonOffsetFactor !== 0) data.polygonOffsetFactor = this.polygonOffsetFactor;\n    if (this.polygonOffsetUnits !== 0) data.polygonOffsetUnits = this.polygonOffsetUnits;\n    if (this.linewidth !== undefined && this.linewidth !== 1) data.linewidth = this.linewidth;\n    if (this.dashSize !== undefined) data.dashSize = this.dashSize;\n    if (this.gapSize !== undefined) data.gapSize = this.gapSize;\n    if (this.scale !== undefined) data.scale = this.scale;\n    if (this.dithering === true) data.dithering = true;\n    if (this.alphaTest > 0) data.alphaTest = this.alphaTest;\n    if (this.alphaHash === true) data.alphaHash = true;\n    if (this.alphaToCoverage === true) data.alphaToCoverage = true;\n    if (this.premultipliedAlpha === true) data.premultipliedAlpha = true;\n    if (this.forceSinglePass === true) data.forceSinglePass = true;\n    if (this.wireframe === true) data.wireframe = true;\n    if (this.wireframeLinewidth > 1) data.wireframeLinewidth = this.wireframeLinewidth;\n    if (this.wireframeLinecap !== 'round') data.wireframeLinecap = this.wireframeLinecap;\n    if (this.wireframeLinejoin !== 'round') data.wireframeLinejoin = this.wireframeLinejoin;\n    if (this.flatShading === true) data.flatShading = true;\n    if (this.visible === false) data.visible = false;\n    if (this.toneMapped === false) data.toneMapped = false;\n    if (this.fog === false) data.fog = false;\n    if (Object.keys(this.userData).length > 0) data.userData = this.userData;\n\n    // TODO: Copied from Object3D.toJSON\n\n    function extractFromCache(cache) {\n      const values = [];\n      for (const key in cache) {\n        const data = cache[key];\n        delete data.metadata;\n        values.push(data);\n      }\n      return values;\n    }\n    if (isRootObject) {\n      const textures = extractFromCache(meta.textures);\n      const images = extractFromCache(meta.images);\n      if (textures.length > 0) data.textures = textures;\n      if (images.length > 0) data.images = images;\n    }\n    return data;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  copy(source) {\n    this.name = source.name;\n    this.blending = source.blending;\n    this.side = source.side;\n    this.vertexColors = source.vertexColors;\n    this.opacity = source.opacity;\n    this.transparent = source.transparent;\n    this.blendSrc = source.blendSrc;\n    this.blendDst = source.blendDst;\n    this.blendEquation = source.blendEquation;\n    this.blendSrcAlpha = source.blendSrcAlpha;\n    this.blendDstAlpha = source.blendDstAlpha;\n    this.blendEquationAlpha = source.blendEquationAlpha;\n    this.blendColor.copy(source.blendColor);\n    this.blendAlpha = source.blendAlpha;\n    this.depthFunc = source.depthFunc;\n    this.depthTest = source.depthTest;\n    this.depthWrite = source.depthWrite;\n    this.stencilWriteMask = source.stencilWriteMask;\n    this.stencilFunc = source.stencilFunc;\n    this.stencilRef = source.stencilRef;\n    this.stencilFuncMask = source.stencilFuncMask;\n    this.stencilFail = source.stencilFail;\n    this.stencilZFail = source.stencilZFail;\n    this.stencilZPass = source.stencilZPass;\n    this.stencilWrite = source.stencilWrite;\n    const srcPlanes = source.clippingPlanes;\n    let dstPlanes = null;\n    if (srcPlanes !== null) {\n      const n = srcPlanes.length;\n      dstPlanes = new Array(n);\n      for (let i = 0; i !== n; ++i) {\n        dstPlanes[i] = srcPlanes[i].clone();\n      }\n    }\n    this.clippingPlanes = dstPlanes;\n    this.clipIntersection = source.clipIntersection;\n    this.clipShadows = source.clipShadows;\n    this.shadowSide = source.shadowSide;\n    this.colorWrite = source.colorWrite;\n    this.precision = source.precision;\n    this.polygonOffset = source.polygonOffset;\n    this.polygonOffsetFactor = source.polygonOffsetFactor;\n    this.polygonOffsetUnits = source.polygonOffsetUnits;\n    this.dithering = source.dithering;\n    this.alphaTest = source.alphaTest;\n    this.alphaHash = source.alphaHash;\n    this.alphaToCoverage = source.alphaToCoverage;\n    this.premultipliedAlpha = source.premultipliedAlpha;\n    this.forceSinglePass = source.forceSinglePass;\n    this.visible = source.visible;\n    this.toneMapped = source.toneMapped;\n    this.userData = JSON.parse(JSON.stringify(source.userData));\n    return this;\n  }\n  dispose() {\n    this.dispatchEvent({\n      type: 'dispose'\n    });\n  }\n  set needsUpdate(value) {\n    if (value === true) this.version++;\n  }\n  onBuild(/* shaderobject, renderer */\n  ) {\n    console.warn('Material: onBuild() has been removed.'); // @deprecated, r166\n  }\n}\nclass MeshBasicMaterial extends Material$1 {\n  constructor(parameters) {\n    super();\n    this.isMeshBasicMaterial = true;\n    this.type = 'MeshBasicMaterial';\n    this.color = new Color(0xffffff); // emissive\n\n    this.map = null;\n    this.lightMap = null;\n    this.lightMapIntensity = 1.0;\n    this.aoMap = null;\n    this.aoMapIntensity = 1.0;\n    this.specularMap = null;\n    this.alphaMap = null;\n    this.envMap = null;\n    this.envMapRotation = new Euler();\n    this.combine = MultiplyOperation;\n    this.reflectivity = 1;\n    this.refractionRatio = 0.98;\n    this.wireframe = false;\n    this.wireframeLinewidth = 1;\n    this.wireframeLinecap = 'round';\n    this.wireframeLinejoin = 'round';\n    this.fog = true;\n    this.setValues(parameters);\n  }\n  copy(source) {\n    super.copy(source);\n    this.color.copy(source.color);\n    this.map = source.map;\n    this.lightMap = source.lightMap;\n    this.lightMapIntensity = source.lightMapIntensity;\n    this.aoMap = source.aoMap;\n    this.aoMapIntensity = source.aoMapIntensity;\n    this.specularMap = source.specularMap;\n    this.alphaMap = source.alphaMap;\n    this.envMap = source.envMap;\n    this.envMapRotation.copy(source.envMapRotation);\n    this.combine = source.combine;\n    this.reflectivity = source.reflectivity;\n    this.refractionRatio = source.refractionRatio;\n    this.wireframe = source.wireframe;\n    this.wireframeLinewidth = source.wireframeLinewidth;\n    this.wireframeLinecap = source.wireframeLinecap;\n    this.wireframeLinejoin = source.wireframeLinejoin;\n    this.fog = source.fog;\n    return this;\n  }\n}\n\n// Fast Half Float Conversions, http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n\nconst _tables = /*@__PURE__*/_generateTables();\nfunction _generateTables() {\n  // float32 to float16 helpers\n\n  const buffer = new ArrayBuffer(4);\n  const floatView = new Float32Array(buffer);\n  const uint32View = new Uint32Array(buffer);\n  const baseTable = new Uint32Array(512);\n  const shiftTable = new Uint32Array(512);\n  for (let i = 0; i < 256; ++i) {\n    const e = i - 127;\n\n    // very small number (0, -0)\n\n    if (e < -27) {\n      baseTable[i] = 0x0000;\n      baseTable[i | 0x100] = 0x8000;\n      shiftTable[i] = 24;\n      shiftTable[i | 0x100] = 24;\n\n      // small number (denorm)\n    } else if (e < -14) {\n      baseTable[i] = 0x0400 >> -e - 14;\n      baseTable[i | 0x100] = 0x0400 >> -e - 14 | 0x8000;\n      shiftTable[i] = -e - 1;\n      shiftTable[i | 0x100] = -e - 1;\n\n      // normal number\n    } else if (e <= 15) {\n      baseTable[i] = e + 15 << 10;\n      baseTable[i | 0x100] = e + 15 << 10 | 0x8000;\n      shiftTable[i] = 13;\n      shiftTable[i | 0x100] = 13;\n\n      // large number (Infinity, -Infinity)\n    } else if (e < 128) {\n      baseTable[i] = 0x7c00;\n      baseTable[i | 0x100] = 0xfc00;\n      shiftTable[i] = 24;\n      shiftTable[i | 0x100] = 24;\n\n      // stay (NaN, Infinity, -Infinity)\n    } else {\n      baseTable[i] = 0x7c00;\n      baseTable[i | 0x100] = 0xfc00;\n      shiftTable[i] = 13;\n      shiftTable[i | 0x100] = 13;\n    }\n  }\n\n  // float16 to float32 helpers\n\n  const mantissaTable = new Uint32Array(2048);\n  const exponentTable = new Uint32Array(64);\n  const offsetTable = new Uint32Array(64);\n  for (let i = 1; i < 1024; ++i) {\n    let m = i << 13; // zero pad mantissa bits\n    let e = 0; // zero exponent\n\n    // normalized\n    while ((m & 0x00800000) === 0) {\n      m <<= 1;\n      e -= 0x00800000; // decrement exponent\n    }\n    m &= ~0x00800000; // clear leading 1 bit\n    e += 0x38800000; // adjust bias\n\n    mantissaTable[i] = m | e;\n  }\n  for (let i = 1024; i < 2048; ++i) {\n    mantissaTable[i] = 0x38000000 + (i - 1024 << 13);\n  }\n  for (let i = 1; i < 31; ++i) {\n    exponentTable[i] = i << 23;\n  }\n  exponentTable[31] = 0x47800000;\n  exponentTable[32] = 0x80000000;\n  for (let i = 33; i < 63; ++i) {\n    exponentTable[i] = 0x80000000 + (i - 32 << 23);\n  }\n  exponentTable[63] = 0xc7800000;\n  for (let i = 1; i < 64; ++i) {\n    if (i !== 32) {\n      offsetTable[i] = 1024;\n    }\n  }\n  return {\n    floatView: floatView,\n    uint32View: uint32View,\n    baseTable: baseTable,\n    shiftTable: shiftTable,\n    mantissaTable: mantissaTable,\n    exponentTable: exponentTable,\n    offsetTable: offsetTable\n  };\n}\n\n// float32 to float16\n\nfunction toHalfFloat(val) {\n  if (Math.abs(val) > 65504) console.warn('THREE.DataUtils.toHalfFloat(): Value out of range.');\n  val = clamp$1(val, -65504, 65504);\n  _tables.floatView[0] = val;\n  const f = _tables.uint32View[0];\n  const e = f >> 23 & 0x1ff;\n  return _tables.baseTable[e] + ((f & 0x007fffff) >> _tables.shiftTable[e]);\n}\n\n// float16 to float32\n\nfunction fromHalfFloat(val) {\n  const m = val >> 10;\n  _tables.uint32View[0] = _tables.mantissaTable[_tables.offsetTable[m] + (val & 0x3ff)] + _tables.exponentTable[m];\n  return _tables.floatView[0];\n}\nconst DataUtils = {\n  toHalfFloat: toHalfFloat,\n  fromHalfFloat: fromHalfFloat\n};\nconst _vector$9 = /*@__PURE__*/new Vector3();\nconst _vector2$1 = /*@__PURE__*/new Vector2();\nclass BufferAttribute {\n  constructor(array, itemSize, normalized = false) {\n    if (Array.isArray(array)) {\n      throw new TypeError('THREE.BufferAttribute: array should be a Typed Array.');\n    }\n    this.isBufferAttribute = true;\n    this.name = '';\n    this.array = array;\n    this.itemSize = itemSize;\n    this.count = array !== undefined ? array.length / itemSize : 0;\n    this.normalized = normalized;\n    this.usage = StaticDrawUsage;\n    this.updateRanges = [];\n    this.gpuType = FloatType;\n    this.version = 0;\n  }\n  onUploadCallback() {}\n  set needsUpdate(value) {\n    if (value === true) this.version++;\n  }\n  setUsage(value) {\n    this.usage = value;\n    return this;\n  }\n  addUpdateRange(start, count) {\n    this.updateRanges.push({\n      start,\n      count\n    });\n  }\n  clearUpdateRanges() {\n    this.updateRanges.length = 0;\n  }\n  copy(source) {\n    this.name = source.name;\n    this.array = new source.array.constructor(source.array);\n    this.itemSize = source.itemSize;\n    this.count = source.count;\n    this.normalized = source.normalized;\n    this.usage = source.usage;\n    this.gpuType = source.gpuType;\n    return this;\n  }\n  copyAt(index1, attribute, index2) {\n    index1 *= this.itemSize;\n    index2 *= attribute.itemSize;\n    for (let i = 0, l = this.itemSize; i < l; i++) {\n      this.array[index1 + i] = attribute.array[index2 + i];\n    }\n    return this;\n  }\n  copyArray(array) {\n    this.array.set(array);\n    return this;\n  }\n  applyMatrix3(m) {\n    if (this.itemSize === 2) {\n      for (let i = 0, l = this.count; i < l; i++) {\n        _vector2$1.fromBufferAttribute(this, i);\n        _vector2$1.applyMatrix3(m);\n        this.setXY(i, _vector2$1.x, _vector2$1.y);\n      }\n    } else if (this.itemSize === 3) {\n      for (let i = 0, l = this.count; i < l; i++) {\n        _vector$9.fromBufferAttribute(this, i);\n        _vector$9.applyMatrix3(m);\n        this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);\n      }\n    }\n    return this;\n  }\n  applyMatrix4(m) {\n    for (let i = 0, l = this.count; i < l; i++) {\n      _vector$9.fromBufferAttribute(this, i);\n      _vector$9.applyMatrix4(m);\n      this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);\n    }\n    return this;\n  }\n  applyNormalMatrix(m) {\n    for (let i = 0, l = this.count; i < l; i++) {\n      _vector$9.fromBufferAttribute(this, i);\n      _vector$9.applyNormalMatrix(m);\n      this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);\n    }\n    return this;\n  }\n  transformDirection(m) {\n    for (let i = 0, l = this.count; i < l; i++) {\n      _vector$9.fromBufferAttribute(this, i);\n      _vector$9.transformDirection(m);\n      this.setXYZ(i, _vector$9.x, _vector$9.y, _vector$9.z);\n    }\n    return this;\n  }\n  set(value, offset = 0) {\n    // Matching BufferAttribute constructor, do not normalize the array.\n    this.array.set(value, offset);\n    return this;\n  }\n  getComponent(index, component) {\n    let value = this.array[index * this.itemSize + component];\n    if (this.normalized) value = denormalize(value, this.array);\n    return value;\n  }\n  setComponent(index, component, value) {\n    if (this.normalized) value = normalize(value, this.array);\n    this.array[index * this.itemSize + component] = value;\n    return this;\n  }\n  getX(index) {\n    let x = this.array[index * this.itemSize];\n    if (this.normalized) x = denormalize(x, this.array);\n    return x;\n  }\n  setX(index, x) {\n    if (this.normalized) x = normalize(x, this.array);\n    this.array[index * this.itemSize] = x;\n    return this;\n  }\n  getY(index) {\n    let y = this.array[index * this.itemSize + 1];\n    if (this.normalized) y = denormalize(y, this.array);\n    return y;\n  }\n  setY(index, y) {\n    if (this.normalized) y = normalize(y, this.array);\n    this.array[index * this.itemSize + 1] = y;\n    return this;\n  }\n  getZ(index) {\n    let z = this.array[index * this.itemSize + 2];\n    if (this.normalized) z = denormalize(z, this.array);\n    return z;\n  }\n  setZ(index, z) {\n    if (this.normalized) z = normalize(z, this.array);\n    this.array[index * this.itemSize + 2] = z;\n    return this;\n  }\n  getW(index) {\n    let w = this.array[index * this.itemSize + 3];\n    if (this.normalized) w = denormalize(w, this.array);\n    return w;\n  }\n  setW(index, w) {\n    if (this.normalized) w = normalize(w, this.array);\n    this.array[index * this.itemSize + 3] = w;\n    return this;\n  }\n  setXY(index, x, y) {\n    index *= this.itemSize;\n    if (this.normalized) {\n      x = normalize(x, this.array);\n      y = normalize(y, this.array);\n    }\n    this.array[index + 0] = x;\n    this.array[index + 1] = y;\n    return this;\n  }\n  setXYZ(index, x, y, z) {\n    index *= this.itemSize;\n    if (this.normalized) {\n      x = normalize(x, this.array);\n      y = normalize(y, this.array);\n      z = normalize(z, this.array);\n    }\n    this.array[index + 0] = x;\n    this.array[index + 1] = y;\n    this.array[index + 2] = z;\n    return this;\n  }\n  setXYZW(index, x, y, z, w) {\n    index *= this.itemSize;\n    if (this.normalized) {\n      x = normalize(x, this.array);\n      y = normalize(y, this.array);\n      z = normalize(z, this.array);\n      w = normalize(w, this.array);\n    }\n    this.array[index + 0] = x;\n    this.array[index + 1] = y;\n    this.array[index + 2] = z;\n    this.array[index + 3] = w;\n    return this;\n  }\n  onUpload(callback) {\n    this.onUploadCallback = callback;\n    return this;\n  }\n  clone() {\n    return new this.constructor(this.array, this.itemSize).copy(this);\n  }\n  toJSON() {\n    const data = {\n      itemSize: this.itemSize,\n      type: this.array.constructor.name,\n      array: Array.from(this.array),\n      normalized: this.normalized\n    };\n    if (this.name !== '') data.name = this.name;\n    if (this.usage !== StaticDrawUsage) data.usage = this.usage;\n    return data;\n  }\n}\nclass Uint16BufferAttribute extends BufferAttribute {\n  constructor(array, itemSize, normalized) {\n    super(new Uint16Array(array), itemSize, normalized);\n  }\n}\nclass Uint32BufferAttribute extends BufferAttribute {\n  constructor(array, itemSize, normalized) {\n    super(new Uint32Array(array), itemSize, normalized);\n  }\n}\nclass Float32BufferAttribute extends BufferAttribute {\n  constructor(array, itemSize, normalized) {\n    super(new Float32Array(array), itemSize, normalized);\n  }\n}\nlet _id$2 = 0;\nconst _m1$2 = /*@__PURE__*/new Matrix4();\nconst _obj = /*@__PURE__*/new Object3D();\nconst _offset = /*@__PURE__*/new Vector3();\nconst _box$2 = /*@__PURE__*/new Box3();\nconst _boxMorphTargets = /*@__PURE__*/new Box3();\nconst _vector$8 = /*@__PURE__*/new Vector3();\nclass BufferGeometry extends EventDispatcher {\n  constructor() {\n    super();\n    this.isBufferGeometry = true;\n    Object.defineProperty(this, 'id', {\n      value: _id$2++\n    });\n    this.uuid = generateUUID();\n    this.name = '';\n    this.type = 'BufferGeometry';\n    this.index = null;\n    this.attributes = {};\n    this.morphAttributes = {};\n    this.morphTargetsRelative = false;\n    this.groups = [];\n    this.boundingBox = null;\n    this.boundingSphere = null;\n    this.drawRange = {\n      start: 0,\n      count: Infinity\n    };\n    this.userData = {};\n  }\n  getIndex() {\n    return this.index;\n  }\n  setIndex(index) {\n    if (Array.isArray(index)) {\n      this.index = new (arrayNeedsUint32(index) ? Uint32BufferAttribute : Uint16BufferAttribute)(index, 1);\n    } else {\n      this.index = index;\n    }\n    return this;\n  }\n  getAttribute(name) {\n    return this.attributes[name];\n  }\n  setAttribute(name, attribute) {\n    this.attributes[name] = attribute;\n    return this;\n  }\n  deleteAttribute(name) {\n    delete this.attributes[name];\n    return this;\n  }\n  hasAttribute(name) {\n    return this.attributes[name] !== undefined;\n  }\n  addGroup(start, count, materialIndex = 0) {\n    this.groups.push({\n      start: start,\n      count: count,\n      materialIndex: materialIndex\n    });\n  }\n  clearGroups() {\n    this.groups = [];\n  }\n  setDrawRange(start, count) {\n    this.drawRange.start = start;\n    this.drawRange.count = count;\n  }\n  applyMatrix4(matrix) {\n    const position = this.attributes.position;\n    if (position !== undefined) {\n      position.applyMatrix4(matrix);\n      position.needsUpdate = true;\n    }\n    const normal = this.attributes.normal;\n    if (normal !== undefined) {\n      const normalMatrix = new Matrix3().getNormalMatrix(matrix);\n      normal.applyNormalMatrix(normalMatrix);\n      normal.needsUpdate = true;\n    }\n    const tangent = this.attributes.tangent;\n    if (tangent !== undefined) {\n      tangent.transformDirection(matrix);\n      tangent.needsUpdate = true;\n    }\n    if (this.boundingBox !== null) {\n      this.computeBoundingBox();\n    }\n    if (this.boundingSphere !== null) {\n      this.computeBoundingSphere();\n    }\n    return this;\n  }\n  applyQuaternion(q) {\n    _m1$2.makeRotationFromQuaternion(q);\n    this.applyMatrix4(_m1$2);\n    return this;\n  }\n  rotateX(angle) {\n    // rotate geometry around world x-axis\n\n    _m1$2.makeRotationX(angle);\n    this.applyMatrix4(_m1$2);\n    return this;\n  }\n  rotateY(angle) {\n    // rotate geometry around world y-axis\n\n    _m1$2.makeRotationY(angle);\n    this.applyMatrix4(_m1$2);\n    return this;\n  }\n  rotateZ(angle) {\n    // rotate geometry around world z-axis\n\n    _m1$2.makeRotationZ(angle);\n    this.applyMatrix4(_m1$2);\n    return this;\n  }\n  translate(x, y, z) {\n    // translate geometry\n\n    _m1$2.makeTranslation(x, y, z);\n    this.applyMatrix4(_m1$2);\n    return this;\n  }\n  scale(x, y, z) {\n    // scale geometry\n\n    _m1$2.makeScale(x, y, z);\n    this.applyMatrix4(_m1$2);\n    return this;\n  }\n  lookAt(vector) {\n    _obj.lookAt(vector);\n    _obj.updateMatrix();\n    this.applyMatrix4(_obj.matrix);\n    return this;\n  }\n  center() {\n    this.computeBoundingBox();\n    this.boundingBox.getCenter(_offset).negate();\n    this.translate(_offset.x, _offset.y, _offset.z);\n    return this;\n  }\n  setFromPoints(points) {\n    const position = [];\n    for (let i = 0, l = points.length; i < l; i++) {\n      const point = points[i];\n      position.push(point.x, point.y, point.z || 0);\n    }\n    this.setAttribute('position', new Float32BufferAttribute(position, 3));\n    return this;\n  }\n  computeBoundingBox() {\n    if (this.boundingBox === null) {\n      this.boundingBox = new Box3();\n    }\n    const position = this.attributes.position;\n    const morphAttributesPosition = this.morphAttributes.position;\n    if (position && position.isGLBufferAttribute) {\n      console.error('THREE.BufferGeometry.computeBoundingBox(): GLBufferAttribute requires a manual bounding box.', this);\n      this.boundingBox.set(new Vector3(-Infinity, -Infinity, -Infinity), new Vector3(+Infinity, +Infinity, +Infinity));\n      return;\n    }\n    if (position !== undefined) {\n      this.boundingBox.setFromBufferAttribute(position);\n\n      // process morph attributes if present\n\n      if (morphAttributesPosition) {\n        for (let i = 0, il = morphAttributesPosition.length; i < il; i++) {\n          const morphAttribute = morphAttributesPosition[i];\n          _box$2.setFromBufferAttribute(morphAttribute);\n          if (this.morphTargetsRelative) {\n            _vector$8.addVectors(this.boundingBox.min, _box$2.min);\n            this.boundingBox.expandByPoint(_vector$8);\n            _vector$8.addVectors(this.boundingBox.max, _box$2.max);\n            this.boundingBox.expandByPoint(_vector$8);\n          } else {\n            this.boundingBox.expandByPoint(_box$2.min);\n            this.boundingBox.expandByPoint(_box$2.max);\n          }\n        }\n      }\n    } else {\n      this.boundingBox.makeEmpty();\n    }\n    if (isNaN(this.boundingBox.min.x) || isNaN(this.boundingBox.min.y) || isNaN(this.boundingBox.min.z)) {\n      console.error('THREE.BufferGeometry.computeBoundingBox(): Computed min/max have NaN values. The \"position\" attribute is likely to have NaN values.', this);\n    }\n  }\n  computeBoundingSphere() {\n    if (this.boundingSphere === null) {\n      this.boundingSphere = new Sphere();\n    }\n    const position = this.attributes.position;\n    const morphAttributesPosition = this.morphAttributes.position;\n    if (position && position.isGLBufferAttribute) {\n      console.error('THREE.BufferGeometry.computeBoundingSphere(): GLBufferAttribute requires a manual bounding sphere.', this);\n      this.boundingSphere.set(new Vector3(), Infinity);\n      return;\n    }\n    if (position) {\n      // first, find the center of the bounding sphere\n\n      const center = this.boundingSphere.center;\n      _box$2.setFromBufferAttribute(position);\n\n      // process morph attributes if present\n\n      if (morphAttributesPosition) {\n        for (let i = 0, il = morphAttributesPosition.length; i < il; i++) {\n          const morphAttribute = morphAttributesPosition[i];\n          _boxMorphTargets.setFromBufferAttribute(morphAttribute);\n          if (this.morphTargetsRelative) {\n            _vector$8.addVectors(_box$2.min, _boxMorphTargets.min);\n            _box$2.expandByPoint(_vector$8);\n            _vector$8.addVectors(_box$2.max, _boxMorphTargets.max);\n            _box$2.expandByPoint(_vector$8);\n          } else {\n            _box$2.expandByPoint(_boxMorphTargets.min);\n            _box$2.expandByPoint(_boxMorphTargets.max);\n          }\n        }\n      }\n      _box$2.getCenter(center);\n\n      // second, try to find a boundingSphere with a radius smaller than the\n      // boundingSphere of the boundingBox: sqrt(3) smaller in the best case\n\n      let maxRadiusSq = 0;\n      for (let i = 0, il = position.count; i < il; i++) {\n        _vector$8.fromBufferAttribute(position, i);\n        maxRadiusSq = Math.max(maxRadiusSq, center.distanceToSquared(_vector$8));\n      }\n\n      // process morph attributes if present\n\n      if (morphAttributesPosition) {\n        for (let i = 0, il = morphAttributesPosition.length; i < il; i++) {\n          const morphAttribute = morphAttributesPosition[i];\n          const morphTargetsRelative = this.morphTargetsRelative;\n          for (let j = 0, jl = morphAttribute.count; j < jl; j++) {\n            _vector$8.fromBufferAttribute(morphAttribute, j);\n            if (morphTargetsRelative) {\n              _offset.fromBufferAttribute(position, j);\n              _vector$8.add(_offset);\n            }\n            maxRadiusSq = Math.max(maxRadiusSq, center.distanceToSquared(_vector$8));\n          }\n        }\n      }\n      this.boundingSphere.radius = Math.sqrt(maxRadiusSq);\n      if (isNaN(this.boundingSphere.radius)) {\n        console.error('THREE.BufferGeometry.computeBoundingSphere(): Computed radius is NaN. The \"position\" attribute is likely to have NaN values.', this);\n      }\n    }\n  }\n  computeTangents() {\n    const index = this.index;\n    const attributes = this.attributes;\n\n    // based on http://www.terathon.com/code/tangent.html\n    // (per vertex tangents)\n\n    if (index === null || attributes.position === undefined || attributes.normal === undefined || attributes.uv === undefined) {\n      console.error('THREE.BufferGeometry: .computeTangents() failed. Missing required attributes (index, position, normal or uv)');\n      return;\n    }\n    const positionAttribute = attributes.position;\n    const normalAttribute = attributes.normal;\n    const uvAttribute = attributes.uv;\n    if (this.hasAttribute('tangent') === false) {\n      this.setAttribute('tangent', new BufferAttribute(new Float32Array(4 * positionAttribute.count), 4));\n    }\n    const tangentAttribute = this.getAttribute('tangent');\n    const tan1 = [],\n      tan2 = [];\n    for (let i = 0; i < positionAttribute.count; i++) {\n      tan1[i] = new Vector3();\n      tan2[i] = new Vector3();\n    }\n    const vA = new Vector3(),\n      vB = new Vector3(),\n      vC = new Vector3(),\n      uvA = new Vector2(),\n      uvB = new Vector2(),\n      uvC = new Vector2(),\n      sdir = new Vector3(),\n      tdir = new Vector3();\n    function handleTriangle(a, b, c) {\n      vA.fromBufferAttribute(positionAttribute, a);\n      vB.fromBufferAttribute(positionAttribute, b);\n      vC.fromBufferAttribute(positionAttribute, c);\n      uvA.fromBufferAttribute(uvAttribute, a);\n      uvB.fromBufferAttribute(uvAttribute, b);\n      uvC.fromBufferAttribute(uvAttribute, c);\n      vB.sub(vA);\n      vC.sub(vA);\n      uvB.sub(uvA);\n      uvC.sub(uvA);\n      const r = 1.0 / (uvB.x * uvC.y - uvC.x * uvB.y);\n\n      // silently ignore degenerate uv triangles having coincident or colinear vertices\n\n      if (!isFinite(r)) return;\n      sdir.copy(vB).multiplyScalar(uvC.y).addScaledVector(vC, -uvB.y).multiplyScalar(r);\n      tdir.copy(vC).multiplyScalar(uvB.x).addScaledVector(vB, -uvC.x).multiplyScalar(r);\n      tan1[a].add(sdir);\n      tan1[b].add(sdir);\n      tan1[c].add(sdir);\n      tan2[a].add(tdir);\n      tan2[b].add(tdir);\n      tan2[c].add(tdir);\n    }\n    let groups = this.groups;\n    if (groups.length === 0) {\n      groups = [{\n        start: 0,\n        count: index.count\n      }];\n    }\n    for (let i = 0, il = groups.length; i < il; ++i) {\n      const group = groups[i];\n      const start = group.start;\n      const count = group.count;\n      for (let j = start, jl = start + count; j < jl; j += 3) {\n        handleTriangle(index.getX(j + 0), index.getX(j + 1), index.getX(j + 2));\n      }\n    }\n    const tmp = new Vector3(),\n      tmp2 = new Vector3();\n    const n = new Vector3(),\n      n2 = new Vector3();\n    function handleVertex(v) {\n      n.fromBufferAttribute(normalAttribute, v);\n      n2.copy(n);\n      const t = tan1[v];\n\n      // Gram-Schmidt orthogonalize\n\n      tmp.copy(t);\n      tmp.sub(n.multiplyScalar(n.dot(t))).normalize();\n\n      // Calculate handedness\n\n      tmp2.crossVectors(n2, t);\n      const test = tmp2.dot(tan2[v]);\n      const w = test < 0.0 ? -1.0 : 1.0;\n      tangentAttribute.setXYZW(v, tmp.x, tmp.y, tmp.z, w);\n    }\n    for (let i = 0, il = groups.length; i < il; ++i) {\n      const group = groups[i];\n      const start = group.start;\n      const count = group.count;\n      for (let j = start, jl = start + count; j < jl; j += 3) {\n        handleVertex(index.getX(j + 0));\n        handleVertex(index.getX(j + 1));\n        handleVertex(index.getX(j + 2));\n      }\n    }\n  }\n  computeVertexNormals() {\n    const index = this.index;\n    const positionAttribute = this.getAttribute('position');\n    if (positionAttribute !== undefined) {\n      let normalAttribute = this.getAttribute('normal');\n      if (normalAttribute === undefined) {\n        normalAttribute = new BufferAttribute(new Float32Array(positionAttribute.count * 3), 3);\n        this.setAttribute('normal', normalAttribute);\n      } else {\n        // reset existing normals to zero\n\n        for (let i = 0, il = normalAttribute.count; i < il; i++) {\n          normalAttribute.setXYZ(i, 0, 0, 0);\n        }\n      }\n      const pA = new Vector3(),\n        pB = new Vector3(),\n        pC = new Vector3();\n      const nA = new Vector3(),\n        nB = new Vector3(),\n        nC = new Vector3();\n      const cb = new Vector3(),\n        ab = new Vector3();\n\n      // indexed elements\n\n      if (index) {\n        for (let i = 0, il = index.count; i < il; i += 3) {\n          const vA = index.getX(i + 0);\n          const vB = index.getX(i + 1);\n          const vC = index.getX(i + 2);\n          pA.fromBufferAttribute(positionAttribute, vA);\n          pB.fromBufferAttribute(positionAttribute, vB);\n          pC.fromBufferAttribute(positionAttribute, vC);\n          cb.subVectors(pC, pB);\n          ab.subVectors(pA, pB);\n          cb.cross(ab);\n          nA.fromBufferAttribute(normalAttribute, vA);\n          nB.fromBufferAttribute(normalAttribute, vB);\n          nC.fromBufferAttribute(normalAttribute, vC);\n          nA.add(cb);\n          nB.add(cb);\n          nC.add(cb);\n          normalAttribute.setXYZ(vA, nA.x, nA.y, nA.z);\n          normalAttribute.setXYZ(vB, nB.x, nB.y, nB.z);\n          normalAttribute.setXYZ(vC, nC.x, nC.y, nC.z);\n        }\n      } else {\n        // non-indexed elements (unconnected triangle soup)\n\n        for (let i = 0, il = positionAttribute.count; i < il; i += 3) {\n          pA.fromBufferAttribute(positionAttribute, i + 0);\n          pB.fromBufferAttribute(positionAttribute, i + 1);\n          pC.fromBufferAttribute(positionAttribute, i + 2);\n          cb.subVectors(pC, pB);\n          ab.subVectors(pA, pB);\n          cb.cross(ab);\n          normalAttribute.setXYZ(i + 0, cb.x, cb.y, cb.z);\n          normalAttribute.setXYZ(i + 1, cb.x, cb.y, cb.z);\n          normalAttribute.setXYZ(i + 2, cb.x, cb.y, cb.z);\n        }\n      }\n      this.normalizeNormals();\n      normalAttribute.needsUpdate = true;\n    }\n  }\n  normalizeNormals() {\n    const normals = this.attributes.normal;\n    for (let i = 0, il = normals.count; i < il; i++) {\n      _vector$8.fromBufferAttribute(normals, i);\n      _vector$8.normalize();\n      normals.setXYZ(i, _vector$8.x, _vector$8.y, _vector$8.z);\n    }\n  }\n  toNonIndexed() {\n    function convertBufferAttribute(attribute, indices) {\n      const array = attribute.array;\n      const itemSize = attribute.itemSize;\n      const normalized = attribute.normalized;\n      const array2 = new array.constructor(indices.length * itemSize);\n      let index = 0,\n        index2 = 0;\n      for (let i = 0, l = indices.length; i < l; i++) {\n        if (attribute.isInterleavedBufferAttribute) {\n          index = indices[i] * attribute.data.stride + attribute.offset;\n        } else {\n          index = indices[i] * itemSize;\n        }\n        for (let j = 0; j < itemSize; j++) {\n          array2[index2++] = array[index++];\n        }\n      }\n      return new BufferAttribute(array2, itemSize, normalized);\n    }\n\n    //\n\n    if (this.index === null) {\n      console.warn('THREE.BufferGeometry.toNonIndexed(): BufferGeometry is already non-indexed.');\n      return this;\n    }\n    const geometry2 = new BufferGeometry();\n    const indices = this.index.array;\n    const attributes = this.attributes;\n\n    // attributes\n\n    for (const name in attributes) {\n      const attribute = attributes[name];\n      const newAttribute = convertBufferAttribute(attribute, indices);\n      geometry2.setAttribute(name, newAttribute);\n    }\n\n    // morph attributes\n\n    const morphAttributes = this.morphAttributes;\n    for (const name in morphAttributes) {\n      const morphArray = [];\n      const morphAttribute = morphAttributes[name]; // morphAttribute: array of Float32BufferAttributes\n\n      for (let i = 0, il = morphAttribute.length; i < il; i++) {\n        const attribute = morphAttribute[i];\n        const newAttribute = convertBufferAttribute(attribute, indices);\n        morphArray.push(newAttribute);\n      }\n      geometry2.morphAttributes[name] = morphArray;\n    }\n    geometry2.morphTargetsRelative = this.morphTargetsRelative;\n\n    // groups\n\n    const groups = this.groups;\n    for (let i = 0, l = groups.length; i < l; i++) {\n      const group = groups[i];\n      geometry2.addGroup(group.start, group.count, group.materialIndex);\n    }\n    return geometry2;\n  }\n  toJSON() {\n    const data = {\n      metadata: {\n        version: 4.6,\n        type: 'BufferGeometry',\n        generator: 'BufferGeometry.toJSON'\n      }\n    };\n\n    // standard BufferGeometry serialization\n\n    data.uuid = this.uuid;\n    data.type = this.type;\n    if (this.name !== '') data.name = this.name;\n    if (Object.keys(this.userData).length > 0) data.userData = this.userData;\n    if (this.parameters !== undefined) {\n      const parameters = this.parameters;\n      for (const key in parameters) {\n        if (parameters[key] !== undefined) data[key] = parameters[key];\n      }\n      return data;\n    }\n\n    // for simplicity the code assumes attributes are not shared across geometries, see #15811\n\n    data.data = {\n      attributes: {}\n    };\n    const index = this.index;\n    if (index !== null) {\n      data.data.index = {\n        type: index.array.constructor.name,\n        array: Array.prototype.slice.call(index.array)\n      };\n    }\n    const attributes = this.attributes;\n    for (const key in attributes) {\n      const attribute = attributes[key];\n      data.data.attributes[key] = attribute.toJSON(data.data);\n    }\n    const morphAttributes = {};\n    let hasMorphAttributes = false;\n    for (const key in this.morphAttributes) {\n      const attributeArray = this.morphAttributes[key];\n      const array = [];\n      for (let i = 0, il = attributeArray.length; i < il; i++) {\n        const attribute = attributeArray[i];\n        array.push(attribute.toJSON(data.data));\n      }\n      if (array.length > 0) {\n        morphAttributes[key] = array;\n        hasMorphAttributes = true;\n      }\n    }\n    if (hasMorphAttributes) {\n      data.data.morphAttributes = morphAttributes;\n      data.data.morphTargetsRelative = this.morphTargetsRelative;\n    }\n    const groups = this.groups;\n    if (groups.length > 0) {\n      data.data.groups = JSON.parse(JSON.stringify(groups));\n    }\n    const boundingSphere = this.boundingSphere;\n    if (boundingSphere !== null) {\n      data.data.boundingSphere = {\n        center: boundingSphere.center.toArray(),\n        radius: boundingSphere.radius\n      };\n    }\n    return data;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  copy(source) {\n    // reset\n\n    this.index = null;\n    this.attributes = {};\n    this.morphAttributes = {};\n    this.groups = [];\n    this.boundingBox = null;\n    this.boundingSphere = null;\n\n    // used for storing cloned, shared data\n\n    const data = {};\n\n    // name\n\n    this.name = source.name;\n\n    // index\n\n    const index = source.index;\n    if (index !== null) {\n      this.setIndex(index.clone(data));\n    }\n\n    // attributes\n\n    const attributes = source.attributes;\n    for (const name in attributes) {\n      const attribute = attributes[name];\n      this.setAttribute(name, attribute.clone(data));\n    }\n\n    // morph attributes\n\n    const morphAttributes = source.morphAttributes;\n    for (const name in morphAttributes) {\n      const array = [];\n      const morphAttribute = morphAttributes[name]; // morphAttribute: array of Float32BufferAttributes\n\n      for (let i = 0, l = morphAttribute.length; i < l; i++) {\n        array.push(morphAttribute[i].clone(data));\n      }\n      this.morphAttributes[name] = array;\n    }\n    this.morphTargetsRelative = source.morphTargetsRelative;\n\n    // groups\n\n    const groups = source.groups;\n    for (let i = 0, l = groups.length; i < l; i++) {\n      const group = groups[i];\n      this.addGroup(group.start, group.count, group.materialIndex);\n    }\n\n    // bounding box\n\n    const boundingBox = source.boundingBox;\n    if (boundingBox !== null) {\n      this.boundingBox = boundingBox.clone();\n    }\n\n    // bounding sphere\n\n    const boundingSphere = source.boundingSphere;\n    if (boundingSphere !== null) {\n      this.boundingSphere = boundingSphere.clone();\n    }\n\n    // draw range\n\n    this.drawRange.start = source.drawRange.start;\n    this.drawRange.count = source.drawRange.count;\n\n    // user data\n\n    this.userData = source.userData;\n    return this;\n  }\n  dispose() {\n    this.dispatchEvent({\n      type: 'dispose'\n    });\n  }\n}\nconst _inverseMatrix$3 = /*@__PURE__*/new Matrix4();\nconst _ray$3 = /*@__PURE__*/new Ray();\nconst _sphere$6 = /*@__PURE__*/new Sphere();\nconst _sphereHitAt = /*@__PURE__*/new Vector3();\nconst _vA$1 = /*@__PURE__*/new Vector3();\nconst _vB$1 = /*@__PURE__*/new Vector3();\nconst _vC$1 = /*@__PURE__*/new Vector3();\nconst _tempA = /*@__PURE__*/new Vector3();\nconst _morphA = /*@__PURE__*/new Vector3();\nconst _intersectionPoint = /*@__PURE__*/new Vector3();\nconst _intersectionPointWorld = /*@__PURE__*/new Vector3();\nclass Mesh extends Object3D {\n  constructor(geometry = new BufferGeometry(), material = new MeshBasicMaterial()) {\n    super();\n    this.isMesh = true;\n    this.type = 'Mesh';\n    this.geometry = geometry;\n    this.material = material;\n    this.updateMorphTargets();\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    if (source.morphTargetInfluences !== undefined) {\n      this.morphTargetInfluences = source.morphTargetInfluences.slice();\n    }\n    if (source.morphTargetDictionary !== undefined) {\n      this.morphTargetDictionary = Object.assign({}, source.morphTargetDictionary);\n    }\n    this.material = Array.isArray(source.material) ? source.material.slice() : source.material;\n    this.geometry = source.geometry;\n    return this;\n  }\n  updateMorphTargets() {\n    const geometry = this.geometry;\n    const morphAttributes = geometry.morphAttributes;\n    const keys = Object.keys(morphAttributes);\n    if (keys.length > 0) {\n      const morphAttribute = morphAttributes[keys[0]];\n      if (morphAttribute !== undefined) {\n        this.morphTargetInfluences = [];\n        this.morphTargetDictionary = {};\n        for (let m = 0, ml = morphAttribute.length; m < ml; m++) {\n          const name = morphAttribute[m].name || String(m);\n          this.morphTargetInfluences.push(0);\n          this.morphTargetDictionary[name] = m;\n        }\n      }\n    }\n  }\n  getVertexPosition(index, target) {\n    const geometry = this.geometry;\n    const position = geometry.attributes.position;\n    const morphPosition = geometry.morphAttributes.position;\n    const morphTargetsRelative = geometry.morphTargetsRelative;\n    target.fromBufferAttribute(position, index);\n    const morphInfluences = this.morphTargetInfluences;\n    if (morphPosition && morphInfluences) {\n      _morphA.set(0, 0, 0);\n      for (let i = 0, il = morphPosition.length; i < il; i++) {\n        const influence = morphInfluences[i];\n        const morphAttribute = morphPosition[i];\n        if (influence === 0) continue;\n        _tempA.fromBufferAttribute(morphAttribute, index);\n        if (morphTargetsRelative) {\n          _morphA.addScaledVector(_tempA, influence);\n        } else {\n          _morphA.addScaledVector(_tempA.sub(target), influence);\n        }\n      }\n      target.add(_morphA);\n    }\n    return target;\n  }\n  raycast(raycaster, intersects) {\n    const geometry = this.geometry;\n    const material = this.material;\n    const matrixWorld = this.matrixWorld;\n    if (material === undefined) return;\n\n    // test with bounding sphere in world space\n\n    if (geometry.boundingSphere === null) geometry.computeBoundingSphere();\n    _sphere$6.copy(geometry.boundingSphere);\n    _sphere$6.applyMatrix4(matrixWorld);\n\n    // check distance from ray origin to bounding sphere\n\n    _ray$3.copy(raycaster.ray).recast(raycaster.near);\n    if (_sphere$6.containsPoint(_ray$3.origin) === false) {\n      if (_ray$3.intersectSphere(_sphere$6, _sphereHitAt) === null) return;\n      if (_ray$3.origin.distanceToSquared(_sphereHitAt) > (raycaster.far - raycaster.near) ** 2) return;\n    }\n\n    // convert ray to local space of mesh\n\n    _inverseMatrix$3.copy(matrixWorld).invert();\n    _ray$3.copy(raycaster.ray).applyMatrix4(_inverseMatrix$3);\n\n    // test with bounding box in local space\n\n    if (geometry.boundingBox !== null) {\n      if (_ray$3.intersectsBox(geometry.boundingBox) === false) return;\n    }\n\n    // test for intersections with geometry\n\n    this._computeIntersections(raycaster, intersects, _ray$3);\n  }\n  _computeIntersections(raycaster, intersects, rayLocalSpace) {\n    let intersection;\n    const geometry = this.geometry;\n    const material = this.material;\n    const index = geometry.index;\n    const position = geometry.attributes.position;\n    const uv = geometry.attributes.uv;\n    const uv1 = geometry.attributes.uv1;\n    const normal = geometry.attributes.normal;\n    const groups = geometry.groups;\n    const drawRange = geometry.drawRange;\n    if (index !== null) {\n      // indexed buffer geometry\n\n      if (Array.isArray(material)) {\n        for (let i = 0, il = groups.length; i < il; i++) {\n          const group = groups[i];\n          const groupMaterial = material[group.materialIndex];\n          const start = Math.max(group.start, drawRange.start);\n          const end = Math.min(index.count, Math.min(group.start + group.count, drawRange.start + drawRange.count));\n          for (let j = start, jl = end; j < jl; j += 3) {\n            const a = index.getX(j);\n            const b = index.getX(j + 1);\n            const c = index.getX(j + 2);\n            intersection = checkGeometryIntersection(this, groupMaterial, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);\n            if (intersection) {\n              intersection.faceIndex = Math.floor(j / 3); // triangle number in indexed buffer semantics\n              intersection.face.materialIndex = group.materialIndex;\n              intersects.push(intersection);\n            }\n          }\n        }\n      } else {\n        const start = Math.max(0, drawRange.start);\n        const end = Math.min(index.count, drawRange.start + drawRange.count);\n        for (let i = start, il = end; i < il; i += 3) {\n          const a = index.getX(i);\n          const b = index.getX(i + 1);\n          const c = index.getX(i + 2);\n          intersection = checkGeometryIntersection(this, material, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);\n          if (intersection) {\n            intersection.faceIndex = Math.floor(i / 3); // triangle number in indexed buffer semantics\n            intersects.push(intersection);\n          }\n        }\n      }\n    } else if (position !== undefined) {\n      // non-indexed buffer geometry\n\n      if (Array.isArray(material)) {\n        for (let i = 0, il = groups.length; i < il; i++) {\n          const group = groups[i];\n          const groupMaterial = material[group.materialIndex];\n          const start = Math.max(group.start, drawRange.start);\n          const end = Math.min(position.count, Math.min(group.start + group.count, drawRange.start + drawRange.count));\n          for (let j = start, jl = end; j < jl; j += 3) {\n            const a = j;\n            const b = j + 1;\n            const c = j + 2;\n            intersection = checkGeometryIntersection(this, groupMaterial, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);\n            if (intersection) {\n              intersection.faceIndex = Math.floor(j / 3); // triangle number in non-indexed buffer semantics\n              intersection.face.materialIndex = group.materialIndex;\n              intersects.push(intersection);\n            }\n          }\n        }\n      } else {\n        const start = Math.max(0, drawRange.start);\n        const end = Math.min(position.count, drawRange.start + drawRange.count);\n        for (let i = start, il = end; i < il; i += 3) {\n          const a = i;\n          const b = i + 1;\n          const c = i + 2;\n          intersection = checkGeometryIntersection(this, material, raycaster, rayLocalSpace, uv, uv1, normal, a, b, c);\n          if (intersection) {\n            intersection.faceIndex = Math.floor(i / 3); // triangle number in non-indexed buffer semantics\n            intersects.push(intersection);\n          }\n        }\n      }\n    }\n  }\n}\nfunction checkIntersection$1(object, material, raycaster, ray, pA, pB, pC, point) {\n  let intersect;\n  if (material.side === BackSide) {\n    intersect = ray.intersectTriangle(pC, pB, pA, true, point);\n  } else {\n    intersect = ray.intersectTriangle(pA, pB, pC, material.side === FrontSide, point);\n  }\n  if (intersect === null) return null;\n  _intersectionPointWorld.copy(point);\n  _intersectionPointWorld.applyMatrix4(object.matrixWorld);\n  const distance = raycaster.ray.origin.distanceTo(_intersectionPointWorld);\n  if (distance < raycaster.near || distance > raycaster.far) return null;\n  return {\n    distance: distance,\n    point: _intersectionPointWorld.clone(),\n    object: object\n  };\n}\nfunction checkGeometryIntersection(object, material, raycaster, ray, uv, uv1, normal, a, b, c) {\n  object.getVertexPosition(a, _vA$1);\n  object.getVertexPosition(b, _vB$1);\n  object.getVertexPosition(c, _vC$1);\n  const intersection = checkIntersection$1(object, material, raycaster, ray, _vA$1, _vB$1, _vC$1, _intersectionPoint);\n  if (intersection) {\n    const barycoord = new Vector3();\n    Triangle.getBarycoord(_intersectionPoint, _vA$1, _vB$1, _vC$1, barycoord);\n    if (uv) {\n      intersection.uv = Triangle.getInterpolatedAttribute(uv, a, b, c, barycoord, new Vector2());\n    }\n    if (uv1) {\n      intersection.uv1 = Triangle.getInterpolatedAttribute(uv1, a, b, c, barycoord, new Vector2());\n    }\n    if (normal) {\n      intersection.normal = Triangle.getInterpolatedAttribute(normal, a, b, c, barycoord, new Vector3());\n      if (intersection.normal.dot(ray.direction) > 0) {\n        intersection.normal.multiplyScalar(-1);\n      }\n    }\n    const face = {\n      a: a,\n      b: b,\n      c: c,\n      normal: new Vector3(),\n      materialIndex: 0\n    };\n    Triangle.getNormal(_vA$1, _vB$1, _vC$1, face.normal);\n    intersection.face = face;\n    intersection.barycoord = barycoord;\n  }\n  return intersection;\n}\nclass BoxGeometry extends BufferGeometry {\n  constructor(width = 1, height = 1, depth = 1, widthSegments = 1, heightSegments = 1, depthSegments = 1) {\n    super();\n    this.type = 'BoxGeometry';\n    this.parameters = {\n      width: width,\n      height: height,\n      depth: depth,\n      widthSegments: widthSegments,\n      heightSegments: heightSegments,\n      depthSegments: depthSegments\n    };\n    const scope = this;\n\n    // segments\n\n    widthSegments = Math.floor(widthSegments);\n    heightSegments = Math.floor(heightSegments);\n    depthSegments = Math.floor(depthSegments);\n\n    // buffers\n\n    const indices = [];\n    const vertices = [];\n    const normals = [];\n    const uvs = [];\n\n    // helper variables\n\n    let numberOfVertices = 0;\n    let groupStart = 0;\n\n    // build each side of the box geometry\n\n    buildPlane('z', 'y', 'x', -1, -1, depth, height, width, depthSegments, heightSegments, 0); // px\n    buildPlane('z', 'y', 'x', 1, -1, depth, height, -width, depthSegments, heightSegments, 1); // nx\n    buildPlane('x', 'z', 'y', 1, 1, width, depth, height, widthSegments, depthSegments, 2); // py\n    buildPlane('x', 'z', 'y', 1, -1, width, depth, -height, widthSegments, depthSegments, 3); // ny\n    buildPlane('x', 'y', 'z', 1, -1, width, height, depth, widthSegments, heightSegments, 4); // pz\n    buildPlane('x', 'y', 'z', -1, -1, width, height, -depth, widthSegments, heightSegments, 5); // nz\n\n    // build geometry\n\n    this.setIndex(indices);\n    this.setAttribute('position', new Float32BufferAttribute(vertices, 3));\n    this.setAttribute('normal', new Float32BufferAttribute(normals, 3));\n    this.setAttribute('uv', new Float32BufferAttribute(uvs, 2));\n    function buildPlane(u, v, w, udir, vdir, width, height, depth, gridX, gridY, materialIndex) {\n      const segmentWidth = width / gridX;\n      const segmentHeight = height / gridY;\n      const widthHalf = width / 2;\n      const heightHalf = height / 2;\n      const depthHalf = depth / 2;\n      const gridX1 = gridX + 1;\n      const gridY1 = gridY + 1;\n      let vertexCounter = 0;\n      let groupCount = 0;\n      const vector = new Vector3();\n\n      // generate vertices, normals and uvs\n\n      for (let iy = 0; iy < gridY1; iy++) {\n        const y = iy * segmentHeight - heightHalf;\n        for (let ix = 0; ix < gridX1; ix++) {\n          const x = ix * segmentWidth - widthHalf;\n\n          // set values to correct vector component\n\n          vector[u] = x * udir;\n          vector[v] = y * vdir;\n          vector[w] = depthHalf;\n\n          // now apply vector to vertex buffer\n\n          vertices.push(vector.x, vector.y, vector.z);\n\n          // set values to correct vector component\n\n          vector[u] = 0;\n          vector[v] = 0;\n          vector[w] = depth > 0 ? 1 : -1;\n\n          // now apply vector to normal buffer\n\n          normals.push(vector.x, vector.y, vector.z);\n\n          // uvs\n\n          uvs.push(ix / gridX);\n          uvs.push(1 - iy / gridY);\n\n          // counters\n\n          vertexCounter += 1;\n        }\n      }\n\n      // indices\n\n      // 1. you need three indices to draw a single face\n      // 2. a single segment consists of two faces\n      // 3. so we need to generate six (2*3) indices per segment\n\n      for (let iy = 0; iy < gridY; iy++) {\n        for (let ix = 0; ix < gridX; ix++) {\n          const a = numberOfVertices + ix + gridX1 * iy;\n          const b = numberOfVertices + ix + gridX1 * (iy + 1);\n          const c = numberOfVertices + (ix + 1) + gridX1 * (iy + 1);\n          const d = numberOfVertices + (ix + 1) + gridX1 * iy;\n\n          // faces\n\n          indices.push(a, b, d);\n          indices.push(b, c, d);\n\n          // increase counter\n\n          groupCount += 6;\n        }\n      }\n\n      // add a group to the geometry. this will ensure multi material support\n\n      scope.addGroup(groupStart, groupCount, materialIndex);\n\n      // calculate new start value for groups\n\n      groupStart += groupCount;\n\n      // update total number of vertices\n\n      numberOfVertices += vertexCounter;\n    }\n  }\n  copy(source) {\n    super.copy(source);\n    this.parameters = Object.assign({}, source.parameters);\n    return this;\n  }\n  static fromJSON(data) {\n    return new BoxGeometry(data.width, data.height, data.depth, data.widthSegments, data.heightSegments, data.depthSegments);\n  }\n}\n\n/**\n * Uniform Utilities\n */\n\nfunction cloneUniforms(src) {\n  const dst = {};\n  for (const u in src) {\n    dst[u] = {};\n    for (const p in src[u]) {\n      const property = src[u][p];\n      if (property && (property.isColor || property.isMatrix3 || property.isMatrix4 || property.isVector2 || property.isVector3 || property.isVector4 || property.isTexture || property.isQuaternion)) {\n        if (property.isRenderTargetTexture) {\n          console.warn('UniformsUtils: Textures of render targets cannot be cloned via cloneUniforms() or mergeUniforms().');\n          dst[u][p] = null;\n        } else {\n          dst[u][p] = property.clone();\n        }\n      } else if (Array.isArray(property)) {\n        dst[u][p] = property.slice();\n      } else {\n        dst[u][p] = property;\n      }\n    }\n  }\n  return dst;\n}\nfunction mergeUniforms(uniforms) {\n  const merged = {};\n  for (let u = 0; u < uniforms.length; u++) {\n    const tmp = cloneUniforms(uniforms[u]);\n    for (const p in tmp) {\n      merged[p] = tmp[p];\n    }\n  }\n  return merged;\n}\nfunction cloneUniformsGroups(src) {\n  const dst = [];\n  for (let u = 0; u < src.length; u++) {\n    dst.push(src[u].clone());\n  }\n  return dst;\n}\nfunction getUnlitUniformColorSpace(renderer) {\n  const currentRenderTarget = renderer.getRenderTarget();\n  if (currentRenderTarget === null) {\n    // https://github.com/mrdoob/three.js/pull/23937#issuecomment-1111067398\n    return renderer.outputColorSpace;\n  }\n\n  // https://github.com/mrdoob/three.js/issues/27868\n  if (currentRenderTarget.isXRRenderTarget === true) {\n    return currentRenderTarget.texture.colorSpace;\n  }\n  return ColorManagement.workingColorSpace;\n}\n\n// Legacy\n\nconst UniformsUtils = {\n  clone: cloneUniforms,\n  merge: mergeUniforms\n};\nvar default_vertex = \"void main() {\\n\\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\\n}\";\nvar default_fragment = \"void main() {\\n\\tgl_FragColor = vec4( 1.0, 0.0, 0.0, 1.0 );\\n}\";\nclass ShaderMaterial extends Material$1 {\n  constructor(parameters) {\n    super();\n    this.isShaderMaterial = true;\n    this.type = 'ShaderMaterial';\n    this.defines = {};\n    this.uniforms = {};\n    this.uniformsGroups = [];\n    this.vertexShader = default_vertex;\n    this.fragmentShader = default_fragment;\n    this.linewidth = 1;\n    this.wireframe = false;\n    this.wireframeLinewidth = 1;\n    this.fog = false; // set to use scene fog\n    this.lights = false; // set to use scene lights\n    this.clipping = false; // set to use user-defined clipping planes\n\n    this.forceSinglePass = true;\n    this.extensions = {\n      clipCullDistance: false,\n      // set to use vertex shader clipping\n      multiDraw: false // set to use vertex shader multi_draw / enable gl_DrawID\n    };\n\n    // When rendered geometry doesn't include these attributes but the material does,\n    // use these default values in WebGL. This avoids errors when buffer data is missing.\n    this.defaultAttributeValues = {\n      'color': [1, 1, 1],\n      'uv': [0, 0],\n      'uv1': [0, 0]\n    };\n    this.index0AttributeName = undefined;\n    this.uniformsNeedUpdate = false;\n    this.glslVersion = null;\n    if (parameters !== undefined) {\n      this.setValues(parameters);\n    }\n  }\n  copy(source) {\n    super.copy(source);\n    this.fragmentShader = source.fragmentShader;\n    this.vertexShader = source.vertexShader;\n    this.uniforms = cloneUniforms(source.uniforms);\n    this.uniformsGroups = cloneUniformsGroups(source.uniformsGroups);\n    this.defines = Object.assign({}, source.defines);\n    this.wireframe = source.wireframe;\n    this.wireframeLinewidth = source.wireframeLinewidth;\n    this.fog = source.fog;\n    this.lights = source.lights;\n    this.clipping = source.clipping;\n    this.extensions = Object.assign({}, source.extensions);\n    this.glslVersion = source.glslVersion;\n    return this;\n  }\n  toJSON(meta) {\n    const data = super.toJSON(meta);\n    data.glslVersion = this.glslVersion;\n    data.uniforms = {};\n    for (const name in this.uniforms) {\n      const uniform = this.uniforms[name];\n      const value = uniform.value;\n      if (value && value.isTexture) {\n        data.uniforms[name] = {\n          type: 't',\n          value: value.toJSON(meta).uuid\n        };\n      } else if (value && value.isColor) {\n        data.uniforms[name] = {\n          type: 'c',\n          value: value.getHex()\n        };\n      } else if (value && value.isVector2) {\n        data.uniforms[name] = {\n          type: 'v2',\n          value: value.toArray()\n        };\n      } else if (value && value.isVector3) {\n        data.uniforms[name] = {\n          type: 'v3',\n          value: value.toArray()\n        };\n      } else if (value && value.isVector4) {\n        data.uniforms[name] = {\n          type: 'v4',\n          value: value.toArray()\n        };\n      } else if (value && value.isMatrix3) {\n        data.uniforms[name] = {\n          type: 'm3',\n          value: value.toArray()\n        };\n      } else if (value && value.isMatrix4) {\n        data.uniforms[name] = {\n          type: 'm4',\n          value: value.toArray()\n        };\n      } else {\n        data.uniforms[name] = {\n          value: value\n        };\n\n        // note: the array variants v2v, v3v, v4v, m4v and tv are not supported so far\n      }\n    }\n    if (Object.keys(this.defines).length > 0) data.defines = this.defines;\n    data.vertexShader = this.vertexShader;\n    data.fragmentShader = this.fragmentShader;\n    data.lights = this.lights;\n    data.clipping = this.clipping;\n    const extensions = {};\n    for (const key in this.extensions) {\n      if (this.extensions[key] === true) extensions[key] = true;\n    }\n    if (Object.keys(extensions).length > 0) data.extensions = extensions;\n    return data;\n  }\n}\nclass Camera extends Object3D {\n  constructor() {\n    super();\n    this.isCamera = true;\n    this.type = 'Camera';\n    this.matrixWorldInverse = new Matrix4();\n    this.projectionMatrix = new Matrix4();\n    this.projectionMatrixInverse = new Matrix4();\n    this.coordinateSystem = WebGLCoordinateSystem;\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.matrixWorldInverse.copy(source.matrixWorldInverse);\n    this.projectionMatrix.copy(source.projectionMatrix);\n    this.projectionMatrixInverse.copy(source.projectionMatrixInverse);\n    this.coordinateSystem = source.coordinateSystem;\n    return this;\n  }\n  getWorldDirection(target) {\n    return super.getWorldDirection(target).negate();\n  }\n  updateMatrixWorld(force) {\n    super.updateMatrixWorld(force);\n    this.matrixWorldInverse.copy(this.matrixWorld).invert();\n  }\n  updateWorldMatrix(updateParents, updateChildren) {\n    super.updateWorldMatrix(updateParents, updateChildren);\n    this.matrixWorldInverse.copy(this.matrixWorld).invert();\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n}\nconst _v3$1 = /*@__PURE__*/new Vector3();\nconst _minTarget = /*@__PURE__*/new Vector2();\nconst _maxTarget = /*@__PURE__*/new Vector2();\nclass PerspectiveCamera extends Camera {\n  constructor(fov = 50, aspect = 1, near = 0.1, far = 2000) {\n    super();\n    this.isPerspectiveCamera = true;\n    this.type = 'PerspectiveCamera';\n    this.fov = fov;\n    this.zoom = 1;\n    this.near = near;\n    this.far = far;\n    this.focus = 10;\n    this.aspect = aspect;\n    this.view = null;\n    this.filmGauge = 35; // width of the film (default in millimeters)\n    this.filmOffset = 0; // horizontal film offset (same unit as gauge)\n\n    this.updateProjectionMatrix();\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.fov = source.fov;\n    this.zoom = source.zoom;\n    this.near = source.near;\n    this.far = source.far;\n    this.focus = source.focus;\n    this.aspect = source.aspect;\n    this.view = source.view === null ? null : Object.assign({}, source.view);\n    this.filmGauge = source.filmGauge;\n    this.filmOffset = source.filmOffset;\n    return this;\n  }\n\n  /**\n   * Sets the FOV by focal length in respect to the current .filmGauge.\n   *\n   * The default film gauge is 35, so that the focal length can be specified for\n   * a 35mm (full frame) camera.\n   *\n   * Values for focal length and film gauge must have the same unit.\n   */\n  setFocalLength(focalLength) {\n    /** see {@link http://www.bobatkins.com/photography/technical/field_of_view.html} */\n    const vExtentSlope = 0.5 * this.getFilmHeight() / focalLength;\n    this.fov = RAD2DEG * 2 * Math.atan(vExtentSlope);\n    this.updateProjectionMatrix();\n  }\n\n  /**\n   * Calculates the focal length from the current .fov and .filmGauge.\n   */\n  getFocalLength() {\n    const vExtentSlope = Math.tan(DEG2RAD * 0.5 * this.fov);\n    return 0.5 * this.getFilmHeight() / vExtentSlope;\n  }\n  getEffectiveFOV() {\n    return RAD2DEG * 2 * Math.atan(Math.tan(DEG2RAD * 0.5 * this.fov) / this.zoom);\n  }\n  getFilmWidth() {\n    // film not completely covered in portrait format (aspect < 1)\n    return this.filmGauge * Math.min(this.aspect, 1);\n  }\n  getFilmHeight() {\n    // film not completely covered in landscape format (aspect > 1)\n    return this.filmGauge / Math.max(this.aspect, 1);\n  }\n\n  /**\n   * Computes the 2D bounds of the camera's viewable rectangle at a given distance along the viewing direction.\n   * Sets minTarget and maxTarget to the coordinates of the lower-left and upper-right corners of the view rectangle.\n   */\n  getViewBounds(distance, minTarget, maxTarget) {\n    _v3$1.set(-1, -1, 0.5).applyMatrix4(this.projectionMatrixInverse);\n    minTarget.set(_v3$1.x, _v3$1.y).multiplyScalar(-distance / _v3$1.z);\n    _v3$1.set(1, 1, 0.5).applyMatrix4(this.projectionMatrixInverse);\n    maxTarget.set(_v3$1.x, _v3$1.y).multiplyScalar(-distance / _v3$1.z);\n  }\n\n  /**\n   * Computes the width and height of the camera's viewable rectangle at a given distance along the viewing direction.\n   * Copies the result into the target Vector2, where x is width and y is height.\n   */\n  getViewSize(distance, target) {\n    this.getViewBounds(distance, _minTarget, _maxTarget);\n    return target.subVectors(_maxTarget, _minTarget);\n  }\n\n  /**\n   * Sets an offset in a larger frustum. This is useful for multi-window or\n   * multi-monitor/multi-machine setups.\n   *\n   * For example, if you have 3x2 monitors and each monitor is 1920x1080 and\n   * the monitors are in grid like this\n   *\n   *   +---+---+---+\n   *   | A | B | C |\n   *   +---+---+---+\n   *   | D | E | F |\n   *   +---+---+---+\n   *\n   * then for each monitor you would call it like this\n   *\n   *   const w = 1920;\n   *   const h = 1080;\n   *   const fullWidth = w * 3;\n   *   const fullHeight = h * 2;\n   *\n   *   --A--\n   *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 0, w, h );\n   *   --B--\n   *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 0, w, h );\n   *   --C--\n   *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 0, w, h );\n   *   --D--\n   *   camera.setViewOffset( fullWidth, fullHeight, w * 0, h * 1, w, h );\n   *   --E--\n   *   camera.setViewOffset( fullWidth, fullHeight, w * 1, h * 1, w, h );\n   *   --F--\n   *   camera.setViewOffset( fullWidth, fullHeight, w * 2, h * 1, w, h );\n   *\n   *   Note there is no reason monitors have to be the same size or in a grid.\n   */\n  setViewOffset(fullWidth, fullHeight, x, y, width, height) {\n    this.aspect = fullWidth / fullHeight;\n    if (this.view === null) {\n      this.view = {\n        enabled: true,\n        fullWidth: 1,\n        fullHeight: 1,\n        offsetX: 0,\n        offsetY: 0,\n        width: 1,\n        height: 1\n      };\n    }\n    this.view.enabled = true;\n    this.view.fullWidth = fullWidth;\n    this.view.fullHeight = fullHeight;\n    this.view.offsetX = x;\n    this.view.offsetY = y;\n    this.view.width = width;\n    this.view.height = height;\n    this.updateProjectionMatrix();\n  }\n  clearViewOffset() {\n    if (this.view !== null) {\n      this.view.enabled = false;\n    }\n    this.updateProjectionMatrix();\n  }\n  updateProjectionMatrix() {\n    const near = this.near;\n    let top = near * Math.tan(DEG2RAD * 0.5 * this.fov) / this.zoom;\n    let height = 2 * top;\n    let width = this.aspect * height;\n    let left = -0.5 * width;\n    const view = this.view;\n    if (this.view !== null && this.view.enabled) {\n      const fullWidth = view.fullWidth,\n        fullHeight = view.fullHeight;\n      left += view.offsetX * width / fullWidth;\n      top -= view.offsetY * height / fullHeight;\n      width *= view.width / fullWidth;\n      height *= view.height / fullHeight;\n    }\n    const skew = this.filmOffset;\n    if (skew !== 0) left += near * skew / this.getFilmWidth();\n    this.projectionMatrix.makePerspective(left, left + width, top, top - height, near, this.far, this.coordinateSystem);\n    this.projectionMatrixInverse.copy(this.projectionMatrix).invert();\n  }\n  toJSON(meta) {\n    const data = super.toJSON(meta);\n    data.object.fov = this.fov;\n    data.object.zoom = this.zoom;\n    data.object.near = this.near;\n    data.object.far = this.far;\n    data.object.focus = this.focus;\n    data.object.aspect = this.aspect;\n    if (this.view !== null) data.object.view = Object.assign({}, this.view);\n    data.object.filmGauge = this.filmGauge;\n    data.object.filmOffset = this.filmOffset;\n    return data;\n  }\n}\nconst fov = -90; // negative fov is not an error\nconst aspect = 1;\nclass CubeCamera extends Object3D {\n  constructor(near, far, renderTarget) {\n    super();\n    this.type = 'CubeCamera';\n    this.renderTarget = renderTarget;\n    this.coordinateSystem = null;\n    this.activeMipmapLevel = 0;\n    const cameraPX = new PerspectiveCamera(fov, aspect, near, far);\n    cameraPX.layers = this.layers;\n    this.add(cameraPX);\n    const cameraNX = new PerspectiveCamera(fov, aspect, near, far);\n    cameraNX.layers = this.layers;\n    this.add(cameraNX);\n    const cameraPY = new PerspectiveCamera(fov, aspect, near, far);\n    cameraPY.layers = this.layers;\n    this.add(cameraPY);\n    const cameraNY = new PerspectiveCamera(fov, aspect, near, far);\n    cameraNY.layers = this.layers;\n    this.add(cameraNY);\n    const cameraPZ = new PerspectiveCamera(fov, aspect, near, far);\n    cameraPZ.layers = this.layers;\n    this.add(cameraPZ);\n    const cameraNZ = new PerspectiveCamera(fov, aspect, near, far);\n    cameraNZ.layers = this.layers;\n    this.add(cameraNZ);\n  }\n  updateCoordinateSystem() {\n    const coordinateSystem = this.coordinateSystem;\n    const cameras = this.children.concat();\n    const [cameraPX, cameraNX, cameraPY, cameraNY, cameraPZ, cameraNZ] = cameras;\n    for (const camera of cameras) this.remove(camera);\n    if (coordinateSystem === WebGLCoordinateSystem) {\n      cameraPX.up.set(0, 1, 0);\n      cameraPX.lookAt(1, 0, 0);\n      cameraNX.up.set(0, 1, 0);\n      cameraNX.lookAt(-1, 0, 0);\n      cameraPY.up.set(0, 0, -1);\n      cameraPY.lookAt(0, 1, 0);\n      cameraNY.up.set(0, 0, 1);\n      cameraNY.lookAt(0, -1, 0);\n      cameraPZ.up.set(0, 1, 0);\n      cameraPZ.lookAt(0, 0, 1);\n      cameraNZ.up.set(0, 1, 0);\n      cameraNZ.lookAt(0, 0, -1);\n    } else if (coordinateSystem === WebGPUCoordinateSystem) {\n      cameraPX.up.set(0, -1, 0);\n      cameraPX.lookAt(-1, 0, 0);\n      cameraNX.up.set(0, -1, 0);\n      cameraNX.lookAt(1, 0, 0);\n      cameraPY.up.set(0, 0, 1);\n      cameraPY.lookAt(0, 1, 0);\n      cameraNY.up.set(0, 0, -1);\n      cameraNY.lookAt(0, -1, 0);\n      cameraPZ.up.set(0, -1, 0);\n      cameraPZ.lookAt(0, 0, 1);\n      cameraNZ.up.set(0, -1, 0);\n      cameraNZ.lookAt(0, 0, -1);\n    } else {\n      throw new Error('THREE.CubeCamera.updateCoordinateSystem(): Invalid coordinate system: ' + coordinateSystem);\n    }\n    for (const camera of cameras) {\n      this.add(camera);\n      camera.updateMatrixWorld();\n    }\n  }\n  update(renderer, scene) {\n    if (this.parent === null) this.updateMatrixWorld();\n    const {\n      renderTarget,\n      activeMipmapLevel\n    } = this;\n    if (this.coordinateSystem !== renderer.coordinateSystem) {\n      this.coordinateSystem = renderer.coordinateSystem;\n      this.updateCoordinateSystem();\n    }\n    const [cameraPX, cameraNX, cameraPY, cameraNY, cameraPZ, cameraNZ] = this.children;\n    const currentRenderTarget = renderer.getRenderTarget();\n    const currentActiveCubeFace = renderer.getActiveCubeFace();\n    const currentActiveMipmapLevel = renderer.getActiveMipmapLevel();\n    const currentXrEnabled = renderer.xr.enabled;\n    renderer.xr.enabled = false;\n    const generateMipmaps = renderTarget.texture.generateMipmaps;\n    renderTarget.texture.generateMipmaps = false;\n    renderer.setRenderTarget(renderTarget, 0, activeMipmapLevel);\n    renderer.render(scene, cameraPX);\n    renderer.setRenderTarget(renderTarget, 1, activeMipmapLevel);\n    renderer.render(scene, cameraNX);\n    renderer.setRenderTarget(renderTarget, 2, activeMipmapLevel);\n    renderer.render(scene, cameraPY);\n    renderer.setRenderTarget(renderTarget, 3, activeMipmapLevel);\n    renderer.render(scene, cameraNY);\n    renderer.setRenderTarget(renderTarget, 4, activeMipmapLevel);\n    renderer.render(scene, cameraPZ);\n\n    // mipmaps are generated during the last call of render()\n    // at this point, all sides of the cube render target are defined\n\n    renderTarget.texture.generateMipmaps = generateMipmaps;\n    renderer.setRenderTarget(renderTarget, 5, activeMipmapLevel);\n    renderer.render(scene, cameraNZ);\n    renderer.setRenderTarget(currentRenderTarget, currentActiveCubeFace, currentActiveMipmapLevel);\n    renderer.xr.enabled = currentXrEnabled;\n    renderTarget.texture.needsPMREMUpdate = true;\n  }\n}\nclass CubeTexture extends Texture$1 {\n  constructor(images, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace) {\n    images = images !== undefined ? images : [];\n    mapping = mapping !== undefined ? mapping : CubeReflectionMapping;\n    super(images, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace);\n    this.isCubeTexture = true;\n    this.flipY = false;\n  }\n  get images() {\n    return this.image;\n  }\n  set images(value) {\n    this.image = value;\n  }\n}\nclass WebGLCubeRenderTarget extends WebGLRenderTarget {\n  constructor(size = 1, options = {}) {\n    super(size, size, options);\n    this.isWebGLCubeRenderTarget = true;\n    const image = {\n      width: size,\n      height: size,\n      depth: 1\n    };\n    const images = [image, image, image, image, image, image];\n    this.texture = new CubeTexture(images, options.mapping, options.wrapS, options.wrapT, options.magFilter, options.minFilter, options.format, options.type, options.anisotropy, options.colorSpace);\n\n    // By convention -- likely based on the RenderMan spec from the 1990's -- cube maps are specified by WebGL (and three.js)\n    // in a coordinate system in which positive-x is to the right when looking up the positive-z axis -- in other words,\n    // in a left-handed coordinate system. By continuing this convention, preexisting cube maps continued to render correctly.\n\n    // three.js uses a right-handed coordinate system. So environment maps used in three.js appear to have px and nx swapped\n    // and the flag isRenderTargetTexture controls this conversion. The flip is not required when using WebGLCubeRenderTarget.texture\n    // as a cube texture (this is detected when isRenderTargetTexture is set to true for cube textures).\n\n    this.texture.isRenderTargetTexture = true;\n    this.texture.generateMipmaps = options.generateMipmaps !== undefined ? options.generateMipmaps : false;\n    this.texture.minFilter = options.minFilter !== undefined ? options.minFilter : LinearFilter;\n  }\n  fromEquirectangularTexture(renderer, texture) {\n    this.texture.type = texture.type;\n    this.texture.colorSpace = texture.colorSpace;\n    this.texture.generateMipmaps = texture.generateMipmaps;\n    this.texture.minFilter = texture.minFilter;\n    this.texture.magFilter = texture.magFilter;\n    const shader = {\n      uniforms: {\n        tEquirect: {\n          value: null\n        }\n      },\n      vertexShader: /* glsl */`\n\n\t\t\t\tvarying vec3 vWorldDirection;\n\n\t\t\t\tvec3 transformDirection( in vec3 dir, in mat4 matrix ) {\n\n\t\t\t\t\treturn normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );\n\n\t\t\t\t}\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\tvWorldDirection = transformDirection( position, modelMatrix );\n\n\t\t\t\t\t#include <begin_vertex>\n\t\t\t\t\t#include <project_vertex>\n\n\t\t\t\t}\n\t\t\t`,\n      fragmentShader: /* glsl */`\n\n\t\t\t\tuniform sampler2D tEquirect;\n\n\t\t\t\tvarying vec3 vWorldDirection;\n\n\t\t\t\t#include <common>\n\n\t\t\t\tvoid main() {\n\n\t\t\t\t\tvec3 direction = normalize( vWorldDirection );\n\n\t\t\t\t\tvec2 sampleUV = equirectUv( direction );\n\n\t\t\t\t\tgl_FragColor = texture2D( tEquirect, sampleUV );\n\n\t\t\t\t}\n\t\t\t`\n    };\n    const geometry = new BoxGeometry(5, 5, 5);\n    const material = new ShaderMaterial({\n      name: 'CubemapFromEquirect',\n      uniforms: cloneUniforms(shader.uniforms),\n      vertexShader: shader.vertexShader,\n      fragmentShader: shader.fragmentShader,\n      side: BackSide,\n      blending: NoBlending\n    });\n    material.uniforms.tEquirect.value = texture;\n    const mesh = new Mesh(geometry, material);\n    const currentMinFilter = texture.minFilter;\n\n    // Avoid blurred poles\n    if (texture.minFilter === LinearMipmapLinearFilter) texture.minFilter = LinearFilter;\n    const camera = new CubeCamera(1, 10, this);\n    camera.update(renderer, mesh);\n    texture.minFilter = currentMinFilter;\n    mesh.geometry.dispose();\n    mesh.material.dispose();\n    return this;\n  }\n  clear(renderer, color, depth, stencil) {\n    const currentRenderTarget = renderer.getRenderTarget();\n    for (let i = 0; i < 6; i++) {\n      renderer.setRenderTarget(this, i);\n      renderer.clear(color, depth, stencil);\n    }\n    renderer.setRenderTarget(currentRenderTarget);\n  }\n}\nconst _vector1 = /*@__PURE__*/new Vector3();\nconst _vector2 = /*@__PURE__*/new Vector3();\nconst _normalMatrix = /*@__PURE__*/new Matrix3();\nclass Plane {\n  constructor(normal = new Vector3(1, 0, 0), constant = 0) {\n    this.isPlane = true;\n\n    // normal is assumed to be normalized\n\n    this.normal = normal;\n    this.constant = constant;\n  }\n  set(normal, constant) {\n    this.normal.copy(normal);\n    this.constant = constant;\n    return this;\n  }\n  setComponents(x, y, z, w) {\n    this.normal.set(x, y, z);\n    this.constant = w;\n    return this;\n  }\n  setFromNormalAndCoplanarPoint(normal, point) {\n    this.normal.copy(normal);\n    this.constant = -point.dot(this.normal);\n    return this;\n  }\n  setFromCoplanarPoints(a, b, c) {\n    const normal = _vector1.subVectors(c, b).cross(_vector2.subVectors(a, b)).normalize();\n\n    // Q: should an error be thrown if normal is zero (e.g. degenerate plane)?\n\n    this.setFromNormalAndCoplanarPoint(normal, a);\n    return this;\n  }\n  copy(plane) {\n    this.normal.copy(plane.normal);\n    this.constant = plane.constant;\n    return this;\n  }\n  normalize() {\n    // Note: will lead to a divide by zero if the plane is invalid.\n\n    const inverseNormalLength = 1.0 / this.normal.length();\n    this.normal.multiplyScalar(inverseNormalLength);\n    this.constant *= inverseNormalLength;\n    return this;\n  }\n  negate() {\n    this.constant *= -1;\n    this.normal.negate();\n    return this;\n  }\n  distanceToPoint(point) {\n    return this.normal.dot(point) + this.constant;\n  }\n  distanceToSphere(sphere) {\n    return this.distanceToPoint(sphere.center) - sphere.radius;\n  }\n  projectPoint(point, target) {\n    return target.copy(point).addScaledVector(this.normal, -this.distanceToPoint(point));\n  }\n  intersectLine(line, target) {\n    const direction = line.delta(_vector1);\n    const denominator = this.normal.dot(direction);\n    if (denominator === 0) {\n      // line is coplanar, return origin\n      if (this.distanceToPoint(line.start) === 0) {\n        return target.copy(line.start);\n      }\n\n      // Unsure if this is the correct method to handle this case.\n      return null;\n    }\n    const t = -(line.start.dot(this.normal) + this.constant) / denominator;\n    if (t < 0 || t > 1) {\n      return null;\n    }\n    return target.copy(line.start).addScaledVector(direction, t);\n  }\n  intersectsLine(line) {\n    // Note: this tests if a line intersects the plane, not whether it (or its end-points) are coplanar with it.\n\n    const startSign = this.distanceToPoint(line.start);\n    const endSign = this.distanceToPoint(line.end);\n    return startSign < 0 && endSign > 0 || endSign < 0 && startSign > 0;\n  }\n  intersectsBox(box) {\n    return box.intersectsPlane(this);\n  }\n  intersectsSphere(sphere) {\n    return sphere.intersectsPlane(this);\n  }\n  coplanarPoint(target) {\n    return target.copy(this.normal).multiplyScalar(-this.constant);\n  }\n  applyMatrix4(matrix, optionalNormalMatrix) {\n    const normalMatrix = optionalNormalMatrix || _normalMatrix.getNormalMatrix(matrix);\n    const referencePoint = this.coplanarPoint(_vector1).applyMatrix4(matrix);\n    const normal = this.normal.applyMatrix3(normalMatrix).normalize();\n    this.constant = -referencePoint.dot(normal);\n    return this;\n  }\n  translate(offset) {\n    this.constant -= offset.dot(this.normal);\n    return this;\n  }\n  equals(plane) {\n    return plane.normal.equals(this.normal) && plane.constant === this.constant;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n}\nconst _sphere$5 = /*@__PURE__*/new Sphere();\nconst _vector$7 = /*@__PURE__*/new Vector3();\nclass Frustum {\n  constructor(p0 = new Plane(), p1 = new Plane(), p2 = new Plane(), p3 = new Plane(), p4 = new Plane(), p5 = new Plane()) {\n    this.planes = [p0, p1, p2, p3, p4, p5];\n  }\n  set(p0, p1, p2, p3, p4, p5) {\n    const planes = this.planes;\n    planes[0].copy(p0);\n    planes[1].copy(p1);\n    planes[2].copy(p2);\n    planes[3].copy(p3);\n    planes[4].copy(p4);\n    planes[5].copy(p5);\n    return this;\n  }\n  copy(frustum) {\n    const planes = this.planes;\n    for (let i = 0; i < 6; i++) {\n      planes[i].copy(frustum.planes[i]);\n    }\n    return this;\n  }\n  setFromProjectionMatrix(m, coordinateSystem = WebGLCoordinateSystem) {\n    const planes = this.planes;\n    const me = m.elements;\n    const me0 = me[0],\n      me1 = me[1],\n      me2 = me[2],\n      me3 = me[3];\n    const me4 = me[4],\n      me5 = me[5],\n      me6 = me[6],\n      me7 = me[7];\n    const me8 = me[8],\n      me9 = me[9],\n      me10 = me[10],\n      me11 = me[11];\n    const me12 = me[12],\n      me13 = me[13],\n      me14 = me[14],\n      me15 = me[15];\n    planes[0].setComponents(me3 - me0, me7 - me4, me11 - me8, me15 - me12).normalize();\n    planes[1].setComponents(me3 + me0, me7 + me4, me11 + me8, me15 + me12).normalize();\n    planes[2].setComponents(me3 + me1, me7 + me5, me11 + me9, me15 + me13).normalize();\n    planes[3].setComponents(me3 - me1, me7 - me5, me11 - me9, me15 - me13).normalize();\n    planes[4].setComponents(me3 - me2, me7 - me6, me11 - me10, me15 - me14).normalize();\n    if (coordinateSystem === WebGLCoordinateSystem) {\n      planes[5].setComponents(me3 + me2, me7 + me6, me11 + me10, me15 + me14).normalize();\n    } else if (coordinateSystem === WebGPUCoordinateSystem) {\n      planes[5].setComponents(me2, me6, me10, me14).normalize();\n    } else {\n      throw new Error('THREE.Frustum.setFromProjectionMatrix(): Invalid coordinate system: ' + coordinateSystem);\n    }\n    return this;\n  }\n  intersectsObject(object) {\n    if (object.boundingSphere !== undefined) {\n      if (object.boundingSphere === null) object.computeBoundingSphere();\n      _sphere$5.copy(object.boundingSphere).applyMatrix4(object.matrixWorld);\n    } else {\n      const geometry = object.geometry;\n      if (geometry.boundingSphere === null) geometry.computeBoundingSphere();\n      _sphere$5.copy(geometry.boundingSphere).applyMatrix4(object.matrixWorld);\n    }\n    return this.intersectsSphere(_sphere$5);\n  }\n  intersectsSprite(sprite) {\n    _sphere$5.center.set(0, 0, 0);\n    _sphere$5.radius = 0.7071067811865476;\n    _sphere$5.applyMatrix4(sprite.matrixWorld);\n    return this.intersectsSphere(_sphere$5);\n  }\n  intersectsSphere(sphere) {\n    const planes = this.planes;\n    const center = sphere.center;\n    const negRadius = -sphere.radius;\n    for (let i = 0; i < 6; i++) {\n      const distance = planes[i].distanceToPoint(center);\n      if (distance < negRadius) {\n        return false;\n      }\n    }\n    return true;\n  }\n  intersectsBox(box) {\n    const planes = this.planes;\n    for (let i = 0; i < 6; i++) {\n      const plane = planes[i];\n\n      // corner at max distance\n\n      _vector$7.x = plane.normal.x > 0 ? box.max.x : box.min.x;\n      _vector$7.y = plane.normal.y > 0 ? box.max.y : box.min.y;\n      _vector$7.z = plane.normal.z > 0 ? box.max.z : box.min.z;\n      if (plane.distanceToPoint(_vector$7) < 0) {\n        return false;\n      }\n    }\n    return true;\n  }\n  containsPoint(point) {\n    const planes = this.planes;\n    for (let i = 0; i < 6; i++) {\n      if (planes[i].distanceToPoint(point) < 0) {\n        return false;\n      }\n    }\n    return true;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n}\nfunction WebGLAnimation() {\n  let context = null;\n  let isAnimating = false;\n  let animationLoop = null;\n  let requestId = null;\n  function onAnimationFrame(time, frame) {\n    animationLoop(time, frame);\n    requestId = context.requestAnimationFrame(onAnimationFrame);\n  }\n  return {\n    start: function () {\n      if (isAnimating === true) return;\n      if (animationLoop === null) return;\n      requestId = context.requestAnimationFrame(onAnimationFrame);\n      isAnimating = true;\n    },\n    stop: function () {\n      context.cancelAnimationFrame(requestId);\n      isAnimating = false;\n    },\n    setAnimationLoop: function (callback) {\n      animationLoop = callback;\n    },\n    setContext: function (value) {\n      context = value;\n    }\n  };\n}\nfunction WebGLAttributes(gl) {\n  const buffers = new WeakMap();\n  function createBuffer(attribute, bufferType) {\n    const array = attribute.array;\n    const usage = attribute.usage;\n    const size = array.byteLength;\n    const buffer = gl.createBuffer();\n    gl.bindBuffer(bufferType, buffer);\n    gl.bufferData(bufferType, array, usage);\n    attribute.onUploadCallback();\n    let type;\n    if (array instanceof Float32Array) {\n      type = gl.FLOAT;\n    } else if (array instanceof Uint16Array) {\n      if (attribute.isFloat16BufferAttribute) {\n        type = gl.HALF_FLOAT;\n      } else {\n        type = gl.UNSIGNED_SHORT;\n      }\n    } else if (array instanceof Int16Array) {\n      type = gl.SHORT;\n    } else if (array instanceof Uint32Array) {\n      type = gl.UNSIGNED_INT;\n    } else if (array instanceof Int32Array) {\n      type = gl.INT;\n    } else if (array instanceof Int8Array) {\n      type = gl.BYTE;\n    } else if (array instanceof Uint8Array) {\n      type = gl.UNSIGNED_BYTE;\n    } else if (array instanceof Uint8ClampedArray) {\n      type = gl.UNSIGNED_BYTE;\n    } else {\n      throw new Error('THREE.WebGLAttributes: Unsupported buffer data format: ' + array);\n    }\n    return {\n      buffer: buffer,\n      type: type,\n      bytesPerElement: array.BYTES_PER_ELEMENT,\n      version: attribute.version,\n      size: size\n    };\n  }\n  function updateBuffer(buffer, attribute, bufferType) {\n    const array = attribute.array;\n    const updateRanges = attribute.updateRanges;\n    gl.bindBuffer(bufferType, buffer);\n    if (updateRanges.length === 0) {\n      // Not using update ranges\n      gl.bufferSubData(bufferType, 0, array);\n    } else {\n      // Before applying update ranges, we merge any adjacent / overlapping\n      // ranges to reduce load on `gl.bufferSubData`. Empirically, this has led\n      // to performance improvements for applications which make heavy use of\n      // update ranges. Likely due to GPU command overhead.\n      //\n      // Note that to reduce garbage collection between frames, we merge the\n      // update ranges in-place. This is safe because this method will clear the\n      // update ranges once updated.\n\n      updateRanges.sort((a, b) => a.start - b.start);\n\n      // To merge the update ranges in-place, we work from left to right in the\n      // existing updateRanges array, merging ranges. This may result in a final\n      // array which is smaller than the original. This index tracks the last\n      // index representing a merged range, any data after this index can be\n      // trimmed once the merge algorithm is completed.\n      let mergeIndex = 0;\n      for (let i = 1; i < updateRanges.length; i++) {\n        const previousRange = updateRanges[mergeIndex];\n        const range = updateRanges[i];\n\n        // We add one here to merge adjacent ranges. This is safe because ranges\n        // operate over positive integers.\n        if (range.start <= previousRange.start + previousRange.count + 1) {\n          previousRange.count = Math.max(previousRange.count, range.start + range.count - previousRange.start);\n        } else {\n          ++mergeIndex;\n          updateRanges[mergeIndex] = range;\n        }\n      }\n\n      // Trim the array to only contain the merged ranges.\n      updateRanges.length = mergeIndex + 1;\n      for (let i = 0, l = updateRanges.length; i < l; i++) {\n        const range = updateRanges[i];\n        gl.bufferSubData(bufferType, range.start * array.BYTES_PER_ELEMENT, array, range.start, range.count);\n      }\n      attribute.clearUpdateRanges();\n    }\n    attribute.onUploadCallback();\n  }\n\n  //\n\n  function get(attribute) {\n    if (attribute.isInterleavedBufferAttribute) attribute = attribute.data;\n    return buffers.get(attribute);\n  }\n  function remove(attribute) {\n    if (attribute.isInterleavedBufferAttribute) attribute = attribute.data;\n    const data = buffers.get(attribute);\n    if (data) {\n      gl.deleteBuffer(data.buffer);\n      buffers.delete(attribute);\n    }\n  }\n  function update(attribute, bufferType) {\n    if (attribute.isInterleavedBufferAttribute) attribute = attribute.data;\n    if (attribute.isGLBufferAttribute) {\n      const cached = buffers.get(attribute);\n      if (!cached || cached.version < attribute.version) {\n        buffers.set(attribute, {\n          buffer: attribute.buffer,\n          type: attribute.type,\n          bytesPerElement: attribute.elementSize,\n          version: attribute.version\n        });\n      }\n      return;\n    }\n    const data = buffers.get(attribute);\n    if (data === undefined) {\n      buffers.set(attribute, createBuffer(attribute, bufferType));\n    } else if (data.version < attribute.version) {\n      if (data.size !== attribute.array.byteLength) {\n        throw new Error('THREE.WebGLAttributes: The size of the buffer attribute\\'s array buffer does not match the original size. Resizing buffer attributes is not supported.');\n      }\n      updateBuffer(data.buffer, attribute, bufferType);\n      data.version = attribute.version;\n    }\n  }\n  return {\n    get: get,\n    remove: remove,\n    update: update\n  };\n}\nclass PlaneGeometry extends BufferGeometry {\n  constructor(width = 1, height = 1, widthSegments = 1, heightSegments = 1) {\n    super();\n    this.type = 'PlaneGeometry';\n    this.parameters = {\n      width: width,\n      height: height,\n      widthSegments: widthSegments,\n      heightSegments: heightSegments\n    };\n    const width_half = width / 2;\n    const height_half = height / 2;\n    const gridX = Math.floor(widthSegments);\n    const gridY = Math.floor(heightSegments);\n    const gridX1 = gridX + 1;\n    const gridY1 = gridY + 1;\n    const segment_width = width / gridX;\n    const segment_height = height / gridY;\n\n    //\n\n    const indices = [];\n    const vertices = [];\n    const normals = [];\n    const uvs = [];\n    for (let iy = 0; iy < gridY1; iy++) {\n      const y = iy * segment_height - height_half;\n      for (let ix = 0; ix < gridX1; ix++) {\n        const x = ix * segment_width - width_half;\n        vertices.push(x, -y, 0);\n        normals.push(0, 0, 1);\n        uvs.push(ix / gridX);\n        uvs.push(1 - iy / gridY);\n      }\n    }\n    for (let iy = 0; iy < gridY; iy++) {\n      for (let ix = 0; ix < gridX; ix++) {\n        const a = ix + gridX1 * iy;\n        const b = ix + gridX1 * (iy + 1);\n        const c = ix + 1 + gridX1 * (iy + 1);\n        const d = ix + 1 + gridX1 * iy;\n        indices.push(a, b, d);\n        indices.push(b, c, d);\n      }\n    }\n    this.setIndex(indices);\n    this.setAttribute('position', new Float32BufferAttribute(vertices, 3));\n    this.setAttribute('normal', new Float32BufferAttribute(normals, 3));\n    this.setAttribute('uv', new Float32BufferAttribute(uvs, 2));\n  }\n  copy(source) {\n    super.copy(source);\n    this.parameters = Object.assign({}, source.parameters);\n    return this;\n  }\n  static fromJSON(data) {\n    return new PlaneGeometry(data.width, data.height, data.widthSegments, data.heightSegments);\n  }\n}\nvar alphahash_fragment = \"#ifdef USE_ALPHAHASH\\n\\tif ( diffuseColor.a < getAlphaHashThreshold( vPosition ) ) discard;\\n#endif\";\nvar alphahash_pars_fragment = \"#ifdef USE_ALPHAHASH\\n\\tconst float ALPHA_HASH_SCALE = 0.05;\\n\\tfloat hash2D( vec2 value ) {\\n\\t\\treturn fract( 1.0e4 * sin( 17.0 * value.x + 0.1 * value.y ) * ( 0.1 + abs( sin( 13.0 * value.y + value.x ) ) ) );\\n\\t}\\n\\tfloat hash3D( vec3 value ) {\\n\\t\\treturn hash2D( vec2( hash2D( value.xy ), value.z ) );\\n\\t}\\n\\tfloat getAlphaHashThreshold( vec3 position ) {\\n\\t\\tfloat maxDeriv = max(\\n\\t\\t\\tlength( dFdx( position.xyz ) ),\\n\\t\\t\\tlength( dFdy( position.xyz ) )\\n\\t\\t);\\n\\t\\tfloat pixScale = 1.0 / ( ALPHA_HASH_SCALE * maxDeriv );\\n\\t\\tvec2 pixScales = vec2(\\n\\t\\t\\texp2( floor( log2( pixScale ) ) ),\\n\\t\\t\\texp2( ceil( log2( pixScale ) ) )\\n\\t\\t);\\n\\t\\tvec2 alpha = vec2(\\n\\t\\t\\thash3D( floor( pixScales.x * position.xyz ) ),\\n\\t\\t\\thash3D( floor( pixScales.y * position.xyz ) )\\n\\t\\t);\\n\\t\\tfloat lerpFactor = fract( log2( pixScale ) );\\n\\t\\tfloat x = ( 1.0 - lerpFactor ) * alpha.x + lerpFactor * alpha.y;\\n\\t\\tfloat a = min( lerpFactor, 1.0 - lerpFactor );\\n\\t\\tvec3 cases = vec3(\\n\\t\\t\\tx * x / ( 2.0 * a * ( 1.0 - a ) ),\\n\\t\\t\\t( x - 0.5 * a ) / ( 1.0 - a ),\\n\\t\\t\\t1.0 - ( ( 1.0 - x ) * ( 1.0 - x ) / ( 2.0 * a * ( 1.0 - a ) ) )\\n\\t\\t);\\n\\t\\tfloat threshold = ( x < ( 1.0 - a ) )\\n\\t\\t\\t? ( ( x < a ) ? cases.x : cases.y )\\n\\t\\t\\t: cases.z;\\n\\t\\treturn clamp( threshold , 1.0e-6, 1.0 );\\n\\t}\\n#endif\";\nvar alphamap_fragment = \"#ifdef USE_ALPHAMAP\\n\\tdiffuseColor.a *= texture2D( alphaMap, vAlphaMapUv ).g;\\n#endif\";\nvar alphamap_pars_fragment = \"#ifdef USE_ALPHAMAP\\n\\tuniform sampler2D alphaMap;\\n#endif\";\nvar alphatest_fragment = \"#ifdef USE_ALPHATEST\\n\\t#ifdef ALPHA_TO_COVERAGE\\n\\tdiffuseColor.a = smoothstep( alphaTest, alphaTest + fwidth( diffuseColor.a ), diffuseColor.a );\\n\\tif ( diffuseColor.a == 0.0 ) discard;\\n\\t#else\\n\\tif ( diffuseColor.a < alphaTest ) discard;\\n\\t#endif\\n#endif\";\nvar alphatest_pars_fragment = \"#ifdef USE_ALPHATEST\\n\\tuniform float alphaTest;\\n#endif\";\nvar aomap_fragment = \"#ifdef USE_AOMAP\\n\\tfloat ambientOcclusion = ( texture2D( aoMap, vAoMapUv ).r - 1.0 ) * aoMapIntensity + 1.0;\\n\\treflectedLight.indirectDiffuse *= ambientOcclusion;\\n\\t#if defined( USE_CLEARCOAT ) \\n\\t\\tclearcoatSpecularIndirect *= ambientOcclusion;\\n\\t#endif\\n\\t#if defined( USE_SHEEN ) \\n\\t\\tsheenSpecularIndirect *= ambientOcclusion;\\n\\t#endif\\n\\t#if defined( USE_ENVMAP ) && defined( STANDARD )\\n\\t\\tfloat dotNV = saturate( dot( geometryNormal, geometryViewDir ) );\\n\\t\\treflectedLight.indirectSpecular *= computeSpecularOcclusion( dotNV, ambientOcclusion, material.roughness );\\n\\t#endif\\n#endif\";\nvar aomap_pars_fragment = \"#ifdef USE_AOMAP\\n\\tuniform sampler2D aoMap;\\n\\tuniform float aoMapIntensity;\\n#endif\";\nvar batching_pars_vertex = \"#ifdef USE_BATCHING\\n\\t#if ! defined( GL_ANGLE_multi_draw )\\n\\t#define gl_DrawID _gl_DrawID\\n\\tuniform int _gl_DrawID;\\n\\t#endif\\n\\tuniform highp sampler2D batchingTexture;\\n\\tuniform highp usampler2D batchingIdTexture;\\n\\tmat4 getBatchingMatrix( const in float i ) {\\n\\t\\tint size = textureSize( batchingTexture, 0 ).x;\\n\\t\\tint j = int( i ) * 4;\\n\\t\\tint x = j % size;\\n\\t\\tint y = j / size;\\n\\t\\tvec4 v1 = texelFetch( batchingTexture, ivec2( x, y ), 0 );\\n\\t\\tvec4 v2 = texelFetch( batchingTexture, ivec2( x + 1, y ), 0 );\\n\\t\\tvec4 v3 = texelFetch( batchingTexture, ivec2( x + 2, y ), 0 );\\n\\t\\tvec4 v4 = texelFetch( batchingTexture, ivec2( x + 3, y ), 0 );\\n\\t\\treturn mat4( v1, v2, v3, v4 );\\n\\t}\\n\\tfloat getIndirectIndex( const in int i ) {\\n\\t\\tint size = textureSize( batchingIdTexture, 0 ).x;\\n\\t\\tint x = i % size;\\n\\t\\tint y = i / size;\\n\\t\\treturn float( texelFetch( batchingIdTexture, ivec2( x, y ), 0 ).r );\\n\\t}\\n#endif\\n#ifdef USE_BATCHING_COLOR\\n\\tuniform sampler2D batchingColorTexture;\\n\\tvec3 getBatchingColor( const in float i ) {\\n\\t\\tint size = textureSize( batchingColorTexture, 0 ).x;\\n\\t\\tint j = int( i );\\n\\t\\tint x = j % size;\\n\\t\\tint y = j / size;\\n\\t\\treturn texelFetch( batchingColorTexture, ivec2( x, y ), 0 ).rgb;\\n\\t}\\n#endif\";\nvar batching_vertex = \"#ifdef USE_BATCHING\\n\\tmat4 batchingMatrix = getBatchingMatrix( getIndirectIndex( gl_DrawID ) );\\n#endif\";\nvar begin_vertex = \"vec3 transformed = vec3( position );\\n#ifdef USE_ALPHAHASH\\n\\tvPosition = vec3( position );\\n#endif\";\nvar beginnormal_vertex = \"vec3 objectNormal = vec3( normal );\\n#ifdef USE_TANGENT\\n\\tvec3 objectTangent = vec3( tangent.xyz );\\n#endif\";\nvar bsdfs = \"float G_BlinnPhong_Implicit( ) {\\n\\treturn 0.25;\\n}\\nfloat D_BlinnPhong( const in float shininess, const in float dotNH ) {\\n\\treturn RECIPROCAL_PI * ( shininess * 0.5 + 1.0 ) * pow( dotNH, shininess );\\n}\\nvec3 BRDF_BlinnPhong( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in vec3 specularColor, const in float shininess ) {\\n\\tvec3 halfDir = normalize( lightDir + viewDir );\\n\\tfloat dotNH = saturate( dot( normal, halfDir ) );\\n\\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\\n\\tvec3 F = F_Schlick( specularColor, 1.0, dotVH );\\n\\tfloat G = G_BlinnPhong_Implicit( );\\n\\tfloat D = D_BlinnPhong( shininess, dotNH );\\n\\treturn F * ( G * D );\\n} // validated\";\nvar iridescence_fragment = \"#ifdef USE_IRIDESCENCE\\n\\tconst mat3 XYZ_TO_REC709 = mat3(\\n\\t\\t 3.2404542, -0.9692660,  0.0556434,\\n\\t\\t-1.5371385,  1.8760108, -0.2040259,\\n\\t\\t-0.4985314,  0.0415560,  1.0572252\\n\\t);\\n\\tvec3 Fresnel0ToIor( vec3 fresnel0 ) {\\n\\t\\tvec3 sqrtF0 = sqrt( fresnel0 );\\n\\t\\treturn ( vec3( 1.0 ) + sqrtF0 ) / ( vec3( 1.0 ) - sqrtF0 );\\n\\t}\\n\\tvec3 IorToFresnel0( vec3 transmittedIor, float incidentIor ) {\\n\\t\\treturn pow2( ( transmittedIor - vec3( incidentIor ) ) / ( transmittedIor + vec3( incidentIor ) ) );\\n\\t}\\n\\tfloat IorToFresnel0( float transmittedIor, float incidentIor ) {\\n\\t\\treturn pow2( ( transmittedIor - incidentIor ) / ( transmittedIor + incidentIor ));\\n\\t}\\n\\tvec3 evalSensitivity( float OPD, vec3 shift ) {\\n\\t\\tfloat phase = 2.0 * PI * OPD * 1.0e-9;\\n\\t\\tvec3 val = vec3( 5.4856e-13, 4.4201e-13, 5.2481e-13 );\\n\\t\\tvec3 pos = vec3( 1.6810e+06, 1.7953e+06, 2.2084e+06 );\\n\\t\\tvec3 var = vec3( 4.3278e+09, 9.3046e+09, 6.6121e+09 );\\n\\t\\tvec3 xyz = val * sqrt( 2.0 * PI * var ) * cos( pos * phase + shift ) * exp( - pow2( phase ) * var );\\n\\t\\txyz.x += 9.7470e-14 * sqrt( 2.0 * PI * 4.5282e+09 ) * cos( 2.2399e+06 * phase + shift[ 0 ] ) * exp( - 4.5282e+09 * pow2( phase ) );\\n\\t\\txyz /= 1.0685e-7;\\n\\t\\tvec3 rgb = XYZ_TO_REC709 * xyz;\\n\\t\\treturn rgb;\\n\\t}\\n\\tvec3 evalIridescence( float outsideIOR, float eta2, float cosTheta1, float thinFilmThickness, vec3 baseF0 ) {\\n\\t\\tvec3 I;\\n\\t\\tfloat iridescenceIOR = mix( outsideIOR, eta2, smoothstep( 0.0, 0.03, thinFilmThickness ) );\\n\\t\\tfloat sinTheta2Sq = pow2( outsideIOR / iridescenceIOR ) * ( 1.0 - pow2( cosTheta1 ) );\\n\\t\\tfloat cosTheta2Sq = 1.0 - sinTheta2Sq;\\n\\t\\tif ( cosTheta2Sq < 0.0 ) {\\n\\t\\t\\treturn vec3( 1.0 );\\n\\t\\t}\\n\\t\\tfloat cosTheta2 = sqrt( cosTheta2Sq );\\n\\t\\tfloat R0 = IorToFresnel0( iridescenceIOR, outsideIOR );\\n\\t\\tfloat R12 = F_Schlick( R0, 1.0, cosTheta1 );\\n\\t\\tfloat T121 = 1.0 - R12;\\n\\t\\tfloat phi12 = 0.0;\\n\\t\\tif ( iridescenceIOR < outsideIOR ) phi12 = PI;\\n\\t\\tfloat phi21 = PI - phi12;\\n\\t\\tvec3 baseIOR = Fresnel0ToIor( clamp( baseF0, 0.0, 0.9999 ) );\\t\\tvec3 R1 = IorToFresnel0( baseIOR, iridescenceIOR );\\n\\t\\tvec3 R23 = F_Schlick( R1, 1.0, cosTheta2 );\\n\\t\\tvec3 phi23 = vec3( 0.0 );\\n\\t\\tif ( baseIOR[ 0 ] < iridescenceIOR ) phi23[ 0 ] = PI;\\n\\t\\tif ( baseIOR[ 1 ] < iridescenceIOR ) phi23[ 1 ] = PI;\\n\\t\\tif ( baseIOR[ 2 ] < iridescenceIOR ) phi23[ 2 ] = PI;\\n\\t\\tfloat OPD = 2.0 * iridescenceIOR * thinFilmThickness * cosTheta2;\\n\\t\\tvec3 phi = vec3( phi21 ) + phi23;\\n\\t\\tvec3 R123 = clamp( R12 * R23, 1e-5, 0.9999 );\\n\\t\\tvec3 r123 = sqrt( R123 );\\n\\t\\tvec3 Rs = pow2( T121 ) * R23 / ( vec3( 1.0 ) - R123 );\\n\\t\\tvec3 C0 = R12 + Rs;\\n\\t\\tI = C0;\\n\\t\\tvec3 Cm = Rs - T121;\\n\\t\\tfor ( int m = 1; m <= 2; ++ m ) {\\n\\t\\t\\tCm *= r123;\\n\\t\\t\\tvec3 Sm = 2.0 * evalSensitivity( float( m ) * OPD, float( m ) * phi );\\n\\t\\t\\tI += Cm * Sm;\\n\\t\\t}\\n\\t\\treturn max( I, vec3( 0.0 ) );\\n\\t}\\n#endif\";\nvar bumpmap_pars_fragment = \"#ifdef USE_BUMPMAP\\n\\tuniform sampler2D bumpMap;\\n\\tuniform float bumpScale;\\n\\tvec2 dHdxy_fwd() {\\n\\t\\tvec2 dSTdx = dFdx( vBumpMapUv );\\n\\t\\tvec2 dSTdy = dFdy( vBumpMapUv );\\n\\t\\tfloat Hll = bumpScale * texture2D( bumpMap, vBumpMapUv ).x;\\n\\t\\tfloat dBx = bumpScale * texture2D( bumpMap, vBumpMapUv + dSTdx ).x - Hll;\\n\\t\\tfloat dBy = bumpScale * texture2D( bumpMap, vBumpMapUv + dSTdy ).x - Hll;\\n\\t\\treturn vec2( dBx, dBy );\\n\\t}\\n\\tvec3 perturbNormalArb( vec3 surf_pos, vec3 surf_norm, vec2 dHdxy, float faceDirection ) {\\n\\t\\tvec3 vSigmaX = normalize( dFdx( surf_pos.xyz ) );\\n\\t\\tvec3 vSigmaY = normalize( dFdy( surf_pos.xyz ) );\\n\\t\\tvec3 vN = surf_norm;\\n\\t\\tvec3 R1 = cross( vSigmaY, vN );\\n\\t\\tvec3 R2 = cross( vN, vSigmaX );\\n\\t\\tfloat fDet = dot( vSigmaX, R1 ) * faceDirection;\\n\\t\\tvec3 vGrad = sign( fDet ) * ( dHdxy.x * R1 + dHdxy.y * R2 );\\n\\t\\treturn normalize( abs( fDet ) * surf_norm - vGrad );\\n\\t}\\n#endif\";\nvar clipping_planes_fragment = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvec4 plane;\\n\\t#ifdef ALPHA_TO_COVERAGE\\n\\t\\tfloat distanceToPlane, distanceGradient;\\n\\t\\tfloat clipOpacity = 1.0;\\n\\t\\t#pragma unroll_loop_start\\n\\t\\tfor ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {\\n\\t\\t\\tplane = clippingPlanes[ i ];\\n\\t\\t\\tdistanceToPlane = - dot( vClipPosition, plane.xyz ) + plane.w;\\n\\t\\t\\tdistanceGradient = fwidth( distanceToPlane ) / 2.0;\\n\\t\\t\\tclipOpacity *= smoothstep( - distanceGradient, distanceGradient, distanceToPlane );\\n\\t\\t\\tif ( clipOpacity == 0.0 ) discard;\\n\\t\\t}\\n\\t\\t#pragma unroll_loop_end\\n\\t\\t#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES\\n\\t\\t\\tfloat unionClipOpacity = 1.0;\\n\\t\\t\\t#pragma unroll_loop_start\\n\\t\\t\\tfor ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {\\n\\t\\t\\t\\tplane = clippingPlanes[ i ];\\n\\t\\t\\t\\tdistanceToPlane = - dot( vClipPosition, plane.xyz ) + plane.w;\\n\\t\\t\\t\\tdistanceGradient = fwidth( distanceToPlane ) / 2.0;\\n\\t\\t\\t\\tunionClipOpacity *= 1.0 - smoothstep( - distanceGradient, distanceGradient, distanceToPlane );\\n\\t\\t\\t}\\n\\t\\t\\t#pragma unroll_loop_end\\n\\t\\t\\tclipOpacity *= 1.0 - unionClipOpacity;\\n\\t\\t#endif\\n\\t\\tdiffuseColor.a *= clipOpacity;\\n\\t\\tif ( diffuseColor.a == 0.0 ) discard;\\n\\t#else\\n\\t\\t#pragma unroll_loop_start\\n\\t\\tfor ( int i = 0; i < UNION_CLIPPING_PLANES; i ++ ) {\\n\\t\\t\\tplane = clippingPlanes[ i ];\\n\\t\\t\\tif ( dot( vClipPosition, plane.xyz ) > plane.w ) discard;\\n\\t\\t}\\n\\t\\t#pragma unroll_loop_end\\n\\t\\t#if UNION_CLIPPING_PLANES < NUM_CLIPPING_PLANES\\n\\t\\t\\tbool clipped = true;\\n\\t\\t\\t#pragma unroll_loop_start\\n\\t\\t\\tfor ( int i = UNION_CLIPPING_PLANES; i < NUM_CLIPPING_PLANES; i ++ ) {\\n\\t\\t\\t\\tplane = clippingPlanes[ i ];\\n\\t\\t\\t\\tclipped = ( dot( vClipPosition, plane.xyz ) > plane.w ) && clipped;\\n\\t\\t\\t}\\n\\t\\t\\t#pragma unroll_loop_end\\n\\t\\t\\tif ( clipped ) discard;\\n\\t\\t#endif\\n\\t#endif\\n#endif\";\nvar clipping_planes_pars_fragment = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvarying vec3 vClipPosition;\\n\\tuniform vec4 clippingPlanes[ NUM_CLIPPING_PLANES ];\\n#endif\";\nvar clipping_planes_pars_vertex = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvarying vec3 vClipPosition;\\n#endif\";\nvar clipping_planes_vertex = \"#if NUM_CLIPPING_PLANES > 0\\n\\tvClipPosition = - mvPosition.xyz;\\n#endif\";\nvar color_fragment = \"#if defined( USE_COLOR_ALPHA )\\n\\tdiffuseColor *= vColor;\\n#elif defined( USE_COLOR )\\n\\tdiffuseColor.rgb *= vColor;\\n#endif\";\nvar color_pars_fragment = \"#if defined( USE_COLOR_ALPHA )\\n\\tvarying vec4 vColor;\\n#elif defined( USE_COLOR )\\n\\tvarying vec3 vColor;\\n#endif\";\nvar color_pars_vertex = \"#if defined( USE_COLOR_ALPHA )\\n\\tvarying vec4 vColor;\\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR ) || defined( USE_BATCHING_COLOR )\\n\\tvarying vec3 vColor;\\n#endif\";\nvar color_vertex = \"#if defined( USE_COLOR_ALPHA )\\n\\tvColor = vec4( 1.0 );\\n#elif defined( USE_COLOR ) || defined( USE_INSTANCING_COLOR ) || defined( USE_BATCHING_COLOR )\\n\\tvColor = vec3( 1.0 );\\n#endif\\n#ifdef USE_COLOR\\n\\tvColor *= color;\\n#endif\\n#ifdef USE_INSTANCING_COLOR\\n\\tvColor.xyz *= instanceColor.xyz;\\n#endif\\n#ifdef USE_BATCHING_COLOR\\n\\tvec3 batchingColor = getBatchingColor( getIndirectIndex( gl_DrawID ) );\\n\\tvColor.xyz *= batchingColor.xyz;\\n#endif\";\nvar common = \"#define PI 3.141592653589793\\n#define PI2 6.283185307179586\\n#define PI_HALF 1.5707963267948966\\n#define RECIPROCAL_PI 0.3183098861837907\\n#define RECIPROCAL_PI2 0.15915494309189535\\n#define EPSILON 1e-6\\n#ifndef saturate\\n#define saturate( a ) clamp( a, 0.0, 1.0 )\\n#endif\\n#define whiteComplement( a ) ( 1.0 - saturate( a ) )\\nfloat pow2( const in float x ) { return x*x; }\\nvec3 pow2( const in vec3 x ) { return x*x; }\\nfloat pow3( const in float x ) { return x*x*x; }\\nfloat pow4( const in float x ) { float x2 = x*x; return x2*x2; }\\nfloat max3( const in vec3 v ) { return max( max( v.x, v.y ), v.z ); }\\nfloat average( const in vec3 v ) { return dot( v, vec3( 0.3333333 ) ); }\\nhighp float rand( const in vec2 uv ) {\\n\\tconst highp float a = 12.9898, b = 78.233, c = 43758.5453;\\n\\thighp float dt = dot( uv.xy, vec2( a,b ) ), sn = mod( dt, PI );\\n\\treturn fract( sin( sn ) * c );\\n}\\n#ifdef HIGH_PRECISION\\n\\tfloat precisionSafeLength( vec3 v ) { return length( v ); }\\n#else\\n\\tfloat precisionSafeLength( vec3 v ) {\\n\\t\\tfloat maxComponent = max3( abs( v ) );\\n\\t\\treturn length( v / maxComponent ) * maxComponent;\\n\\t}\\n#endif\\nstruct IncidentLight {\\n\\tvec3 color;\\n\\tvec3 direction;\\n\\tbool visible;\\n};\\nstruct ReflectedLight {\\n\\tvec3 directDiffuse;\\n\\tvec3 directSpecular;\\n\\tvec3 indirectDiffuse;\\n\\tvec3 indirectSpecular;\\n};\\n#ifdef USE_ALPHAHASH\\n\\tvarying vec3 vPosition;\\n#endif\\nvec3 transformDirection( in vec3 dir, in mat4 matrix ) {\\n\\treturn normalize( ( matrix * vec4( dir, 0.0 ) ).xyz );\\n}\\nvec3 inverseTransformDirection( in vec3 dir, in mat4 matrix ) {\\n\\treturn normalize( ( vec4( dir, 0.0 ) * matrix ).xyz );\\n}\\nmat3 transposeMat3( const in mat3 m ) {\\n\\tmat3 tmp;\\n\\ttmp[ 0 ] = vec3( m[ 0 ].x, m[ 1 ].x, m[ 2 ].x );\\n\\ttmp[ 1 ] = vec3( m[ 0 ].y, m[ 1 ].y, m[ 2 ].y );\\n\\ttmp[ 2 ] = vec3( m[ 0 ].z, m[ 1 ].z, m[ 2 ].z );\\n\\treturn tmp;\\n}\\nbool isPerspectiveMatrix( mat4 m ) {\\n\\treturn m[ 2 ][ 3 ] == - 1.0;\\n}\\nvec2 equirectUv( in vec3 dir ) {\\n\\tfloat u = atan( dir.z, dir.x ) * RECIPROCAL_PI2 + 0.5;\\n\\tfloat v = asin( clamp( dir.y, - 1.0, 1.0 ) ) * RECIPROCAL_PI + 0.5;\\n\\treturn vec2( u, v );\\n}\\nvec3 BRDF_Lambert( const in vec3 diffuseColor ) {\\n\\treturn RECIPROCAL_PI * diffuseColor;\\n}\\nvec3 F_Schlick( const in vec3 f0, const in float f90, const in float dotVH ) {\\n\\tfloat fresnel = exp2( ( - 5.55473 * dotVH - 6.98316 ) * dotVH );\\n\\treturn f0 * ( 1.0 - fresnel ) + ( f90 * fresnel );\\n}\\nfloat F_Schlick( const in float f0, const in float f90, const in float dotVH ) {\\n\\tfloat fresnel = exp2( ( - 5.55473 * dotVH - 6.98316 ) * dotVH );\\n\\treturn f0 * ( 1.0 - fresnel ) + ( f90 * fresnel );\\n} // validated\";\nvar cube_uv_reflection_fragment = \"#ifdef ENVMAP_TYPE_CUBE_UV\\n\\t#define cubeUV_minMipLevel 4.0\\n\\t#define cubeUV_minTileSize 16.0\\n\\tfloat getFace( vec3 direction ) {\\n\\t\\tvec3 absDirection = abs( direction );\\n\\t\\tfloat face = - 1.0;\\n\\t\\tif ( absDirection.x > absDirection.z ) {\\n\\t\\t\\tif ( absDirection.x > absDirection.y )\\n\\t\\t\\t\\tface = direction.x > 0.0 ? 0.0 : 3.0;\\n\\t\\t\\telse\\n\\t\\t\\t\\tface = direction.y > 0.0 ? 1.0 : 4.0;\\n\\t\\t} else {\\n\\t\\t\\tif ( absDirection.z > absDirection.y )\\n\\t\\t\\t\\tface = direction.z > 0.0 ? 2.0 : 5.0;\\n\\t\\t\\telse\\n\\t\\t\\t\\tface = direction.y > 0.0 ? 1.0 : 4.0;\\n\\t\\t}\\n\\t\\treturn face;\\n\\t}\\n\\tvec2 getUV( vec3 direction, float face ) {\\n\\t\\tvec2 uv;\\n\\t\\tif ( face == 0.0 ) {\\n\\t\\t\\tuv = vec2( direction.z, direction.y ) / abs( direction.x );\\n\\t\\t} else if ( face == 1.0 ) {\\n\\t\\t\\tuv = vec2( - direction.x, - direction.z ) / abs( direction.y );\\n\\t\\t} else if ( face == 2.0 ) {\\n\\t\\t\\tuv = vec2( - direction.x, direction.y ) / abs( direction.z );\\n\\t\\t} else if ( face == 3.0 ) {\\n\\t\\t\\tuv = vec2( - direction.z, direction.y ) / abs( direction.x );\\n\\t\\t} else if ( face == 4.0 ) {\\n\\t\\t\\tuv = vec2( - direction.x, direction.z ) / abs( direction.y );\\n\\t\\t} else {\\n\\t\\t\\tuv = vec2( direction.x, direction.y ) / abs( direction.z );\\n\\t\\t}\\n\\t\\treturn 0.5 * ( uv + 1.0 );\\n\\t}\\n\\tvec3 bilinearCubeUV( sampler2D envMap, vec3 direction, float mipInt ) {\\n\\t\\tfloat face = getFace( direction );\\n\\t\\tfloat filterInt = max( cubeUV_minMipLevel - mipInt, 0.0 );\\n\\t\\tmipInt = max( mipInt, cubeUV_minMipLevel );\\n\\t\\tfloat faceSize = exp2( mipInt );\\n\\t\\thighp vec2 uv = getUV( direction, face ) * ( faceSize - 2.0 ) + 1.0;\\n\\t\\tif ( face > 2.0 ) {\\n\\t\\t\\tuv.y += faceSize;\\n\\t\\t\\tface -= 3.0;\\n\\t\\t}\\n\\t\\tuv.x += face * faceSize;\\n\\t\\tuv.x += filterInt * 3.0 * cubeUV_minTileSize;\\n\\t\\tuv.y += 4.0 * ( exp2( CUBEUV_MAX_MIP ) - faceSize );\\n\\t\\tuv.x *= CUBEUV_TEXEL_WIDTH;\\n\\t\\tuv.y *= CUBEUV_TEXEL_HEIGHT;\\n\\t\\t#ifdef texture2DGradEXT\\n\\t\\t\\treturn texture2DGradEXT( envMap, uv, vec2( 0.0 ), vec2( 0.0 ) ).rgb;\\n\\t\\t#else\\n\\t\\t\\treturn texture2D( envMap, uv ).rgb;\\n\\t\\t#endif\\n\\t}\\n\\t#define cubeUV_r0 1.0\\n\\t#define cubeUV_m0 - 2.0\\n\\t#define cubeUV_r1 0.8\\n\\t#define cubeUV_m1 - 1.0\\n\\t#define cubeUV_r4 0.4\\n\\t#define cubeUV_m4 2.0\\n\\t#define cubeUV_r5 0.305\\n\\t#define cubeUV_m5 3.0\\n\\t#define cubeUV_r6 0.21\\n\\t#define cubeUV_m6 4.0\\n\\tfloat roughnessToMip( float roughness ) {\\n\\t\\tfloat mip = 0.0;\\n\\t\\tif ( roughness >= cubeUV_r1 ) {\\n\\t\\t\\tmip = ( cubeUV_r0 - roughness ) * ( cubeUV_m1 - cubeUV_m0 ) / ( cubeUV_r0 - cubeUV_r1 ) + cubeUV_m0;\\n\\t\\t} else if ( roughness >= cubeUV_r4 ) {\\n\\t\\t\\tmip = ( cubeUV_r1 - roughness ) * ( cubeUV_m4 - cubeUV_m1 ) / ( cubeUV_r1 - cubeUV_r4 ) + cubeUV_m1;\\n\\t\\t} else if ( roughness >= cubeUV_r5 ) {\\n\\t\\t\\tmip = ( cubeUV_r4 - roughness ) * ( cubeUV_m5 - cubeUV_m4 ) / ( cubeUV_r4 - cubeUV_r5 ) + cubeUV_m4;\\n\\t\\t} else if ( roughness >= cubeUV_r6 ) {\\n\\t\\t\\tmip = ( cubeUV_r5 - roughness ) * ( cubeUV_m6 - cubeUV_m5 ) / ( cubeUV_r5 - cubeUV_r6 ) + cubeUV_m5;\\n\\t\\t} else {\\n\\t\\t\\tmip = - 2.0 * log2( 1.16 * roughness );\\t\\t}\\n\\t\\treturn mip;\\n\\t}\\n\\tvec4 textureCubeUV( sampler2D envMap, vec3 sampleDir, float roughness ) {\\n\\t\\tfloat mip = clamp( roughnessToMip( roughness ), cubeUV_m0, CUBEUV_MAX_MIP );\\n\\t\\tfloat mipF = fract( mip );\\n\\t\\tfloat mipInt = floor( mip );\\n\\t\\tvec3 color0 = bilinearCubeUV( envMap, sampleDir, mipInt );\\n\\t\\tif ( mipF == 0.0 ) {\\n\\t\\t\\treturn vec4( color0, 1.0 );\\n\\t\\t} else {\\n\\t\\t\\tvec3 color1 = bilinearCubeUV( envMap, sampleDir, mipInt + 1.0 );\\n\\t\\t\\treturn vec4( mix( color0, color1, mipF ), 1.0 );\\n\\t\\t}\\n\\t}\\n#endif\";\nvar defaultnormal_vertex = \"vec3 transformedNormal = objectNormal;\\n#ifdef USE_TANGENT\\n\\tvec3 transformedTangent = objectTangent;\\n#endif\\n#ifdef USE_BATCHING\\n\\tmat3 bm = mat3( batchingMatrix );\\n\\ttransformedNormal /= vec3( dot( bm[ 0 ], bm[ 0 ] ), dot( bm[ 1 ], bm[ 1 ] ), dot( bm[ 2 ], bm[ 2 ] ) );\\n\\ttransformedNormal = bm * transformedNormal;\\n\\t#ifdef USE_TANGENT\\n\\t\\ttransformedTangent = bm * transformedTangent;\\n\\t#endif\\n#endif\\n#ifdef USE_INSTANCING\\n\\tmat3 im = mat3( instanceMatrix );\\n\\ttransformedNormal /= vec3( dot( im[ 0 ], im[ 0 ] ), dot( im[ 1 ], im[ 1 ] ), dot( im[ 2 ], im[ 2 ] ) );\\n\\ttransformedNormal = im * transformedNormal;\\n\\t#ifdef USE_TANGENT\\n\\t\\ttransformedTangent = im * transformedTangent;\\n\\t#endif\\n#endif\\ntransformedNormal = normalMatrix * transformedNormal;\\n#ifdef FLIP_SIDED\\n\\ttransformedNormal = - transformedNormal;\\n#endif\\n#ifdef USE_TANGENT\\n\\ttransformedTangent = ( modelViewMatrix * vec4( transformedTangent, 0.0 ) ).xyz;\\n\\t#ifdef FLIP_SIDED\\n\\t\\ttransformedTangent = - transformedTangent;\\n\\t#endif\\n#endif\";\nvar displacementmap_pars_vertex = \"#ifdef USE_DISPLACEMENTMAP\\n\\tuniform sampler2D displacementMap;\\n\\tuniform float displacementScale;\\n\\tuniform float displacementBias;\\n#endif\";\nvar displacementmap_vertex = \"#ifdef USE_DISPLACEMENTMAP\\n\\ttransformed += normalize( objectNormal ) * ( texture2D( displacementMap, vDisplacementMapUv ).x * displacementScale + displacementBias );\\n#endif\";\nvar emissivemap_fragment = \"#ifdef USE_EMISSIVEMAP\\n\\tvec4 emissiveColor = texture2D( emissiveMap, vEmissiveMapUv );\\n\\ttotalEmissiveRadiance *= emissiveColor.rgb;\\n#endif\";\nvar emissivemap_pars_fragment = \"#ifdef USE_EMISSIVEMAP\\n\\tuniform sampler2D emissiveMap;\\n#endif\";\nvar colorspace_fragment = \"gl_FragColor = linearToOutputTexel( gl_FragColor );\";\nvar colorspace_pars_fragment = \"\\nconst mat3 LINEAR_SRGB_TO_LINEAR_DISPLAY_P3 = mat3(\\n\\tvec3( 0.8224621, 0.177538, 0.0 ),\\n\\tvec3( 0.0331941, 0.9668058, 0.0 ),\\n\\tvec3( 0.0170827, 0.0723974, 0.9105199 )\\n);\\nconst mat3 LINEAR_DISPLAY_P3_TO_LINEAR_SRGB = mat3(\\n\\tvec3( 1.2249401, - 0.2249404, 0.0 ),\\n\\tvec3( - 0.0420569, 1.0420571, 0.0 ),\\n\\tvec3( - 0.0196376, - 0.0786361, 1.0982735 )\\n);\\nvec4 LinearSRGBToLinearDisplayP3( in vec4 value ) {\\n\\treturn vec4( value.rgb * LINEAR_SRGB_TO_LINEAR_DISPLAY_P3, value.a );\\n}\\nvec4 LinearDisplayP3ToLinearSRGB( in vec4 value ) {\\n\\treturn vec4( value.rgb * LINEAR_DISPLAY_P3_TO_LINEAR_SRGB, value.a );\\n}\\nvec4 LinearTransferOETF( in vec4 value ) {\\n\\treturn value;\\n}\\nvec4 sRGBTransferOETF( in vec4 value ) {\\n\\treturn vec4( mix( pow( value.rgb, vec3( 0.41666 ) ) * 1.055 - vec3( 0.055 ), value.rgb * 12.92, vec3( lessThanEqual( value.rgb, vec3( 0.0031308 ) ) ) ), value.a );\\n}\";\nvar envmap_fragment = \"#ifdef USE_ENVMAP\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\tvec3 cameraToFrag;\\n\\t\\tif ( isOrthographic ) {\\n\\t\\t\\tcameraToFrag = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\\n\\t\\t} else {\\n\\t\\t\\tcameraToFrag = normalize( vWorldPosition - cameraPosition );\\n\\t\\t}\\n\\t\\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\\n\\t\\t#ifdef ENVMAP_MODE_REFLECTION\\n\\t\\t\\tvec3 reflectVec = reflect( cameraToFrag, worldNormal );\\n\\t\\t#else\\n\\t\\t\\tvec3 reflectVec = refract( cameraToFrag, worldNormal, refractionRatio );\\n\\t\\t#endif\\n\\t#else\\n\\t\\tvec3 reflectVec = vReflect;\\n\\t#endif\\n\\t#ifdef ENVMAP_TYPE_CUBE\\n\\t\\tvec4 envColor = textureCube( envMap, envMapRotation * vec3( flipEnvMap * reflectVec.x, reflectVec.yz ) );\\n\\t#else\\n\\t\\tvec4 envColor = vec4( 0.0 );\\n\\t#endif\\n\\t#ifdef ENVMAP_BLENDING_MULTIPLY\\n\\t\\toutgoingLight = mix( outgoingLight, outgoingLight * envColor.xyz, specularStrength * reflectivity );\\n\\t#elif defined( ENVMAP_BLENDING_MIX )\\n\\t\\toutgoingLight = mix( outgoingLight, envColor.xyz, specularStrength * reflectivity );\\n\\t#elif defined( ENVMAP_BLENDING_ADD )\\n\\t\\toutgoingLight += envColor.xyz * specularStrength * reflectivity;\\n\\t#endif\\n#endif\";\nvar envmap_common_pars_fragment = \"#ifdef USE_ENVMAP\\n\\tuniform float envMapIntensity;\\n\\tuniform float flipEnvMap;\\n\\tuniform mat3 envMapRotation;\\n\\t#ifdef ENVMAP_TYPE_CUBE\\n\\t\\tuniform samplerCube envMap;\\n\\t#else\\n\\t\\tuniform sampler2D envMap;\\n\\t#endif\\n\\t\\n#endif\";\nvar envmap_pars_fragment = \"#ifdef USE_ENVMAP\\n\\tuniform float reflectivity;\\n\\t#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG ) || defined( LAMBERT )\\n\\t\\t#define ENV_WORLDPOS\\n\\t#endif\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\tvarying vec3 vWorldPosition;\\n\\t\\tuniform float refractionRatio;\\n\\t#else\\n\\t\\tvarying vec3 vReflect;\\n\\t#endif\\n#endif\";\nvar envmap_pars_vertex = \"#ifdef USE_ENVMAP\\n\\t#if defined( USE_BUMPMAP ) || defined( USE_NORMALMAP ) || defined( PHONG ) || defined( LAMBERT )\\n\\t\\t#define ENV_WORLDPOS\\n\\t#endif\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\t\\n\\t\\tvarying vec3 vWorldPosition;\\n\\t#else\\n\\t\\tvarying vec3 vReflect;\\n\\t\\tuniform float refractionRatio;\\n\\t#endif\\n#endif\";\nvar envmap_vertex = \"#ifdef USE_ENVMAP\\n\\t#ifdef ENV_WORLDPOS\\n\\t\\tvWorldPosition = worldPosition.xyz;\\n\\t#else\\n\\t\\tvec3 cameraToVertex;\\n\\t\\tif ( isOrthographic ) {\\n\\t\\t\\tcameraToVertex = normalize( vec3( - viewMatrix[ 0 ][ 2 ], - viewMatrix[ 1 ][ 2 ], - viewMatrix[ 2 ][ 2 ] ) );\\n\\t\\t} else {\\n\\t\\t\\tcameraToVertex = normalize( worldPosition.xyz - cameraPosition );\\n\\t\\t}\\n\\t\\tvec3 worldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\\n\\t\\t#ifdef ENVMAP_MODE_REFLECTION\\n\\t\\t\\tvReflect = reflect( cameraToVertex, worldNormal );\\n\\t\\t#else\\n\\t\\t\\tvReflect = refract( cameraToVertex, worldNormal, refractionRatio );\\n\\t\\t#endif\\n\\t#endif\\n#endif\";\nvar fog_vertex = \"#ifdef USE_FOG\\n\\tvFogDepth = - mvPosition.z;\\n#endif\";\nvar fog_pars_vertex = \"#ifdef USE_FOG\\n\\tvarying float vFogDepth;\\n#endif\";\nvar fog_fragment = \"#ifdef USE_FOG\\n\\t#ifdef FOG_EXP2\\n\\t\\tfloat fogFactor = 1.0 - exp( - fogDensity * fogDensity * vFogDepth * vFogDepth );\\n\\t#else\\n\\t\\tfloat fogFactor = smoothstep( fogNear, fogFar, vFogDepth );\\n\\t#endif\\n\\tgl_FragColor.rgb = mix( gl_FragColor.rgb, fogColor, fogFactor );\\n#endif\";\nvar fog_pars_fragment = \"#ifdef USE_FOG\\n\\tuniform vec3 fogColor;\\n\\tvarying float vFogDepth;\\n\\t#ifdef FOG_EXP2\\n\\t\\tuniform float fogDensity;\\n\\t#else\\n\\t\\tuniform float fogNear;\\n\\t\\tuniform float fogFar;\\n\\t#endif\\n#endif\";\nvar gradientmap_pars_fragment = \"#ifdef USE_GRADIENTMAP\\n\\tuniform sampler2D gradientMap;\\n#endif\\nvec3 getGradientIrradiance( vec3 normal, vec3 lightDirection ) {\\n\\tfloat dotNL = dot( normal, lightDirection );\\n\\tvec2 coord = vec2( dotNL * 0.5 + 0.5, 0.0 );\\n\\t#ifdef USE_GRADIENTMAP\\n\\t\\treturn vec3( texture2D( gradientMap, coord ).r );\\n\\t#else\\n\\t\\tvec2 fw = fwidth( coord ) * 0.5;\\n\\t\\treturn mix( vec3( 0.7 ), vec3( 1.0 ), smoothstep( 0.7 - fw.x, 0.7 + fw.x, coord.x ) );\\n\\t#endif\\n}\";\nvar lightmap_pars_fragment = \"#ifdef USE_LIGHTMAP\\n\\tuniform sampler2D lightMap;\\n\\tuniform float lightMapIntensity;\\n#endif\";\nvar lights_lambert_fragment = \"LambertMaterial material;\\nmaterial.diffuseColor = diffuseColor.rgb;\\nmaterial.specularStrength = specularStrength;\";\nvar lights_lambert_pars_fragment = \"varying vec3 vViewPosition;\\nstruct LambertMaterial {\\n\\tvec3 diffuseColor;\\n\\tfloat specularStrength;\\n};\\nvoid RE_Direct_Lambert( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in LambertMaterial material, inout ReflectedLight reflectedLight ) {\\n\\tfloat dotNL = saturate( dot( geometryNormal, directLight.direction ) );\\n\\tvec3 irradiance = dotNL * directLight.color;\\n\\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\nvoid RE_IndirectDiffuse_Lambert( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in LambertMaterial material, inout ReflectedLight reflectedLight ) {\\n\\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\n#define RE_Direct\\t\\t\\t\\tRE_Direct_Lambert\\n#define RE_IndirectDiffuse\\t\\tRE_IndirectDiffuse_Lambert\";\nvar lights_pars_begin = \"uniform bool receiveShadow;\\nuniform vec3 ambientLightColor;\\n#if defined( USE_LIGHT_PROBES )\\n\\tuniform vec3 lightProbe[ 9 ];\\n#endif\\nvec3 shGetIrradianceAt( in vec3 normal, in vec3 shCoefficients[ 9 ] ) {\\n\\tfloat x = normal.x, y = normal.y, z = normal.z;\\n\\tvec3 result = shCoefficients[ 0 ] * 0.886227;\\n\\tresult += shCoefficients[ 1 ] * 2.0 * 0.511664 * y;\\n\\tresult += shCoefficients[ 2 ] * 2.0 * 0.511664 * z;\\n\\tresult += shCoefficients[ 3 ] * 2.0 * 0.511664 * x;\\n\\tresult += shCoefficients[ 4 ] * 2.0 * 0.429043 * x * y;\\n\\tresult += shCoefficients[ 5 ] * 2.0 * 0.429043 * y * z;\\n\\tresult += shCoefficients[ 6 ] * ( 0.743125 * z * z - 0.247708 );\\n\\tresult += shCoefficients[ 7 ] * 2.0 * 0.429043 * x * z;\\n\\tresult += shCoefficients[ 8 ] * 0.429043 * ( x * x - y * y );\\n\\treturn result;\\n}\\nvec3 getLightProbeIrradiance( const in vec3 lightProbe[ 9 ], const in vec3 normal ) {\\n\\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\\n\\tvec3 irradiance = shGetIrradianceAt( worldNormal, lightProbe );\\n\\treturn irradiance;\\n}\\nvec3 getAmbientLightIrradiance( const in vec3 ambientLightColor ) {\\n\\tvec3 irradiance = ambientLightColor;\\n\\treturn irradiance;\\n}\\nfloat getDistanceAttenuation( const in float lightDistance, const in float cutoffDistance, const in float decayExponent ) {\\n\\tfloat distanceFalloff = 1.0 / max( pow( lightDistance, decayExponent ), 0.01 );\\n\\tif ( cutoffDistance > 0.0 ) {\\n\\t\\tdistanceFalloff *= pow2( saturate( 1.0 - pow4( lightDistance / cutoffDistance ) ) );\\n\\t}\\n\\treturn distanceFalloff;\\n}\\nfloat getSpotAttenuation( const in float coneCosine, const in float penumbraCosine, const in float angleCosine ) {\\n\\treturn smoothstep( coneCosine, penumbraCosine, angleCosine );\\n}\\n#if NUM_DIR_LIGHTS > 0\\n\\tstruct DirectionalLight {\\n\\t\\tvec3 direction;\\n\\t\\tvec3 color;\\n\\t};\\n\\tuniform DirectionalLight directionalLights[ NUM_DIR_LIGHTS ];\\n\\tvoid getDirectionalLightInfo( const in DirectionalLight directionalLight, out IncidentLight light ) {\\n\\t\\tlight.color = directionalLight.color;\\n\\t\\tlight.direction = directionalLight.direction;\\n\\t\\tlight.visible = true;\\n\\t}\\n#endif\\n#if NUM_POINT_LIGHTS > 0\\n\\tstruct PointLight {\\n\\t\\tvec3 position;\\n\\t\\tvec3 color;\\n\\t\\tfloat distance;\\n\\t\\tfloat decay;\\n\\t};\\n\\tuniform PointLight pointLights[ NUM_POINT_LIGHTS ];\\n\\tvoid getPointLightInfo( const in PointLight pointLight, const in vec3 geometryPosition, out IncidentLight light ) {\\n\\t\\tvec3 lVector = pointLight.position - geometryPosition;\\n\\t\\tlight.direction = normalize( lVector );\\n\\t\\tfloat lightDistance = length( lVector );\\n\\t\\tlight.color = pointLight.color;\\n\\t\\tlight.color *= getDistanceAttenuation( lightDistance, pointLight.distance, pointLight.decay );\\n\\t\\tlight.visible = ( light.color != vec3( 0.0 ) );\\n\\t}\\n#endif\\n#if NUM_SPOT_LIGHTS > 0\\n\\tstruct SpotLight {\\n\\t\\tvec3 position;\\n\\t\\tvec3 direction;\\n\\t\\tvec3 color;\\n\\t\\tfloat distance;\\n\\t\\tfloat decay;\\n\\t\\tfloat coneCos;\\n\\t\\tfloat penumbraCos;\\n\\t};\\n\\tuniform SpotLight spotLights[ NUM_SPOT_LIGHTS ];\\n\\tvoid getSpotLightInfo( const in SpotLight spotLight, const in vec3 geometryPosition, out IncidentLight light ) {\\n\\t\\tvec3 lVector = spotLight.position - geometryPosition;\\n\\t\\tlight.direction = normalize( lVector );\\n\\t\\tfloat angleCos = dot( light.direction, spotLight.direction );\\n\\t\\tfloat spotAttenuation = getSpotAttenuation( spotLight.coneCos, spotLight.penumbraCos, angleCos );\\n\\t\\tif ( spotAttenuation > 0.0 ) {\\n\\t\\t\\tfloat lightDistance = length( lVector );\\n\\t\\t\\tlight.color = spotLight.color * spotAttenuation;\\n\\t\\t\\tlight.color *= getDistanceAttenuation( lightDistance, spotLight.distance, spotLight.decay );\\n\\t\\t\\tlight.visible = ( light.color != vec3( 0.0 ) );\\n\\t\\t} else {\\n\\t\\t\\tlight.color = vec3( 0.0 );\\n\\t\\t\\tlight.visible = false;\\n\\t\\t}\\n\\t}\\n#endif\\n#if NUM_RECT_AREA_LIGHTS > 0\\n\\tstruct RectAreaLight {\\n\\t\\tvec3 color;\\n\\t\\tvec3 position;\\n\\t\\tvec3 halfWidth;\\n\\t\\tvec3 halfHeight;\\n\\t};\\n\\tuniform sampler2D ltc_1;\\tuniform sampler2D ltc_2;\\n\\tuniform RectAreaLight rectAreaLights[ NUM_RECT_AREA_LIGHTS ];\\n#endif\\n#if NUM_HEMI_LIGHTS > 0\\n\\tstruct HemisphereLight {\\n\\t\\tvec3 direction;\\n\\t\\tvec3 skyColor;\\n\\t\\tvec3 groundColor;\\n\\t};\\n\\tuniform HemisphereLight hemisphereLights[ NUM_HEMI_LIGHTS ];\\n\\tvec3 getHemisphereLightIrradiance( const in HemisphereLight hemiLight, const in vec3 normal ) {\\n\\t\\tfloat dotNL = dot( normal, hemiLight.direction );\\n\\t\\tfloat hemiDiffuseWeight = 0.5 * dotNL + 0.5;\\n\\t\\tvec3 irradiance = mix( hemiLight.groundColor, hemiLight.skyColor, hemiDiffuseWeight );\\n\\t\\treturn irradiance;\\n\\t}\\n#endif\";\nvar envmap_physical_pars_fragment = \"#ifdef USE_ENVMAP\\n\\tvec3 getIBLIrradiance( const in vec3 normal ) {\\n\\t\\t#ifdef ENVMAP_TYPE_CUBE_UV\\n\\t\\t\\tvec3 worldNormal = inverseTransformDirection( normal, viewMatrix );\\n\\t\\t\\tvec4 envMapColor = textureCubeUV( envMap, envMapRotation * worldNormal, 1.0 );\\n\\t\\t\\treturn PI * envMapColor.rgb * envMapIntensity;\\n\\t\\t#else\\n\\t\\t\\treturn vec3( 0.0 );\\n\\t\\t#endif\\n\\t}\\n\\tvec3 getIBLRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness ) {\\n\\t\\t#ifdef ENVMAP_TYPE_CUBE_UV\\n\\t\\t\\tvec3 reflectVec = reflect( - viewDir, normal );\\n\\t\\t\\treflectVec = normalize( mix( reflectVec, normal, roughness * roughness) );\\n\\t\\t\\treflectVec = inverseTransformDirection( reflectVec, viewMatrix );\\n\\t\\t\\tvec4 envMapColor = textureCubeUV( envMap, envMapRotation * reflectVec, roughness );\\n\\t\\t\\treturn envMapColor.rgb * envMapIntensity;\\n\\t\\t#else\\n\\t\\t\\treturn vec3( 0.0 );\\n\\t\\t#endif\\n\\t}\\n\\t#ifdef USE_ANISOTROPY\\n\\t\\tvec3 getIBLAnisotropyRadiance( const in vec3 viewDir, const in vec3 normal, const in float roughness, const in vec3 bitangent, const in float anisotropy ) {\\n\\t\\t\\t#ifdef ENVMAP_TYPE_CUBE_UV\\n\\t\\t\\t\\tvec3 bentNormal = cross( bitangent, viewDir );\\n\\t\\t\\t\\tbentNormal = normalize( cross( bentNormal, bitangent ) );\\n\\t\\t\\t\\tbentNormal = normalize( mix( bentNormal, normal, pow2( pow2( 1.0 - anisotropy * ( 1.0 - roughness ) ) ) ) );\\n\\t\\t\\t\\treturn getIBLRadiance( viewDir, bentNormal, roughness );\\n\\t\\t\\t#else\\n\\t\\t\\t\\treturn vec3( 0.0 );\\n\\t\\t\\t#endif\\n\\t\\t}\\n\\t#endif\\n#endif\";\nvar lights_toon_fragment = \"ToonMaterial material;\\nmaterial.diffuseColor = diffuseColor.rgb;\";\nvar lights_toon_pars_fragment = \"varying vec3 vViewPosition;\\nstruct ToonMaterial {\\n\\tvec3 diffuseColor;\\n};\\nvoid RE_Direct_Toon( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\\n\\tvec3 irradiance = getGradientIrradiance( geometryNormal, directLight.direction ) * directLight.color;\\n\\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\nvoid RE_IndirectDiffuse_Toon( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in ToonMaterial material, inout ReflectedLight reflectedLight ) {\\n\\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\n#define RE_Direct\\t\\t\\t\\tRE_Direct_Toon\\n#define RE_IndirectDiffuse\\t\\tRE_IndirectDiffuse_Toon\";\nvar lights_phong_fragment = \"BlinnPhongMaterial material;\\nmaterial.diffuseColor = diffuseColor.rgb;\\nmaterial.specularColor = specular;\\nmaterial.specularShininess = shininess;\\nmaterial.specularStrength = specularStrength;\";\nvar lights_phong_pars_fragment = \"varying vec3 vViewPosition;\\nstruct BlinnPhongMaterial {\\n\\tvec3 diffuseColor;\\n\\tvec3 specularColor;\\n\\tfloat specularShininess;\\n\\tfloat specularStrength;\\n};\\nvoid RE_Direct_BlinnPhong( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\\n\\tfloat dotNL = saturate( dot( geometryNormal, directLight.direction ) );\\n\\tvec3 irradiance = dotNL * directLight.color;\\n\\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n\\treflectedLight.directSpecular += irradiance * BRDF_BlinnPhong( directLight.direction, geometryViewDir, geometryNormal, material.specularColor, material.specularShininess ) * material.specularStrength;\\n}\\nvoid RE_IndirectDiffuse_BlinnPhong( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in BlinnPhongMaterial material, inout ReflectedLight reflectedLight ) {\\n\\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\n#define RE_Direct\\t\\t\\t\\tRE_Direct_BlinnPhong\\n#define RE_IndirectDiffuse\\t\\tRE_IndirectDiffuse_BlinnPhong\";\nvar lights_physical_fragment = \"PhysicalMaterial material;\\nmaterial.diffuseColor = diffuseColor.rgb * ( 1.0 - metalnessFactor );\\nvec3 dxy = max( abs( dFdx( nonPerturbedNormal ) ), abs( dFdy( nonPerturbedNormal ) ) );\\nfloat geometryRoughness = max( max( dxy.x, dxy.y ), dxy.z );\\nmaterial.roughness = max( roughnessFactor, 0.0525 );material.roughness += geometryRoughness;\\nmaterial.roughness = min( material.roughness, 1.0 );\\n#ifdef IOR\\n\\tmaterial.ior = ior;\\n\\t#ifdef USE_SPECULAR\\n\\t\\tfloat specularIntensityFactor = specularIntensity;\\n\\t\\tvec3 specularColorFactor = specularColor;\\n\\t\\t#ifdef USE_SPECULAR_COLORMAP\\n\\t\\t\\tspecularColorFactor *= texture2D( specularColorMap, vSpecularColorMapUv ).rgb;\\n\\t\\t#endif\\n\\t\\t#ifdef USE_SPECULAR_INTENSITYMAP\\n\\t\\t\\tspecularIntensityFactor *= texture2D( specularIntensityMap, vSpecularIntensityMapUv ).a;\\n\\t\\t#endif\\n\\t\\tmaterial.specularF90 = mix( specularIntensityFactor, 1.0, metalnessFactor );\\n\\t#else\\n\\t\\tfloat specularIntensityFactor = 1.0;\\n\\t\\tvec3 specularColorFactor = vec3( 1.0 );\\n\\t\\tmaterial.specularF90 = 1.0;\\n\\t#endif\\n\\tmaterial.specularColor = mix( min( pow2( ( material.ior - 1.0 ) / ( material.ior + 1.0 ) ) * specularColorFactor, vec3( 1.0 ) ) * specularIntensityFactor, diffuseColor.rgb, metalnessFactor );\\n#else\\n\\tmaterial.specularColor = mix( vec3( 0.04 ), diffuseColor.rgb, metalnessFactor );\\n\\tmaterial.specularF90 = 1.0;\\n#endif\\n#ifdef USE_CLEARCOAT\\n\\tmaterial.clearcoat = clearcoat;\\n\\tmaterial.clearcoatRoughness = clearcoatRoughness;\\n\\tmaterial.clearcoatF0 = vec3( 0.04 );\\n\\tmaterial.clearcoatF90 = 1.0;\\n\\t#ifdef USE_CLEARCOATMAP\\n\\t\\tmaterial.clearcoat *= texture2D( clearcoatMap, vClearcoatMapUv ).x;\\n\\t#endif\\n\\t#ifdef USE_CLEARCOAT_ROUGHNESSMAP\\n\\t\\tmaterial.clearcoatRoughness *= texture2D( clearcoatRoughnessMap, vClearcoatRoughnessMapUv ).y;\\n\\t#endif\\n\\tmaterial.clearcoat = saturate( material.clearcoat );\\tmaterial.clearcoatRoughness = max( material.clearcoatRoughness, 0.0525 );\\n\\tmaterial.clearcoatRoughness += geometryRoughness;\\n\\tmaterial.clearcoatRoughness = min( material.clearcoatRoughness, 1.0 );\\n#endif\\n#ifdef USE_DISPERSION\\n\\tmaterial.dispersion = dispersion;\\n#endif\\n#ifdef USE_IRIDESCENCE\\n\\tmaterial.iridescence = iridescence;\\n\\tmaterial.iridescenceIOR = iridescenceIOR;\\n\\t#ifdef USE_IRIDESCENCEMAP\\n\\t\\tmaterial.iridescence *= texture2D( iridescenceMap, vIridescenceMapUv ).r;\\n\\t#endif\\n\\t#ifdef USE_IRIDESCENCE_THICKNESSMAP\\n\\t\\tmaterial.iridescenceThickness = (iridescenceThicknessMaximum - iridescenceThicknessMinimum) * texture2D( iridescenceThicknessMap, vIridescenceThicknessMapUv ).g + iridescenceThicknessMinimum;\\n\\t#else\\n\\t\\tmaterial.iridescenceThickness = iridescenceThicknessMaximum;\\n\\t#endif\\n#endif\\n#ifdef USE_SHEEN\\n\\tmaterial.sheenColor = sheenColor;\\n\\t#ifdef USE_SHEEN_COLORMAP\\n\\t\\tmaterial.sheenColor *= texture2D( sheenColorMap, vSheenColorMapUv ).rgb;\\n\\t#endif\\n\\tmaterial.sheenRoughness = clamp( sheenRoughness, 0.07, 1.0 );\\n\\t#ifdef USE_SHEEN_ROUGHNESSMAP\\n\\t\\tmaterial.sheenRoughness *= texture2D( sheenRoughnessMap, vSheenRoughnessMapUv ).a;\\n\\t#endif\\n#endif\\n#ifdef USE_ANISOTROPY\\n\\t#ifdef USE_ANISOTROPYMAP\\n\\t\\tmat2 anisotropyMat = mat2( anisotropyVector.x, anisotropyVector.y, - anisotropyVector.y, anisotropyVector.x );\\n\\t\\tvec3 anisotropyPolar = texture2D( anisotropyMap, vAnisotropyMapUv ).rgb;\\n\\t\\tvec2 anisotropyV = anisotropyMat * normalize( 2.0 * anisotropyPolar.rg - vec2( 1.0 ) ) * anisotropyPolar.b;\\n\\t#else\\n\\t\\tvec2 anisotropyV = anisotropyVector;\\n\\t#endif\\n\\tmaterial.anisotropy = length( anisotropyV );\\n\\tif( material.anisotropy == 0.0 ) {\\n\\t\\tanisotropyV = vec2( 1.0, 0.0 );\\n\\t} else {\\n\\t\\tanisotropyV /= material.anisotropy;\\n\\t\\tmaterial.anisotropy = saturate( material.anisotropy );\\n\\t}\\n\\tmaterial.alphaT = mix( pow2( material.roughness ), 1.0, pow2( material.anisotropy ) );\\n\\tmaterial.anisotropyT = tbn[ 0 ] * anisotropyV.x + tbn[ 1 ] * anisotropyV.y;\\n\\tmaterial.anisotropyB = tbn[ 1 ] * anisotropyV.x - tbn[ 0 ] * anisotropyV.y;\\n#endif\";\nvar lights_physical_pars_fragment = \"struct PhysicalMaterial {\\n\\tvec3 diffuseColor;\\n\\tfloat roughness;\\n\\tvec3 specularColor;\\n\\tfloat specularF90;\\n\\tfloat dispersion;\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tfloat clearcoat;\\n\\t\\tfloat clearcoatRoughness;\\n\\t\\tvec3 clearcoatF0;\\n\\t\\tfloat clearcoatF90;\\n\\t#endif\\n\\t#ifdef USE_IRIDESCENCE\\n\\t\\tfloat iridescence;\\n\\t\\tfloat iridescenceIOR;\\n\\t\\tfloat iridescenceThickness;\\n\\t\\tvec3 iridescenceFresnel;\\n\\t\\tvec3 iridescenceF0;\\n\\t#endif\\n\\t#ifdef USE_SHEEN\\n\\t\\tvec3 sheenColor;\\n\\t\\tfloat sheenRoughness;\\n\\t#endif\\n\\t#ifdef IOR\\n\\t\\tfloat ior;\\n\\t#endif\\n\\t#ifdef USE_TRANSMISSION\\n\\t\\tfloat transmission;\\n\\t\\tfloat transmissionAlpha;\\n\\t\\tfloat thickness;\\n\\t\\tfloat attenuationDistance;\\n\\t\\tvec3 attenuationColor;\\n\\t#endif\\n\\t#ifdef USE_ANISOTROPY\\n\\t\\tfloat anisotropy;\\n\\t\\tfloat alphaT;\\n\\t\\tvec3 anisotropyT;\\n\\t\\tvec3 anisotropyB;\\n\\t#endif\\n};\\nvec3 clearcoatSpecularDirect = vec3( 0.0 );\\nvec3 clearcoatSpecularIndirect = vec3( 0.0 );\\nvec3 sheenSpecularDirect = vec3( 0.0 );\\nvec3 sheenSpecularIndirect = vec3(0.0 );\\nvec3 Schlick_to_F0( const in vec3 f, const in float f90, const in float dotVH ) {\\n    float x = clamp( 1.0 - dotVH, 0.0, 1.0 );\\n    float x2 = x * x;\\n    float x5 = clamp( x * x2 * x2, 0.0, 0.9999 );\\n    return ( f - vec3( f90 ) * x5 ) / ( 1.0 - x5 );\\n}\\nfloat V_GGX_SmithCorrelated( const in float alpha, const in float dotNL, const in float dotNV ) {\\n\\tfloat a2 = pow2( alpha );\\n\\tfloat gv = dotNL * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNV ) );\\n\\tfloat gl = dotNV * sqrt( a2 + ( 1.0 - a2 ) * pow2( dotNL ) );\\n\\treturn 0.5 / max( gv + gl, EPSILON );\\n}\\nfloat D_GGX( const in float alpha, const in float dotNH ) {\\n\\tfloat a2 = pow2( alpha );\\n\\tfloat denom = pow2( dotNH ) * ( a2 - 1.0 ) + 1.0;\\n\\treturn RECIPROCAL_PI * a2 / pow2( denom );\\n}\\n#ifdef USE_ANISOTROPY\\n\\tfloat V_GGX_SmithCorrelated_Anisotropic( const in float alphaT, const in float alphaB, const in float dotTV, const in float dotBV, const in float dotTL, const in float dotBL, const in float dotNV, const in float dotNL ) {\\n\\t\\tfloat gv = dotNL * length( vec3( alphaT * dotTV, alphaB * dotBV, dotNV ) );\\n\\t\\tfloat gl = dotNV * length( vec3( alphaT * dotTL, alphaB * dotBL, dotNL ) );\\n\\t\\tfloat v = 0.5 / ( gv + gl );\\n\\t\\treturn saturate(v);\\n\\t}\\n\\tfloat D_GGX_Anisotropic( const in float alphaT, const in float alphaB, const in float dotNH, const in float dotTH, const in float dotBH ) {\\n\\t\\tfloat a2 = alphaT * alphaB;\\n\\t\\thighp vec3 v = vec3( alphaB * dotTH, alphaT * dotBH, a2 * dotNH );\\n\\t\\thighp float v2 = dot( v, v );\\n\\t\\tfloat w2 = a2 / v2;\\n\\t\\treturn RECIPROCAL_PI * a2 * pow2 ( w2 );\\n\\t}\\n#endif\\n#ifdef USE_CLEARCOAT\\n\\tvec3 BRDF_GGX_Clearcoat( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in PhysicalMaterial material) {\\n\\t\\tvec3 f0 = material.clearcoatF0;\\n\\t\\tfloat f90 = material.clearcoatF90;\\n\\t\\tfloat roughness = material.clearcoatRoughness;\\n\\t\\tfloat alpha = pow2( roughness );\\n\\t\\tvec3 halfDir = normalize( lightDir + viewDir );\\n\\t\\tfloat dotNL = saturate( dot( normal, lightDir ) );\\n\\t\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\t\\tfloat dotNH = saturate( dot( normal, halfDir ) );\\n\\t\\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\\n\\t\\tvec3 F = F_Schlick( f0, f90, dotVH );\\n\\t\\tfloat V = V_GGX_SmithCorrelated( alpha, dotNL, dotNV );\\n\\t\\tfloat D = D_GGX( alpha, dotNH );\\n\\t\\treturn F * ( V * D );\\n\\t}\\n#endif\\nvec3 BRDF_GGX( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, const in PhysicalMaterial material ) {\\n\\tvec3 f0 = material.specularColor;\\n\\tfloat f90 = material.specularF90;\\n\\tfloat roughness = material.roughness;\\n\\tfloat alpha = pow2( roughness );\\n\\tvec3 halfDir = normalize( lightDir + viewDir );\\n\\tfloat dotNL = saturate( dot( normal, lightDir ) );\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tfloat dotNH = saturate( dot( normal, halfDir ) );\\n\\tfloat dotVH = saturate( dot( viewDir, halfDir ) );\\n\\tvec3 F = F_Schlick( f0, f90, dotVH );\\n\\t#ifdef USE_IRIDESCENCE\\n\\t\\tF = mix( F, material.iridescenceFresnel, material.iridescence );\\n\\t#endif\\n\\t#ifdef USE_ANISOTROPY\\n\\t\\tfloat dotTL = dot( material.anisotropyT, lightDir );\\n\\t\\tfloat dotTV = dot( material.anisotropyT, viewDir );\\n\\t\\tfloat dotTH = dot( material.anisotropyT, halfDir );\\n\\t\\tfloat dotBL = dot( material.anisotropyB, lightDir );\\n\\t\\tfloat dotBV = dot( material.anisotropyB, viewDir );\\n\\t\\tfloat dotBH = dot( material.anisotropyB, halfDir );\\n\\t\\tfloat V = V_GGX_SmithCorrelated_Anisotropic( material.alphaT, alpha, dotTV, dotBV, dotTL, dotBL, dotNV, dotNL );\\n\\t\\tfloat D = D_GGX_Anisotropic( material.alphaT, alpha, dotNH, dotTH, dotBH );\\n\\t#else\\n\\t\\tfloat V = V_GGX_SmithCorrelated( alpha, dotNL, dotNV );\\n\\t\\tfloat D = D_GGX( alpha, dotNH );\\n\\t#endif\\n\\treturn F * ( V * D );\\n}\\nvec2 LTC_Uv( const in vec3 N, const in vec3 V, const in float roughness ) {\\n\\tconst float LUT_SIZE = 64.0;\\n\\tconst float LUT_SCALE = ( LUT_SIZE - 1.0 ) / LUT_SIZE;\\n\\tconst float LUT_BIAS = 0.5 / LUT_SIZE;\\n\\tfloat dotNV = saturate( dot( N, V ) );\\n\\tvec2 uv = vec2( roughness, sqrt( 1.0 - dotNV ) );\\n\\tuv = uv * LUT_SCALE + LUT_BIAS;\\n\\treturn uv;\\n}\\nfloat LTC_ClippedSphereFormFactor( const in vec3 f ) {\\n\\tfloat l = length( f );\\n\\treturn max( ( l * l + f.z ) / ( l + 1.0 ), 0.0 );\\n}\\nvec3 LTC_EdgeVectorFormFactor( const in vec3 v1, const in vec3 v2 ) {\\n\\tfloat x = dot( v1, v2 );\\n\\tfloat y = abs( x );\\n\\tfloat a = 0.8543985 + ( 0.4965155 + 0.0145206 * y ) * y;\\n\\tfloat b = 3.4175940 + ( 4.1616724 + y ) * y;\\n\\tfloat v = a / b;\\n\\tfloat theta_sintheta = ( x > 0.0 ) ? v : 0.5 * inversesqrt( max( 1.0 - x * x, 1e-7 ) ) - v;\\n\\treturn cross( v1, v2 ) * theta_sintheta;\\n}\\nvec3 LTC_Evaluate( const in vec3 N, const in vec3 V, const in vec3 P, const in mat3 mInv, const in vec3 rectCoords[ 4 ] ) {\\n\\tvec3 v1 = rectCoords[ 1 ] - rectCoords[ 0 ];\\n\\tvec3 v2 = rectCoords[ 3 ] - rectCoords[ 0 ];\\n\\tvec3 lightNormal = cross( v1, v2 );\\n\\tif( dot( lightNormal, P - rectCoords[ 0 ] ) < 0.0 ) return vec3( 0.0 );\\n\\tvec3 T1, T2;\\n\\tT1 = normalize( V - N * dot( V, N ) );\\n\\tT2 = - cross( N, T1 );\\n\\tmat3 mat = mInv * transposeMat3( mat3( T1, T2, N ) );\\n\\tvec3 coords[ 4 ];\\n\\tcoords[ 0 ] = mat * ( rectCoords[ 0 ] - P );\\n\\tcoords[ 1 ] = mat * ( rectCoords[ 1 ] - P );\\n\\tcoords[ 2 ] = mat * ( rectCoords[ 2 ] - P );\\n\\tcoords[ 3 ] = mat * ( rectCoords[ 3 ] - P );\\n\\tcoords[ 0 ] = normalize( coords[ 0 ] );\\n\\tcoords[ 1 ] = normalize( coords[ 1 ] );\\n\\tcoords[ 2 ] = normalize( coords[ 2 ] );\\n\\tcoords[ 3 ] = normalize( coords[ 3 ] );\\n\\tvec3 vectorFormFactor = vec3( 0.0 );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 0 ], coords[ 1 ] );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 1 ], coords[ 2 ] );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 2 ], coords[ 3 ] );\\n\\tvectorFormFactor += LTC_EdgeVectorFormFactor( coords[ 3 ], coords[ 0 ] );\\n\\tfloat result = LTC_ClippedSphereFormFactor( vectorFormFactor );\\n\\treturn vec3( result );\\n}\\n#if defined( USE_SHEEN )\\nfloat D_Charlie( float roughness, float dotNH ) {\\n\\tfloat alpha = pow2( roughness );\\n\\tfloat invAlpha = 1.0 / alpha;\\n\\tfloat cos2h = dotNH * dotNH;\\n\\tfloat sin2h = max( 1.0 - cos2h, 0.0078125 );\\n\\treturn ( 2.0 + invAlpha ) * pow( sin2h, invAlpha * 0.5 ) / ( 2.0 * PI );\\n}\\nfloat V_Neubelt( float dotNV, float dotNL ) {\\n\\treturn saturate( 1.0 / ( 4.0 * ( dotNL + dotNV - dotNL * dotNV ) ) );\\n}\\nvec3 BRDF_Sheen( const in vec3 lightDir, const in vec3 viewDir, const in vec3 normal, vec3 sheenColor, const in float sheenRoughness ) {\\n\\tvec3 halfDir = normalize( lightDir + viewDir );\\n\\tfloat dotNL = saturate( dot( normal, lightDir ) );\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tfloat dotNH = saturate( dot( normal, halfDir ) );\\n\\tfloat D = D_Charlie( sheenRoughness, dotNH );\\n\\tfloat V = V_Neubelt( dotNV, dotNL );\\n\\treturn sheenColor * ( D * V );\\n}\\n#endif\\nfloat IBLSheenBRDF( const in vec3 normal, const in vec3 viewDir, const in float roughness ) {\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tfloat r2 = roughness * roughness;\\n\\tfloat a = roughness < 0.25 ? -339.2 * r2 + 161.4 * roughness - 25.9 : -8.48 * r2 + 14.3 * roughness - 9.95;\\n\\tfloat b = roughness < 0.25 ? 44.0 * r2 - 23.7 * roughness + 3.26 : 1.97 * r2 - 3.27 * roughness + 0.72;\\n\\tfloat DG = exp( a * dotNV + b ) + ( roughness < 0.25 ? 0.0 : 0.1 * ( roughness - 0.25 ) );\\n\\treturn saturate( DG * RECIPROCAL_PI );\\n}\\nvec2 DFGApprox( const in vec3 normal, const in vec3 viewDir, const in float roughness ) {\\n\\tfloat dotNV = saturate( dot( normal, viewDir ) );\\n\\tconst vec4 c0 = vec4( - 1, - 0.0275, - 0.572, 0.022 );\\n\\tconst vec4 c1 = vec4( 1, 0.0425, 1.04, - 0.04 );\\n\\tvec4 r = roughness * c0 + c1;\\n\\tfloat a004 = min( r.x * r.x, exp2( - 9.28 * dotNV ) ) * r.x + r.y;\\n\\tvec2 fab = vec2( - 1.04, 1.04 ) * a004 + r.zw;\\n\\treturn fab;\\n}\\nvec3 EnvironmentBRDF( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness ) {\\n\\tvec2 fab = DFGApprox( normal, viewDir, roughness );\\n\\treturn specularColor * fab.x + specularF90 * fab.y;\\n}\\n#ifdef USE_IRIDESCENCE\\nvoid computeMultiscatteringIridescence( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float iridescence, const in vec3 iridescenceF0, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {\\n#else\\nvoid computeMultiscattering( const in vec3 normal, const in vec3 viewDir, const in vec3 specularColor, const in float specularF90, const in float roughness, inout vec3 singleScatter, inout vec3 multiScatter ) {\\n#endif\\n\\tvec2 fab = DFGApprox( normal, viewDir, roughness );\\n\\t#ifdef USE_IRIDESCENCE\\n\\t\\tvec3 Fr = mix( specularColor, iridescenceF0, iridescence );\\n\\t#else\\n\\t\\tvec3 Fr = specularColor;\\n\\t#endif\\n\\tvec3 FssEss = Fr * fab.x + specularF90 * fab.y;\\n\\tfloat Ess = fab.x + fab.y;\\n\\tfloat Ems = 1.0 - Ess;\\n\\tvec3 Favg = Fr + ( 1.0 - Fr ) * 0.047619;\\tvec3 Fms = FssEss * Favg / ( 1.0 - Ems * Favg );\\n\\tsingleScatter += FssEss;\\n\\tmultiScatter += Fms * Ems;\\n}\\n#if NUM_RECT_AREA_LIGHTS > 0\\n\\tvoid RE_Direct_RectArea_Physical( const in RectAreaLight rectAreaLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\\n\\t\\tvec3 normal = geometryNormal;\\n\\t\\tvec3 viewDir = geometryViewDir;\\n\\t\\tvec3 position = geometryPosition;\\n\\t\\tvec3 lightPos = rectAreaLight.position;\\n\\t\\tvec3 halfWidth = rectAreaLight.halfWidth;\\n\\t\\tvec3 halfHeight = rectAreaLight.halfHeight;\\n\\t\\tvec3 lightColor = rectAreaLight.color;\\n\\t\\tfloat roughness = material.roughness;\\n\\t\\tvec3 rectCoords[ 4 ];\\n\\t\\trectCoords[ 0 ] = lightPos + halfWidth - halfHeight;\\t\\trectCoords[ 1 ] = lightPos - halfWidth - halfHeight;\\n\\t\\trectCoords[ 2 ] = lightPos - halfWidth + halfHeight;\\n\\t\\trectCoords[ 3 ] = lightPos + halfWidth + halfHeight;\\n\\t\\tvec2 uv = LTC_Uv( normal, viewDir, roughness );\\n\\t\\tvec4 t1 = texture2D( ltc_1, uv );\\n\\t\\tvec4 t2 = texture2D( ltc_2, uv );\\n\\t\\tmat3 mInv = mat3(\\n\\t\\t\\tvec3( t1.x, 0, t1.y ),\\n\\t\\t\\tvec3(    0, 1,    0 ),\\n\\t\\t\\tvec3( t1.z, 0, t1.w )\\n\\t\\t);\\n\\t\\tvec3 fresnel = ( material.specularColor * t2.x + ( vec3( 1.0 ) - material.specularColor ) * t2.y );\\n\\t\\treflectedLight.directSpecular += lightColor * fresnel * LTC_Evaluate( normal, viewDir, position, mInv, rectCoords );\\n\\t\\treflectedLight.directDiffuse += lightColor * material.diffuseColor * LTC_Evaluate( normal, viewDir, position, mat3( 1.0 ), rectCoords );\\n\\t}\\n#endif\\nvoid RE_Direct_Physical( const in IncidentLight directLight, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\\n\\tfloat dotNL = saturate( dot( geometryNormal, directLight.direction ) );\\n\\tvec3 irradiance = dotNL * directLight.color;\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tfloat dotNLcc = saturate( dot( geometryClearcoatNormal, directLight.direction ) );\\n\\t\\tvec3 ccIrradiance = dotNLcc * directLight.color;\\n\\t\\tclearcoatSpecularDirect += ccIrradiance * BRDF_GGX_Clearcoat( directLight.direction, geometryViewDir, geometryClearcoatNormal, material );\\n\\t#endif\\n\\t#ifdef USE_SHEEN\\n\\t\\tsheenSpecularDirect += irradiance * BRDF_Sheen( directLight.direction, geometryViewDir, geometryNormal, material.sheenColor, material.sheenRoughness );\\n\\t#endif\\n\\treflectedLight.directSpecular += irradiance * BRDF_GGX( directLight.direction, geometryViewDir, geometryNormal, material );\\n\\treflectedLight.directDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\nvoid RE_IndirectDiffuse_Physical( const in vec3 irradiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight ) {\\n\\treflectedLight.indirectDiffuse += irradiance * BRDF_Lambert( material.diffuseColor );\\n}\\nvoid RE_IndirectSpecular_Physical( const in vec3 radiance, const in vec3 irradiance, const in vec3 clearcoatRadiance, const in vec3 geometryPosition, const in vec3 geometryNormal, const in vec3 geometryViewDir, const in vec3 geometryClearcoatNormal, const in PhysicalMaterial material, inout ReflectedLight reflectedLight) {\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tclearcoatSpecularIndirect += clearcoatRadiance * EnvironmentBRDF( geometryClearcoatNormal, geometryViewDir, material.clearcoatF0, material.clearcoatF90, material.clearcoatRoughness );\\n\\t#endif\\n\\t#ifdef USE_SHEEN\\n\\t\\tsheenSpecularIndirect += irradiance * material.sheenColor * IBLSheenBRDF( geometryNormal, geometryViewDir, material.sheenRoughness );\\n\\t#endif\\n\\tvec3 singleScattering = vec3( 0.0 );\\n\\tvec3 multiScattering = vec3( 0.0 );\\n\\tvec3 cosineWeightedIrradiance = irradiance * RECIPROCAL_PI;\\n\\t#ifdef USE_IRIDESCENCE\\n\\t\\tcomputeMultiscatteringIridescence( geometryNormal, geometryViewDir, material.specularColor, material.specularF90, material.iridescence, material.iridescenceFresnel, material.roughness, singleScattering, multiScattering );\\n\\t#else\\n\\t\\tcomputeMultiscattering( geometryNormal, geometryViewDir, material.specularColor, material.specularF90, material.roughness, singleScattering, multiScattering );\\n\\t#endif\\n\\tvec3 totalScattering = singleScattering + multiScattering;\\n\\tvec3 diffuse = material.diffuseColor * ( 1.0 - max( max( totalScattering.r, totalScattering.g ), totalScattering.b ) );\\n\\treflectedLight.indirectSpecular += radiance * singleScattering;\\n\\treflectedLight.indirectSpecular += multiScattering * cosineWeightedIrradiance;\\n\\treflectedLight.indirectDiffuse += diffuse * cosineWeightedIrradiance;\\n}\\n#define RE_Direct\\t\\t\\t\\tRE_Direct_Physical\\n#define RE_Direct_RectArea\\t\\tRE_Direct_RectArea_Physical\\n#define RE_IndirectDiffuse\\t\\tRE_IndirectDiffuse_Physical\\n#define RE_IndirectSpecular\\t\\tRE_IndirectSpecular_Physical\\nfloat computeSpecularOcclusion( const in float dotNV, const in float ambientOcclusion, const in float roughness ) {\\n\\treturn saturate( pow( dotNV + ambientOcclusion, exp2( - 16.0 * roughness - 1.0 ) ) - 1.0 + ambientOcclusion );\\n}\";\nvar lights_fragment_begin = \"\\nvec3 geometryPosition = - vViewPosition;\\nvec3 geometryNormal = normal;\\nvec3 geometryViewDir = ( isOrthographic ) ? vec3( 0, 0, 1 ) : normalize( vViewPosition );\\nvec3 geometryClearcoatNormal = vec3( 0.0 );\\n#ifdef USE_CLEARCOAT\\n\\tgeometryClearcoatNormal = clearcoatNormal;\\n#endif\\n#ifdef USE_IRIDESCENCE\\n\\tfloat dotNVi = saturate( dot( normal, geometryViewDir ) );\\n\\tif ( material.iridescenceThickness == 0.0 ) {\\n\\t\\tmaterial.iridescence = 0.0;\\n\\t} else {\\n\\t\\tmaterial.iridescence = saturate( material.iridescence );\\n\\t}\\n\\tif ( material.iridescence > 0.0 ) {\\n\\t\\tmaterial.iridescenceFresnel = evalIridescence( 1.0, material.iridescenceIOR, dotNVi, material.iridescenceThickness, material.specularColor );\\n\\t\\tmaterial.iridescenceF0 = Schlick_to_F0( material.iridescenceFresnel, 1.0, dotNVi );\\n\\t}\\n#endif\\nIncidentLight directLight;\\n#if ( NUM_POINT_LIGHTS > 0 ) && defined( RE_Direct )\\n\\tPointLight pointLight;\\n\\t#if defined( USE_SHADOWMAP ) && NUM_POINT_LIGHT_SHADOWS > 0\\n\\tPointLightShadow pointLightShadow;\\n\\t#endif\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_POINT_LIGHTS; i ++ ) {\\n\\t\\tpointLight = pointLights[ i ];\\n\\t\\tgetPointLightInfo( pointLight, geometryPosition, directLight );\\n\\t\\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_POINT_LIGHT_SHADOWS )\\n\\t\\tpointLightShadow = pointLightShadows[ i ];\\n\\t\\tdirectLight.color *= ( directLight.visible && receiveShadow ) ? getPointShadow( pointShadowMap[ i ], pointLightShadow.shadowMapSize, pointLightShadow.shadowIntensity, pointLightShadow.shadowBias, pointLightShadow.shadowRadius, vPointShadowCoord[ i ], pointLightShadow.shadowCameraNear, pointLightShadow.shadowCameraFar ) : 1.0;\\n\\t\\t#endif\\n\\t\\tRE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if ( NUM_SPOT_LIGHTS > 0 ) && defined( RE_Direct )\\n\\tSpotLight spotLight;\\n\\tvec4 spotColor;\\n\\tvec3 spotLightCoord;\\n\\tbool inSpotLightMap;\\n\\t#if defined( USE_SHADOWMAP ) && NUM_SPOT_LIGHT_SHADOWS > 0\\n\\tSpotLightShadow spotLightShadow;\\n\\t#endif\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_SPOT_LIGHTS; i ++ ) {\\n\\t\\tspotLight = spotLights[ i ];\\n\\t\\tgetSpotLightInfo( spotLight, geometryPosition, directLight );\\n\\t\\t#if ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS )\\n\\t\\t#define SPOT_LIGHT_MAP_INDEX UNROLLED_LOOP_INDEX\\n\\t\\t#elif ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\\n\\t\\t#define SPOT_LIGHT_MAP_INDEX NUM_SPOT_LIGHT_MAPS\\n\\t\\t#else\\n\\t\\t#define SPOT_LIGHT_MAP_INDEX ( UNROLLED_LOOP_INDEX - NUM_SPOT_LIGHT_SHADOWS + NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS )\\n\\t\\t#endif\\n\\t\\t#if ( SPOT_LIGHT_MAP_INDEX < NUM_SPOT_LIGHT_MAPS )\\n\\t\\t\\tspotLightCoord = vSpotLightCoord[ i ].xyz / vSpotLightCoord[ i ].w;\\n\\t\\t\\tinSpotLightMap = all( lessThan( abs( spotLightCoord * 2. - 1. ), vec3( 1.0 ) ) );\\n\\t\\t\\tspotColor = texture2D( spotLightMap[ SPOT_LIGHT_MAP_INDEX ], spotLightCoord.xy );\\n\\t\\t\\tdirectLight.color = inSpotLightMap ? directLight.color * spotColor.rgb : directLight.color;\\n\\t\\t#endif\\n\\t\\t#undef SPOT_LIGHT_MAP_INDEX\\n\\t\\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\\n\\t\\tspotLightShadow = spotLightShadows[ i ];\\n\\t\\tdirectLight.color *= ( directLight.visible && receiveShadow ) ? getShadow( spotShadowMap[ i ], spotLightShadow.shadowMapSize, spotLightShadow.shadowIntensity, spotLightShadow.shadowBias, spotLightShadow.shadowRadius, vSpotLightCoord[ i ] ) : 1.0;\\n\\t\\t#endif\\n\\t\\tRE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if ( NUM_DIR_LIGHTS > 0 ) && defined( RE_Direct )\\n\\tDirectionalLight directionalLight;\\n\\t#if defined( USE_SHADOWMAP ) && NUM_DIR_LIGHT_SHADOWS > 0\\n\\tDirectionalLightShadow directionalLightShadow;\\n\\t#endif\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_DIR_LIGHTS; i ++ ) {\\n\\t\\tdirectionalLight = directionalLights[ i ];\\n\\t\\tgetDirectionalLightInfo( directionalLight, directLight );\\n\\t\\t#if defined( USE_SHADOWMAP ) && ( UNROLLED_LOOP_INDEX < NUM_DIR_LIGHT_SHADOWS )\\n\\t\\tdirectionalLightShadow = directionalLightShadows[ i ];\\n\\t\\tdirectLight.color *= ( directLight.visible && receiveShadow ) ? getShadow( directionalShadowMap[ i ], directionalLightShadow.shadowMapSize, directionalLightShadow.shadowIntensity, directionalLightShadow.shadowBias, directionalLightShadow.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\\n\\t\\t#endif\\n\\t\\tRE_Direct( directLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if ( NUM_RECT_AREA_LIGHTS > 0 ) && defined( RE_Direct_RectArea )\\n\\tRectAreaLight rectAreaLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_RECT_AREA_LIGHTS; i ++ ) {\\n\\t\\trectAreaLight = rectAreaLights[ i ];\\n\\t\\tRE_Direct_RectArea( rectAreaLight, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\\n#if defined( RE_IndirectDiffuse )\\n\\tvec3 iblIrradiance = vec3( 0.0 );\\n\\tvec3 irradiance = getAmbientLightIrradiance( ambientLightColor );\\n\\t#if defined( USE_LIGHT_PROBES )\\n\\t\\tirradiance += getLightProbeIrradiance( lightProbe, geometryNormal );\\n\\t#endif\\n\\t#if ( NUM_HEMI_LIGHTS > 0 )\\n\\t\\t#pragma unroll_loop_start\\n\\t\\tfor ( int i = 0; i < NUM_HEMI_LIGHTS; i ++ ) {\\n\\t\\t\\tirradiance += getHemisphereLightIrradiance( hemisphereLights[ i ], geometryNormal );\\n\\t\\t}\\n\\t\\t#pragma unroll_loop_end\\n\\t#endif\\n#endif\\n#if defined( RE_IndirectSpecular )\\n\\tvec3 radiance = vec3( 0.0 );\\n\\tvec3 clearcoatRadiance = vec3( 0.0 );\\n#endif\";\nvar lights_fragment_maps = \"#if defined( RE_IndirectDiffuse )\\n\\t#ifdef USE_LIGHTMAP\\n\\t\\tvec4 lightMapTexel = texture2D( lightMap, vLightMapUv );\\n\\t\\tvec3 lightMapIrradiance = lightMapTexel.rgb * lightMapIntensity;\\n\\t\\tirradiance += lightMapIrradiance;\\n\\t#endif\\n\\t#if defined( USE_ENVMAP ) && defined( STANDARD ) && defined( ENVMAP_TYPE_CUBE_UV )\\n\\t\\tiblIrradiance += getIBLIrradiance( geometryNormal );\\n\\t#endif\\n#endif\\n#if defined( USE_ENVMAP ) && defined( RE_IndirectSpecular )\\n\\t#ifdef USE_ANISOTROPY\\n\\t\\tradiance += getIBLAnisotropyRadiance( geometryViewDir, geometryNormal, material.roughness, material.anisotropyB, material.anisotropy );\\n\\t#else\\n\\t\\tradiance += getIBLRadiance( geometryViewDir, geometryNormal, material.roughness );\\n\\t#endif\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tclearcoatRadiance += getIBLRadiance( geometryViewDir, geometryClearcoatNormal, material.clearcoatRoughness );\\n\\t#endif\\n#endif\";\nvar lights_fragment_end = \"#if defined( RE_IndirectDiffuse )\\n\\tRE_IndirectDiffuse( irradiance, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\\n#endif\\n#if defined( RE_IndirectSpecular )\\n\\tRE_IndirectSpecular( radiance, iblIrradiance, clearcoatRadiance, geometryPosition, geometryNormal, geometryViewDir, geometryClearcoatNormal, material, reflectedLight );\\n#endif\";\nvar logdepthbuf_fragment = \"#if defined( USE_LOGDEPTHBUF )\\n\\tgl_FragDepth = vIsPerspective == 0.0 ? gl_FragCoord.z : log2( vFragDepth ) * logDepthBufFC * 0.5;\\n#endif\";\nvar logdepthbuf_pars_fragment = \"#if defined( USE_LOGDEPTHBUF )\\n\\tuniform float logDepthBufFC;\\n\\tvarying float vFragDepth;\\n\\tvarying float vIsPerspective;\\n#endif\";\nvar logdepthbuf_pars_vertex = \"#ifdef USE_LOGDEPTHBUF\\n\\tvarying float vFragDepth;\\n\\tvarying float vIsPerspective;\\n#endif\";\nvar logdepthbuf_vertex = \"#ifdef USE_LOGDEPTHBUF\\n\\tvFragDepth = 1.0 + gl_Position.w;\\n\\tvIsPerspective = float( isPerspectiveMatrix( projectionMatrix ) );\\n#endif\";\nvar map_fragment = \"#ifdef USE_MAP\\n\\tvec4 sampledDiffuseColor = texture2D( map, vMapUv );\\n\\t#ifdef DECODE_VIDEO_TEXTURE\\n\\t\\tsampledDiffuseColor = vec4( mix( pow( sampledDiffuseColor.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), sampledDiffuseColor.rgb * 0.0773993808, vec3( lessThanEqual( sampledDiffuseColor.rgb, vec3( 0.04045 ) ) ) ), sampledDiffuseColor.w );\\n\\t\\n\\t#endif\\n\\tdiffuseColor *= sampledDiffuseColor;\\n#endif\";\nvar map_pars_fragment = \"#ifdef USE_MAP\\n\\tuniform sampler2D map;\\n#endif\";\nvar map_particle_fragment = \"#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\\n\\t#if defined( USE_POINTS_UV )\\n\\t\\tvec2 uv = vUv;\\n\\t#else\\n\\t\\tvec2 uv = ( uvTransform * vec3( gl_PointCoord.x, 1.0 - gl_PointCoord.y, 1 ) ).xy;\\n\\t#endif\\n#endif\\n#ifdef USE_MAP\\n\\tdiffuseColor *= texture2D( map, uv );\\n#endif\\n#ifdef USE_ALPHAMAP\\n\\tdiffuseColor.a *= texture2D( alphaMap, uv ).g;\\n#endif\";\nvar map_particle_pars_fragment = \"#if defined( USE_POINTS_UV )\\n\\tvarying vec2 vUv;\\n#else\\n\\t#if defined( USE_MAP ) || defined( USE_ALPHAMAP )\\n\\t\\tuniform mat3 uvTransform;\\n\\t#endif\\n#endif\\n#ifdef USE_MAP\\n\\tuniform sampler2D map;\\n#endif\\n#ifdef USE_ALPHAMAP\\n\\tuniform sampler2D alphaMap;\\n#endif\";\nvar metalnessmap_fragment = \"float metalnessFactor = metalness;\\n#ifdef USE_METALNESSMAP\\n\\tvec4 texelMetalness = texture2D( metalnessMap, vMetalnessMapUv );\\n\\tmetalnessFactor *= texelMetalness.b;\\n#endif\";\nvar metalnessmap_pars_fragment = \"#ifdef USE_METALNESSMAP\\n\\tuniform sampler2D metalnessMap;\\n#endif\";\nvar morphinstance_vertex = \"#ifdef USE_INSTANCING_MORPH\\n\\tfloat morphTargetInfluences[ MORPHTARGETS_COUNT ];\\n\\tfloat morphTargetBaseInfluence = texelFetch( morphTexture, ivec2( 0, gl_InstanceID ), 0 ).r;\\n\\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\\n\\t\\tmorphTargetInfluences[i] =  texelFetch( morphTexture, ivec2( i + 1, gl_InstanceID ), 0 ).r;\\n\\t}\\n#endif\";\nvar morphcolor_vertex = \"#if defined( USE_MORPHCOLORS )\\n\\tvColor *= morphTargetBaseInfluence;\\n\\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\\n\\t\\t#if defined( USE_COLOR_ALPHA )\\n\\t\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ) * morphTargetInfluences[ i ];\\n\\t\\t#elif defined( USE_COLOR )\\n\\t\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) vColor += getMorph( gl_VertexID, i, 2 ).rgb * morphTargetInfluences[ i ];\\n\\t\\t#endif\\n\\t}\\n#endif\";\nvar morphnormal_vertex = \"#ifdef USE_MORPHNORMALS\\n\\tobjectNormal *= morphTargetBaseInfluence;\\n\\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\\n\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) objectNormal += getMorph( gl_VertexID, i, 1 ).xyz * morphTargetInfluences[ i ];\\n\\t}\\n#endif\";\nvar morphtarget_pars_vertex = \"#ifdef USE_MORPHTARGETS\\n\\t#ifndef USE_INSTANCING_MORPH\\n\\t\\tuniform float morphTargetBaseInfluence;\\n\\t\\tuniform float morphTargetInfluences[ MORPHTARGETS_COUNT ];\\n\\t#endif\\n\\tuniform sampler2DArray morphTargetsTexture;\\n\\tuniform ivec2 morphTargetsTextureSize;\\n\\tvec4 getMorph( const in int vertexIndex, const in int morphTargetIndex, const in int offset ) {\\n\\t\\tint texelIndex = vertexIndex * MORPHTARGETS_TEXTURE_STRIDE + offset;\\n\\t\\tint y = texelIndex / morphTargetsTextureSize.x;\\n\\t\\tint x = texelIndex - y * morphTargetsTextureSize.x;\\n\\t\\tivec3 morphUV = ivec3( x, y, morphTargetIndex );\\n\\t\\treturn texelFetch( morphTargetsTexture, morphUV, 0 );\\n\\t}\\n#endif\";\nvar morphtarget_vertex = \"#ifdef USE_MORPHTARGETS\\n\\ttransformed *= morphTargetBaseInfluence;\\n\\tfor ( int i = 0; i < MORPHTARGETS_COUNT; i ++ ) {\\n\\t\\tif ( morphTargetInfluences[ i ] != 0.0 ) transformed += getMorph( gl_VertexID, i, 0 ).xyz * morphTargetInfluences[ i ];\\n\\t}\\n#endif\";\nvar normal_fragment_begin = \"float faceDirection = gl_FrontFacing ? 1.0 : - 1.0;\\n#ifdef FLAT_SHADED\\n\\tvec3 fdx = dFdx( vViewPosition );\\n\\tvec3 fdy = dFdy( vViewPosition );\\n\\tvec3 normal = normalize( cross( fdx, fdy ) );\\n#else\\n\\tvec3 normal = normalize( vNormal );\\n\\t#ifdef DOUBLE_SIDED\\n\\t\\tnormal *= faceDirection;\\n\\t#endif\\n#endif\\n#if defined( USE_NORMALMAP_TANGENTSPACE ) || defined( USE_CLEARCOAT_NORMALMAP ) || defined( USE_ANISOTROPY )\\n\\t#ifdef USE_TANGENT\\n\\t\\tmat3 tbn = mat3( normalize( vTangent ), normalize( vBitangent ), normal );\\n\\t#else\\n\\t\\tmat3 tbn = getTangentFrame( - vViewPosition, normal,\\n\\t\\t#if defined( USE_NORMALMAP )\\n\\t\\t\\tvNormalMapUv\\n\\t\\t#elif defined( USE_CLEARCOAT_NORMALMAP )\\n\\t\\t\\tvClearcoatNormalMapUv\\n\\t\\t#else\\n\\t\\t\\tvUv\\n\\t\\t#endif\\n\\t\\t);\\n\\t#endif\\n\\t#if defined( DOUBLE_SIDED ) && ! defined( FLAT_SHADED )\\n\\t\\ttbn[0] *= faceDirection;\\n\\t\\ttbn[1] *= faceDirection;\\n\\t#endif\\n#endif\\n#ifdef USE_CLEARCOAT_NORMALMAP\\n\\t#ifdef USE_TANGENT\\n\\t\\tmat3 tbn2 = mat3( normalize( vTangent ), normalize( vBitangent ), normal );\\n\\t#else\\n\\t\\tmat3 tbn2 = getTangentFrame( - vViewPosition, normal, vClearcoatNormalMapUv );\\n\\t#endif\\n\\t#if defined( DOUBLE_SIDED ) && ! defined( FLAT_SHADED )\\n\\t\\ttbn2[0] *= faceDirection;\\n\\t\\ttbn2[1] *= faceDirection;\\n\\t#endif\\n#endif\\nvec3 nonPerturbedNormal = normal;\";\nvar normal_fragment_maps = \"#ifdef USE_NORMALMAP_OBJECTSPACE\\n\\tnormal = texture2D( normalMap, vNormalMapUv ).xyz * 2.0 - 1.0;\\n\\t#ifdef FLIP_SIDED\\n\\t\\tnormal = - normal;\\n\\t#endif\\n\\t#ifdef DOUBLE_SIDED\\n\\t\\tnormal = normal * faceDirection;\\n\\t#endif\\n\\tnormal = normalize( normalMatrix * normal );\\n#elif defined( USE_NORMALMAP_TANGENTSPACE )\\n\\tvec3 mapN = texture2D( normalMap, vNormalMapUv ).xyz * 2.0 - 1.0;\\n\\tmapN.xy *= normalScale;\\n\\tnormal = normalize( tbn * mapN );\\n#elif defined( USE_BUMPMAP )\\n\\tnormal = perturbNormalArb( - vViewPosition, normal, dHdxy_fwd(), faceDirection );\\n#endif\";\nvar normal_pars_fragment = \"#ifndef FLAT_SHADED\\n\\tvarying vec3 vNormal;\\n\\t#ifdef USE_TANGENT\\n\\t\\tvarying vec3 vTangent;\\n\\t\\tvarying vec3 vBitangent;\\n\\t#endif\\n#endif\";\nvar normal_pars_vertex = \"#ifndef FLAT_SHADED\\n\\tvarying vec3 vNormal;\\n\\t#ifdef USE_TANGENT\\n\\t\\tvarying vec3 vTangent;\\n\\t\\tvarying vec3 vBitangent;\\n\\t#endif\\n#endif\";\nvar normal_vertex = \"#ifndef FLAT_SHADED\\n\\tvNormal = normalize( transformedNormal );\\n\\t#ifdef USE_TANGENT\\n\\t\\tvTangent = normalize( transformedTangent );\\n\\t\\tvBitangent = normalize( cross( vNormal, vTangent ) * tangent.w );\\n\\t#endif\\n#endif\";\nvar normalmap_pars_fragment = \"#ifdef USE_NORMALMAP\\n\\tuniform sampler2D normalMap;\\n\\tuniform vec2 normalScale;\\n#endif\\n#ifdef USE_NORMALMAP_OBJECTSPACE\\n\\tuniform mat3 normalMatrix;\\n#endif\\n#if ! defined ( USE_TANGENT ) && ( defined ( USE_NORMALMAP_TANGENTSPACE ) || defined ( USE_CLEARCOAT_NORMALMAP ) || defined( USE_ANISOTROPY ) )\\n\\tmat3 getTangentFrame( vec3 eye_pos, vec3 surf_norm, vec2 uv ) {\\n\\t\\tvec3 q0 = dFdx( eye_pos.xyz );\\n\\t\\tvec3 q1 = dFdy( eye_pos.xyz );\\n\\t\\tvec2 st0 = dFdx( uv.st );\\n\\t\\tvec2 st1 = dFdy( uv.st );\\n\\t\\tvec3 N = surf_norm;\\n\\t\\tvec3 q1perp = cross( q1, N );\\n\\t\\tvec3 q0perp = cross( N, q0 );\\n\\t\\tvec3 T = q1perp * st0.x + q0perp * st1.x;\\n\\t\\tvec3 B = q1perp * st0.y + q0perp * st1.y;\\n\\t\\tfloat det = max( dot( T, T ), dot( B, B ) );\\n\\t\\tfloat scale = ( det == 0.0 ) ? 0.0 : inversesqrt( det );\\n\\t\\treturn mat3( T * scale, B * scale, N );\\n\\t}\\n#endif\";\nvar clearcoat_normal_fragment_begin = \"#ifdef USE_CLEARCOAT\\n\\tvec3 clearcoatNormal = nonPerturbedNormal;\\n#endif\";\nvar clearcoat_normal_fragment_maps = \"#ifdef USE_CLEARCOAT_NORMALMAP\\n\\tvec3 clearcoatMapN = texture2D( clearcoatNormalMap, vClearcoatNormalMapUv ).xyz * 2.0 - 1.0;\\n\\tclearcoatMapN.xy *= clearcoatNormalScale;\\n\\tclearcoatNormal = normalize( tbn2 * clearcoatMapN );\\n#endif\";\nvar clearcoat_pars_fragment = \"#ifdef USE_CLEARCOATMAP\\n\\tuniform sampler2D clearcoatMap;\\n#endif\\n#ifdef USE_CLEARCOAT_NORMALMAP\\n\\tuniform sampler2D clearcoatNormalMap;\\n\\tuniform vec2 clearcoatNormalScale;\\n#endif\\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\\n\\tuniform sampler2D clearcoatRoughnessMap;\\n#endif\";\nvar iridescence_pars_fragment = \"#ifdef USE_IRIDESCENCEMAP\\n\\tuniform sampler2D iridescenceMap;\\n#endif\\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\\n\\tuniform sampler2D iridescenceThicknessMap;\\n#endif\";\nvar opaque_fragment = \"#ifdef OPAQUE\\ndiffuseColor.a = 1.0;\\n#endif\\n#ifdef USE_TRANSMISSION\\ndiffuseColor.a *= material.transmissionAlpha;\\n#endif\\ngl_FragColor = vec4( outgoingLight, diffuseColor.a );\";\nvar packing = \"vec3 packNormalToRGB( const in vec3 normal ) {\\n\\treturn normalize( normal ) * 0.5 + 0.5;\\n}\\nvec3 unpackRGBToNormal( const in vec3 rgb ) {\\n\\treturn 2.0 * rgb.xyz - 1.0;\\n}\\nconst float PackUpscale = 256. / 255.;const float UnpackDownscale = 255. / 256.;const float ShiftRight8 = 1. / 256.;\\nconst float Inv255 = 1. / 255.;\\nconst vec4 PackFactors = vec4( 1.0, 256.0, 256.0 * 256.0, 256.0 * 256.0 * 256.0 );\\nconst vec2 UnpackFactors2 = vec2( UnpackDownscale, 1.0 / PackFactors.g );\\nconst vec3 UnpackFactors3 = vec3( UnpackDownscale / PackFactors.rg, 1.0 / PackFactors.b );\\nconst vec4 UnpackFactors4 = vec4( UnpackDownscale / PackFactors.rgb, 1.0 / PackFactors.a );\\nvec4 packDepthToRGBA( const in float v ) {\\n\\tif( v <= 0.0 )\\n\\t\\treturn vec4( 0., 0., 0., 0. );\\n\\tif( v >= 1.0 )\\n\\t\\treturn vec4( 1., 1., 1., 1. );\\n\\tfloat vuf;\\n\\tfloat af = modf( v * PackFactors.a, vuf );\\n\\tfloat bf = modf( vuf * ShiftRight8, vuf );\\n\\tfloat gf = modf( vuf * ShiftRight8, vuf );\\n\\treturn vec4( vuf * Inv255, gf * PackUpscale, bf * PackUpscale, af );\\n}\\nvec3 packDepthToRGB( const in float v ) {\\n\\tif( v <= 0.0 )\\n\\t\\treturn vec3( 0., 0., 0. );\\n\\tif( v >= 1.0 )\\n\\t\\treturn vec3( 1., 1., 1. );\\n\\tfloat vuf;\\n\\tfloat bf = modf( v * PackFactors.b, vuf );\\n\\tfloat gf = modf( vuf * ShiftRight8, vuf );\\n\\treturn vec3( vuf * Inv255, gf * PackUpscale, bf );\\n}\\nvec2 packDepthToRG( const in float v ) {\\n\\tif( v <= 0.0 )\\n\\t\\treturn vec2( 0., 0. );\\n\\tif( v >= 1.0 )\\n\\t\\treturn vec2( 1., 1. );\\n\\tfloat vuf;\\n\\tfloat gf = modf( v * 256., vuf );\\n\\treturn vec2( vuf * Inv255, gf );\\n}\\nfloat unpackRGBAToDepth( const in vec4 v ) {\\n\\treturn dot( v, UnpackFactors4 );\\n}\\nfloat unpackRGBToDepth( const in vec3 v ) {\\n\\treturn dot( v, UnpackFactors3 );\\n}\\nfloat unpackRGToDepth( const in vec2 v ) {\\n\\treturn v.r * UnpackFactors2.r + v.g * UnpackFactors2.g;\\n}\\nvec4 pack2HalfToRGBA( const in vec2 v ) {\\n\\tvec4 r = vec4( v.x, fract( v.x * 255.0 ), v.y, fract( v.y * 255.0 ) );\\n\\treturn vec4( r.x - r.y / 255.0, r.y, r.z - r.w / 255.0, r.w );\\n}\\nvec2 unpackRGBATo2Half( const in vec4 v ) {\\n\\treturn vec2( v.x + ( v.y / 255.0 ), v.z + ( v.w / 255.0 ) );\\n}\\nfloat viewZToOrthographicDepth( const in float viewZ, const in float near, const in float far ) {\\n\\treturn ( viewZ + near ) / ( near - far );\\n}\\nfloat orthographicDepthToViewZ( const in float depth, const in float near, const in float far ) {\\n\\treturn depth * ( near - far ) - near;\\n}\\nfloat viewZToPerspectiveDepth( const in float viewZ, const in float near, const in float far ) {\\n\\treturn ( ( near + viewZ ) * far ) / ( ( far - near ) * viewZ );\\n}\\nfloat perspectiveDepthToViewZ( const in float depth, const in float near, const in float far ) {\\n\\treturn ( near * far ) / ( ( far - near ) * depth - far );\\n}\";\nvar premultiplied_alpha_fragment = \"#ifdef PREMULTIPLIED_ALPHA\\n\\tgl_FragColor.rgb *= gl_FragColor.a;\\n#endif\";\nvar project_vertex = \"vec4 mvPosition = vec4( transformed, 1.0 );\\n#ifdef USE_BATCHING\\n\\tmvPosition = batchingMatrix * mvPosition;\\n#endif\\n#ifdef USE_INSTANCING\\n\\tmvPosition = instanceMatrix * mvPosition;\\n#endif\\nmvPosition = modelViewMatrix * mvPosition;\\ngl_Position = projectionMatrix * mvPosition;\";\nvar dithering_fragment = \"#ifdef DITHERING\\n\\tgl_FragColor.rgb = dithering( gl_FragColor.rgb );\\n#endif\";\nvar dithering_pars_fragment = \"#ifdef DITHERING\\n\\tvec3 dithering( vec3 color ) {\\n\\t\\tfloat grid_position = rand( gl_FragCoord.xy );\\n\\t\\tvec3 dither_shift_RGB = vec3( 0.25 / 255.0, -0.25 / 255.0, 0.25 / 255.0 );\\n\\t\\tdither_shift_RGB = mix( 2.0 * dither_shift_RGB, -2.0 * dither_shift_RGB, grid_position );\\n\\t\\treturn color + dither_shift_RGB;\\n\\t}\\n#endif\";\nvar roughnessmap_fragment = \"float roughnessFactor = roughness;\\n#ifdef USE_ROUGHNESSMAP\\n\\tvec4 texelRoughness = texture2D( roughnessMap, vRoughnessMapUv );\\n\\troughnessFactor *= texelRoughness.g;\\n#endif\";\nvar roughnessmap_pars_fragment = \"#ifdef USE_ROUGHNESSMAP\\n\\tuniform sampler2D roughnessMap;\\n#endif\";\nvar shadowmap_pars_fragment = \"#if NUM_SPOT_LIGHT_COORDS > 0\\n\\tvarying vec4 vSpotLightCoord[ NUM_SPOT_LIGHT_COORDS ];\\n#endif\\n#if NUM_SPOT_LIGHT_MAPS > 0\\n\\tuniform sampler2D spotLightMap[ NUM_SPOT_LIGHT_MAPS ];\\n#endif\\n#ifdef USE_SHADOWMAP\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\t\\tuniform sampler2D directionalShadowMap[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tstruct DirectionalLightShadow {\\n\\t\\t\\tfloat shadowIntensity;\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_SPOT_LIGHT_SHADOWS > 0\\n\\t\\tuniform sampler2D spotShadowMap[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t\\tstruct SpotLightShadow {\\n\\t\\t\\tfloat shadowIntensity;\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\t\\tuniform sampler2D pointShadowMap[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tstruct PointLightShadow {\\n\\t\\t\\tfloat shadowIntensity;\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t\\tfloat shadowCameraNear;\\n\\t\\t\\tfloat shadowCameraFar;\\n\\t\\t};\\n\\t\\tuniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t#endif\\n\\tfloat texture2DCompare( sampler2D depths, vec2 uv, float compare ) {\\n\\t\\treturn step( compare, unpackRGBAToDepth( texture2D( depths, uv ) ) );\\n\\t}\\n\\tvec2 texture2DDistribution( sampler2D shadow, vec2 uv ) {\\n\\t\\treturn unpackRGBATo2Half( texture2D( shadow, uv ) );\\n\\t}\\n\\tfloat VSMShadow (sampler2D shadow, vec2 uv, float compare ){\\n\\t\\tfloat occlusion = 1.0;\\n\\t\\tvec2 distribution = texture2DDistribution( shadow, uv );\\n\\t\\tfloat hard_shadow = step( compare , distribution.x );\\n\\t\\tif (hard_shadow != 1.0 ) {\\n\\t\\t\\tfloat distance = compare - distribution.x ;\\n\\t\\t\\tfloat variance = max( 0.00000, distribution.y * distribution.y );\\n\\t\\t\\tfloat softness_probability = variance / (variance + distance * distance );\\t\\t\\tsoftness_probability = clamp( ( softness_probability - 0.3 ) / ( 0.95 - 0.3 ), 0.0, 1.0 );\\t\\t\\tocclusion = clamp( max( hard_shadow, softness_probability ), 0.0, 1.0 );\\n\\t\\t}\\n\\t\\treturn occlusion;\\n\\t}\\n\\tfloat getShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowIntensity, float shadowBias, float shadowRadius, vec4 shadowCoord ) {\\n\\t\\tfloat shadow = 1.0;\\n\\t\\tshadowCoord.xyz /= shadowCoord.w;\\n\\t\\tshadowCoord.z += shadowBias;\\n\\t\\tbool inFrustum = shadowCoord.x >= 0.0 && shadowCoord.x <= 1.0 && shadowCoord.y >= 0.0 && shadowCoord.y <= 1.0;\\n\\t\\tbool frustumTest = inFrustum && shadowCoord.z <= 1.0;\\n\\t\\tif ( frustumTest ) {\\n\\t\\t#if defined( SHADOWMAP_TYPE_PCF )\\n\\t\\t\\tvec2 texelSize = vec2( 1.0 ) / shadowMapSize;\\n\\t\\t\\tfloat dx0 = - texelSize.x * shadowRadius;\\n\\t\\t\\tfloat dy0 = - texelSize.y * shadowRadius;\\n\\t\\t\\tfloat dx1 = + texelSize.x * shadowRadius;\\n\\t\\t\\tfloat dy1 = + texelSize.y * shadowRadius;\\n\\t\\t\\tfloat dx2 = dx0 / 2.0;\\n\\t\\t\\tfloat dy2 = dy0 / 2.0;\\n\\t\\t\\tfloat dx3 = dx1 / 2.0;\\n\\t\\t\\tfloat dy3 = dy1 / 2.0;\\n\\t\\t\\tshadow = (\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy2 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy2 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy2 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx2, dy3 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy3 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx3, dy3 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx0, dy1 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( 0.0, dy1 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, shadowCoord.xy + vec2( dx1, dy1 ), shadowCoord.z )\\n\\t\\t\\t) * ( 1.0 / 17.0 );\\n\\t\\t#elif defined( SHADOWMAP_TYPE_PCF_SOFT )\\n\\t\\t\\tvec2 texelSize = vec2( 1.0 ) / shadowMapSize;\\n\\t\\t\\tfloat dx = texelSize.x;\\n\\t\\t\\tfloat dy = texelSize.y;\\n\\t\\t\\tvec2 uv = shadowCoord.xy;\\n\\t\\t\\tvec2 f = fract( uv * shadowMapSize + 0.5 );\\n\\t\\t\\tuv -= f * texelSize;\\n\\t\\t\\tshadow = (\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv, shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv + vec2( dx, 0.0 ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv + vec2( 0.0, dy ), shadowCoord.z ) +\\n\\t\\t\\t\\ttexture2DCompare( shadowMap, uv + texelSize, shadowCoord.z ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( -dx, 0.0 ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 0.0 ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.x ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( -dx, dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.x ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( 0.0, -dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( 0.0, 2.0 * dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.y ) +\\n\\t\\t\\t\\tmix( texture2DCompare( shadowMap, uv + vec2( dx, -dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t texture2DCompare( shadowMap, uv + vec2( dx, 2.0 * dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t f.y ) +\\n\\t\\t\\t\\tmix( mix( texture2DCompare( shadowMap, uv + vec2( -dx, -dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t\\t  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, -dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t\\t  f.x ),\\n\\t\\t\\t\\t\\t mix( texture2DCompare( shadowMap, uv + vec2( -dx, 2.0 * dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t\\t  texture2DCompare( shadowMap, uv + vec2( 2.0 * dx, 2.0 * dy ), shadowCoord.z ),\\n\\t\\t\\t\\t\\t\\t  f.x ),\\n\\t\\t\\t\\t\\t f.y )\\n\\t\\t\\t) * ( 1.0 / 9.0 );\\n\\t\\t#elif defined( SHADOWMAP_TYPE_VSM )\\n\\t\\t\\tshadow = VSMShadow( shadowMap, shadowCoord.xy, shadowCoord.z );\\n\\t\\t#else\\n\\t\\t\\tshadow = texture2DCompare( shadowMap, shadowCoord.xy, shadowCoord.z );\\n\\t\\t#endif\\n\\t\\t}\\n\\t\\treturn mix( 1.0, shadow, shadowIntensity );\\n\\t}\\n\\tvec2 cubeToUV( vec3 v, float texelSizeY ) {\\n\\t\\tvec3 absV = abs( v );\\n\\t\\tfloat scaleToCube = 1.0 / max( absV.x, max( absV.y, absV.z ) );\\n\\t\\tabsV *= scaleToCube;\\n\\t\\tv *= scaleToCube * ( 1.0 - 2.0 * texelSizeY );\\n\\t\\tvec2 planar = v.xy;\\n\\t\\tfloat almostATexel = 1.5 * texelSizeY;\\n\\t\\tfloat almostOne = 1.0 - almostATexel;\\n\\t\\tif ( absV.z >= almostOne ) {\\n\\t\\t\\tif ( v.z > 0.0 )\\n\\t\\t\\t\\tplanar.x = 4.0 - v.x;\\n\\t\\t} else if ( absV.x >= almostOne ) {\\n\\t\\t\\tfloat signX = sign( v.x );\\n\\t\\t\\tplanar.x = v.z * signX + 2.0 * signX;\\n\\t\\t} else if ( absV.y >= almostOne ) {\\n\\t\\t\\tfloat signY = sign( v.y );\\n\\t\\t\\tplanar.x = v.x + 2.0 * signY + 2.0;\\n\\t\\t\\tplanar.y = v.z * signY - 2.0;\\n\\t\\t}\\n\\t\\treturn vec2( 0.125, 0.25 ) * planar + vec2( 0.375, 0.75 );\\n\\t}\\n\\tfloat getPointShadow( sampler2D shadowMap, vec2 shadowMapSize, float shadowIntensity, float shadowBias, float shadowRadius, vec4 shadowCoord, float shadowCameraNear, float shadowCameraFar ) {\\n\\t\\tfloat shadow = 1.0;\\n\\t\\tvec3 lightToPosition = shadowCoord.xyz;\\n\\t\\t\\n\\t\\tfloat lightToPositionLength = length( lightToPosition );\\n\\t\\tif ( lightToPositionLength - shadowCameraFar <= 0.0 && lightToPositionLength - shadowCameraNear >= 0.0 ) {\\n\\t\\t\\tfloat dp = ( lightToPositionLength - shadowCameraNear ) / ( shadowCameraFar - shadowCameraNear );\\t\\t\\tdp += shadowBias;\\n\\t\\t\\tvec3 bd3D = normalize( lightToPosition );\\n\\t\\t\\tvec2 texelSize = vec2( 1.0 ) / ( shadowMapSize * vec2( 4.0, 2.0 ) );\\n\\t\\t\\t#if defined( SHADOWMAP_TYPE_PCF ) || defined( SHADOWMAP_TYPE_PCF_SOFT ) || defined( SHADOWMAP_TYPE_VSM )\\n\\t\\t\\t\\tvec2 offset = vec2( - 1, 1 ) * shadowRadius * texelSize.y;\\n\\t\\t\\t\\tshadow = (\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyy, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyy, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xyx, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yyx, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxy, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxy, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.xxx, texelSize.y ), dp ) +\\n\\t\\t\\t\\t\\ttexture2DCompare( shadowMap, cubeToUV( bd3D + offset.yxx, texelSize.y ), dp )\\n\\t\\t\\t\\t) * ( 1.0 / 9.0 );\\n\\t\\t\\t#else\\n\\t\\t\\t\\tshadow = texture2DCompare( shadowMap, cubeToUV( bd3D, texelSize.y ), dp );\\n\\t\\t\\t#endif\\n\\t\\t}\\n\\t\\treturn mix( 1.0, shadow, shadowIntensity );\\n\\t}\\n#endif\";\nvar shadowmap_pars_vertex = \"#if NUM_SPOT_LIGHT_COORDS > 0\\n\\tuniform mat4 spotLightMatrix[ NUM_SPOT_LIGHT_COORDS ];\\n\\tvarying vec4 vSpotLightCoord[ NUM_SPOT_LIGHT_COORDS ];\\n#endif\\n#ifdef USE_SHADOWMAP\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\t\\tuniform mat4 directionalShadowMatrix[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vDirectionalShadowCoord[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t\\tstruct DirectionalLightShadow {\\n\\t\\t\\tfloat shadowIntensity;\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform DirectionalLightShadow directionalLightShadows[ NUM_DIR_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_SPOT_LIGHT_SHADOWS > 0\\n\\t\\tstruct SpotLightShadow {\\n\\t\\t\\tfloat shadowIntensity;\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t};\\n\\t\\tuniform SpotLightShadow spotLightShadows[ NUM_SPOT_LIGHT_SHADOWS ];\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\t\\tuniform mat4 pointShadowMatrix[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tvarying vec4 vPointShadowCoord[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t\\tstruct PointLightShadow {\\n\\t\\t\\tfloat shadowIntensity;\\n\\t\\t\\tfloat shadowBias;\\n\\t\\t\\tfloat shadowNormalBias;\\n\\t\\t\\tfloat shadowRadius;\\n\\t\\t\\tvec2 shadowMapSize;\\n\\t\\t\\tfloat shadowCameraNear;\\n\\t\\t\\tfloat shadowCameraFar;\\n\\t\\t};\\n\\t\\tuniform PointLightShadow pointLightShadows[ NUM_POINT_LIGHT_SHADOWS ];\\n\\t#endif\\n#endif\";\nvar shadowmap_vertex = \"#if ( defined( USE_SHADOWMAP ) && ( NUM_DIR_LIGHT_SHADOWS > 0 || NUM_POINT_LIGHT_SHADOWS > 0 ) ) || ( NUM_SPOT_LIGHT_COORDS > 0 )\\n\\tvec3 shadowWorldNormal = inverseTransformDirection( transformedNormal, viewMatrix );\\n\\tvec4 shadowWorldPosition;\\n#endif\\n#if defined( USE_SHADOWMAP )\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\t\\t#pragma unroll_loop_start\\n\\t\\tfor ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\\n\\t\\t\\tshadowWorldPosition = worldPosition + vec4( shadowWorldNormal * directionalLightShadows[ i ].shadowNormalBias, 0 );\\n\\t\\t\\tvDirectionalShadowCoord[ i ] = directionalShadowMatrix[ i ] * shadowWorldPosition;\\n\\t\\t}\\n\\t\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\t\\t#pragma unroll_loop_start\\n\\t\\tfor ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\\n\\t\\t\\tshadowWorldPosition = worldPosition + vec4( shadowWorldNormal * pointLightShadows[ i ].shadowNormalBias, 0 );\\n\\t\\t\\tvPointShadowCoord[ i ] = pointShadowMatrix[ i ] * shadowWorldPosition;\\n\\t\\t}\\n\\t\\t#pragma unroll_loop_end\\n\\t#endif\\n#endif\\n#if NUM_SPOT_LIGHT_COORDS > 0\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_SPOT_LIGHT_COORDS; i ++ ) {\\n\\t\\tshadowWorldPosition = worldPosition;\\n\\t\\t#if ( defined( USE_SHADOWMAP ) && UNROLLED_LOOP_INDEX < NUM_SPOT_LIGHT_SHADOWS )\\n\\t\\t\\tshadowWorldPosition.xyz += shadowWorldNormal * spotLightShadows[ i ].shadowNormalBias;\\n\\t\\t#endif\\n\\t\\tvSpotLightCoord[ i ] = spotLightMatrix[ i ] * shadowWorldPosition;\\n\\t}\\n\\t#pragma unroll_loop_end\\n#endif\";\nvar shadowmask_pars_fragment = \"float getShadowMask() {\\n\\tfloat shadow = 1.0;\\n\\t#ifdef USE_SHADOWMAP\\n\\t#if NUM_DIR_LIGHT_SHADOWS > 0\\n\\tDirectionalLightShadow directionalLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_DIR_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tdirectionalLight = directionalLightShadows[ i ];\\n\\t\\tshadow *= receiveShadow ? getShadow( directionalShadowMap[ i ], directionalLight.shadowMapSize, directionalLight.shadowIntensity, directionalLight.shadowBias, directionalLight.shadowRadius, vDirectionalShadowCoord[ i ] ) : 1.0;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#if NUM_SPOT_LIGHT_SHADOWS > 0\\n\\tSpotLightShadow spotLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_SPOT_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tspotLight = spotLightShadows[ i ];\\n\\t\\tshadow *= receiveShadow ? getShadow( spotShadowMap[ i ], spotLight.shadowMapSize, spotLight.shadowIntensity, spotLight.shadowBias, spotLight.shadowRadius, vSpotLightCoord[ i ] ) : 1.0;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#if NUM_POINT_LIGHT_SHADOWS > 0\\n\\tPointLightShadow pointLight;\\n\\t#pragma unroll_loop_start\\n\\tfor ( int i = 0; i < NUM_POINT_LIGHT_SHADOWS; i ++ ) {\\n\\t\\tpointLight = pointLightShadows[ i ];\\n\\t\\tshadow *= receiveShadow ? getPointShadow( pointShadowMap[ i ], pointLight.shadowMapSize, pointLight.shadowIntensity, pointLight.shadowBias, pointLight.shadowRadius, vPointShadowCoord[ i ], pointLight.shadowCameraNear, pointLight.shadowCameraFar ) : 1.0;\\n\\t}\\n\\t#pragma unroll_loop_end\\n\\t#endif\\n\\t#endif\\n\\treturn shadow;\\n}\";\nvar skinbase_vertex = \"#ifdef USE_SKINNING\\n\\tmat4 boneMatX = getBoneMatrix( skinIndex.x );\\n\\tmat4 boneMatY = getBoneMatrix( skinIndex.y );\\n\\tmat4 boneMatZ = getBoneMatrix( skinIndex.z );\\n\\tmat4 boneMatW = getBoneMatrix( skinIndex.w );\\n#endif\";\nvar skinning_pars_vertex = \"#ifdef USE_SKINNING\\n\\tuniform mat4 bindMatrix;\\n\\tuniform mat4 bindMatrixInverse;\\n\\tuniform highp sampler2D boneTexture;\\n\\tmat4 getBoneMatrix( const in float i ) {\\n\\t\\tint size = textureSize( boneTexture, 0 ).x;\\n\\t\\tint j = int( i ) * 4;\\n\\t\\tint x = j % size;\\n\\t\\tint y = j / size;\\n\\t\\tvec4 v1 = texelFetch( boneTexture, ivec2( x, y ), 0 );\\n\\t\\tvec4 v2 = texelFetch( boneTexture, ivec2( x + 1, y ), 0 );\\n\\t\\tvec4 v3 = texelFetch( boneTexture, ivec2( x + 2, y ), 0 );\\n\\t\\tvec4 v4 = texelFetch( boneTexture, ivec2( x + 3, y ), 0 );\\n\\t\\treturn mat4( v1, v2, v3, v4 );\\n\\t}\\n#endif\";\nvar skinning_vertex = \"#ifdef USE_SKINNING\\n\\tvec4 skinVertex = bindMatrix * vec4( transformed, 1.0 );\\n\\tvec4 skinned = vec4( 0.0 );\\n\\tskinned += boneMatX * skinVertex * skinWeight.x;\\n\\tskinned += boneMatY * skinVertex * skinWeight.y;\\n\\tskinned += boneMatZ * skinVertex * skinWeight.z;\\n\\tskinned += boneMatW * skinVertex * skinWeight.w;\\n\\ttransformed = ( bindMatrixInverse * skinned ).xyz;\\n#endif\";\nvar skinnormal_vertex = \"#ifdef USE_SKINNING\\n\\tmat4 skinMatrix = mat4( 0.0 );\\n\\tskinMatrix += skinWeight.x * boneMatX;\\n\\tskinMatrix += skinWeight.y * boneMatY;\\n\\tskinMatrix += skinWeight.z * boneMatZ;\\n\\tskinMatrix += skinWeight.w * boneMatW;\\n\\tskinMatrix = bindMatrixInverse * skinMatrix * bindMatrix;\\n\\tobjectNormal = vec4( skinMatrix * vec4( objectNormal, 0.0 ) ).xyz;\\n\\t#ifdef USE_TANGENT\\n\\t\\tobjectTangent = vec4( skinMatrix * vec4( objectTangent, 0.0 ) ).xyz;\\n\\t#endif\\n#endif\";\nvar specularmap_fragment = \"float specularStrength;\\n#ifdef USE_SPECULARMAP\\n\\tvec4 texelSpecular = texture2D( specularMap, vSpecularMapUv );\\n\\tspecularStrength = texelSpecular.r;\\n#else\\n\\tspecularStrength = 1.0;\\n#endif\";\nvar specularmap_pars_fragment = \"#ifdef USE_SPECULARMAP\\n\\tuniform sampler2D specularMap;\\n#endif\";\nvar tonemapping_fragment = \"#if defined( TONE_MAPPING )\\n\\tgl_FragColor.rgb = toneMapping( gl_FragColor.rgb );\\n#endif\";\nvar tonemapping_pars_fragment = \"#ifndef saturate\\n#define saturate( a ) clamp( a, 0.0, 1.0 )\\n#endif\\nuniform float toneMappingExposure;\\nvec3 LinearToneMapping( vec3 color ) {\\n\\treturn saturate( toneMappingExposure * color );\\n}\\nvec3 ReinhardToneMapping( vec3 color ) {\\n\\tcolor *= toneMappingExposure;\\n\\treturn saturate( color / ( vec3( 1.0 ) + color ) );\\n}\\nvec3 CineonToneMapping( vec3 color ) {\\n\\tcolor *= toneMappingExposure;\\n\\tcolor = max( vec3( 0.0 ), color - 0.004 );\\n\\treturn pow( ( color * ( 6.2 * color + 0.5 ) ) / ( color * ( 6.2 * color + 1.7 ) + 0.06 ), vec3( 2.2 ) );\\n}\\nvec3 RRTAndODTFit( vec3 v ) {\\n\\tvec3 a = v * ( v + 0.0245786 ) - 0.000090537;\\n\\tvec3 b = v * ( 0.983729 * v + 0.4329510 ) + 0.238081;\\n\\treturn a / b;\\n}\\nvec3 ACESFilmicToneMapping( vec3 color ) {\\n\\tconst mat3 ACESInputMat = mat3(\\n\\t\\tvec3( 0.59719, 0.07600, 0.02840 ),\\t\\tvec3( 0.35458, 0.90834, 0.13383 ),\\n\\t\\tvec3( 0.04823, 0.01566, 0.83777 )\\n\\t);\\n\\tconst mat3 ACESOutputMat = mat3(\\n\\t\\tvec3(  1.60475, -0.10208, -0.00327 ),\\t\\tvec3( -0.53108,  1.10813, -0.07276 ),\\n\\t\\tvec3( -0.07367, -0.00605,  1.07602 )\\n\\t);\\n\\tcolor *= toneMappingExposure / 0.6;\\n\\tcolor = ACESInputMat * color;\\n\\tcolor = RRTAndODTFit( color );\\n\\tcolor = ACESOutputMat * color;\\n\\treturn saturate( color );\\n}\\nconst mat3 LINEAR_REC2020_TO_LINEAR_SRGB = mat3(\\n\\tvec3( 1.6605, - 0.1246, - 0.0182 ),\\n\\tvec3( - 0.5876, 1.1329, - 0.1006 ),\\n\\tvec3( - 0.0728, - 0.0083, 1.1187 )\\n);\\nconst mat3 LINEAR_SRGB_TO_LINEAR_REC2020 = mat3(\\n\\tvec3( 0.6274, 0.0691, 0.0164 ),\\n\\tvec3( 0.3293, 0.9195, 0.0880 ),\\n\\tvec3( 0.0433, 0.0113, 0.8956 )\\n);\\nvec3 agxDefaultContrastApprox( vec3 x ) {\\n\\tvec3 x2 = x * x;\\n\\tvec3 x4 = x2 * x2;\\n\\treturn + 15.5 * x4 * x2\\n\\t\\t- 40.14 * x4 * x\\n\\t\\t+ 31.96 * x4\\n\\t\\t- 6.868 * x2 * x\\n\\t\\t+ 0.4298 * x2\\n\\t\\t+ 0.1191 * x\\n\\t\\t- 0.00232;\\n}\\nvec3 AgXToneMapping( vec3 color ) {\\n\\tconst mat3 AgXInsetMatrix = mat3(\\n\\t\\tvec3( 0.856627153315983, 0.137318972929847, 0.11189821299995 ),\\n\\t\\tvec3( 0.0951212405381588, 0.761241990602591, 0.0767994186031903 ),\\n\\t\\tvec3( 0.0482516061458583, 0.101439036467562, 0.811302368396859 )\\n\\t);\\n\\tconst mat3 AgXOutsetMatrix = mat3(\\n\\t\\tvec3( 1.1271005818144368, - 0.1413297634984383, - 0.14132976349843826 ),\\n\\t\\tvec3( - 0.11060664309660323, 1.157823702216272, - 0.11060664309660294 ),\\n\\t\\tvec3( - 0.016493938717834573, - 0.016493938717834257, 1.2519364065950405 )\\n\\t);\\n\\tconst float AgxMinEv = - 12.47393;\\tconst float AgxMaxEv = 4.026069;\\n\\tcolor *= toneMappingExposure;\\n\\tcolor = LINEAR_SRGB_TO_LINEAR_REC2020 * color;\\n\\tcolor = AgXInsetMatrix * color;\\n\\tcolor = max( color, 1e-10 );\\tcolor = log2( color );\\n\\tcolor = ( color - AgxMinEv ) / ( AgxMaxEv - AgxMinEv );\\n\\tcolor = clamp( color, 0.0, 1.0 );\\n\\tcolor = agxDefaultContrastApprox( color );\\n\\tcolor = AgXOutsetMatrix * color;\\n\\tcolor = pow( max( vec3( 0.0 ), color ), vec3( 2.2 ) );\\n\\tcolor = LINEAR_REC2020_TO_LINEAR_SRGB * color;\\n\\tcolor = clamp( color, 0.0, 1.0 );\\n\\treturn color;\\n}\\nvec3 NeutralToneMapping( vec3 color ) {\\n\\tconst float StartCompression = 0.8 - 0.04;\\n\\tconst float Desaturation = 0.15;\\n\\tcolor *= toneMappingExposure;\\n\\tfloat x = min( color.r, min( color.g, color.b ) );\\n\\tfloat offset = x < 0.08 ? x - 6.25 * x * x : 0.04;\\n\\tcolor -= offset;\\n\\tfloat peak = max( color.r, max( color.g, color.b ) );\\n\\tif ( peak < StartCompression ) return color;\\n\\tfloat d = 1. - StartCompression;\\n\\tfloat newPeak = 1. - d * d / ( peak + d - StartCompression );\\n\\tcolor *= newPeak / peak;\\n\\tfloat g = 1. - 1. / ( Desaturation * ( peak - newPeak ) + 1. );\\n\\treturn mix( color, vec3( newPeak ), g );\\n}\\nvec3 CustomToneMapping( vec3 color ) { return color; }\";\nvar transmission_fragment = \"#ifdef USE_TRANSMISSION\\n\\tmaterial.transmission = transmission;\\n\\tmaterial.transmissionAlpha = 1.0;\\n\\tmaterial.thickness = thickness;\\n\\tmaterial.attenuationDistance = attenuationDistance;\\n\\tmaterial.attenuationColor = attenuationColor;\\n\\t#ifdef USE_TRANSMISSIONMAP\\n\\t\\tmaterial.transmission *= texture2D( transmissionMap, vTransmissionMapUv ).r;\\n\\t#endif\\n\\t#ifdef USE_THICKNESSMAP\\n\\t\\tmaterial.thickness *= texture2D( thicknessMap, vThicknessMapUv ).g;\\n\\t#endif\\n\\tvec3 pos = vWorldPosition;\\n\\tvec3 v = normalize( cameraPosition - pos );\\n\\tvec3 n = inverseTransformDirection( normal, viewMatrix );\\n\\tvec4 transmitted = getIBLVolumeRefraction(\\n\\t\\tn, v, material.roughness, material.diffuseColor, material.specularColor, material.specularF90,\\n\\t\\tpos, modelMatrix, viewMatrix, projectionMatrix, material.dispersion, material.ior, material.thickness,\\n\\t\\tmaterial.attenuationColor, material.attenuationDistance );\\n\\tmaterial.transmissionAlpha = mix( material.transmissionAlpha, transmitted.a, material.transmission );\\n\\ttotalDiffuse = mix( totalDiffuse, transmitted.rgb, material.transmission );\\n#endif\";\nvar transmission_pars_fragment = \"#ifdef USE_TRANSMISSION\\n\\tuniform float transmission;\\n\\tuniform float thickness;\\n\\tuniform float attenuationDistance;\\n\\tuniform vec3 attenuationColor;\\n\\t#ifdef USE_TRANSMISSIONMAP\\n\\t\\tuniform sampler2D transmissionMap;\\n\\t#endif\\n\\t#ifdef USE_THICKNESSMAP\\n\\t\\tuniform sampler2D thicknessMap;\\n\\t#endif\\n\\tuniform vec2 transmissionSamplerSize;\\n\\tuniform sampler2D transmissionSamplerMap;\\n\\tuniform mat4 modelMatrix;\\n\\tuniform mat4 projectionMatrix;\\n\\tvarying vec3 vWorldPosition;\\n\\tfloat w0( float a ) {\\n\\t\\treturn ( 1.0 / 6.0 ) * ( a * ( a * ( - a + 3.0 ) - 3.0 ) + 1.0 );\\n\\t}\\n\\tfloat w1( float a ) {\\n\\t\\treturn ( 1.0 / 6.0 ) * ( a *  a * ( 3.0 * a - 6.0 ) + 4.0 );\\n\\t}\\n\\tfloat w2( float a ){\\n\\t\\treturn ( 1.0 / 6.0 ) * ( a * ( a * ( - 3.0 * a + 3.0 ) + 3.0 ) + 1.0 );\\n\\t}\\n\\tfloat w3( float a ) {\\n\\t\\treturn ( 1.0 / 6.0 ) * ( a * a * a );\\n\\t}\\n\\tfloat g0( float a ) {\\n\\t\\treturn w0( a ) + w1( a );\\n\\t}\\n\\tfloat g1( float a ) {\\n\\t\\treturn w2( a ) + w3( a );\\n\\t}\\n\\tfloat h0( float a ) {\\n\\t\\treturn - 1.0 + w1( a ) / ( w0( a ) + w1( a ) );\\n\\t}\\n\\tfloat h1( float a ) {\\n\\t\\treturn 1.0 + w3( a ) / ( w2( a ) + w3( a ) );\\n\\t}\\n\\tvec4 bicubic( sampler2D tex, vec2 uv, vec4 texelSize, float lod ) {\\n\\t\\tuv = uv * texelSize.zw + 0.5;\\n\\t\\tvec2 iuv = floor( uv );\\n\\t\\tvec2 fuv = fract( uv );\\n\\t\\tfloat g0x = g0( fuv.x );\\n\\t\\tfloat g1x = g1( fuv.x );\\n\\t\\tfloat h0x = h0( fuv.x );\\n\\t\\tfloat h1x = h1( fuv.x );\\n\\t\\tfloat h0y = h0( fuv.y );\\n\\t\\tfloat h1y = h1( fuv.y );\\n\\t\\tvec2 p0 = ( vec2( iuv.x + h0x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\\n\\t\\tvec2 p1 = ( vec2( iuv.x + h1x, iuv.y + h0y ) - 0.5 ) * texelSize.xy;\\n\\t\\tvec2 p2 = ( vec2( iuv.x + h0x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\\n\\t\\tvec2 p3 = ( vec2( iuv.x + h1x, iuv.y + h1y ) - 0.5 ) * texelSize.xy;\\n\\t\\treturn g0( fuv.y ) * ( g0x * textureLod( tex, p0, lod ) + g1x * textureLod( tex, p1, lod ) ) +\\n\\t\\t\\tg1( fuv.y ) * ( g0x * textureLod( tex, p2, lod ) + g1x * textureLod( tex, p3, lod ) );\\n\\t}\\n\\tvec4 textureBicubic( sampler2D sampler, vec2 uv, float lod ) {\\n\\t\\tvec2 fLodSize = vec2( textureSize( sampler, int( lod ) ) );\\n\\t\\tvec2 cLodSize = vec2( textureSize( sampler, int( lod + 1.0 ) ) );\\n\\t\\tvec2 fLodSizeInv = 1.0 / fLodSize;\\n\\t\\tvec2 cLodSizeInv = 1.0 / cLodSize;\\n\\t\\tvec4 fSample = bicubic( sampler, uv, vec4( fLodSizeInv, fLodSize ), floor( lod ) );\\n\\t\\tvec4 cSample = bicubic( sampler, uv, vec4( cLodSizeInv, cLodSize ), ceil( lod ) );\\n\\t\\treturn mix( fSample, cSample, fract( lod ) );\\n\\t}\\n\\tvec3 getVolumeTransmissionRay( const in vec3 n, const in vec3 v, const in float thickness, const in float ior, const in mat4 modelMatrix ) {\\n\\t\\tvec3 refractionVector = refract( - v, normalize( n ), 1.0 / ior );\\n\\t\\tvec3 modelScale;\\n\\t\\tmodelScale.x = length( vec3( modelMatrix[ 0 ].xyz ) );\\n\\t\\tmodelScale.y = length( vec3( modelMatrix[ 1 ].xyz ) );\\n\\t\\tmodelScale.z = length( vec3( modelMatrix[ 2 ].xyz ) );\\n\\t\\treturn normalize( refractionVector ) * thickness * modelScale;\\n\\t}\\n\\tfloat applyIorToRoughness( const in float roughness, const in float ior ) {\\n\\t\\treturn roughness * clamp( ior * 2.0 - 2.0, 0.0, 1.0 );\\n\\t}\\n\\tvec4 getTransmissionSample( const in vec2 fragCoord, const in float roughness, const in float ior ) {\\n\\t\\tfloat lod = log2( transmissionSamplerSize.x ) * applyIorToRoughness( roughness, ior );\\n\\t\\treturn textureBicubic( transmissionSamplerMap, fragCoord.xy, lod );\\n\\t}\\n\\tvec3 volumeAttenuation( const in float transmissionDistance, const in vec3 attenuationColor, const in float attenuationDistance ) {\\n\\t\\tif ( isinf( attenuationDistance ) ) {\\n\\t\\t\\treturn vec3( 1.0 );\\n\\t\\t} else {\\n\\t\\t\\tvec3 attenuationCoefficient = -log( attenuationColor ) / attenuationDistance;\\n\\t\\t\\tvec3 transmittance = exp( - attenuationCoefficient * transmissionDistance );\\t\\t\\treturn transmittance;\\n\\t\\t}\\n\\t}\\n\\tvec4 getIBLVolumeRefraction( const in vec3 n, const in vec3 v, const in float roughness, const in vec3 diffuseColor,\\n\\t\\tconst in vec3 specularColor, const in float specularF90, const in vec3 position, const in mat4 modelMatrix,\\n\\t\\tconst in mat4 viewMatrix, const in mat4 projMatrix, const in float dispersion, const in float ior, const in float thickness,\\n\\t\\tconst in vec3 attenuationColor, const in float attenuationDistance ) {\\n\\t\\tvec4 transmittedLight;\\n\\t\\tvec3 transmittance;\\n\\t\\t#ifdef USE_DISPERSION\\n\\t\\t\\tfloat halfSpread = ( ior - 1.0 ) * 0.025 * dispersion;\\n\\t\\t\\tvec3 iors = vec3( ior - halfSpread, ior, ior + halfSpread );\\n\\t\\t\\tfor ( int i = 0; i < 3; i ++ ) {\\n\\t\\t\\t\\tvec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, iors[ i ], modelMatrix );\\n\\t\\t\\t\\tvec3 refractedRayExit = position + transmissionRay;\\n\\t\\t\\n\\t\\t\\t\\tvec4 ndcPos = projMatrix * viewMatrix * vec4( refractedRayExit, 1.0 );\\n\\t\\t\\t\\tvec2 refractionCoords = ndcPos.xy / ndcPos.w;\\n\\t\\t\\t\\trefractionCoords += 1.0;\\n\\t\\t\\t\\trefractionCoords /= 2.0;\\n\\t\\t\\n\\t\\t\\t\\tvec4 transmissionSample = getTransmissionSample( refractionCoords, roughness, iors[ i ] );\\n\\t\\t\\t\\ttransmittedLight[ i ] = transmissionSample[ i ];\\n\\t\\t\\t\\ttransmittedLight.a += transmissionSample.a;\\n\\t\\t\\t\\ttransmittance[ i ] = diffuseColor[ i ] * volumeAttenuation( length( transmissionRay ), attenuationColor, attenuationDistance )[ i ];\\n\\t\\t\\t}\\n\\t\\t\\ttransmittedLight.a /= 3.0;\\n\\t\\t\\n\\t\\t#else\\n\\t\\t\\n\\t\\t\\tvec3 transmissionRay = getVolumeTransmissionRay( n, v, thickness, ior, modelMatrix );\\n\\t\\t\\tvec3 refractedRayExit = position + transmissionRay;\\n\\t\\t\\tvec4 ndcPos = projMatrix * viewMatrix * vec4( refractedRayExit, 1.0 );\\n\\t\\t\\tvec2 refractionCoords = ndcPos.xy / ndcPos.w;\\n\\t\\t\\trefractionCoords += 1.0;\\n\\t\\t\\trefractionCoords /= 2.0;\\n\\t\\t\\ttransmittedLight = getTransmissionSample( refractionCoords, roughness, ior );\\n\\t\\t\\ttransmittance = diffuseColor * volumeAttenuation( length( transmissionRay ), attenuationColor, attenuationDistance );\\n\\t\\t\\n\\t\\t#endif\\n\\t\\tvec3 attenuatedColor = transmittance * transmittedLight.rgb;\\n\\t\\tvec3 F = EnvironmentBRDF( n, v, specularColor, specularF90, roughness );\\n\\t\\tfloat transmittanceFactor = ( transmittance.r + transmittance.g + transmittance.b ) / 3.0;\\n\\t\\treturn vec4( ( 1.0 - F ) * attenuatedColor, 1.0 - ( 1.0 - transmittedLight.a ) * transmittanceFactor );\\n\\t}\\n#endif\";\nvar uv_pars_fragment = \"#if defined( USE_UV ) || defined( USE_ANISOTROPY )\\n\\tvarying vec2 vUv;\\n#endif\\n#ifdef USE_MAP\\n\\tvarying vec2 vMapUv;\\n#endif\\n#ifdef USE_ALPHAMAP\\n\\tvarying vec2 vAlphaMapUv;\\n#endif\\n#ifdef USE_LIGHTMAP\\n\\tvarying vec2 vLightMapUv;\\n#endif\\n#ifdef USE_AOMAP\\n\\tvarying vec2 vAoMapUv;\\n#endif\\n#ifdef USE_BUMPMAP\\n\\tvarying vec2 vBumpMapUv;\\n#endif\\n#ifdef USE_NORMALMAP\\n\\tvarying vec2 vNormalMapUv;\\n#endif\\n#ifdef USE_EMISSIVEMAP\\n\\tvarying vec2 vEmissiveMapUv;\\n#endif\\n#ifdef USE_METALNESSMAP\\n\\tvarying vec2 vMetalnessMapUv;\\n#endif\\n#ifdef USE_ROUGHNESSMAP\\n\\tvarying vec2 vRoughnessMapUv;\\n#endif\\n#ifdef USE_ANISOTROPYMAP\\n\\tvarying vec2 vAnisotropyMapUv;\\n#endif\\n#ifdef USE_CLEARCOATMAP\\n\\tvarying vec2 vClearcoatMapUv;\\n#endif\\n#ifdef USE_CLEARCOAT_NORMALMAP\\n\\tvarying vec2 vClearcoatNormalMapUv;\\n#endif\\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\\n\\tvarying vec2 vClearcoatRoughnessMapUv;\\n#endif\\n#ifdef USE_IRIDESCENCEMAP\\n\\tvarying vec2 vIridescenceMapUv;\\n#endif\\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\\n\\tvarying vec2 vIridescenceThicknessMapUv;\\n#endif\\n#ifdef USE_SHEEN_COLORMAP\\n\\tvarying vec2 vSheenColorMapUv;\\n#endif\\n#ifdef USE_SHEEN_ROUGHNESSMAP\\n\\tvarying vec2 vSheenRoughnessMapUv;\\n#endif\\n#ifdef USE_SPECULARMAP\\n\\tvarying vec2 vSpecularMapUv;\\n#endif\\n#ifdef USE_SPECULAR_COLORMAP\\n\\tvarying vec2 vSpecularColorMapUv;\\n#endif\\n#ifdef USE_SPECULAR_INTENSITYMAP\\n\\tvarying vec2 vSpecularIntensityMapUv;\\n#endif\\n#ifdef USE_TRANSMISSIONMAP\\n\\tuniform mat3 transmissionMapTransform;\\n\\tvarying vec2 vTransmissionMapUv;\\n#endif\\n#ifdef USE_THICKNESSMAP\\n\\tuniform mat3 thicknessMapTransform;\\n\\tvarying vec2 vThicknessMapUv;\\n#endif\";\nvar uv_pars_vertex = \"#if defined( USE_UV ) || defined( USE_ANISOTROPY )\\n\\tvarying vec2 vUv;\\n#endif\\n#ifdef USE_MAP\\n\\tuniform mat3 mapTransform;\\n\\tvarying vec2 vMapUv;\\n#endif\\n#ifdef USE_ALPHAMAP\\n\\tuniform mat3 alphaMapTransform;\\n\\tvarying vec2 vAlphaMapUv;\\n#endif\\n#ifdef USE_LIGHTMAP\\n\\tuniform mat3 lightMapTransform;\\n\\tvarying vec2 vLightMapUv;\\n#endif\\n#ifdef USE_AOMAP\\n\\tuniform mat3 aoMapTransform;\\n\\tvarying vec2 vAoMapUv;\\n#endif\\n#ifdef USE_BUMPMAP\\n\\tuniform mat3 bumpMapTransform;\\n\\tvarying vec2 vBumpMapUv;\\n#endif\\n#ifdef USE_NORMALMAP\\n\\tuniform mat3 normalMapTransform;\\n\\tvarying vec2 vNormalMapUv;\\n#endif\\n#ifdef USE_DISPLACEMENTMAP\\n\\tuniform mat3 displacementMapTransform;\\n\\tvarying vec2 vDisplacementMapUv;\\n#endif\\n#ifdef USE_EMISSIVEMAP\\n\\tuniform mat3 emissiveMapTransform;\\n\\tvarying vec2 vEmissiveMapUv;\\n#endif\\n#ifdef USE_METALNESSMAP\\n\\tuniform mat3 metalnessMapTransform;\\n\\tvarying vec2 vMetalnessMapUv;\\n#endif\\n#ifdef USE_ROUGHNESSMAP\\n\\tuniform mat3 roughnessMapTransform;\\n\\tvarying vec2 vRoughnessMapUv;\\n#endif\\n#ifdef USE_ANISOTROPYMAP\\n\\tuniform mat3 anisotropyMapTransform;\\n\\tvarying vec2 vAnisotropyMapUv;\\n#endif\\n#ifdef USE_CLEARCOATMAP\\n\\tuniform mat3 clearcoatMapTransform;\\n\\tvarying vec2 vClearcoatMapUv;\\n#endif\\n#ifdef USE_CLEARCOAT_NORMALMAP\\n\\tuniform mat3 clearcoatNormalMapTransform;\\n\\tvarying vec2 vClearcoatNormalMapUv;\\n#endif\\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\\n\\tuniform mat3 clearcoatRoughnessMapTransform;\\n\\tvarying vec2 vClearcoatRoughnessMapUv;\\n#endif\\n#ifdef USE_SHEEN_COLORMAP\\n\\tuniform mat3 sheenColorMapTransform;\\n\\tvarying vec2 vSheenColorMapUv;\\n#endif\\n#ifdef USE_SHEEN_ROUGHNESSMAP\\n\\tuniform mat3 sheenRoughnessMapTransform;\\n\\tvarying vec2 vSheenRoughnessMapUv;\\n#endif\\n#ifdef USE_IRIDESCENCEMAP\\n\\tuniform mat3 iridescenceMapTransform;\\n\\tvarying vec2 vIridescenceMapUv;\\n#endif\\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\\n\\tuniform mat3 iridescenceThicknessMapTransform;\\n\\tvarying vec2 vIridescenceThicknessMapUv;\\n#endif\\n#ifdef USE_SPECULARMAP\\n\\tuniform mat3 specularMapTransform;\\n\\tvarying vec2 vSpecularMapUv;\\n#endif\\n#ifdef USE_SPECULAR_COLORMAP\\n\\tuniform mat3 specularColorMapTransform;\\n\\tvarying vec2 vSpecularColorMapUv;\\n#endif\\n#ifdef USE_SPECULAR_INTENSITYMAP\\n\\tuniform mat3 specularIntensityMapTransform;\\n\\tvarying vec2 vSpecularIntensityMapUv;\\n#endif\\n#ifdef USE_TRANSMISSIONMAP\\n\\tuniform mat3 transmissionMapTransform;\\n\\tvarying vec2 vTransmissionMapUv;\\n#endif\\n#ifdef USE_THICKNESSMAP\\n\\tuniform mat3 thicknessMapTransform;\\n\\tvarying vec2 vThicknessMapUv;\\n#endif\";\nvar uv_vertex = \"#if defined( USE_UV ) || defined( USE_ANISOTROPY )\\n\\tvUv = vec3( uv, 1 ).xy;\\n#endif\\n#ifdef USE_MAP\\n\\tvMapUv = ( mapTransform * vec3( MAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_ALPHAMAP\\n\\tvAlphaMapUv = ( alphaMapTransform * vec3( ALPHAMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_LIGHTMAP\\n\\tvLightMapUv = ( lightMapTransform * vec3( LIGHTMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_AOMAP\\n\\tvAoMapUv = ( aoMapTransform * vec3( AOMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_BUMPMAP\\n\\tvBumpMapUv = ( bumpMapTransform * vec3( BUMPMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_NORMALMAP\\n\\tvNormalMapUv = ( normalMapTransform * vec3( NORMALMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_DISPLACEMENTMAP\\n\\tvDisplacementMapUv = ( displacementMapTransform * vec3( DISPLACEMENTMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_EMISSIVEMAP\\n\\tvEmissiveMapUv = ( emissiveMapTransform * vec3( EMISSIVEMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_METALNESSMAP\\n\\tvMetalnessMapUv = ( metalnessMapTransform * vec3( METALNESSMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_ROUGHNESSMAP\\n\\tvRoughnessMapUv = ( roughnessMapTransform * vec3( ROUGHNESSMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_ANISOTROPYMAP\\n\\tvAnisotropyMapUv = ( anisotropyMapTransform * vec3( ANISOTROPYMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_CLEARCOATMAP\\n\\tvClearcoatMapUv = ( clearcoatMapTransform * vec3( CLEARCOATMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_CLEARCOAT_NORMALMAP\\n\\tvClearcoatNormalMapUv = ( clearcoatNormalMapTransform * vec3( CLEARCOAT_NORMALMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_CLEARCOAT_ROUGHNESSMAP\\n\\tvClearcoatRoughnessMapUv = ( clearcoatRoughnessMapTransform * vec3( CLEARCOAT_ROUGHNESSMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_IRIDESCENCEMAP\\n\\tvIridescenceMapUv = ( iridescenceMapTransform * vec3( IRIDESCENCEMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_IRIDESCENCE_THICKNESSMAP\\n\\tvIridescenceThicknessMapUv = ( iridescenceThicknessMapTransform * vec3( IRIDESCENCE_THICKNESSMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_SHEEN_COLORMAP\\n\\tvSheenColorMapUv = ( sheenColorMapTransform * vec3( SHEEN_COLORMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_SHEEN_ROUGHNESSMAP\\n\\tvSheenRoughnessMapUv = ( sheenRoughnessMapTransform * vec3( SHEEN_ROUGHNESSMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_SPECULARMAP\\n\\tvSpecularMapUv = ( specularMapTransform * vec3( SPECULARMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_SPECULAR_COLORMAP\\n\\tvSpecularColorMapUv = ( specularColorMapTransform * vec3( SPECULAR_COLORMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_SPECULAR_INTENSITYMAP\\n\\tvSpecularIntensityMapUv = ( specularIntensityMapTransform * vec3( SPECULAR_INTENSITYMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_TRANSMISSIONMAP\\n\\tvTransmissionMapUv = ( transmissionMapTransform * vec3( TRANSMISSIONMAP_UV, 1 ) ).xy;\\n#endif\\n#ifdef USE_THICKNESSMAP\\n\\tvThicknessMapUv = ( thicknessMapTransform * vec3( THICKNESSMAP_UV, 1 ) ).xy;\\n#endif\";\nvar worldpos_vertex = \"#if defined( USE_ENVMAP ) || defined( DISTANCE ) || defined ( USE_SHADOWMAP ) || defined ( USE_TRANSMISSION ) || NUM_SPOT_LIGHT_COORDS > 0\\n\\tvec4 worldPosition = vec4( transformed, 1.0 );\\n\\t#ifdef USE_BATCHING\\n\\t\\tworldPosition = batchingMatrix * worldPosition;\\n\\t#endif\\n\\t#ifdef USE_INSTANCING\\n\\t\\tworldPosition = instanceMatrix * worldPosition;\\n\\t#endif\\n\\tworldPosition = modelMatrix * worldPosition;\\n#endif\";\nconst vertex$h = \"varying vec2 vUv;\\nuniform mat3 uvTransform;\\nvoid main() {\\n\\tvUv = ( uvTransform * vec3( uv, 1 ) ).xy;\\n\\tgl_Position = vec4( position.xy, 1.0, 1.0 );\\n}\";\nconst fragment$h = \"uniform sampler2D t2D;\\nuniform float backgroundIntensity;\\nvarying vec2 vUv;\\nvoid main() {\\n\\tvec4 texColor = texture2D( t2D, vUv );\\n\\t#ifdef DECODE_VIDEO_TEXTURE\\n\\t\\ttexColor = vec4( mix( pow( texColor.rgb * 0.9478672986 + vec3( 0.0521327014 ), vec3( 2.4 ) ), texColor.rgb * 0.0773993808, vec3( lessThanEqual( texColor.rgb, vec3( 0.04045 ) ) ) ), texColor.w );\\n\\t#endif\\n\\ttexColor.rgb *= backgroundIntensity;\\n\\tgl_FragColor = texColor;\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n}\";\nconst vertex$g = \"varying vec3 vWorldDirection;\\n#include <common>\\nvoid main() {\\n\\tvWorldDirection = transformDirection( position, modelMatrix );\\n\\t#include <begin_vertex>\\n\\t#include <project_vertex>\\n\\tgl_Position.z = gl_Position.w;\\n}\";\nconst fragment$g = \"#ifdef ENVMAP_TYPE_CUBE\\n\\tuniform samplerCube envMap;\\n#elif defined( ENVMAP_TYPE_CUBE_UV )\\n\\tuniform sampler2D envMap;\\n#endif\\nuniform float flipEnvMap;\\nuniform float backgroundBlurriness;\\nuniform float backgroundIntensity;\\nuniform mat3 backgroundRotation;\\nvarying vec3 vWorldDirection;\\n#include <cube_uv_reflection_fragment>\\nvoid main() {\\n\\t#ifdef ENVMAP_TYPE_CUBE\\n\\t\\tvec4 texColor = textureCube( envMap, backgroundRotation * vec3( flipEnvMap * vWorldDirection.x, vWorldDirection.yz ) );\\n\\t#elif defined( ENVMAP_TYPE_CUBE_UV )\\n\\t\\tvec4 texColor = textureCubeUV( envMap, backgroundRotation * vWorldDirection, backgroundBlurriness );\\n\\t#else\\n\\t\\tvec4 texColor = vec4( 0.0, 0.0, 0.0, 1.0 );\\n\\t#endif\\n\\ttexColor.rgb *= backgroundIntensity;\\n\\tgl_FragColor = texColor;\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n}\";\nconst vertex$f = \"varying vec3 vWorldDirection;\\n#include <common>\\nvoid main() {\\n\\tvWorldDirection = transformDirection( position, modelMatrix );\\n\\t#include <begin_vertex>\\n\\t#include <project_vertex>\\n\\tgl_Position.z = gl_Position.w;\\n}\";\nconst fragment$f = \"uniform samplerCube tCube;\\nuniform float tFlip;\\nuniform float opacity;\\nvarying vec3 vWorldDirection;\\nvoid main() {\\n\\tvec4 texColor = textureCube( tCube, vec3( tFlip * vWorldDirection.x, vWorldDirection.yz ) );\\n\\tgl_FragColor = texColor;\\n\\tgl_FragColor.a *= opacity;\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n}\";\nconst vertex$e = \"#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvarying vec2 vHighPrecisionZW;\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#ifdef USE_DISPLACEMENTMAP\\n\\t\\t#include <beginnormal_vertex>\\n\\t\\t#include <morphnormal_vertex>\\n\\t\\t#include <skinnormal_vertex>\\n\\t#endif\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvHighPrecisionZW = gl_Position.zw;\\n}\";\nconst fragment$e = \"#if DEPTH_PACKING == 3200\\n\\tuniform float opacity;\\n#endif\\n#include <common>\\n#include <packing>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvarying vec2 vHighPrecisionZW;\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( 1.0 );\\n\\t#include <clipping_planes_fragment>\\n\\t#if DEPTH_PACKING == 3200\\n\\t\\tdiffuseColor.a = opacity;\\n\\t#endif\\n\\t#include <map_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\t#include <logdepthbuf_fragment>\\n\\tfloat fragCoordZ = 0.5 * vHighPrecisionZW[0] / vHighPrecisionZW[1] + 0.5;\\n\\t#if DEPTH_PACKING == 3200\\n\\t\\tgl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity );\\n\\t#elif DEPTH_PACKING == 3201\\n\\t\\tgl_FragColor = packDepthToRGBA( fragCoordZ );\\n\\t#elif DEPTH_PACKING == 3202\\n\\t\\tgl_FragColor = vec4( packDepthToRGB( fragCoordZ ), 1.0 );\\n\\t#elif DEPTH_PACKING == 3203\\n\\t\\tgl_FragColor = vec4( packDepthToRG( fragCoordZ ), 0.0, 1.0 );\\n\\t#endif\\n}\";\nconst vertex$d = \"#define DISTANCE\\nvarying vec3 vWorldPosition;\\n#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#ifdef USE_DISPLACEMENTMAP\\n\\t\\t#include <beginnormal_vertex>\\n\\t\\t#include <morphnormal_vertex>\\n\\t\\t#include <skinnormal_vertex>\\n\\t#endif\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvWorldPosition = worldPosition.xyz;\\n}\";\nconst fragment$d = \"#define DISTANCE\\nuniform vec3 referencePosition;\\nuniform float nearDistance;\\nuniform float farDistance;\\nvarying vec3 vWorldPosition;\\n#include <common>\\n#include <packing>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main () {\\n\\tvec4 diffuseColor = vec4( 1.0 );\\n\\t#include <clipping_planes_fragment>\\n\\t#include <map_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\tfloat dist = length( vWorldPosition - referencePosition );\\n\\tdist = ( dist - nearDistance ) / ( farDistance - nearDistance );\\n\\tdist = saturate( dist );\\n\\tgl_FragColor = packDepthToRGBA( dist );\\n}\";\nconst vertex$c = \"varying vec3 vWorldDirection;\\n#include <common>\\nvoid main() {\\n\\tvWorldDirection = transformDirection( position, modelMatrix );\\n\\t#include <begin_vertex>\\n\\t#include <project_vertex>\\n}\";\nconst fragment$c = \"uniform sampler2D tEquirect;\\nvarying vec3 vWorldDirection;\\n#include <common>\\nvoid main() {\\n\\tvec3 direction = normalize( vWorldDirection );\\n\\tvec2 sampleUV = equirectUv( direction );\\n\\tgl_FragColor = texture2D( tEquirect, sampleUV );\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n}\";\nconst vertex$b = \"uniform float scale;\\nattribute float lineDistance;\\nvarying float vLineDistance;\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\tvLineDistance = scale * lineDistance;\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$b = \"uniform vec3 diffuse;\\nuniform float opacity;\\nuniform float dashSize;\\nuniform float totalSize;\\nvarying float vLineDistance;\\n#include <common>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\tif ( mod( vLineDistance, totalSize ) > dashSize ) {\\n\\t\\tdiscard;\\n\\t}\\n\\tvec3 outgoingLight = vec3( 0.0 );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\toutgoingLight = diffuseColor.rgb;\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n}\";\nconst vertex$a = \"#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <envmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <batching_vertex>\\n\\t#if defined ( USE_ENVMAP ) || defined ( USE_SKINNING )\\n\\t\\t#include <beginnormal_vertex>\\n\\t\\t#include <morphnormal_vertex>\\n\\t\\t#include <skinbase_vertex>\\n\\t\\t#include <skinnormal_vertex>\\n\\t\\t#include <defaultnormal_vertex>\\n\\t#endif\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <envmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$a = \"uniform vec3 diffuse;\\nuniform float opacity;\\n#ifndef FLAT_SHADED\\n\\tvarying vec3 vNormal;\\n#endif\\n#include <common>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <specularmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\t#include <specularmap_fragment>\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\t#ifdef USE_LIGHTMAP\\n\\t\\tvec4 lightMapTexel = texture2D( lightMap, vLightMapUv );\\n\\t\\treflectedLight.indirectDiffuse += lightMapTexel.rgb * lightMapIntensity * RECIPROCAL_PI;\\n\\t#else\\n\\t\\treflectedLight.indirectDiffuse += vec3( 1.0 );\\n\\t#endif\\n\\t#include <aomap_fragment>\\n\\treflectedLight.indirectDiffuse *= diffuseColor.rgb;\\n\\tvec3 outgoingLight = reflectedLight.indirectDiffuse;\\n\\t#include <envmap_fragment>\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\nconst vertex$9 = \"#define LAMBERT\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <envmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n\\t#include <worldpos_vertex>\\n\\t#include <envmap_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$9 = \"#define LAMBERT\\nuniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform float opacity;\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <normal_pars_fragment>\\n#include <lights_lambert_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <specularmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\t#include <specularmap_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\t#include <emissivemap_fragment>\\n\\t#include <lights_lambert_fragment>\\n\\t#include <lights_fragment_begin>\\n\\t#include <lights_fragment_maps>\\n\\t#include <lights_fragment_end>\\n\\t#include <aomap_fragment>\\n\\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\\n\\t#include <envmap_fragment>\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\nconst vertex$8 = \"#define MATCAP\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <color_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <fog_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n}\";\nconst fragment$8 = \"#define MATCAP\\nuniform vec3 diffuse;\\nuniform float opacity;\\nuniform sampler2D matcap;\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <normal_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\tvec3 viewDir = normalize( vViewPosition );\\n\\tvec3 x = normalize( vec3( viewDir.z, 0.0, - viewDir.x ) );\\n\\tvec3 y = cross( viewDir, x );\\n\\tvec2 uv = vec2( dot( x, normal ), dot( y, normal ) ) * 0.495 + 0.5;\\n\\t#ifdef USE_MATCAP\\n\\t\\tvec4 matcapColor = texture2D( matcap, uv );\\n\\t#else\\n\\t\\tvec4 matcapColor = vec4( vec3( mix( 0.2, 0.8, uv.y ) ), 1.0 );\\n\\t#endif\\n\\tvec3 outgoingLight = diffuseColor.rgb * matcapColor.rgb;\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\nconst vertex$7 = \"#define NORMAL\\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\\n\\tvarying vec3 vViewPosition;\\n#endif\\n#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\\n\\tvViewPosition = - mvPosition.xyz;\\n#endif\\n}\";\nconst fragment$7 = \"#define NORMAL\\nuniform float opacity;\\n#if defined( FLAT_SHADED ) || defined( USE_BUMPMAP ) || defined( USE_NORMALMAP_TANGENTSPACE )\\n\\tvarying vec3 vViewPosition;\\n#endif\\n#include <packing>\\n#include <uv_pars_fragment>\\n#include <normal_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( 0.0, 0.0, 0.0, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\tgl_FragColor = vec4( packNormalToRGB( normal ), diffuseColor.a );\\n\\t#ifdef OPAQUE\\n\\t\\tgl_FragColor.a = 1.0;\\n\\t#endif\\n}\";\nconst vertex$6 = \"#define PHONG\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <envmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n\\t#include <worldpos_vertex>\\n\\t#include <envmap_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$6 = \"#define PHONG\\nuniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform vec3 specular;\\nuniform float shininess;\\nuniform float opacity;\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <normal_pars_fragment>\\n#include <lights_phong_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <specularmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\t#include <specularmap_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\t#include <emissivemap_fragment>\\n\\t#include <lights_phong_fragment>\\n\\t#include <lights_fragment_begin>\\n\\t#include <lights_fragment_maps>\\n\\t#include <lights_fragment_end>\\n\\t#include <aomap_fragment>\\n\\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + reflectedLight.directSpecular + reflectedLight.indirectSpecular + totalEmissiveRadiance;\\n\\t#include <envmap_fragment>\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\nconst vertex$5 = \"#define STANDARD\\nvarying vec3 vViewPosition;\\n#ifdef USE_TRANSMISSION\\n\\tvarying vec3 vWorldPosition;\\n#endif\\n#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n\\t#include <worldpos_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n#ifdef USE_TRANSMISSION\\n\\tvWorldPosition = worldPosition.xyz;\\n#endif\\n}\";\nconst fragment$5 = \"#define STANDARD\\n#ifdef PHYSICAL\\n\\t#define IOR\\n\\t#define USE_SPECULAR\\n#endif\\nuniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform float roughness;\\nuniform float metalness;\\nuniform float opacity;\\n#ifdef IOR\\n\\tuniform float ior;\\n#endif\\n#ifdef USE_SPECULAR\\n\\tuniform float specularIntensity;\\n\\tuniform vec3 specularColor;\\n\\t#ifdef USE_SPECULAR_COLORMAP\\n\\t\\tuniform sampler2D specularColorMap;\\n\\t#endif\\n\\t#ifdef USE_SPECULAR_INTENSITYMAP\\n\\t\\tuniform sampler2D specularIntensityMap;\\n\\t#endif\\n#endif\\n#ifdef USE_CLEARCOAT\\n\\tuniform float clearcoat;\\n\\tuniform float clearcoatRoughness;\\n#endif\\n#ifdef USE_DISPERSION\\n\\tuniform float dispersion;\\n#endif\\n#ifdef USE_IRIDESCENCE\\n\\tuniform float iridescence;\\n\\tuniform float iridescenceIOR;\\n\\tuniform float iridescenceThicknessMinimum;\\n\\tuniform float iridescenceThicknessMaximum;\\n#endif\\n#ifdef USE_SHEEN\\n\\tuniform vec3 sheenColor;\\n\\tuniform float sheenRoughness;\\n\\t#ifdef USE_SHEEN_COLORMAP\\n\\t\\tuniform sampler2D sheenColorMap;\\n\\t#endif\\n\\t#ifdef USE_SHEEN_ROUGHNESSMAP\\n\\t\\tuniform sampler2D sheenRoughnessMap;\\n\\t#endif\\n#endif\\n#ifdef USE_ANISOTROPY\\n\\tuniform vec2 anisotropyVector;\\n\\t#ifdef USE_ANISOTROPYMAP\\n\\t\\tuniform sampler2D anisotropyMap;\\n\\t#endif\\n#endif\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <iridescence_fragment>\\n#include <cube_uv_reflection_fragment>\\n#include <envmap_common_pars_fragment>\\n#include <envmap_physical_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <lights_pars_begin>\\n#include <normal_pars_fragment>\\n#include <lights_physical_pars_fragment>\\n#include <transmission_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <clearcoat_pars_fragment>\\n#include <iridescence_pars_fragment>\\n#include <roughnessmap_pars_fragment>\\n#include <metalnessmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\t#include <roughnessmap_fragment>\\n\\t#include <metalnessmap_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\t#include <clearcoat_normal_fragment_begin>\\n\\t#include <clearcoat_normal_fragment_maps>\\n\\t#include <emissivemap_fragment>\\n\\t#include <lights_physical_fragment>\\n\\t#include <lights_fragment_begin>\\n\\t#include <lights_fragment_maps>\\n\\t#include <lights_fragment_end>\\n\\t#include <aomap_fragment>\\n\\tvec3 totalDiffuse = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse;\\n\\tvec3 totalSpecular = reflectedLight.directSpecular + reflectedLight.indirectSpecular;\\n\\t#include <transmission_fragment>\\n\\tvec3 outgoingLight = totalDiffuse + totalSpecular + totalEmissiveRadiance;\\n\\t#ifdef USE_SHEEN\\n\\t\\tfloat sheenEnergyComp = 1.0 - 0.157 * max3( material.sheenColor );\\n\\t\\toutgoingLight = outgoingLight * sheenEnergyComp + sheenSpecularDirect + sheenSpecularIndirect;\\n\\t#endif\\n\\t#ifdef USE_CLEARCOAT\\n\\t\\tfloat dotNVcc = saturate( dot( geometryClearcoatNormal, geometryViewDir ) );\\n\\t\\tvec3 Fcc = F_Schlick( material.clearcoatF0, material.clearcoatF90, dotNVcc );\\n\\t\\toutgoingLight = outgoingLight * ( 1.0 - material.clearcoat * Fcc ) + ( clearcoatSpecularDirect + clearcoatSpecularIndirect ) * material.clearcoat;\\n\\t#endif\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\nconst vertex$4 = \"#define TOON\\nvarying vec3 vViewPosition;\\n#include <common>\\n#include <batching_pars_vertex>\\n#include <uv_pars_vertex>\\n#include <displacementmap_pars_vertex>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <normal_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <shadowmap_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\t#include <color_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <batching_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <normal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <displacementmap_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\tvViewPosition = - mvPosition.xyz;\\n\\t#include <worldpos_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$4 = \"#define TOON\\nuniform vec3 diffuse;\\nuniform vec3 emissive;\\nuniform float opacity;\\n#include <common>\\n#include <packing>\\n#include <dithering_pars_fragment>\\n#include <color_pars_fragment>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <aomap_pars_fragment>\\n#include <lightmap_pars_fragment>\\n#include <emissivemap_pars_fragment>\\n#include <gradientmap_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <normal_pars_fragment>\\n#include <lights_toon_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <bumpmap_pars_fragment>\\n#include <normalmap_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\tReflectedLight reflectedLight = ReflectedLight( vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ), vec3( 0.0 ) );\\n\\tvec3 totalEmissiveRadiance = emissive;\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\t#include <normal_fragment_begin>\\n\\t#include <normal_fragment_maps>\\n\\t#include <emissivemap_fragment>\\n\\t#include <lights_toon_fragment>\\n\\t#include <lights_fragment_begin>\\n\\t#include <lights_fragment_maps>\\n\\t#include <lights_fragment_end>\\n\\t#include <aomap_fragment>\\n\\tvec3 outgoingLight = reflectedLight.directDiffuse + reflectedLight.indirectDiffuse + totalEmissiveRadiance;\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n\\t#include <dithering_fragment>\\n}\";\nconst vertex$3 = \"uniform float size;\\nuniform float scale;\\n#include <common>\\n#include <color_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\n#ifdef USE_POINTS_UV\\n\\tvarying vec2 vUv;\\n\\tuniform mat3 uvTransform;\\n#endif\\nvoid main() {\\n\\t#ifdef USE_POINTS_UV\\n\\t\\tvUv = ( uvTransform * vec3( uv, 1 ) ).xy;\\n\\t#endif\\n\\t#include <color_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphcolor_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <project_vertex>\\n\\tgl_PointSize = size;\\n\\t#ifdef USE_SIZEATTENUATION\\n\\t\\tbool isPerspective = isPerspectiveMatrix( projectionMatrix );\\n\\t\\tif ( isPerspective ) gl_PointSize *= ( scale / - mvPosition.z );\\n\\t#endif\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$3 = \"uniform vec3 diffuse;\\nuniform float opacity;\\n#include <common>\\n#include <color_pars_fragment>\\n#include <map_particle_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\tvec3 outgoingLight = vec3( 0.0 );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_particle_fragment>\\n\\t#include <color_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\toutgoingLight = diffuseColor.rgb;\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n\\t#include <premultiplied_alpha_fragment>\\n}\";\nconst vertex$2 = \"#include <common>\\n#include <batching_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <morphtarget_pars_vertex>\\n#include <skinning_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <shadowmap_pars_vertex>\\nvoid main() {\\n\\t#include <batching_vertex>\\n\\t#include <beginnormal_vertex>\\n\\t#include <morphinstance_vertex>\\n\\t#include <morphnormal_vertex>\\n\\t#include <skinbase_vertex>\\n\\t#include <skinnormal_vertex>\\n\\t#include <defaultnormal_vertex>\\n\\t#include <begin_vertex>\\n\\t#include <morphtarget_vertex>\\n\\t#include <skinning_vertex>\\n\\t#include <project_vertex>\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <worldpos_vertex>\\n\\t#include <shadowmap_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$2 = \"uniform vec3 color;\\nuniform float opacity;\\n#include <common>\\n#include <packing>\\n#include <fog_pars_fragment>\\n#include <bsdfs>\\n#include <lights_pars_begin>\\n#include <logdepthbuf_pars_fragment>\\n#include <shadowmap_pars_fragment>\\n#include <shadowmask_pars_fragment>\\nvoid main() {\\n\\t#include <logdepthbuf_fragment>\\n\\tgl_FragColor = vec4( color, opacity * ( 1.0 - getShadowMask() ) );\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n}\";\nconst vertex$1 = \"uniform float rotation;\\nuniform vec2 center;\\n#include <common>\\n#include <uv_pars_vertex>\\n#include <fog_pars_vertex>\\n#include <logdepthbuf_pars_vertex>\\n#include <clipping_planes_pars_vertex>\\nvoid main() {\\n\\t#include <uv_vertex>\\n\\tvec4 mvPosition = modelViewMatrix[ 3 ];\\n\\tvec2 scale = vec2( length( modelMatrix[ 0 ].xyz ), length( modelMatrix[ 1 ].xyz ) );\\n\\t#ifndef USE_SIZEATTENUATION\\n\\t\\tbool isPerspective = isPerspectiveMatrix( projectionMatrix );\\n\\t\\tif ( isPerspective ) scale *= - mvPosition.z;\\n\\t#endif\\n\\tvec2 alignedPosition = ( position.xy - ( center - vec2( 0.5 ) ) ) * scale;\\n\\tvec2 rotatedPosition;\\n\\trotatedPosition.x = cos( rotation ) * alignedPosition.x - sin( rotation ) * alignedPosition.y;\\n\\trotatedPosition.y = sin( rotation ) * alignedPosition.x + cos( rotation ) * alignedPosition.y;\\n\\tmvPosition.xy += rotatedPosition;\\n\\tgl_Position = projectionMatrix * mvPosition;\\n\\t#include <logdepthbuf_vertex>\\n\\t#include <clipping_planes_vertex>\\n\\t#include <fog_vertex>\\n}\";\nconst fragment$1 = \"uniform vec3 diffuse;\\nuniform float opacity;\\n#include <common>\\n#include <uv_pars_fragment>\\n#include <map_pars_fragment>\\n#include <alphamap_pars_fragment>\\n#include <alphatest_pars_fragment>\\n#include <alphahash_pars_fragment>\\n#include <fog_pars_fragment>\\n#include <logdepthbuf_pars_fragment>\\n#include <clipping_planes_pars_fragment>\\nvoid main() {\\n\\tvec4 diffuseColor = vec4( diffuse, opacity );\\n\\t#include <clipping_planes_fragment>\\n\\tvec3 outgoingLight = vec3( 0.0 );\\n\\t#include <logdepthbuf_fragment>\\n\\t#include <map_fragment>\\n\\t#include <alphamap_fragment>\\n\\t#include <alphatest_fragment>\\n\\t#include <alphahash_fragment>\\n\\toutgoingLight = diffuseColor.rgb;\\n\\t#include <opaque_fragment>\\n\\t#include <tonemapping_fragment>\\n\\t#include <colorspace_fragment>\\n\\t#include <fog_fragment>\\n}\";\nconst ShaderChunk = {\n  alphahash_fragment: alphahash_fragment,\n  alphahash_pars_fragment: alphahash_pars_fragment,\n  alphamap_fragment: alphamap_fragment,\n  alphamap_pars_fragment: alphamap_pars_fragment,\n  alphatest_fragment: alphatest_fragment,\n  alphatest_pars_fragment: alphatest_pars_fragment,\n  aomap_fragment: aomap_fragment,\n  aomap_pars_fragment: aomap_pars_fragment,\n  batching_pars_vertex: batching_pars_vertex,\n  batching_vertex: batching_vertex,\n  begin_vertex: begin_vertex,\n  beginnormal_vertex: beginnormal_vertex,\n  bsdfs: bsdfs,\n  iridescence_fragment: iridescence_fragment,\n  bumpmap_pars_fragment: bumpmap_pars_fragment,\n  clipping_planes_fragment: clipping_planes_fragment,\n  clipping_planes_pars_fragment: clipping_planes_pars_fragment,\n  clipping_planes_pars_vertex: clipping_planes_pars_vertex,\n  clipping_planes_vertex: clipping_planes_vertex,\n  color_fragment: color_fragment,\n  color_pars_fragment: color_pars_fragment,\n  color_pars_vertex: color_pars_vertex,\n  color_vertex: color_vertex,\n  common: common,\n  cube_uv_reflection_fragment: cube_uv_reflection_fragment,\n  defaultnormal_vertex: defaultnormal_vertex,\n  displacementmap_pars_vertex: displacementmap_pars_vertex,\n  displacementmap_vertex: displacementmap_vertex,\n  emissivemap_fragment: emissivemap_fragment,\n  emissivemap_pars_fragment: emissivemap_pars_fragment,\n  colorspace_fragment: colorspace_fragment,\n  colorspace_pars_fragment: colorspace_pars_fragment,\n  envmap_fragment: envmap_fragment,\n  envmap_common_pars_fragment: envmap_common_pars_fragment,\n  envmap_pars_fragment: envmap_pars_fragment,\n  envmap_pars_vertex: envmap_pars_vertex,\n  envmap_physical_pars_fragment: envmap_physical_pars_fragment,\n  envmap_vertex: envmap_vertex,\n  fog_vertex: fog_vertex,\n  fog_pars_vertex: fog_pars_vertex,\n  fog_fragment: fog_fragment,\n  fog_pars_fragment: fog_pars_fragment,\n  gradientmap_pars_fragment: gradientmap_pars_fragment,\n  lightmap_pars_fragment: lightmap_pars_fragment,\n  lights_lambert_fragment: lights_lambert_fragment,\n  lights_lambert_pars_fragment: lights_lambert_pars_fragment,\n  lights_pars_begin: lights_pars_begin,\n  lights_toon_fragment: lights_toon_fragment,\n  lights_toon_pars_fragment: lights_toon_pars_fragment,\n  lights_phong_fragment: lights_phong_fragment,\n  lights_phong_pars_fragment: lights_phong_pars_fragment,\n  lights_physical_fragment: lights_physical_fragment,\n  lights_physical_pars_fragment: lights_physical_pars_fragment,\n  lights_fragment_begin: lights_fragment_begin,\n  lights_fragment_maps: lights_fragment_maps,\n  lights_fragment_end: lights_fragment_end,\n  logdepthbuf_fragment: logdepthbuf_fragment,\n  logdepthbuf_pars_fragment: logdepthbuf_pars_fragment,\n  logdepthbuf_pars_vertex: logdepthbuf_pars_vertex,\n  logdepthbuf_vertex: logdepthbuf_vertex,\n  map_fragment: map_fragment,\n  map_pars_fragment: map_pars_fragment,\n  map_particle_fragment: map_particle_fragment,\n  map_particle_pars_fragment: map_particle_pars_fragment,\n  metalnessmap_fragment: metalnessmap_fragment,\n  metalnessmap_pars_fragment: metalnessmap_pars_fragment,\n  morphinstance_vertex: morphinstance_vertex,\n  morphcolor_vertex: morphcolor_vertex,\n  morphnormal_vertex: morphnormal_vertex,\n  morphtarget_pars_vertex: morphtarget_pars_vertex,\n  morphtarget_vertex: morphtarget_vertex,\n  normal_fragment_begin: normal_fragment_begin,\n  normal_fragment_maps: normal_fragment_maps,\n  normal_pars_fragment: normal_pars_fragment,\n  normal_pars_vertex: normal_pars_vertex,\n  normal_vertex: normal_vertex,\n  normalmap_pars_fragment: normalmap_pars_fragment,\n  clearcoat_normal_fragment_begin: clearcoat_normal_fragment_begin,\n  clearcoat_normal_fragment_maps: clearcoat_normal_fragment_maps,\n  clearcoat_pars_fragment: clearcoat_pars_fragment,\n  iridescence_pars_fragment: iridescence_pars_fragment,\n  opaque_fragment: opaque_fragment,\n  packing: packing,\n  premultiplied_alpha_fragment: premultiplied_alpha_fragment,\n  project_vertex: project_vertex,\n  dithering_fragment: dithering_fragment,\n  dithering_pars_fragment: dithering_pars_fragment,\n  roughnessmap_fragment: roughnessmap_fragment,\n  roughnessmap_pars_fragment: roughnessmap_pars_fragment,\n  shadowmap_pars_fragment: shadowmap_pars_fragment,\n  shadowmap_pars_vertex: shadowmap_pars_vertex,\n  shadowmap_vertex: shadowmap_vertex,\n  shadowmask_pars_fragment: shadowmask_pars_fragment,\n  skinbase_vertex: skinbase_vertex,\n  skinning_pars_vertex: skinning_pars_vertex,\n  skinning_vertex: skinning_vertex,\n  skinnormal_vertex: skinnormal_vertex,\n  specularmap_fragment: specularmap_fragment,\n  specularmap_pars_fragment: specularmap_pars_fragment,\n  tonemapping_fragment: tonemapping_fragment,\n  tonemapping_pars_fragment: tonemapping_pars_fragment,\n  transmission_fragment: transmission_fragment,\n  transmission_pars_fragment: transmission_pars_fragment,\n  uv_pars_fragment: uv_pars_fragment,\n  uv_pars_vertex: uv_pars_vertex,\n  uv_vertex: uv_vertex,\n  worldpos_vertex: worldpos_vertex,\n  background_vert: vertex$h,\n  background_frag: fragment$h,\n  backgroundCube_vert: vertex$g,\n  backgroundCube_frag: fragment$g,\n  cube_vert: vertex$f,\n  cube_frag: fragment$f,\n  depth_vert: vertex$e,\n  depth_frag: fragment$e,\n  distanceRGBA_vert: vertex$d,\n  distanceRGBA_frag: fragment$d,\n  equirect_vert: vertex$c,\n  equirect_frag: fragment$c,\n  linedashed_vert: vertex$b,\n  linedashed_frag: fragment$b,\n  meshbasic_vert: vertex$a,\n  meshbasic_frag: fragment$a,\n  meshlambert_vert: vertex$9,\n  meshlambert_frag: fragment$9,\n  meshmatcap_vert: vertex$8,\n  meshmatcap_frag: fragment$8,\n  meshnormal_vert: vertex$7,\n  meshnormal_frag: fragment$7,\n  meshphong_vert: vertex$6,\n  meshphong_frag: fragment$6,\n  meshphysical_vert: vertex$5,\n  meshphysical_frag: fragment$5,\n  meshtoon_vert: vertex$4,\n  meshtoon_frag: fragment$4,\n  points_vert: vertex$3,\n  points_frag: fragment$3,\n  shadow_vert: vertex$2,\n  shadow_frag: fragment$2,\n  sprite_vert: vertex$1,\n  sprite_frag: fragment$1\n};\n\n/**\n * Uniforms library for shared webgl shaders\n */\n\nconst UniformsLib = {\n  common: {\n    diffuse: {\n      value: /*@__PURE__*/new Color(0xffffff)\n    },\n    opacity: {\n      value: 1.0\n    },\n    map: {\n      value: null\n    },\n    mapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    alphaMap: {\n      value: null\n    },\n    alphaMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    alphaTest: {\n      value: 0\n    }\n  },\n  specularmap: {\n    specularMap: {\n      value: null\n    },\n    specularMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  },\n  envmap: {\n    envMap: {\n      value: null\n    },\n    envMapRotation: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    flipEnvMap: {\n      value: -1\n    },\n    reflectivity: {\n      value: 1.0\n    },\n    // basic, lambert, phong\n    ior: {\n      value: 1.5\n    },\n    // physical\n    refractionRatio: {\n      value: 0.98\n    } // basic, lambert, phong\n  },\n  aomap: {\n    aoMap: {\n      value: null\n    },\n    aoMapIntensity: {\n      value: 1\n    },\n    aoMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  },\n  lightmap: {\n    lightMap: {\n      value: null\n    },\n    lightMapIntensity: {\n      value: 1\n    },\n    lightMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  },\n  bumpmap: {\n    bumpMap: {\n      value: null\n    },\n    bumpMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    bumpScale: {\n      value: 1\n    }\n  },\n  normalmap: {\n    normalMap: {\n      value: null\n    },\n    normalMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    normalScale: {\n      value: /*@__PURE__*/new Vector2(1, 1)\n    }\n  },\n  displacementmap: {\n    displacementMap: {\n      value: null\n    },\n    displacementMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    displacementScale: {\n      value: 1\n    },\n    displacementBias: {\n      value: 0\n    }\n  },\n  emissivemap: {\n    emissiveMap: {\n      value: null\n    },\n    emissiveMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  },\n  metalnessmap: {\n    metalnessMap: {\n      value: null\n    },\n    metalnessMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  },\n  roughnessmap: {\n    roughnessMap: {\n      value: null\n    },\n    roughnessMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  },\n  gradientmap: {\n    gradientMap: {\n      value: null\n    }\n  },\n  fog: {\n    fogDensity: {\n      value: 0.00025\n    },\n    fogNear: {\n      value: 1\n    },\n    fogFar: {\n      value: 2000\n    },\n    fogColor: {\n      value: /*@__PURE__*/new Color(0xffffff)\n    }\n  },\n  lights: {\n    ambientLightColor: {\n      value: []\n    },\n    lightProbe: {\n      value: []\n    },\n    directionalLights: {\n      value: [],\n      properties: {\n        direction: {},\n        color: {}\n      }\n    },\n    directionalLightShadows: {\n      value: [],\n      properties: {\n        shadowIntensity: 1,\n        shadowBias: {},\n        shadowNormalBias: {},\n        shadowRadius: {},\n        shadowMapSize: {}\n      }\n    },\n    directionalShadowMap: {\n      value: []\n    },\n    directionalShadowMatrix: {\n      value: []\n    },\n    spotLights: {\n      value: [],\n      properties: {\n        color: {},\n        position: {},\n        direction: {},\n        distance: {},\n        coneCos: {},\n        penumbraCos: {},\n        decay: {}\n      }\n    },\n    spotLightShadows: {\n      value: [],\n      properties: {\n        shadowIntensity: 1,\n        shadowBias: {},\n        shadowNormalBias: {},\n        shadowRadius: {},\n        shadowMapSize: {}\n      }\n    },\n    spotLightMap: {\n      value: []\n    },\n    spotShadowMap: {\n      value: []\n    },\n    spotLightMatrix: {\n      value: []\n    },\n    pointLights: {\n      value: [],\n      properties: {\n        color: {},\n        position: {},\n        decay: {},\n        distance: {}\n      }\n    },\n    pointLightShadows: {\n      value: [],\n      properties: {\n        shadowIntensity: 1,\n        shadowBias: {},\n        shadowNormalBias: {},\n        shadowRadius: {},\n        shadowMapSize: {},\n        shadowCameraNear: {},\n        shadowCameraFar: {}\n      }\n    },\n    pointShadowMap: {\n      value: []\n    },\n    pointShadowMatrix: {\n      value: []\n    },\n    hemisphereLights: {\n      value: [],\n      properties: {\n        direction: {},\n        skyColor: {},\n        groundColor: {}\n      }\n    },\n    // TODO (abelnation): RectAreaLight BRDF data needs to be moved from example to main src\n    rectAreaLights: {\n      value: [],\n      properties: {\n        color: {},\n        position: {},\n        width: {},\n        height: {}\n      }\n    },\n    ltc_1: {\n      value: null\n    },\n    ltc_2: {\n      value: null\n    }\n  },\n  points: {\n    diffuse: {\n      value: /*@__PURE__*/new Color(0xffffff)\n    },\n    opacity: {\n      value: 1.0\n    },\n    size: {\n      value: 1.0\n    },\n    scale: {\n      value: 1.0\n    },\n    map: {\n      value: null\n    },\n    alphaMap: {\n      value: null\n    },\n    alphaMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    alphaTest: {\n      value: 0\n    },\n    uvTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  },\n  sprite: {\n    diffuse: {\n      value: /*@__PURE__*/new Color(0xffffff)\n    },\n    opacity: {\n      value: 1.0\n    },\n    center: {\n      value: /*@__PURE__*/new Vector2(0.5, 0.5)\n    },\n    rotation: {\n      value: 0.0\n    },\n    map: {\n      value: null\n    },\n    mapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    alphaMap: {\n      value: null\n    },\n    alphaMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    alphaTest: {\n      value: 0\n    }\n  }\n};\nconst ShaderLib = {\n  basic: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.specularmap, UniformsLib.envmap, UniformsLib.aomap, UniformsLib.lightmap, UniformsLib.fog]),\n    vertexShader: ShaderChunk.meshbasic_vert,\n    fragmentShader: ShaderChunk.meshbasic_frag\n  },\n  lambert: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.specularmap, UniformsLib.envmap, UniformsLib.aomap, UniformsLib.lightmap, UniformsLib.emissivemap, UniformsLib.bumpmap, UniformsLib.normalmap, UniformsLib.displacementmap, UniformsLib.fog, UniformsLib.lights, {\n      emissive: {\n        value: /*@__PURE__*/new Color(0x000000)\n      }\n    }]),\n    vertexShader: ShaderChunk.meshlambert_vert,\n    fragmentShader: ShaderChunk.meshlambert_frag\n  },\n  phong: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.specularmap, UniformsLib.envmap, UniformsLib.aomap, UniformsLib.lightmap, UniformsLib.emissivemap, UniformsLib.bumpmap, UniformsLib.normalmap, UniformsLib.displacementmap, UniformsLib.fog, UniformsLib.lights, {\n      emissive: {\n        value: /*@__PURE__*/new Color(0x000000)\n      },\n      specular: {\n        value: /*@__PURE__*/new Color(0x111111)\n      },\n      shininess: {\n        value: 30\n      }\n    }]),\n    vertexShader: ShaderChunk.meshphong_vert,\n    fragmentShader: ShaderChunk.meshphong_frag\n  },\n  standard: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.envmap, UniformsLib.aomap, UniformsLib.lightmap, UniformsLib.emissivemap, UniformsLib.bumpmap, UniformsLib.normalmap, UniformsLib.displacementmap, UniformsLib.roughnessmap, UniformsLib.metalnessmap, UniformsLib.fog, UniformsLib.lights, {\n      emissive: {\n        value: /*@__PURE__*/new Color(0x000000)\n      },\n      roughness: {\n        value: 1.0\n      },\n      metalness: {\n        value: 0.0\n      },\n      envMapIntensity: {\n        value: 1\n      }\n    }]),\n    vertexShader: ShaderChunk.meshphysical_vert,\n    fragmentShader: ShaderChunk.meshphysical_frag\n  },\n  toon: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.aomap, UniformsLib.lightmap, UniformsLib.emissivemap, UniformsLib.bumpmap, UniformsLib.normalmap, UniformsLib.displacementmap, UniformsLib.gradientmap, UniformsLib.fog, UniformsLib.lights, {\n      emissive: {\n        value: /*@__PURE__*/new Color(0x000000)\n      }\n    }]),\n    vertexShader: ShaderChunk.meshtoon_vert,\n    fragmentShader: ShaderChunk.meshtoon_frag\n  },\n  matcap: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.bumpmap, UniformsLib.normalmap, UniformsLib.displacementmap, UniformsLib.fog, {\n      matcap: {\n        value: null\n      }\n    }]),\n    vertexShader: ShaderChunk.meshmatcap_vert,\n    fragmentShader: ShaderChunk.meshmatcap_frag\n  },\n  points: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.points, UniformsLib.fog]),\n    vertexShader: ShaderChunk.points_vert,\n    fragmentShader: ShaderChunk.points_frag\n  },\n  dashed: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.fog, {\n      scale: {\n        value: 1\n      },\n      dashSize: {\n        value: 1\n      },\n      totalSize: {\n        value: 2\n      }\n    }]),\n    vertexShader: ShaderChunk.linedashed_vert,\n    fragmentShader: ShaderChunk.linedashed_frag\n  },\n  depth: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.displacementmap]),\n    vertexShader: ShaderChunk.depth_vert,\n    fragmentShader: ShaderChunk.depth_frag\n  },\n  normal: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.bumpmap, UniformsLib.normalmap, UniformsLib.displacementmap, {\n      opacity: {\n        value: 1.0\n      }\n    }]),\n    vertexShader: ShaderChunk.meshnormal_vert,\n    fragmentShader: ShaderChunk.meshnormal_frag\n  },\n  sprite: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.sprite, UniformsLib.fog]),\n    vertexShader: ShaderChunk.sprite_vert,\n    fragmentShader: ShaderChunk.sprite_frag\n  },\n  background: {\n    uniforms: {\n      uvTransform: {\n        value: /*@__PURE__*/new Matrix3()\n      },\n      t2D: {\n        value: null\n      },\n      backgroundIntensity: {\n        value: 1\n      }\n    },\n    vertexShader: ShaderChunk.background_vert,\n    fragmentShader: ShaderChunk.background_frag\n  },\n  backgroundCube: {\n    uniforms: {\n      envMap: {\n        value: null\n      },\n      flipEnvMap: {\n        value: -1\n      },\n      backgroundBlurriness: {\n        value: 0\n      },\n      backgroundIntensity: {\n        value: 1\n      },\n      backgroundRotation: {\n        value: /*@__PURE__*/new Matrix3()\n      }\n    },\n    vertexShader: ShaderChunk.backgroundCube_vert,\n    fragmentShader: ShaderChunk.backgroundCube_frag\n  },\n  cube: {\n    uniforms: {\n      tCube: {\n        value: null\n      },\n      tFlip: {\n        value: -1\n      },\n      opacity: {\n        value: 1.0\n      }\n    },\n    vertexShader: ShaderChunk.cube_vert,\n    fragmentShader: ShaderChunk.cube_frag\n  },\n  equirect: {\n    uniforms: {\n      tEquirect: {\n        value: null\n      }\n    },\n    vertexShader: ShaderChunk.equirect_vert,\n    fragmentShader: ShaderChunk.equirect_frag\n  },\n  distanceRGBA: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.common, UniformsLib.displacementmap, {\n      referencePosition: {\n        value: /*@__PURE__*/new Vector3()\n      },\n      nearDistance: {\n        value: 1\n      },\n      farDistance: {\n        value: 1000\n      }\n    }]),\n    vertexShader: ShaderChunk.distanceRGBA_vert,\n    fragmentShader: ShaderChunk.distanceRGBA_frag\n  },\n  shadow: {\n    uniforms: /*@__PURE__*/mergeUniforms([UniformsLib.lights, UniformsLib.fog, {\n      color: {\n        value: /*@__PURE__*/new Color(0x00000)\n      },\n      opacity: {\n        value: 1.0\n      }\n    }]),\n    vertexShader: ShaderChunk.shadow_vert,\n    fragmentShader: ShaderChunk.shadow_frag\n  }\n};\nShaderLib.physical = {\n  uniforms: /*@__PURE__*/mergeUniforms([ShaderLib.standard.uniforms, {\n    clearcoat: {\n      value: 0\n    },\n    clearcoatMap: {\n      value: null\n    },\n    clearcoatMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    clearcoatNormalMap: {\n      value: null\n    },\n    clearcoatNormalMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    clearcoatNormalScale: {\n      value: /*@__PURE__*/new Vector2(1, 1)\n    },\n    clearcoatRoughness: {\n      value: 0\n    },\n    clearcoatRoughnessMap: {\n      value: null\n    },\n    clearcoatRoughnessMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    dispersion: {\n      value: 0\n    },\n    iridescence: {\n      value: 0\n    },\n    iridescenceMap: {\n      value: null\n    },\n    iridescenceMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    iridescenceIOR: {\n      value: 1.3\n    },\n    iridescenceThicknessMinimum: {\n      value: 100\n    },\n    iridescenceThicknessMaximum: {\n      value: 400\n    },\n    iridescenceThicknessMap: {\n      value: null\n    },\n    iridescenceThicknessMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    sheen: {\n      value: 0\n    },\n    sheenColor: {\n      value: /*@__PURE__*/new Color(0x000000)\n    },\n    sheenColorMap: {\n      value: null\n    },\n    sheenColorMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    sheenRoughness: {\n      value: 1\n    },\n    sheenRoughnessMap: {\n      value: null\n    },\n    sheenRoughnessMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    transmission: {\n      value: 0\n    },\n    transmissionMap: {\n      value: null\n    },\n    transmissionMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    transmissionSamplerSize: {\n      value: /*@__PURE__*/new Vector2()\n    },\n    transmissionSamplerMap: {\n      value: null\n    },\n    thickness: {\n      value: 0\n    },\n    thicknessMap: {\n      value: null\n    },\n    thicknessMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    attenuationDistance: {\n      value: 0\n    },\n    attenuationColor: {\n      value: /*@__PURE__*/new Color(0x000000)\n    },\n    specularColor: {\n      value: /*@__PURE__*/new Color(1, 1, 1)\n    },\n    specularColorMap: {\n      value: null\n    },\n    specularColorMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    specularIntensity: {\n      value: 1\n    },\n    specularIntensityMap: {\n      value: null\n    },\n    specularIntensityMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    },\n    anisotropyVector: {\n      value: /*@__PURE__*/new Vector2()\n    },\n    anisotropyMap: {\n      value: null\n    },\n    anisotropyMapTransform: {\n      value: /*@__PURE__*/new Matrix3()\n    }\n  }]),\n  vertexShader: ShaderChunk.meshphysical_vert,\n  fragmentShader: ShaderChunk.meshphysical_frag\n};\nconst _rgb = {\n  r: 0,\n  b: 0,\n  g: 0\n};\nconst _e1$1 = /*@__PURE__*/new Euler();\nconst _m1$1 = /*@__PURE__*/new Matrix4();\nfunction WebGLBackground(renderer, cubemaps, cubeuvmaps, state, objects, alpha, premultipliedAlpha) {\n  const clearColor = new Color(0x000000);\n  let clearAlpha = alpha === true ? 0 : 1;\n  let planeMesh;\n  let boxMesh;\n  let currentBackground = null;\n  let currentBackgroundVersion = 0;\n  let currentTonemapping = null;\n  function getBackground(scene) {\n    let background = scene.isScene === true ? scene.background : null;\n    if (background && background.isTexture) {\n      const usePMREM = scene.backgroundBlurriness > 0; // use PMREM if the user wants to blur the background\n      background = (usePMREM ? cubeuvmaps : cubemaps).get(background);\n    }\n    return background;\n  }\n  function render(scene) {\n    let forceClear = false;\n    const background = getBackground(scene);\n    if (background === null) {\n      setClear(clearColor, clearAlpha);\n    } else if (background && background.isColor) {\n      setClear(background, 1);\n      forceClear = true;\n    }\n    const environmentBlendMode = renderer.xr.getEnvironmentBlendMode();\n    if (environmentBlendMode === 'additive') {\n      state.buffers.color.setClear(0, 0, 0, 1, premultipliedAlpha);\n    } else if (environmentBlendMode === 'alpha-blend') {\n      state.buffers.color.setClear(0, 0, 0, 0, premultipliedAlpha);\n    }\n    if (renderer.autoClear || forceClear) {\n      // buffers might not be writable which is required to ensure a correct clear\n\n      state.buffers.depth.setTest(true);\n      state.buffers.depth.setMask(true);\n      state.buffers.color.setMask(true);\n      renderer.clear(renderer.autoClearColor, renderer.autoClearDepth, renderer.autoClearStencil);\n    }\n  }\n  function addToRenderList(renderList, scene) {\n    const background = getBackground(scene);\n    if (background && (background.isCubeTexture || background.mapping === CubeUVReflectionMapping)) {\n      if (boxMesh === undefined) {\n        boxMesh = new Mesh(new BoxGeometry(1, 1, 1), new ShaderMaterial({\n          name: 'BackgroundCubeMaterial',\n          uniforms: cloneUniforms(ShaderLib.backgroundCube.uniforms),\n          vertexShader: ShaderLib.backgroundCube.vertexShader,\n          fragmentShader: ShaderLib.backgroundCube.fragmentShader,\n          side: BackSide,\n          depthTest: false,\n          depthWrite: false,\n          fog: false\n        }));\n        boxMesh.geometry.deleteAttribute('normal');\n        boxMesh.geometry.deleteAttribute('uv');\n        boxMesh.onBeforeRender = function (renderer, scene, camera) {\n          this.matrixWorld.copyPosition(camera.matrixWorld);\n        };\n\n        // add \"envMap\" material property so the renderer can evaluate it like for built-in materials\n        Object.defineProperty(boxMesh.material, 'envMap', {\n          get: function () {\n            return this.uniforms.envMap.value;\n          }\n        });\n        objects.update(boxMesh);\n      }\n      _e1$1.copy(scene.backgroundRotation);\n\n      // accommodate left-handed frame\n      _e1$1.x *= -1;\n      _e1$1.y *= -1;\n      _e1$1.z *= -1;\n      if (background.isCubeTexture && background.isRenderTargetTexture === false) {\n        // environment maps which are not cube render targets or PMREMs follow a different convention\n        _e1$1.y *= -1;\n        _e1$1.z *= -1;\n      }\n      boxMesh.material.uniforms.envMap.value = background;\n      boxMesh.material.uniforms.flipEnvMap.value = background.isCubeTexture && background.isRenderTargetTexture === false ? -1 : 1;\n      boxMesh.material.uniforms.backgroundBlurriness.value = scene.backgroundBlurriness;\n      boxMesh.material.uniforms.backgroundIntensity.value = scene.backgroundIntensity;\n      boxMesh.material.uniforms.backgroundRotation.value.setFromMatrix4(_m1$1.makeRotationFromEuler(_e1$1));\n      boxMesh.material.toneMapped = ColorManagement.getTransfer(background.colorSpace) !== SRGBTransfer;\n      if (currentBackground !== background || currentBackgroundVersion !== background.version || currentTonemapping !== renderer.toneMapping) {\n        boxMesh.material.needsUpdate = true;\n        currentBackground = background;\n        currentBackgroundVersion = background.version;\n        currentTonemapping = renderer.toneMapping;\n      }\n      boxMesh.layers.enableAll();\n\n      // push to the pre-sorted opaque render list\n      renderList.unshift(boxMesh, boxMesh.geometry, boxMesh.material, 0, 0, null);\n    } else if (background && background.isTexture) {\n      if (planeMesh === undefined) {\n        planeMesh = new Mesh(new PlaneGeometry(2, 2), new ShaderMaterial({\n          name: 'BackgroundMaterial',\n          uniforms: cloneUniforms(ShaderLib.background.uniforms),\n          vertexShader: ShaderLib.background.vertexShader,\n          fragmentShader: ShaderLib.background.fragmentShader,\n          side: FrontSide,\n          depthTest: false,\n          depthWrite: false,\n          fog: false\n        }));\n        planeMesh.geometry.deleteAttribute('normal');\n\n        // add \"map\" material property so the renderer can evaluate it like for built-in materials\n        Object.defineProperty(planeMesh.material, 'map', {\n          get: function () {\n            return this.uniforms.t2D.value;\n          }\n        });\n        objects.update(planeMesh);\n      }\n      planeMesh.material.uniforms.t2D.value = background;\n      planeMesh.material.uniforms.backgroundIntensity.value = scene.backgroundIntensity;\n      planeMesh.material.toneMapped = ColorManagement.getTransfer(background.colorSpace) !== SRGBTransfer;\n      if (background.matrixAutoUpdate === true) {\n        background.updateMatrix();\n      }\n      planeMesh.material.uniforms.uvTransform.value.copy(background.matrix);\n      if (currentBackground !== background || currentBackgroundVersion !== background.version || currentTonemapping !== renderer.toneMapping) {\n        planeMesh.material.needsUpdate = true;\n        currentBackground = background;\n        currentBackgroundVersion = background.version;\n        currentTonemapping = renderer.toneMapping;\n      }\n      planeMesh.layers.enableAll();\n\n      // push to the pre-sorted opaque render list\n      renderList.unshift(planeMesh, planeMesh.geometry, planeMesh.material, 0, 0, null);\n    }\n  }\n  function setClear(color, alpha) {\n    color.getRGB(_rgb, getUnlitUniformColorSpace(renderer));\n    state.buffers.color.setClear(_rgb.r, _rgb.g, _rgb.b, alpha, premultipliedAlpha);\n  }\n  return {\n    getClearColor: function () {\n      return clearColor;\n    },\n    setClearColor: function (color, alpha = 1) {\n      clearColor.set(color);\n      clearAlpha = alpha;\n      setClear(clearColor, clearAlpha);\n    },\n    getClearAlpha: function () {\n      return clearAlpha;\n    },\n    setClearAlpha: function (alpha) {\n      clearAlpha = alpha;\n      setClear(clearColor, clearAlpha);\n    },\n    render: render,\n    addToRenderList: addToRenderList\n  };\n}\nfunction WebGLBindingStates(gl, attributes) {\n  const maxVertexAttributes = gl.getParameter(gl.MAX_VERTEX_ATTRIBS);\n  const bindingStates = {};\n  const defaultState = createBindingState(null);\n  let currentState = defaultState;\n  let forceUpdate = false;\n  function setup(object, material, program, geometry, index) {\n    let updateBuffers = false;\n    const state = getBindingState(geometry, program, material);\n    if (currentState !== state) {\n      currentState = state;\n      bindVertexArrayObject(currentState.object);\n    }\n    updateBuffers = needsUpdate(object, geometry, program, index);\n    if (updateBuffers) saveCache(object, geometry, program, index);\n    if (index !== null) {\n      attributes.update(index, gl.ELEMENT_ARRAY_BUFFER);\n    }\n    if (updateBuffers || forceUpdate) {\n      forceUpdate = false;\n      setupVertexAttributes(object, material, program, geometry);\n      if (index !== null) {\n        gl.bindBuffer(gl.ELEMENT_ARRAY_BUFFER, attributes.get(index).buffer);\n      }\n    }\n  }\n  function createVertexArrayObject() {\n    return gl.createVertexArray();\n  }\n  function bindVertexArrayObject(vao) {\n    return gl.bindVertexArray(vao);\n  }\n  function deleteVertexArrayObject(vao) {\n    return gl.deleteVertexArray(vao);\n  }\n  function getBindingState(geometry, program, material) {\n    const wireframe = material.wireframe === true;\n    let programMap = bindingStates[geometry.id];\n    if (programMap === undefined) {\n      programMap = {};\n      bindingStates[geometry.id] = programMap;\n    }\n    let stateMap = programMap[program.id];\n    if (stateMap === undefined) {\n      stateMap = {};\n      programMap[program.id] = stateMap;\n    }\n    let state = stateMap[wireframe];\n    if (state === undefined) {\n      state = createBindingState(createVertexArrayObject());\n      stateMap[wireframe] = state;\n    }\n    return state;\n  }\n  function createBindingState(vao) {\n    const newAttributes = [];\n    const enabledAttributes = [];\n    const attributeDivisors = [];\n    for (let i = 0; i < maxVertexAttributes; i++) {\n      newAttributes[i] = 0;\n      enabledAttributes[i] = 0;\n      attributeDivisors[i] = 0;\n    }\n    return {\n      // for backward compatibility on non-VAO support browser\n      geometry: null,\n      program: null,\n      wireframe: false,\n      newAttributes: newAttributes,\n      enabledAttributes: enabledAttributes,\n      attributeDivisors: attributeDivisors,\n      object: vao,\n      attributes: {},\n      index: null\n    };\n  }\n  function needsUpdate(object, geometry, program, index) {\n    const cachedAttributes = currentState.attributes;\n    const geometryAttributes = geometry.attributes;\n    let attributesNum = 0;\n    const programAttributes = program.getAttributes();\n    for (const name in programAttributes) {\n      const programAttribute = programAttributes[name];\n      if (programAttribute.location >= 0) {\n        const cachedAttribute = cachedAttributes[name];\n        let geometryAttribute = geometryAttributes[name];\n        if (geometryAttribute === undefined) {\n          if (name === 'instanceMatrix' && object.instanceMatrix) geometryAttribute = object.instanceMatrix;\n          if (name === 'instanceColor' && object.instanceColor) geometryAttribute = object.instanceColor;\n        }\n        if (cachedAttribute === undefined) return true;\n        if (cachedAttribute.attribute !== geometryAttribute) return true;\n        if (geometryAttribute && cachedAttribute.data !== geometryAttribute.data) return true;\n        attributesNum++;\n      }\n    }\n    if (currentState.attributesNum !== attributesNum) return true;\n    if (currentState.index !== index) return true;\n    return false;\n  }\n  function saveCache(object, geometry, program, index) {\n    const cache = {};\n    const attributes = geometry.attributes;\n    let attributesNum = 0;\n    const programAttributes = program.getAttributes();\n    for (const name in programAttributes) {\n      const programAttribute = programAttributes[name];\n      if (programAttribute.location >= 0) {\n        let attribute = attributes[name];\n        if (attribute === undefined) {\n          if (name === 'instanceMatrix' && object.instanceMatrix) attribute = object.instanceMatrix;\n          if (name === 'instanceColor' && object.instanceColor) attribute = object.instanceColor;\n        }\n        const data = {};\n        data.attribute = attribute;\n        if (attribute && attribute.data) {\n          data.data = attribute.data;\n        }\n        cache[name] = data;\n        attributesNum++;\n      }\n    }\n    currentState.attributes = cache;\n    currentState.attributesNum = attributesNum;\n    currentState.index = index;\n  }\n  function initAttributes() {\n    const newAttributes = currentState.newAttributes;\n    for (let i = 0, il = newAttributes.length; i < il; i++) {\n      newAttributes[i] = 0;\n    }\n  }\n  function enableAttribute(attribute) {\n    enableAttributeAndDivisor(attribute, 0);\n  }\n  function enableAttributeAndDivisor(attribute, meshPerAttribute) {\n    const newAttributes = currentState.newAttributes;\n    const enabledAttributes = currentState.enabledAttributes;\n    const attributeDivisors = currentState.attributeDivisors;\n    newAttributes[attribute] = 1;\n    if (enabledAttributes[attribute] === 0) {\n      gl.enableVertexAttribArray(attribute);\n      enabledAttributes[attribute] = 1;\n    }\n    if (attributeDivisors[attribute] !== meshPerAttribute) {\n      gl.vertexAttribDivisor(attribute, meshPerAttribute);\n      attributeDivisors[attribute] = meshPerAttribute;\n    }\n  }\n  function disableUnusedAttributes() {\n    const newAttributes = currentState.newAttributes;\n    const enabledAttributes = currentState.enabledAttributes;\n    for (let i = 0, il = enabledAttributes.length; i < il; i++) {\n      if (enabledAttributes[i] !== newAttributes[i]) {\n        gl.disableVertexAttribArray(i);\n        enabledAttributes[i] = 0;\n      }\n    }\n  }\n  function vertexAttribPointer(index, size, type, normalized, stride, offset, integer) {\n    if (integer === true) {\n      gl.vertexAttribIPointer(index, size, type, stride, offset);\n    } else {\n      gl.vertexAttribPointer(index, size, type, normalized, stride, offset);\n    }\n  }\n  function setupVertexAttributes(object, material, program, geometry) {\n    initAttributes();\n    const geometryAttributes = geometry.attributes;\n    const programAttributes = program.getAttributes();\n    const materialDefaultAttributeValues = material.defaultAttributeValues;\n    for (const name in programAttributes) {\n      const programAttribute = programAttributes[name];\n      if (programAttribute.location >= 0) {\n        let geometryAttribute = geometryAttributes[name];\n        if (geometryAttribute === undefined) {\n          if (name === 'instanceMatrix' && object.instanceMatrix) geometryAttribute = object.instanceMatrix;\n          if (name === 'instanceColor' && object.instanceColor) geometryAttribute = object.instanceColor;\n        }\n        if (geometryAttribute !== undefined) {\n          const normalized = geometryAttribute.normalized;\n          const size = geometryAttribute.itemSize;\n          const attribute = attributes.get(geometryAttribute);\n\n          // TODO Attribute may not be available on context restore\n\n          if (attribute === undefined) continue;\n          const buffer = attribute.buffer;\n          const type = attribute.type;\n          const bytesPerElement = attribute.bytesPerElement;\n\n          // check for integer attributes\n\n          const integer = type === gl.INT || type === gl.UNSIGNED_INT || geometryAttribute.gpuType === IntType;\n          if (geometryAttribute.isInterleavedBufferAttribute) {\n            const data = geometryAttribute.data;\n            const stride = data.stride;\n            const offset = geometryAttribute.offset;\n            if (data.isInstancedInterleavedBuffer) {\n              for (let i = 0; i < programAttribute.locationSize; i++) {\n                enableAttributeAndDivisor(programAttribute.location + i, data.meshPerAttribute);\n              }\n              if (object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined) {\n                geometry._maxInstanceCount = data.meshPerAttribute * data.count;\n              }\n            } else {\n              for (let i = 0; i < programAttribute.locationSize; i++) {\n                enableAttribute(programAttribute.location + i);\n              }\n            }\n            gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n            for (let i = 0; i < programAttribute.locationSize; i++) {\n              vertexAttribPointer(programAttribute.location + i, size / programAttribute.locationSize, type, normalized, stride * bytesPerElement, (offset + size / programAttribute.locationSize * i) * bytesPerElement, integer);\n            }\n          } else {\n            if (geometryAttribute.isInstancedBufferAttribute) {\n              for (let i = 0; i < programAttribute.locationSize; i++) {\n                enableAttributeAndDivisor(programAttribute.location + i, geometryAttribute.meshPerAttribute);\n              }\n              if (object.isInstancedMesh !== true && geometry._maxInstanceCount === undefined) {\n                geometry._maxInstanceCount = geometryAttribute.meshPerAttribute * geometryAttribute.count;\n              }\n            } else {\n              for (let i = 0; i < programAttribute.locationSize; i++) {\n                enableAttribute(programAttribute.location + i);\n              }\n            }\n            gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n            for (let i = 0; i < programAttribute.locationSize; i++) {\n              vertexAttribPointer(programAttribute.location + i, size / programAttribute.locationSize, type, normalized, size * bytesPerElement, size / programAttribute.locationSize * i * bytesPerElement, integer);\n            }\n          }\n        } else if (materialDefaultAttributeValues !== undefined) {\n          const value = materialDefaultAttributeValues[name];\n          if (value !== undefined) {\n            switch (value.length) {\n              case 2:\n                gl.vertexAttrib2fv(programAttribute.location, value);\n                break;\n              case 3:\n                gl.vertexAttrib3fv(programAttribute.location, value);\n                break;\n              case 4:\n                gl.vertexAttrib4fv(programAttribute.location, value);\n                break;\n              default:\n                gl.vertexAttrib1fv(programAttribute.location, value);\n            }\n          }\n        }\n      }\n    }\n    disableUnusedAttributes();\n  }\n  function dispose() {\n    reset();\n    for (const geometryId in bindingStates) {\n      const programMap = bindingStates[geometryId];\n      for (const programId in programMap) {\n        const stateMap = programMap[programId];\n        for (const wireframe in stateMap) {\n          deleteVertexArrayObject(stateMap[wireframe].object);\n          delete stateMap[wireframe];\n        }\n        delete programMap[programId];\n      }\n      delete bindingStates[geometryId];\n    }\n  }\n  function releaseStatesOfGeometry(geometry) {\n    if (bindingStates[geometry.id] === undefined) return;\n    const programMap = bindingStates[geometry.id];\n    for (const programId in programMap) {\n      const stateMap = programMap[programId];\n      for (const wireframe in stateMap) {\n        deleteVertexArrayObject(stateMap[wireframe].object);\n        delete stateMap[wireframe];\n      }\n      delete programMap[programId];\n    }\n    delete bindingStates[geometry.id];\n  }\n  function releaseStatesOfProgram(program) {\n    for (const geometryId in bindingStates) {\n      const programMap = bindingStates[geometryId];\n      if (programMap[program.id] === undefined) continue;\n      const stateMap = programMap[program.id];\n      for (const wireframe in stateMap) {\n        deleteVertexArrayObject(stateMap[wireframe].object);\n        delete stateMap[wireframe];\n      }\n      delete programMap[program.id];\n    }\n  }\n  function reset() {\n    resetDefaultState();\n    forceUpdate = true;\n    if (currentState === defaultState) return;\n    currentState = defaultState;\n    bindVertexArrayObject(currentState.object);\n  }\n\n  // for backward-compatibility\n\n  function resetDefaultState() {\n    defaultState.geometry = null;\n    defaultState.program = null;\n    defaultState.wireframe = false;\n  }\n  return {\n    setup: setup,\n    reset: reset,\n    resetDefaultState: resetDefaultState,\n    dispose: dispose,\n    releaseStatesOfGeometry: releaseStatesOfGeometry,\n    releaseStatesOfProgram: releaseStatesOfProgram,\n    initAttributes: initAttributes,\n    enableAttribute: enableAttribute,\n    disableUnusedAttributes: disableUnusedAttributes\n  };\n}\nfunction WebGLBufferRenderer(gl, extensions, info) {\n  let mode;\n  function setMode(value) {\n    mode = value;\n  }\n  function render(start, count) {\n    gl.drawArrays(mode, start, count);\n    info.update(count, mode, 1);\n  }\n  function renderInstances(start, count, primcount) {\n    if (primcount === 0) return;\n    gl.drawArraysInstanced(mode, start, count, primcount);\n    info.update(count, mode, primcount);\n  }\n  function renderMultiDraw(starts, counts, drawCount) {\n    if (drawCount === 0) return;\n    const extension = extensions.get('WEBGL_multi_draw');\n    extension.multiDrawArraysWEBGL(mode, starts, 0, counts, 0, drawCount);\n    let elementCount = 0;\n    for (let i = 0; i < drawCount; i++) {\n      elementCount += counts[i];\n    }\n    info.update(elementCount, mode, 1);\n  }\n  function renderMultiDrawInstances(starts, counts, drawCount, primcount) {\n    if (drawCount === 0) return;\n    const extension = extensions.get('WEBGL_multi_draw');\n    if (extension === null) {\n      for (let i = 0; i < starts.length; i++) {\n        renderInstances(starts[i], counts[i], primcount[i]);\n      }\n    } else {\n      extension.multiDrawArraysInstancedWEBGL(mode, starts, 0, counts, 0, primcount, 0, drawCount);\n      let elementCount = 0;\n      for (let i = 0; i < drawCount; i++) {\n        elementCount += counts[i];\n      }\n      for (let i = 0; i < primcount.length; i++) {\n        info.update(elementCount, mode, primcount[i]);\n      }\n    }\n  }\n\n  //\n\n  this.setMode = setMode;\n  this.render = render;\n  this.renderInstances = renderInstances;\n  this.renderMultiDraw = renderMultiDraw;\n  this.renderMultiDrawInstances = renderMultiDrawInstances;\n}\nfunction WebGLCapabilities(gl, extensions, parameters, utils) {\n  let maxAnisotropy;\n  function getMaxAnisotropy() {\n    if (maxAnisotropy !== undefined) return maxAnisotropy;\n    if (extensions.has('EXT_texture_filter_anisotropic') === true) {\n      const extension = extensions.get('EXT_texture_filter_anisotropic');\n      maxAnisotropy = gl.getParameter(extension.MAX_TEXTURE_MAX_ANISOTROPY_EXT);\n    } else {\n      maxAnisotropy = 0;\n    }\n    return maxAnisotropy;\n  }\n  function textureFormatReadable(textureFormat) {\n    if (textureFormat !== RGBAFormat && utils.convert(textureFormat) !== gl.getParameter(gl.IMPLEMENTATION_COLOR_READ_FORMAT)) {\n      return false;\n    }\n    return true;\n  }\n  function textureTypeReadable(textureType) {\n    const halfFloatSupportedByExt = textureType === HalfFloatType && (extensions.has('EXT_color_buffer_half_float') || extensions.has('EXT_color_buffer_float'));\n    if (textureType !== UnsignedByteType && utils.convert(textureType) !== gl.getParameter(gl.IMPLEMENTATION_COLOR_READ_TYPE) &&\n    // Edge and Chrome Mac < 52 (#9513)\n    textureType !== FloatType && !halfFloatSupportedByExt) {\n      return false;\n    }\n    return true;\n  }\n  function getMaxPrecision(precision) {\n    if (precision === 'highp') {\n      if (gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.HIGH_FLOAT).precision > 0 && gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.HIGH_FLOAT).precision > 0) {\n        return 'highp';\n      }\n      precision = 'mediump';\n    }\n    if (precision === 'mediump') {\n      if (gl.getShaderPrecisionFormat(gl.VERTEX_SHADER, gl.MEDIUM_FLOAT).precision > 0 && gl.getShaderPrecisionFormat(gl.FRAGMENT_SHADER, gl.MEDIUM_FLOAT).precision > 0) {\n        return 'mediump';\n      }\n    }\n    return 'lowp';\n  }\n  let precision = parameters.precision !== undefined ? parameters.precision : 'highp';\n  const maxPrecision = getMaxPrecision(precision);\n  if (maxPrecision !== precision) {\n    console.warn('THREE.WebGLRenderer:', precision, 'not supported, using', maxPrecision, 'instead.');\n    precision = maxPrecision;\n  }\n  const logarithmicDepthBuffer = parameters.logarithmicDepthBuffer === true;\n  const reverseDepthBuffer = parameters.reverseDepthBuffer === true && extensions.has('EXT_clip_control');\n  if (reverseDepthBuffer === true) {\n    const ext = extensions.get('EXT_clip_control');\n    ext.clipControlEXT(ext.LOWER_LEFT_EXT, ext.ZERO_TO_ONE_EXT);\n  }\n  const maxTextures = gl.getParameter(gl.MAX_TEXTURE_IMAGE_UNITS);\n  const maxVertexTextures = gl.getParameter(gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS);\n  const maxTextureSize = gl.getParameter(gl.MAX_TEXTURE_SIZE);\n  const maxCubemapSize = gl.getParameter(gl.MAX_CUBE_MAP_TEXTURE_SIZE);\n  const maxAttributes = gl.getParameter(gl.MAX_VERTEX_ATTRIBS);\n  const maxVertexUniforms = gl.getParameter(gl.MAX_VERTEX_UNIFORM_VECTORS);\n  const maxVaryings = gl.getParameter(gl.MAX_VARYING_VECTORS);\n  const maxFragmentUniforms = gl.getParameter(gl.MAX_FRAGMENT_UNIFORM_VECTORS);\n  const vertexTextures = maxVertexTextures > 0;\n  const maxSamples = gl.getParameter(gl.MAX_SAMPLES);\n  return {\n    isWebGL2: true,\n    // keeping this for backwards compatibility\n\n    getMaxAnisotropy: getMaxAnisotropy,\n    getMaxPrecision: getMaxPrecision,\n    textureFormatReadable: textureFormatReadable,\n    textureTypeReadable: textureTypeReadable,\n    precision: precision,\n    logarithmicDepthBuffer: logarithmicDepthBuffer,\n    reverseDepthBuffer: reverseDepthBuffer,\n    maxTextures: maxTextures,\n    maxVertexTextures: maxVertexTextures,\n    maxTextureSize: maxTextureSize,\n    maxCubemapSize: maxCubemapSize,\n    maxAttributes: maxAttributes,\n    maxVertexUniforms: maxVertexUniforms,\n    maxVaryings: maxVaryings,\n    maxFragmentUniforms: maxFragmentUniforms,\n    vertexTextures: vertexTextures,\n    maxSamples: maxSamples\n  };\n}\nfunction WebGLClipping(properties) {\n  const scope = this;\n  let globalState = null,\n    numGlobalPlanes = 0,\n    localClippingEnabled = false,\n    renderingShadows = false;\n  const plane = new Plane(),\n    viewNormalMatrix = new Matrix3(),\n    uniform = {\n      value: null,\n      needsUpdate: false\n    };\n  this.uniform = uniform;\n  this.numPlanes = 0;\n  this.numIntersection = 0;\n  this.init = function (planes, enableLocalClipping) {\n    const enabled = planes.length !== 0 || enableLocalClipping ||\n    // enable state of previous frame - the clipping code has to\n    // run another frame in order to reset the state:\n    numGlobalPlanes !== 0 || localClippingEnabled;\n    localClippingEnabled = enableLocalClipping;\n    numGlobalPlanes = planes.length;\n    return enabled;\n  };\n  this.beginShadows = function () {\n    renderingShadows = true;\n    projectPlanes(null);\n  };\n  this.endShadows = function () {\n    renderingShadows = false;\n  };\n  this.setGlobalState = function (planes, camera) {\n    globalState = projectPlanes(planes, camera, 0);\n  };\n  this.setState = function (material, camera, useCache) {\n    const planes = material.clippingPlanes,\n      clipIntersection = material.clipIntersection,\n      clipShadows = material.clipShadows;\n    const materialProperties = properties.get(material);\n    if (!localClippingEnabled || planes === null || planes.length === 0 || renderingShadows && !clipShadows) {\n      // there's no local clipping\n\n      if (renderingShadows) {\n        // there's no global clipping\n\n        projectPlanes(null);\n      } else {\n        resetGlobalState();\n      }\n    } else {\n      const nGlobal = renderingShadows ? 0 : numGlobalPlanes,\n        lGlobal = nGlobal * 4;\n      let dstArray = materialProperties.clippingState || null;\n      uniform.value = dstArray; // ensure unique state\n\n      dstArray = projectPlanes(planes, camera, lGlobal, useCache);\n      for (let i = 0; i !== lGlobal; ++i) {\n        dstArray[i] = globalState[i];\n      }\n      materialProperties.clippingState = dstArray;\n      this.numIntersection = clipIntersection ? this.numPlanes : 0;\n      this.numPlanes += nGlobal;\n    }\n  };\n  function resetGlobalState() {\n    if (uniform.value !== globalState) {\n      uniform.value = globalState;\n      uniform.needsUpdate = numGlobalPlanes > 0;\n    }\n    scope.numPlanes = numGlobalPlanes;\n    scope.numIntersection = 0;\n  }\n  function projectPlanes(planes, camera, dstOffset, skipTransform) {\n    const nPlanes = planes !== null ? planes.length : 0;\n    let dstArray = null;\n    if (nPlanes !== 0) {\n      dstArray = uniform.value;\n      if (skipTransform !== true || dstArray === null) {\n        const flatSize = dstOffset + nPlanes * 4,\n          viewMatrix = camera.matrixWorldInverse;\n        viewNormalMatrix.getNormalMatrix(viewMatrix);\n        if (dstArray === null || dstArray.length < flatSize) {\n          dstArray = new Float32Array(flatSize);\n        }\n        for (let i = 0, i4 = dstOffset; i !== nPlanes; ++i, i4 += 4) {\n          plane.copy(planes[i]).applyMatrix4(viewMatrix, viewNormalMatrix);\n          plane.normal.toArray(dstArray, i4);\n          dstArray[i4 + 3] = plane.constant;\n        }\n      }\n      uniform.value = dstArray;\n      uniform.needsUpdate = true;\n    }\n    scope.numPlanes = nPlanes;\n    scope.numIntersection = 0;\n    return dstArray;\n  }\n}\nfunction WebGLCubeMaps(renderer) {\n  let cubemaps = new WeakMap();\n  function mapTextureMapping(texture, mapping) {\n    if (mapping === EquirectangularReflectionMapping) {\n      texture.mapping = CubeReflectionMapping;\n    } else if (mapping === EquirectangularRefractionMapping) {\n      texture.mapping = CubeRefractionMapping;\n    }\n    return texture;\n  }\n  function get(texture) {\n    if (texture && texture.isTexture) {\n      const mapping = texture.mapping;\n      if (mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping) {\n        if (cubemaps.has(texture)) {\n          const cubemap = cubemaps.get(texture).texture;\n          return mapTextureMapping(cubemap, texture.mapping);\n        } else {\n          const image = texture.image;\n          if (image && image.height > 0) {\n            const renderTarget = new WebGLCubeRenderTarget(image.height);\n            renderTarget.fromEquirectangularTexture(renderer, texture);\n            cubemaps.set(texture, renderTarget);\n            texture.addEventListener('dispose', onTextureDispose);\n            return mapTextureMapping(renderTarget.texture, texture.mapping);\n          } else {\n            // image not yet ready. try the conversion next frame\n\n            return null;\n          }\n        }\n      }\n    }\n    return texture;\n  }\n  function onTextureDispose(event) {\n    const texture = event.target;\n    texture.removeEventListener('dispose', onTextureDispose);\n    const cubemap = cubemaps.get(texture);\n    if (cubemap !== undefined) {\n      cubemaps.delete(texture);\n      cubemap.dispose();\n    }\n  }\n  function dispose() {\n    cubemaps = new WeakMap();\n  }\n  return {\n    get: get,\n    dispose: dispose\n  };\n}\nclass OrthographicCamera extends Camera {\n  constructor(left = -1, right = 1, top = 1, bottom = -1, near = 0.1, far = 2000) {\n    super();\n    this.isOrthographicCamera = true;\n    this.type = 'OrthographicCamera';\n    this.zoom = 1;\n    this.view = null;\n    this.left = left;\n    this.right = right;\n    this.top = top;\n    this.bottom = bottom;\n    this.near = near;\n    this.far = far;\n    this.updateProjectionMatrix();\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.left = source.left;\n    this.right = source.right;\n    this.top = source.top;\n    this.bottom = source.bottom;\n    this.near = source.near;\n    this.far = source.far;\n    this.zoom = source.zoom;\n    this.view = source.view === null ? null : Object.assign({}, source.view);\n    return this;\n  }\n  setViewOffset(fullWidth, fullHeight, x, y, width, height) {\n    if (this.view === null) {\n      this.view = {\n        enabled: true,\n        fullWidth: 1,\n        fullHeight: 1,\n        offsetX: 0,\n        offsetY: 0,\n        width: 1,\n        height: 1\n      };\n    }\n    this.view.enabled = true;\n    this.view.fullWidth = fullWidth;\n    this.view.fullHeight = fullHeight;\n    this.view.offsetX = x;\n    this.view.offsetY = y;\n    this.view.width = width;\n    this.view.height = height;\n    this.updateProjectionMatrix();\n  }\n  clearViewOffset() {\n    if (this.view !== null) {\n      this.view.enabled = false;\n    }\n    this.updateProjectionMatrix();\n  }\n  updateProjectionMatrix() {\n    const dx = (this.right - this.left) / (2 * this.zoom);\n    const dy = (this.top - this.bottom) / (2 * this.zoom);\n    const cx = (this.right + this.left) / 2;\n    const cy = (this.top + this.bottom) / 2;\n    let left = cx - dx;\n    let right = cx + dx;\n    let top = cy + dy;\n    let bottom = cy - dy;\n    if (this.view !== null && this.view.enabled) {\n      const scaleW = (this.right - this.left) / this.view.fullWidth / this.zoom;\n      const scaleH = (this.top - this.bottom) / this.view.fullHeight / this.zoom;\n      left += scaleW * this.view.offsetX;\n      right = left + scaleW * this.view.width;\n      top -= scaleH * this.view.offsetY;\n      bottom = top - scaleH * this.view.height;\n    }\n    this.projectionMatrix.makeOrthographic(left, right, top, bottom, this.near, this.far, this.coordinateSystem);\n    this.projectionMatrixInverse.copy(this.projectionMatrix).invert();\n  }\n  toJSON(meta) {\n    const data = super.toJSON(meta);\n    data.object.zoom = this.zoom;\n    data.object.left = this.left;\n    data.object.right = this.right;\n    data.object.top = this.top;\n    data.object.bottom = this.bottom;\n    data.object.near = this.near;\n    data.object.far = this.far;\n    if (this.view !== null) data.object.view = Object.assign({}, this.view);\n    return data;\n  }\n}\nconst LOD_MIN = 4;\n\n// The standard deviations (radians) associated with the extra mips. These are\n// chosen to approximate a Trowbridge-Reitz distribution function times the\n// geometric shadowing function. These sigma values squared must match the\n// variance #defines in cube_uv_reflection_fragment.glsl.js.\nconst EXTRA_LOD_SIGMA = [0.125, 0.215, 0.35, 0.446, 0.526, 0.582];\n\n// The maximum length of the blur for loop. Smaller sigmas will use fewer\n// samples and exit early, but not recompile the shader.\nconst MAX_SAMPLES$1 = 20;\nconst _flatCamera = /*@__PURE__*/new OrthographicCamera();\nconst _clearColor = /*@__PURE__*/new Color();\nlet _oldTarget = null;\nlet _oldActiveCubeFace = 0;\nlet _oldActiveMipmapLevel = 0;\nlet _oldXrEnabled = false;\n\n// Golden Ratio\nconst PHI = (1 + Math.sqrt(5)) / 2;\nconst INV_PHI = 1 / PHI;\n\n// Vertices of a dodecahedron (except the opposites, which represent the\n// same axis), used as axis directions evenly spread on a sphere.\nconst _axisDirections = [/*@__PURE__*/new Vector3(-PHI, INV_PHI, 0), /*@__PURE__*/new Vector3(PHI, INV_PHI, 0), /*@__PURE__*/new Vector3(-INV_PHI, 0, PHI), /*@__PURE__*/new Vector3(INV_PHI, 0, PHI), /*@__PURE__*/new Vector3(0, PHI, -INV_PHI), /*@__PURE__*/new Vector3(0, PHI, INV_PHI), /*@__PURE__*/new Vector3(-1, 1, -1), /*@__PURE__*/new Vector3(1, 1, -1), /*@__PURE__*/new Vector3(-1, 1, 1), /*@__PURE__*/new Vector3(1, 1, 1)];\n\n/**\n * This class generates a Prefiltered, Mipmapped Radiance Environment Map\n * (PMREM) from a cubeMap environment texture. This allows different levels of\n * blur to be quickly accessed based on material roughness. It is packed into a\n * special CubeUV format that allows us to perform custom interpolation so that\n * we can support nonlinear formats such as RGBE. Unlike a traditional mipmap\n * chain, it only goes down to the LOD_MIN level (above), and then creates extra\n * even more filtered 'mips' at the same LOD_MIN resolution, associated with\n * higher roughness levels. In this way we maintain resolution to smoothly\n * interpolate diffuse lighting while limiting sampling computation.\n *\n * Paper: Fast, Accurate Image-Based Lighting\n * https://drive.google.com/file/d/15y8r_UpKlU9SvV4ILb0C3qCPecS8pvLz/view\n*/\n\nclass PMREMGenerator {\n  constructor(renderer) {\n    this._renderer = renderer;\n    this._pingPongRenderTarget = null;\n    this._lodMax = 0;\n    this._cubeSize = 0;\n    this._lodPlanes = [];\n    this._sizeLods = [];\n    this._sigmas = [];\n    this._blurMaterial = null;\n    this._cubemapMaterial = null;\n    this._equirectMaterial = null;\n    this._compileMaterial(this._blurMaterial);\n  }\n\n  /**\n   * Generates a PMREM from a supplied Scene, which can be faster than using an\n   * image if networking bandwidth is low. Optional sigma specifies a blur radius\n   * in radians to be applied to the scene before PMREM generation. Optional near\n   * and far planes ensure the scene is rendered in its entirety (the cubeCamera\n   * is placed at the origin).\n   */\n  fromScene(scene, sigma = 0, near = 0.1, far = 100) {\n    _oldTarget = this._renderer.getRenderTarget();\n    _oldActiveCubeFace = this._renderer.getActiveCubeFace();\n    _oldActiveMipmapLevel = this._renderer.getActiveMipmapLevel();\n    _oldXrEnabled = this._renderer.xr.enabled;\n    this._renderer.xr.enabled = false;\n    this._setSize(256);\n    const cubeUVRenderTarget = this._allocateTargets();\n    cubeUVRenderTarget.depthBuffer = true;\n    this._sceneToCubeUV(scene, near, far, cubeUVRenderTarget);\n    if (sigma > 0) {\n      this._blur(cubeUVRenderTarget, 0, 0, sigma);\n    }\n    this._applyPMREM(cubeUVRenderTarget);\n    this._cleanup(cubeUVRenderTarget);\n    return cubeUVRenderTarget;\n  }\n\n  /**\n   * Generates a PMREM from an equirectangular texture, which can be either LDR\n   * or HDR. The ideal input image size is 1k (1024 x 512),\n   * as this matches best with the 256 x 256 cubemap output.\n   * The smallest supported equirectangular image size is 64 x 32.\n   */\n  fromEquirectangular(equirectangular, renderTarget = null) {\n    return this._fromTexture(equirectangular, renderTarget);\n  }\n\n  /**\n   * Generates a PMREM from an cubemap texture, which can be either LDR\n   * or HDR. The ideal input cube size is 256 x 256,\n   * as this matches best with the 256 x 256 cubemap output.\n   * The smallest supported cube size is 16 x 16.\n   */\n  fromCubemap(cubemap, renderTarget = null) {\n    return this._fromTexture(cubemap, renderTarget);\n  }\n\n  /**\n   * Pre-compiles the cubemap shader. You can get faster start-up by invoking this method during\n   * your texture's network fetch for increased concurrency.\n   */\n  compileCubemapShader() {\n    if (this._cubemapMaterial === null) {\n      this._cubemapMaterial = _getCubemapMaterial();\n      this._compileMaterial(this._cubemapMaterial);\n    }\n  }\n\n  /**\n   * Pre-compiles the equirectangular shader. You can get faster start-up by invoking this method during\n   * your texture's network fetch for increased concurrency.\n   */\n  compileEquirectangularShader() {\n    if (this._equirectMaterial === null) {\n      this._equirectMaterial = _getEquirectMaterial();\n      this._compileMaterial(this._equirectMaterial);\n    }\n  }\n\n  /**\n   * Disposes of the PMREMGenerator's internal memory. Note that PMREMGenerator is a static class,\n   * so you should not need more than one PMREMGenerator object. If you do, calling dispose() on\n   * one of them will cause any others to also become unusable.\n   */\n  dispose() {\n    this._dispose();\n    if (this._cubemapMaterial !== null) this._cubemapMaterial.dispose();\n    if (this._equirectMaterial !== null) this._equirectMaterial.dispose();\n  }\n\n  // private interface\n\n  _setSize(cubeSize) {\n    this._lodMax = Math.floor(Math.log2(cubeSize));\n    this._cubeSize = Math.pow(2, this._lodMax);\n  }\n  _dispose() {\n    if (this._blurMaterial !== null) this._blurMaterial.dispose();\n    if (this._pingPongRenderTarget !== null) this._pingPongRenderTarget.dispose();\n    for (let i = 0; i < this._lodPlanes.length; i++) {\n      this._lodPlanes[i].dispose();\n    }\n  }\n  _cleanup(outputTarget) {\n    this._renderer.setRenderTarget(_oldTarget, _oldActiveCubeFace, _oldActiveMipmapLevel);\n    this._renderer.xr.enabled = _oldXrEnabled;\n    outputTarget.scissorTest = false;\n    _setViewport(outputTarget, 0, 0, outputTarget.width, outputTarget.height);\n  }\n  _fromTexture(texture, renderTarget) {\n    if (texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping) {\n      this._setSize(texture.image.length === 0 ? 16 : texture.image[0].width || texture.image[0].image.width);\n    } else {\n      // Equirectangular\n\n      this._setSize(texture.image.width / 4);\n    }\n    _oldTarget = this._renderer.getRenderTarget();\n    _oldActiveCubeFace = this._renderer.getActiveCubeFace();\n    _oldActiveMipmapLevel = this._renderer.getActiveMipmapLevel();\n    _oldXrEnabled = this._renderer.xr.enabled;\n    this._renderer.xr.enabled = false;\n    const cubeUVRenderTarget = renderTarget || this._allocateTargets();\n    this._textureToCubeUV(texture, cubeUVRenderTarget);\n    this._applyPMREM(cubeUVRenderTarget);\n    this._cleanup(cubeUVRenderTarget);\n    return cubeUVRenderTarget;\n  }\n  _allocateTargets() {\n    const width = 3 * Math.max(this._cubeSize, 16 * 7);\n    const height = 4 * this._cubeSize;\n    const params = {\n      magFilter: LinearFilter,\n      minFilter: LinearFilter,\n      generateMipmaps: false,\n      type: HalfFloatType,\n      format: RGBAFormat,\n      colorSpace: LinearSRGBColorSpace,\n      depthBuffer: false\n    };\n    const cubeUVRenderTarget = _createRenderTarget(width, height, params);\n    if (this._pingPongRenderTarget === null || this._pingPongRenderTarget.width !== width || this._pingPongRenderTarget.height !== height) {\n      if (this._pingPongRenderTarget !== null) {\n        this._dispose();\n      }\n      this._pingPongRenderTarget = _createRenderTarget(width, height, params);\n      const {\n        _lodMax\n      } = this;\n      ({\n        sizeLods: this._sizeLods,\n        lodPlanes: this._lodPlanes,\n        sigmas: this._sigmas\n      } = _createPlanes(_lodMax));\n      this._blurMaterial = _getBlurShader(_lodMax, width, height);\n    }\n    return cubeUVRenderTarget;\n  }\n  _compileMaterial(material) {\n    const tmpMesh = new Mesh(this._lodPlanes[0], material);\n    this._renderer.compile(tmpMesh, _flatCamera);\n  }\n  _sceneToCubeUV(scene, near, far, cubeUVRenderTarget) {\n    const fov = 90;\n    const aspect = 1;\n    const cubeCamera = new PerspectiveCamera(fov, aspect, near, far);\n    const upSign = [1, -1, 1, 1, 1, 1];\n    const forwardSign = [1, 1, 1, -1, -1, -1];\n    const renderer = this._renderer;\n    const originalAutoClear = renderer.autoClear;\n    const toneMapping = renderer.toneMapping;\n    renderer.getClearColor(_clearColor);\n    renderer.toneMapping = NoToneMapping;\n    renderer.autoClear = false;\n    const backgroundMaterial = new MeshBasicMaterial({\n      name: 'PMREM.Background',\n      side: BackSide,\n      depthWrite: false,\n      depthTest: false\n    });\n    const backgroundBox = new Mesh(new BoxGeometry(), backgroundMaterial);\n    let useSolidColor = false;\n    const background = scene.background;\n    if (background) {\n      if (background.isColor) {\n        backgroundMaterial.color.copy(background);\n        scene.background = null;\n        useSolidColor = true;\n      }\n    } else {\n      backgroundMaterial.color.copy(_clearColor);\n      useSolidColor = true;\n    }\n    for (let i = 0; i < 6; i++) {\n      const col = i % 3;\n      if (col === 0) {\n        cubeCamera.up.set(0, upSign[i], 0);\n        cubeCamera.lookAt(forwardSign[i], 0, 0);\n      } else if (col === 1) {\n        cubeCamera.up.set(0, 0, upSign[i]);\n        cubeCamera.lookAt(0, forwardSign[i], 0);\n      } else {\n        cubeCamera.up.set(0, upSign[i], 0);\n        cubeCamera.lookAt(0, 0, forwardSign[i]);\n      }\n      const size = this._cubeSize;\n      _setViewport(cubeUVRenderTarget, col * size, i > 2 ? size : 0, size, size);\n      renderer.setRenderTarget(cubeUVRenderTarget);\n      if (useSolidColor) {\n        renderer.render(backgroundBox, cubeCamera);\n      }\n      renderer.render(scene, cubeCamera);\n    }\n    backgroundBox.geometry.dispose();\n    backgroundBox.material.dispose();\n    renderer.toneMapping = toneMapping;\n    renderer.autoClear = originalAutoClear;\n    scene.background = background;\n  }\n  _textureToCubeUV(texture, cubeUVRenderTarget) {\n    const renderer = this._renderer;\n    const isCubeTexture = texture.mapping === CubeReflectionMapping || texture.mapping === CubeRefractionMapping;\n    if (isCubeTexture) {\n      if (this._cubemapMaterial === null) {\n        this._cubemapMaterial = _getCubemapMaterial();\n      }\n      this._cubemapMaterial.uniforms.flipEnvMap.value = texture.isRenderTargetTexture === false ? -1 : 1;\n    } else {\n      if (this._equirectMaterial === null) {\n        this._equirectMaterial = _getEquirectMaterial();\n      }\n    }\n    const material = isCubeTexture ? this._cubemapMaterial : this._equirectMaterial;\n    const mesh = new Mesh(this._lodPlanes[0], material);\n    const uniforms = material.uniforms;\n    uniforms['envMap'].value = texture;\n    const size = this._cubeSize;\n    _setViewport(cubeUVRenderTarget, 0, 0, 3 * size, 2 * size);\n    renderer.setRenderTarget(cubeUVRenderTarget);\n    renderer.render(mesh, _flatCamera);\n  }\n  _applyPMREM(cubeUVRenderTarget) {\n    const renderer = this._renderer;\n    const autoClear = renderer.autoClear;\n    renderer.autoClear = false;\n    const n = this._lodPlanes.length;\n    for (let i = 1; i < n; i++) {\n      const sigma = Math.sqrt(this._sigmas[i] * this._sigmas[i] - this._sigmas[i - 1] * this._sigmas[i - 1]);\n      const poleAxis = _axisDirections[(n - i - 1) % _axisDirections.length];\n      this._blur(cubeUVRenderTarget, i - 1, i, sigma, poleAxis);\n    }\n    renderer.autoClear = autoClear;\n  }\n\n  /**\n   * This is a two-pass Gaussian blur for a cubemap. Normally this is done\n   * vertically and horizontally, but this breaks down on a cube. Here we apply\n   * the blur latitudinally (around the poles), and then longitudinally (towards\n   * the poles) to approximate the orthogonally-separable blur. It is least\n   * accurate at the poles, but still does a decent job.\n   */\n  _blur(cubeUVRenderTarget, lodIn, lodOut, sigma, poleAxis) {\n    const pingPongRenderTarget = this._pingPongRenderTarget;\n    this._halfBlur(cubeUVRenderTarget, pingPongRenderTarget, lodIn, lodOut, sigma, 'latitudinal', poleAxis);\n    this._halfBlur(pingPongRenderTarget, cubeUVRenderTarget, lodOut, lodOut, sigma, 'longitudinal', poleAxis);\n  }\n  _halfBlur(targetIn, targetOut, lodIn, lodOut, sigmaRadians, direction, poleAxis) {\n    const renderer = this._renderer;\n    const blurMaterial = this._blurMaterial;\n    if (direction !== 'latitudinal' && direction !== 'longitudinal') {\n      console.error('blur direction must be either latitudinal or longitudinal!');\n    }\n\n    // Number of standard deviations at which to cut off the discrete approximation.\n    const STANDARD_DEVIATIONS = 3;\n    const blurMesh = new Mesh(this._lodPlanes[lodOut], blurMaterial);\n    const blurUniforms = blurMaterial.uniforms;\n    const pixels = this._sizeLods[lodIn] - 1;\n    const radiansPerPixel = isFinite(sigmaRadians) ? Math.PI / (2 * pixels) : 2 * Math.PI / (2 * MAX_SAMPLES$1 - 1);\n    const sigmaPixels = sigmaRadians / radiansPerPixel;\n    const samples = isFinite(sigmaRadians) ? 1 + Math.floor(STANDARD_DEVIATIONS * sigmaPixels) : MAX_SAMPLES$1;\n    if (samples > MAX_SAMPLES$1) {\n      console.warn(`sigmaRadians, ${sigmaRadians}, is too large and will clip, as it requested ${samples} samples when the maximum is set to ${MAX_SAMPLES$1}`);\n    }\n    const weights = [];\n    let sum = 0;\n    for (let i = 0; i < MAX_SAMPLES$1; ++i) {\n      const x = i / sigmaPixels;\n      const weight = Math.exp(-x * x / 2);\n      weights.push(weight);\n      if (i === 0) {\n        sum += weight;\n      } else if (i < samples) {\n        sum += 2 * weight;\n      }\n    }\n    for (let i = 0; i < weights.length; i++) {\n      weights[i] = weights[i] / sum;\n    }\n    blurUniforms['envMap'].value = targetIn.texture;\n    blurUniforms['samples'].value = samples;\n    blurUniforms['weights'].value = weights;\n    blurUniforms['latitudinal'].value = direction === 'latitudinal';\n    if (poleAxis) {\n      blurUniforms['poleAxis'].value = poleAxis;\n    }\n    const {\n      _lodMax\n    } = this;\n    blurUniforms['dTheta'].value = radiansPerPixel;\n    blurUniforms['mipInt'].value = _lodMax - lodIn;\n    const outputSize = this._sizeLods[lodOut];\n    const x = 3 * outputSize * (lodOut > _lodMax - LOD_MIN ? lodOut - _lodMax + LOD_MIN : 0);\n    const y = 4 * (this._cubeSize - outputSize);\n    _setViewport(targetOut, x, y, 3 * outputSize, 2 * outputSize);\n    renderer.setRenderTarget(targetOut);\n    renderer.render(blurMesh, _flatCamera);\n  }\n}\nfunction _createPlanes(lodMax) {\n  const lodPlanes = [];\n  const sizeLods = [];\n  const sigmas = [];\n  let lod = lodMax;\n  const totalLods = lodMax - LOD_MIN + 1 + EXTRA_LOD_SIGMA.length;\n  for (let i = 0; i < totalLods; i++) {\n    const sizeLod = Math.pow(2, lod);\n    sizeLods.push(sizeLod);\n    let sigma = 1.0 / sizeLod;\n    if (i > lodMax - LOD_MIN) {\n      sigma = EXTRA_LOD_SIGMA[i - lodMax + LOD_MIN - 1];\n    } else if (i === 0) {\n      sigma = 0;\n    }\n    sigmas.push(sigma);\n    const texelSize = 1.0 / (sizeLod - 2);\n    const min = -texelSize;\n    const max = 1 + texelSize;\n    const uv1 = [min, min, max, min, max, max, min, min, max, max, min, max];\n    const cubeFaces = 6;\n    const vertices = 6;\n    const positionSize = 3;\n    const uvSize = 2;\n    const faceIndexSize = 1;\n    const position = new Float32Array(positionSize * vertices * cubeFaces);\n    const uv = new Float32Array(uvSize * vertices * cubeFaces);\n    const faceIndex = new Float32Array(faceIndexSize * vertices * cubeFaces);\n    for (let face = 0; face < cubeFaces; face++) {\n      const x = face % 3 * 2 / 3 - 1;\n      const y = face > 2 ? 0 : -1;\n      const coordinates = [x, y, 0, x + 2 / 3, y, 0, x + 2 / 3, y + 1, 0, x, y, 0, x + 2 / 3, y + 1, 0, x, y + 1, 0];\n      position.set(coordinates, positionSize * vertices * face);\n      uv.set(uv1, uvSize * vertices * face);\n      const fill = [face, face, face, face, face, face];\n      faceIndex.set(fill, faceIndexSize * vertices * face);\n    }\n    const planes = new BufferGeometry();\n    planes.setAttribute('position', new BufferAttribute(position, positionSize));\n    planes.setAttribute('uv', new BufferAttribute(uv, uvSize));\n    planes.setAttribute('faceIndex', new BufferAttribute(faceIndex, faceIndexSize));\n    lodPlanes.push(planes);\n    if (lod > LOD_MIN) {\n      lod--;\n    }\n  }\n  return {\n    lodPlanes,\n    sizeLods,\n    sigmas\n  };\n}\nfunction _createRenderTarget(width, height, params) {\n  const cubeUVRenderTarget = new WebGLRenderTarget(width, height, params);\n  cubeUVRenderTarget.texture.mapping = CubeUVReflectionMapping;\n  cubeUVRenderTarget.texture.name = 'PMREM.cubeUv';\n  cubeUVRenderTarget.scissorTest = true;\n  return cubeUVRenderTarget;\n}\nfunction _setViewport(target, x, y, width, height) {\n  target.viewport.set(x, y, width, height);\n  target.scissor.set(x, y, width, height);\n}\nfunction _getBlurShader(lodMax, width, height) {\n  const weights = new Float32Array(MAX_SAMPLES$1);\n  const poleAxis = new Vector3(0, 1, 0);\n  const shaderMaterial = new ShaderMaterial({\n    name: 'SphericalGaussianBlur',\n    defines: {\n      'n': MAX_SAMPLES$1,\n      'CUBEUV_TEXEL_WIDTH': 1.0 / width,\n      'CUBEUV_TEXEL_HEIGHT': 1.0 / height,\n      'CUBEUV_MAX_MIP': `${lodMax}.0`\n    },\n    uniforms: {\n      'envMap': {\n        value: null\n      },\n      'samples': {\n        value: 1\n      },\n      'weights': {\n        value: weights\n      },\n      'latitudinal': {\n        value: false\n      },\n      'dTheta': {\n        value: 0\n      },\n      'mipInt': {\n        value: 0\n      },\n      'poleAxis': {\n        value: poleAxis\n      }\n    },\n    vertexShader: _getCommonVertexShader(),\n    fragmentShader: /* glsl */`\n\n\t\t\tprecision mediump float;\n\t\t\tprecision mediump int;\n\n\t\t\tvarying vec3 vOutputDirection;\n\n\t\t\tuniform sampler2D envMap;\n\t\t\tuniform int samples;\n\t\t\tuniform float weights[ n ];\n\t\t\tuniform bool latitudinal;\n\t\t\tuniform float dTheta;\n\t\t\tuniform float mipInt;\n\t\t\tuniform vec3 poleAxis;\n\n\t\t\t#define ENVMAP_TYPE_CUBE_UV\n\t\t\t#include <cube_uv_reflection_fragment>\n\n\t\t\tvec3 getSample( float theta, vec3 axis ) {\n\n\t\t\t\tfloat cosTheta = cos( theta );\n\t\t\t\t// Rodrigues' axis-angle rotation\n\t\t\t\tvec3 sampleDirection = vOutputDirection * cosTheta\n\t\t\t\t\t+ cross( axis, vOutputDirection ) * sin( theta )\n\t\t\t\t\t+ axis * dot( axis, vOutputDirection ) * ( 1.0 - cosTheta );\n\n\t\t\t\treturn bilinearCubeUV( envMap, sampleDirection, mipInt );\n\n\t\t\t}\n\n\t\t\tvoid main() {\n\n\t\t\t\tvec3 axis = latitudinal ? poleAxis : cross( poleAxis, vOutputDirection );\n\n\t\t\t\tif ( all( equal( axis, vec3( 0.0 ) ) ) ) {\n\n\t\t\t\t\taxis = vec3( vOutputDirection.z, 0.0, - vOutputDirection.x );\n\n\t\t\t\t}\n\n\t\t\t\taxis = normalize( axis );\n\n\t\t\t\tgl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );\n\t\t\t\tgl_FragColor.rgb += weights[ 0 ] * getSample( 0.0, axis );\n\n\t\t\t\tfor ( int i = 1; i < n; i++ ) {\n\n\t\t\t\t\tif ( i >= samples ) {\n\n\t\t\t\t\t\tbreak;\n\n\t\t\t\t\t}\n\n\t\t\t\t\tfloat theta = dTheta * float( i );\n\t\t\t\t\tgl_FragColor.rgb += weights[ i ] * getSample( -1.0 * theta, axis );\n\t\t\t\t\tgl_FragColor.rgb += weights[ i ] * getSample( theta, axis );\n\n\t\t\t\t}\n\n\t\t\t}\n\t\t`,\n    blending: NoBlending,\n    depthTest: false,\n    depthWrite: false\n  });\n  return shaderMaterial;\n}\nfunction _getEquirectMaterial() {\n  return new ShaderMaterial({\n    name: 'EquirectangularToCubeUV',\n    uniforms: {\n      'envMap': {\n        value: null\n      }\n    },\n    vertexShader: _getCommonVertexShader(),\n    fragmentShader: /* glsl */`\n\n\t\t\tprecision mediump float;\n\t\t\tprecision mediump int;\n\n\t\t\tvarying vec3 vOutputDirection;\n\n\t\t\tuniform sampler2D envMap;\n\n\t\t\t#include <common>\n\n\t\t\tvoid main() {\n\n\t\t\t\tvec3 outputDirection = normalize( vOutputDirection );\n\t\t\t\tvec2 uv = equirectUv( outputDirection );\n\n\t\t\t\tgl_FragColor = vec4( texture2D ( envMap, uv ).rgb, 1.0 );\n\n\t\t\t}\n\t\t`,\n    blending: NoBlending,\n    depthTest: false,\n    depthWrite: false\n  });\n}\nfunction _getCubemapMaterial() {\n  return new ShaderMaterial({\n    name: 'CubemapToCubeUV',\n    uniforms: {\n      'envMap': {\n        value: null\n      },\n      'flipEnvMap': {\n        value: -1\n      }\n    },\n    vertexShader: _getCommonVertexShader(),\n    fragmentShader: /* glsl */`\n\n\t\t\tprecision mediump float;\n\t\t\tprecision mediump int;\n\n\t\t\tuniform float flipEnvMap;\n\n\t\t\tvarying vec3 vOutputDirection;\n\n\t\t\tuniform samplerCube envMap;\n\n\t\t\tvoid main() {\n\n\t\t\t\tgl_FragColor = textureCube( envMap, vec3( flipEnvMap * vOutputDirection.x, vOutputDirection.yz ) );\n\n\t\t\t}\n\t\t`,\n    blending: NoBlending,\n    depthTest: false,\n    depthWrite: false\n  });\n}\nfunction _getCommonVertexShader() {\n  return /* glsl */`\n\n\t\tprecision mediump float;\n\t\tprecision mediump int;\n\n\t\tattribute float faceIndex;\n\n\t\tvarying vec3 vOutputDirection;\n\n\t\t// RH coordinate system; PMREM face-indexing convention\n\t\tvec3 getDirection( vec2 uv, float face ) {\n\n\t\t\tuv = 2.0 * uv - 1.0;\n\n\t\t\tvec3 direction = vec3( uv, 1.0 );\n\n\t\t\tif ( face == 0.0 ) {\n\n\t\t\t\tdirection = direction.zyx; // ( 1, v, u ) pos x\n\n\t\t\t} else if ( face == 1.0 ) {\n\n\t\t\t\tdirection = direction.xzy;\n\t\t\t\tdirection.xz *= -1.0; // ( -u, 1, -v ) pos y\n\n\t\t\t} else if ( face == 2.0 ) {\n\n\t\t\t\tdirection.x *= -1.0; // ( -u, v, 1 ) pos z\n\n\t\t\t} else if ( face == 3.0 ) {\n\n\t\t\t\tdirection = direction.zyx;\n\t\t\t\tdirection.xz *= -1.0; // ( -1, v, -u ) neg x\n\n\t\t\t} else if ( face == 4.0 ) {\n\n\t\t\t\tdirection = direction.xzy;\n\t\t\t\tdirection.xy *= -1.0; // ( -u, -1, v ) neg y\n\n\t\t\t} else if ( face == 5.0 ) {\n\n\t\t\t\tdirection.z *= -1.0; // ( u, v, -1 ) neg z\n\n\t\t\t}\n\n\t\t\treturn direction;\n\n\t\t}\n\n\t\tvoid main() {\n\n\t\t\tvOutputDirection = getDirection( uv, faceIndex );\n\t\t\tgl_Position = vec4( position, 1.0 );\n\n\t\t}\n\t`;\n}\nfunction WebGLCubeUVMaps(renderer) {\n  let cubeUVmaps = new WeakMap();\n  let pmremGenerator = null;\n  function get(texture) {\n    if (texture && texture.isTexture) {\n      const mapping = texture.mapping;\n      const isEquirectMap = mapping === EquirectangularReflectionMapping || mapping === EquirectangularRefractionMapping;\n      const isCubeMap = mapping === CubeReflectionMapping || mapping === CubeRefractionMapping;\n\n      // equirect/cube map to cubeUV conversion\n\n      if (isEquirectMap || isCubeMap) {\n        let renderTarget = cubeUVmaps.get(texture);\n        const currentPMREMVersion = renderTarget !== undefined ? renderTarget.texture.pmremVersion : 0;\n        if (texture.isRenderTargetTexture && texture.pmremVersion !== currentPMREMVersion) {\n          if (pmremGenerator === null) pmremGenerator = new PMREMGenerator(renderer);\n          renderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular(texture, renderTarget) : pmremGenerator.fromCubemap(texture, renderTarget);\n          renderTarget.texture.pmremVersion = texture.pmremVersion;\n          cubeUVmaps.set(texture, renderTarget);\n          return renderTarget.texture;\n        } else {\n          if (renderTarget !== undefined) {\n            return renderTarget.texture;\n          } else {\n            const image = texture.image;\n            if (isEquirectMap && image && image.height > 0 || isCubeMap && image && isCubeTextureComplete(image)) {\n              if (pmremGenerator === null) pmremGenerator = new PMREMGenerator(renderer);\n              renderTarget = isEquirectMap ? pmremGenerator.fromEquirectangular(texture) : pmremGenerator.fromCubemap(texture);\n              renderTarget.texture.pmremVersion = texture.pmremVersion;\n              cubeUVmaps.set(texture, renderTarget);\n              texture.addEventListener('dispose', onTextureDispose);\n              return renderTarget.texture;\n            } else {\n              // image not yet ready. try the conversion next frame\n\n              return null;\n            }\n          }\n        }\n      }\n    }\n    return texture;\n  }\n  function isCubeTextureComplete(image) {\n    let count = 0;\n    const length = 6;\n    for (let i = 0; i < length; i++) {\n      if (image[i] !== undefined) count++;\n    }\n    return count === length;\n  }\n  function onTextureDispose(event) {\n    const texture = event.target;\n    texture.removeEventListener('dispose', onTextureDispose);\n    const cubemapUV = cubeUVmaps.get(texture);\n    if (cubemapUV !== undefined) {\n      cubeUVmaps.delete(texture);\n      cubemapUV.dispose();\n    }\n  }\n  function dispose() {\n    cubeUVmaps = new WeakMap();\n    if (pmremGenerator !== null) {\n      pmremGenerator.dispose();\n      pmremGenerator = null;\n    }\n  }\n  return {\n    get: get,\n    dispose: dispose\n  };\n}\nfunction WebGLExtensions(gl) {\n  const extensions = {};\n  function getExtension(name) {\n    if (extensions[name] !== undefined) {\n      return extensions[name];\n    }\n    let extension;\n    switch (name) {\n      case 'WEBGL_depth_texture':\n        extension = gl.getExtension('WEBGL_depth_texture') || gl.getExtension('MOZ_WEBGL_depth_texture') || gl.getExtension('WEBKIT_WEBGL_depth_texture');\n        break;\n      case 'EXT_texture_filter_anisotropic':\n        extension = gl.getExtension('EXT_texture_filter_anisotropic') || gl.getExtension('MOZ_EXT_texture_filter_anisotropic') || gl.getExtension('WEBKIT_EXT_texture_filter_anisotropic');\n        break;\n      case 'WEBGL_compressed_texture_s3tc':\n        extension = gl.getExtension('WEBGL_compressed_texture_s3tc') || gl.getExtension('MOZ_WEBGL_compressed_texture_s3tc') || gl.getExtension('WEBKIT_WEBGL_compressed_texture_s3tc');\n        break;\n      case 'WEBGL_compressed_texture_pvrtc':\n        extension = gl.getExtension('WEBGL_compressed_texture_pvrtc') || gl.getExtension('WEBKIT_WEBGL_compressed_texture_pvrtc');\n        break;\n      default:\n        extension = gl.getExtension(name);\n    }\n    extensions[name] = extension;\n    return extension;\n  }\n  return {\n    has: function (name) {\n      return getExtension(name) !== null;\n    },\n    init: function () {\n      getExtension('EXT_color_buffer_float');\n      getExtension('WEBGL_clip_cull_distance');\n      getExtension('OES_texture_float_linear');\n      getExtension('EXT_color_buffer_half_float');\n      getExtension('WEBGL_multisampled_render_to_texture');\n      getExtension('WEBGL_render_shared_exponent');\n    },\n    get: function (name) {\n      const extension = getExtension(name);\n      if (extension === null) {\n        warnOnce('THREE.WebGLRenderer: ' + name + ' extension not supported.');\n      }\n      return extension;\n    }\n  };\n}\nfunction WebGLGeometries(gl, attributes, info, bindingStates) {\n  const geometries = {};\n  const wireframeAttributes = new WeakMap();\n  function onGeometryDispose(event) {\n    const geometry = event.target;\n    if (geometry.index !== null) {\n      attributes.remove(geometry.index);\n    }\n    for (const name in geometry.attributes) {\n      attributes.remove(geometry.attributes[name]);\n    }\n    for (const name in geometry.morphAttributes) {\n      const array = geometry.morphAttributes[name];\n      for (let i = 0, l = array.length; i < l; i++) {\n        attributes.remove(array[i]);\n      }\n    }\n    geometry.removeEventListener('dispose', onGeometryDispose);\n    delete geometries[geometry.id];\n    const attribute = wireframeAttributes.get(geometry);\n    if (attribute) {\n      attributes.remove(attribute);\n      wireframeAttributes.delete(geometry);\n    }\n    bindingStates.releaseStatesOfGeometry(geometry);\n    if (geometry.isInstancedBufferGeometry === true) {\n      delete geometry._maxInstanceCount;\n    }\n\n    //\n\n    info.memory.geometries--;\n  }\n  function get(object, geometry) {\n    if (geometries[geometry.id] === true) return geometry;\n    geometry.addEventListener('dispose', onGeometryDispose);\n    geometries[geometry.id] = true;\n    info.memory.geometries++;\n    return geometry;\n  }\n  function update(geometry) {\n    const geometryAttributes = geometry.attributes;\n\n    // Updating index buffer in VAO now. See WebGLBindingStates.\n\n    for (const name in geometryAttributes) {\n      attributes.update(geometryAttributes[name], gl.ARRAY_BUFFER);\n    }\n\n    // morph targets\n\n    const morphAttributes = geometry.morphAttributes;\n    for (const name in morphAttributes) {\n      const array = morphAttributes[name];\n      for (let i = 0, l = array.length; i < l; i++) {\n        attributes.update(array[i], gl.ARRAY_BUFFER);\n      }\n    }\n  }\n  function updateWireframeAttribute(geometry) {\n    const indices = [];\n    const geometryIndex = geometry.index;\n    const geometryPosition = geometry.attributes.position;\n    let version = 0;\n    if (geometryIndex !== null) {\n      const array = geometryIndex.array;\n      version = geometryIndex.version;\n      for (let i = 0, l = array.length; i < l; i += 3) {\n        const a = array[i + 0];\n        const b = array[i + 1];\n        const c = array[i + 2];\n        indices.push(a, b, b, c, c, a);\n      }\n    } else if (geometryPosition !== undefined) {\n      const array = geometryPosition.array;\n      version = geometryPosition.version;\n      for (let i = 0, l = array.length / 3 - 1; i < l; i += 3) {\n        const a = i + 0;\n        const b = i + 1;\n        const c = i + 2;\n        indices.push(a, b, b, c, c, a);\n      }\n    } else {\n      return;\n    }\n    const attribute = new (arrayNeedsUint32(indices) ? Uint32BufferAttribute : Uint16BufferAttribute)(indices, 1);\n    attribute.version = version;\n\n    // Updating index buffer in VAO now. See WebGLBindingStates\n\n    //\n\n    const previousAttribute = wireframeAttributes.get(geometry);\n    if (previousAttribute) attributes.remove(previousAttribute);\n\n    //\n\n    wireframeAttributes.set(geometry, attribute);\n  }\n  function getWireframeAttribute(geometry) {\n    const currentAttribute = wireframeAttributes.get(geometry);\n    if (currentAttribute) {\n      const geometryIndex = geometry.index;\n      if (geometryIndex !== null) {\n        // if the attribute is obsolete, create a new one\n\n        if (currentAttribute.version < geometryIndex.version) {\n          updateWireframeAttribute(geometry);\n        }\n      }\n    } else {\n      updateWireframeAttribute(geometry);\n    }\n    return wireframeAttributes.get(geometry);\n  }\n  return {\n    get: get,\n    update: update,\n    getWireframeAttribute: getWireframeAttribute\n  };\n}\nfunction WebGLIndexedBufferRenderer(gl, extensions, info) {\n  let mode;\n  function setMode(value) {\n    mode = value;\n  }\n  let type, bytesPerElement;\n  function setIndex(value) {\n    type = value.type;\n    bytesPerElement = value.bytesPerElement;\n  }\n  function render(start, count) {\n    gl.drawElements(mode, count, type, start * bytesPerElement);\n    info.update(count, mode, 1);\n  }\n  function renderInstances(start, count, primcount) {\n    if (primcount === 0) return;\n    gl.drawElementsInstanced(mode, count, type, start * bytesPerElement, primcount);\n    info.update(count, mode, primcount);\n  }\n  function renderMultiDraw(starts, counts, drawCount) {\n    if (drawCount === 0) return;\n    const extension = extensions.get('WEBGL_multi_draw');\n    extension.multiDrawElementsWEBGL(mode, counts, 0, type, starts, 0, drawCount);\n    let elementCount = 0;\n    for (let i = 0; i < drawCount; i++) {\n      elementCount += counts[i];\n    }\n    info.update(elementCount, mode, 1);\n  }\n  function renderMultiDrawInstances(starts, counts, drawCount, primcount) {\n    if (drawCount === 0) return;\n    const extension = extensions.get('WEBGL_multi_draw');\n    if (extension === null) {\n      for (let i = 0; i < starts.length; i++) {\n        renderInstances(starts[i] / bytesPerElement, counts[i], primcount[i]);\n      }\n    } else {\n      extension.multiDrawElementsInstancedWEBGL(mode, counts, 0, type, starts, 0, primcount, 0, drawCount);\n      let elementCount = 0;\n      for (let i = 0; i < drawCount; i++) {\n        elementCount += counts[i];\n      }\n      for (let i = 0; i < primcount.length; i++) {\n        info.update(elementCount, mode, primcount[i]);\n      }\n    }\n  }\n\n  //\n\n  this.setMode = setMode;\n  this.setIndex = setIndex;\n  this.render = render;\n  this.renderInstances = renderInstances;\n  this.renderMultiDraw = renderMultiDraw;\n  this.renderMultiDrawInstances = renderMultiDrawInstances;\n}\nfunction WebGLInfo(gl) {\n  const memory = {\n    geometries: 0,\n    textures: 0\n  };\n  const render = {\n    frame: 0,\n    calls: 0,\n    triangles: 0,\n    points: 0,\n    lines: 0\n  };\n  function update(count, mode, instanceCount) {\n    render.calls++;\n    switch (mode) {\n      case gl.TRIANGLES:\n        render.triangles += instanceCount * (count / 3);\n        break;\n      case gl.LINES:\n        render.lines += instanceCount * (count / 2);\n        break;\n      case gl.LINE_STRIP:\n        render.lines += instanceCount * (count - 1);\n        break;\n      case gl.LINE_LOOP:\n        render.lines += instanceCount * count;\n        break;\n      case gl.POINTS:\n        render.points += instanceCount * count;\n        break;\n      default:\n        console.error('THREE.WebGLInfo: Unknown draw mode:', mode);\n        break;\n    }\n  }\n  function reset() {\n    render.calls = 0;\n    render.triangles = 0;\n    render.points = 0;\n    render.lines = 0;\n  }\n  return {\n    memory: memory,\n    render: render,\n    programs: null,\n    autoReset: true,\n    reset: reset,\n    update: update\n  };\n}\nfunction WebGLMorphtargets(gl, capabilities, textures) {\n  const morphTextures = new WeakMap();\n  const morph = new Vector4();\n  function update(object, geometry, program) {\n    const objectInfluences = object.morphTargetInfluences;\n\n    // the following encodes morph targets into an array of data textures. Each layer represents a single morph target.\n\n    const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;\n    const morphTargetsCount = morphAttribute !== undefined ? morphAttribute.length : 0;\n    let entry = morphTextures.get(geometry);\n    if (entry === undefined || entry.count !== morphTargetsCount) {\n      if (entry !== undefined) entry.texture.dispose();\n      const hasMorphPosition = geometry.morphAttributes.position !== undefined;\n      const hasMorphNormals = geometry.morphAttributes.normal !== undefined;\n      const hasMorphColors = geometry.morphAttributes.color !== undefined;\n      const morphTargets = geometry.morphAttributes.position || [];\n      const morphNormals = geometry.morphAttributes.normal || [];\n      const morphColors = geometry.morphAttributes.color || [];\n      let vertexDataCount = 0;\n      if (hasMorphPosition === true) vertexDataCount = 1;\n      if (hasMorphNormals === true) vertexDataCount = 2;\n      if (hasMorphColors === true) vertexDataCount = 3;\n      let width = geometry.attributes.position.count * vertexDataCount;\n      let height = 1;\n      if (width > capabilities.maxTextureSize) {\n        height = Math.ceil(width / capabilities.maxTextureSize);\n        width = capabilities.maxTextureSize;\n      }\n      const buffer = new Float32Array(width * height * 4 * morphTargetsCount);\n      const texture = new DataArrayTexture(buffer, width, height, morphTargetsCount);\n      texture.type = FloatType;\n      texture.needsUpdate = true;\n\n      // fill buffer\n\n      const vertexDataStride = vertexDataCount * 4;\n      for (let i = 0; i < morphTargetsCount; i++) {\n        const morphTarget = morphTargets[i];\n        const morphNormal = morphNormals[i];\n        const morphColor = morphColors[i];\n        const offset = width * height * 4 * i;\n        for (let j = 0; j < morphTarget.count; j++) {\n          const stride = j * vertexDataStride;\n          if (hasMorphPosition === true) {\n            morph.fromBufferAttribute(morphTarget, j);\n            buffer[offset + stride + 0] = morph.x;\n            buffer[offset + stride + 1] = morph.y;\n            buffer[offset + stride + 2] = morph.z;\n            buffer[offset + stride + 3] = 0;\n          }\n          if (hasMorphNormals === true) {\n            morph.fromBufferAttribute(morphNormal, j);\n            buffer[offset + stride + 4] = morph.x;\n            buffer[offset + stride + 5] = morph.y;\n            buffer[offset + stride + 6] = morph.z;\n            buffer[offset + stride + 7] = 0;\n          }\n          if (hasMorphColors === true) {\n            morph.fromBufferAttribute(morphColor, j);\n            buffer[offset + stride + 8] = morph.x;\n            buffer[offset + stride + 9] = morph.y;\n            buffer[offset + stride + 10] = morph.z;\n            buffer[offset + stride + 11] = morphColor.itemSize === 4 ? morph.w : 1;\n          }\n        }\n      }\n      entry = {\n        count: morphTargetsCount,\n        texture: texture,\n        size: new Vector2(width, height)\n      };\n      morphTextures.set(geometry, entry);\n      function disposeTexture() {\n        texture.dispose();\n        morphTextures.delete(geometry);\n        geometry.removeEventListener('dispose', disposeTexture);\n      }\n      geometry.addEventListener('dispose', disposeTexture);\n    }\n\n    //\n    if (object.isInstancedMesh === true && object.morphTexture !== null) {\n      program.getUniforms().setValue(gl, 'morphTexture', object.morphTexture, textures);\n    } else {\n      let morphInfluencesSum = 0;\n      for (let i = 0; i < objectInfluences.length; i++) {\n        morphInfluencesSum += objectInfluences[i];\n      }\n      const morphBaseInfluence = geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;\n      program.getUniforms().setValue(gl, 'morphTargetBaseInfluence', morphBaseInfluence);\n      program.getUniforms().setValue(gl, 'morphTargetInfluences', objectInfluences);\n    }\n    program.getUniforms().setValue(gl, 'morphTargetsTexture', entry.texture, textures);\n    program.getUniforms().setValue(gl, 'morphTargetsTextureSize', entry.size);\n  }\n  return {\n    update: update\n  };\n}\nfunction WebGLObjects(gl, geometries, attributes, info) {\n  let updateMap = new WeakMap();\n  function update(object) {\n    const frame = info.render.frame;\n    const geometry = object.geometry;\n    const buffergeometry = geometries.get(object, geometry);\n\n    // Update once per frame\n\n    if (updateMap.get(buffergeometry) !== frame) {\n      geometries.update(buffergeometry);\n      updateMap.set(buffergeometry, frame);\n    }\n    if (object.isInstancedMesh) {\n      if (object.hasEventListener('dispose', onInstancedMeshDispose) === false) {\n        object.addEventListener('dispose', onInstancedMeshDispose);\n      }\n      if (updateMap.get(object) !== frame) {\n        attributes.update(object.instanceMatrix, gl.ARRAY_BUFFER);\n        if (object.instanceColor !== null) {\n          attributes.update(object.instanceColor, gl.ARRAY_BUFFER);\n        }\n        updateMap.set(object, frame);\n      }\n    }\n    if (object.isSkinnedMesh) {\n      const skeleton = object.skeleton;\n      if (updateMap.get(skeleton) !== frame) {\n        skeleton.update();\n        updateMap.set(skeleton, frame);\n      }\n    }\n    return buffergeometry;\n  }\n  function dispose() {\n    updateMap = new WeakMap();\n  }\n  function onInstancedMeshDispose(event) {\n    const instancedMesh = event.target;\n    instancedMesh.removeEventListener('dispose', onInstancedMeshDispose);\n    attributes.remove(instancedMesh.instanceMatrix);\n    if (instancedMesh.instanceColor !== null) attributes.remove(instancedMesh.instanceColor);\n  }\n  return {\n    update: update,\n    dispose: dispose\n  };\n}\nclass DepthTexture extends Texture$1 {\n  constructor(width, height, type, mapping, wrapS, wrapT, magFilter, minFilter, anisotropy, format = DepthFormat) {\n    if (format !== DepthFormat && format !== DepthStencilFormat) {\n      throw new Error('DepthTexture format must be either THREE.DepthFormat or THREE.DepthStencilFormat');\n    }\n    if (type === undefined && format === DepthFormat) type = UnsignedIntType;\n    if (type === undefined && format === DepthStencilFormat) type = UnsignedInt248Type;\n    super(null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy);\n    this.isDepthTexture = true;\n    this.image = {\n      width: width,\n      height: height\n    };\n    this.magFilter = magFilter !== undefined ? magFilter : NearestFilter;\n    this.minFilter = minFilter !== undefined ? minFilter : NearestFilter;\n    this.flipY = false;\n    this.generateMipmaps = false;\n    this.compareFunction = null;\n  }\n  copy(source) {\n    super.copy(source);\n    this.compareFunction = source.compareFunction;\n    return this;\n  }\n  toJSON(meta) {\n    const data = super.toJSON(meta);\n    if (this.compareFunction !== null) data.compareFunction = this.compareFunction;\n    return data;\n  }\n}\n\n/**\n * Uniforms of a program.\n * Those form a tree structure with a special top-level container for the root,\n * which you get by calling 'new WebGLUniforms( gl, program )'.\n *\n *\n * Properties of inner nodes including the top-level container:\n *\n * .seq - array of nested uniforms\n * .map - nested uniforms by name\n *\n *\n * Methods of all nodes except the top-level container:\n *\n * .setValue( gl, value, [textures] )\n *\n * \t\tuploads a uniform value(s)\n *  \tthe 'textures' parameter is needed for sampler uniforms\n *\n *\n * Static methods of the top-level container (textures factorizations):\n *\n * .upload( gl, seq, values, textures )\n *\n * \t\tsets uniforms in 'seq' to 'values[id].value'\n *\n * .seqWithValue( seq, values ) : filteredSeq\n *\n * \t\tfilters 'seq' entries with corresponding entry in values\n *\n *\n * Methods of the top-level container (textures factorizations):\n *\n * .setValue( gl, name, value, textures )\n *\n * \t\tsets uniform with  name 'name' to 'value'\n *\n * .setOptional( gl, obj, prop )\n *\n * \t\tlike .set for an optional property of the object\n *\n */\n\nconst emptyTexture = /*@__PURE__*/new Texture$1();\nconst emptyShadowTexture = /*@__PURE__*/new DepthTexture(1, 1);\nconst emptyArrayTexture = /*@__PURE__*/new DataArrayTexture();\nconst empty3dTexture = /*@__PURE__*/new Data3DTexture();\nconst emptyCubeTexture = /*@__PURE__*/new CubeTexture();\n\n// --- Utilities ---\n\n// Array Caches (provide typed arrays for temporary by size)\n\nconst arrayCacheF32 = [];\nconst arrayCacheI32 = [];\n\n// Float32Array caches used for uploading Matrix uniforms\n\nconst mat4array = new Float32Array(16);\nconst mat3array = new Float32Array(9);\nconst mat2array = new Float32Array(4);\n\n// Flattening for arrays of vectors and matrices\n\nfunction flatten(array, nBlocks, blockSize) {\n  const firstElem = array[0];\n  if (firstElem <= 0 || firstElem > 0) return array;\n  // unoptimized: ! isNaN( firstElem )\n  // see http://jacksondunstan.com/articles/983\n\n  const n = nBlocks * blockSize;\n  let r = arrayCacheF32[n];\n  if (r === undefined) {\n    r = new Float32Array(n);\n    arrayCacheF32[n] = r;\n  }\n  if (nBlocks !== 0) {\n    firstElem.toArray(r, 0);\n    for (let i = 1, offset = 0; i !== nBlocks; ++i) {\n      offset += blockSize;\n      array[i].toArray(r, offset);\n    }\n  }\n  return r;\n}\nfunction arraysEqual(a, b) {\n  if (a.length !== b.length) return false;\n  for (let i = 0, l = a.length; i < l; i++) {\n    if (a[i] !== b[i]) return false;\n  }\n  return true;\n}\nfunction copyArray(a, b) {\n  for (let i = 0, l = b.length; i < l; i++) {\n    a[i] = b[i];\n  }\n}\n\n// Texture unit allocation\n\nfunction allocTexUnits(textures, n) {\n  let r = arrayCacheI32[n];\n  if (r === undefined) {\n    r = new Int32Array(n);\n    arrayCacheI32[n] = r;\n  }\n  for (let i = 0; i !== n; ++i) {\n    r[i] = textures.allocateTextureUnit();\n  }\n  return r;\n}\n\n// --- Setters ---\n\n// Note: Defining these methods externally, because they come in a bunch\n// and this way their names minify.\n\n// Single scalar\n\nfunction setValueV1f(gl, v) {\n  const cache = this.cache;\n  if (cache[0] === v) return;\n  gl.uniform1f(this.addr, v);\n  cache[0] = v;\n}\n\n// Single float vector (from flat array or THREE.VectorN)\n\nfunction setValueV2f(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y) {\n      gl.uniform2f(this.addr, v.x, v.y);\n      cache[0] = v.x;\n      cache[1] = v.y;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform2fv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\nfunction setValueV3f(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z) {\n      gl.uniform3f(this.addr, v.x, v.y, v.z);\n      cache[0] = v.x;\n      cache[1] = v.y;\n      cache[2] = v.z;\n    }\n  } else if (v.r !== undefined) {\n    if (cache[0] !== v.r || cache[1] !== v.g || cache[2] !== v.b) {\n      gl.uniform3f(this.addr, v.r, v.g, v.b);\n      cache[0] = v.r;\n      cache[1] = v.g;\n      cache[2] = v.b;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform3fv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\nfunction setValueV4f(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z || cache[3] !== v.w) {\n      gl.uniform4f(this.addr, v.x, v.y, v.z, v.w);\n      cache[0] = v.x;\n      cache[1] = v.y;\n      cache[2] = v.z;\n      cache[3] = v.w;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform4fv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\n\n// Single matrix (from flat array or THREE.MatrixN)\n\nfunction setValueM2(gl, v) {\n  const cache = this.cache;\n  const elements = v.elements;\n  if (elements === undefined) {\n    if (arraysEqual(cache, v)) return;\n    gl.uniformMatrix2fv(this.addr, false, v);\n    copyArray(cache, v);\n  } else {\n    if (arraysEqual(cache, elements)) return;\n    mat2array.set(elements);\n    gl.uniformMatrix2fv(this.addr, false, mat2array);\n    copyArray(cache, elements);\n  }\n}\nfunction setValueM3(gl, v) {\n  const cache = this.cache;\n  const elements = v.elements;\n  if (elements === undefined) {\n    if (arraysEqual(cache, v)) return;\n    gl.uniformMatrix3fv(this.addr, false, v);\n    copyArray(cache, v);\n  } else {\n    if (arraysEqual(cache, elements)) return;\n    mat3array.set(elements);\n    gl.uniformMatrix3fv(this.addr, false, mat3array);\n    copyArray(cache, elements);\n  }\n}\nfunction setValueM4(gl, v) {\n  const cache = this.cache;\n  const elements = v.elements;\n  if (elements === undefined) {\n    if (arraysEqual(cache, v)) return;\n    gl.uniformMatrix4fv(this.addr, false, v);\n    copyArray(cache, v);\n  } else {\n    if (arraysEqual(cache, elements)) return;\n    mat4array.set(elements);\n    gl.uniformMatrix4fv(this.addr, false, mat4array);\n    copyArray(cache, elements);\n  }\n}\n\n// Single integer / boolean\n\nfunction setValueV1i(gl, v) {\n  const cache = this.cache;\n  if (cache[0] === v) return;\n  gl.uniform1i(this.addr, v);\n  cache[0] = v;\n}\n\n// Single integer / boolean vector (from flat array or THREE.VectorN)\n\nfunction setValueV2i(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y) {\n      gl.uniform2i(this.addr, v.x, v.y);\n      cache[0] = v.x;\n      cache[1] = v.y;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform2iv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\nfunction setValueV3i(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z) {\n      gl.uniform3i(this.addr, v.x, v.y, v.z);\n      cache[0] = v.x;\n      cache[1] = v.y;\n      cache[2] = v.z;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform3iv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\nfunction setValueV4i(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z || cache[3] !== v.w) {\n      gl.uniform4i(this.addr, v.x, v.y, v.z, v.w);\n      cache[0] = v.x;\n      cache[1] = v.y;\n      cache[2] = v.z;\n      cache[3] = v.w;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform4iv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\n\n// Single unsigned integer\n\nfunction setValueV1ui(gl, v) {\n  const cache = this.cache;\n  if (cache[0] === v) return;\n  gl.uniform1ui(this.addr, v);\n  cache[0] = v;\n}\n\n// Single unsigned integer vector (from flat array or THREE.VectorN)\n\nfunction setValueV2ui(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y) {\n      gl.uniform2ui(this.addr, v.x, v.y);\n      cache[0] = v.x;\n      cache[1] = v.y;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform2uiv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\nfunction setValueV3ui(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z) {\n      gl.uniform3ui(this.addr, v.x, v.y, v.z);\n      cache[0] = v.x;\n      cache[1] = v.y;\n      cache[2] = v.z;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform3uiv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\nfunction setValueV4ui(gl, v) {\n  const cache = this.cache;\n  if (v.x !== undefined) {\n    if (cache[0] !== v.x || cache[1] !== v.y || cache[2] !== v.z || cache[3] !== v.w) {\n      gl.uniform4ui(this.addr, v.x, v.y, v.z, v.w);\n      cache[0] = v.x;\n      cache[1] = v.y;\n      cache[2] = v.z;\n      cache[3] = v.w;\n    }\n  } else {\n    if (arraysEqual(cache, v)) return;\n    gl.uniform4uiv(this.addr, v);\n    copyArray(cache, v);\n  }\n}\n\n// Single texture (2D / Cube)\n\nfunction setValueT1(gl, v, textures) {\n  const cache = this.cache;\n  const unit = textures.allocateTextureUnit();\n  if (cache[0] !== unit) {\n    gl.uniform1i(this.addr, unit);\n    cache[0] = unit;\n  }\n  let emptyTexture2D;\n  if (this.type === gl.SAMPLER_2D_SHADOW) {\n    emptyShadowTexture.compareFunction = LessEqualCompare; // #28670\n    emptyTexture2D = emptyShadowTexture;\n  } else {\n    emptyTexture2D = emptyTexture;\n  }\n  textures.setTexture2D(v || emptyTexture2D, unit);\n}\nfunction setValueT3D1(gl, v, textures) {\n  const cache = this.cache;\n  const unit = textures.allocateTextureUnit();\n  if (cache[0] !== unit) {\n    gl.uniform1i(this.addr, unit);\n    cache[0] = unit;\n  }\n  textures.setTexture3D(v || empty3dTexture, unit);\n}\nfunction setValueT6(gl, v, textures) {\n  const cache = this.cache;\n  const unit = textures.allocateTextureUnit();\n  if (cache[0] !== unit) {\n    gl.uniform1i(this.addr, unit);\n    cache[0] = unit;\n  }\n  textures.setTextureCube(v || emptyCubeTexture, unit);\n}\nfunction setValueT2DArray1(gl, v, textures) {\n  const cache = this.cache;\n  const unit = textures.allocateTextureUnit();\n  if (cache[0] !== unit) {\n    gl.uniform1i(this.addr, unit);\n    cache[0] = unit;\n  }\n  textures.setTexture2DArray(v || emptyArrayTexture, unit);\n}\n\n// Helper to pick the right setter for the singular case\n\nfunction getSingularSetter(type) {\n  switch (type) {\n    case 0x1406:\n      return setValueV1f;\n    // FLOAT\n    case 0x8b50:\n      return setValueV2f;\n    // _VEC2\n    case 0x8b51:\n      return setValueV3f;\n    // _VEC3\n    case 0x8b52:\n      return setValueV4f;\n    // _VEC4\n\n    case 0x8b5a:\n      return setValueM2;\n    // _MAT2\n    case 0x8b5b:\n      return setValueM3;\n    // _MAT3\n    case 0x8b5c:\n      return setValueM4;\n    // _MAT4\n\n    case 0x1404:\n    case 0x8b56:\n      return setValueV1i;\n    // INT, BOOL\n    case 0x8b53:\n    case 0x8b57:\n      return setValueV2i;\n    // _VEC2\n    case 0x8b54:\n    case 0x8b58:\n      return setValueV3i;\n    // _VEC3\n    case 0x8b55:\n    case 0x8b59:\n      return setValueV4i;\n    // _VEC4\n\n    case 0x1405:\n      return setValueV1ui;\n    // UINT\n    case 0x8dc6:\n      return setValueV2ui;\n    // _VEC2\n    case 0x8dc7:\n      return setValueV3ui;\n    // _VEC3\n    case 0x8dc8:\n      return setValueV4ui;\n    // _VEC4\n\n    case 0x8b5e: // SAMPLER_2D\n    case 0x8d66: // SAMPLER_EXTERNAL_OES\n    case 0x8dca: // INT_SAMPLER_2D\n    case 0x8dd2: // UNSIGNED_INT_SAMPLER_2D\n    case 0x8b62:\n      // SAMPLER_2D_SHADOW\n      return setValueT1;\n    case 0x8b5f: // SAMPLER_3D\n    case 0x8dcb: // INT_SAMPLER_3D\n    case 0x8dd3:\n      // UNSIGNED_INT_SAMPLER_3D\n      return setValueT3D1;\n    case 0x8b60: // SAMPLER_CUBE\n    case 0x8dcc: // INT_SAMPLER_CUBE\n    case 0x8dd4: // UNSIGNED_INT_SAMPLER_CUBE\n    case 0x8dc5:\n      // SAMPLER_CUBE_SHADOW\n      return setValueT6;\n    case 0x8dc1: // SAMPLER_2D_ARRAY\n    case 0x8dcf: // INT_SAMPLER_2D_ARRAY\n    case 0x8dd7: // UNSIGNED_INT_SAMPLER_2D_ARRAY\n    case 0x8dc4:\n      // SAMPLER_2D_ARRAY_SHADOW\n      return setValueT2DArray1;\n  }\n}\n\n// Array of scalars\n\nfunction setValueV1fArray(gl, v) {\n  gl.uniform1fv(this.addr, v);\n}\n\n// Array of vectors (from flat array or array of THREE.VectorN)\n\nfunction setValueV2fArray(gl, v) {\n  const data = flatten(v, this.size, 2);\n  gl.uniform2fv(this.addr, data);\n}\nfunction setValueV3fArray(gl, v) {\n  const data = flatten(v, this.size, 3);\n  gl.uniform3fv(this.addr, data);\n}\nfunction setValueV4fArray(gl, v) {\n  const data = flatten(v, this.size, 4);\n  gl.uniform4fv(this.addr, data);\n}\n\n// Array of matrices (from flat array or array of THREE.MatrixN)\n\nfunction setValueM2Array(gl, v) {\n  const data = flatten(v, this.size, 4);\n  gl.uniformMatrix2fv(this.addr, false, data);\n}\nfunction setValueM3Array(gl, v) {\n  const data = flatten(v, this.size, 9);\n  gl.uniformMatrix3fv(this.addr, false, data);\n}\nfunction setValueM4Array(gl, v) {\n  const data = flatten(v, this.size, 16);\n  gl.uniformMatrix4fv(this.addr, false, data);\n}\n\n// Array of integer / boolean\n\nfunction setValueV1iArray(gl, v) {\n  gl.uniform1iv(this.addr, v);\n}\n\n// Array of integer / boolean vectors (from flat array)\n\nfunction setValueV2iArray(gl, v) {\n  gl.uniform2iv(this.addr, v);\n}\nfunction setValueV3iArray(gl, v) {\n  gl.uniform3iv(this.addr, v);\n}\nfunction setValueV4iArray(gl, v) {\n  gl.uniform4iv(this.addr, v);\n}\n\n// Array of unsigned integer\n\nfunction setValueV1uiArray(gl, v) {\n  gl.uniform1uiv(this.addr, v);\n}\n\n// Array of unsigned integer vectors (from flat array)\n\nfunction setValueV2uiArray(gl, v) {\n  gl.uniform2uiv(this.addr, v);\n}\nfunction setValueV3uiArray(gl, v) {\n  gl.uniform3uiv(this.addr, v);\n}\nfunction setValueV4uiArray(gl, v) {\n  gl.uniform4uiv(this.addr, v);\n}\n\n// Array of textures (2D / 3D / Cube / 2DArray)\n\nfunction setValueT1Array(gl, v, textures) {\n  const cache = this.cache;\n  const n = v.length;\n  const units = allocTexUnits(textures, n);\n  if (!arraysEqual(cache, units)) {\n    gl.uniform1iv(this.addr, units);\n    copyArray(cache, units);\n  }\n  for (let i = 0; i !== n; ++i) {\n    textures.setTexture2D(v[i] || emptyTexture, units[i]);\n  }\n}\nfunction setValueT3DArray(gl, v, textures) {\n  const cache = this.cache;\n  const n = v.length;\n  const units = allocTexUnits(textures, n);\n  if (!arraysEqual(cache, units)) {\n    gl.uniform1iv(this.addr, units);\n    copyArray(cache, units);\n  }\n  for (let i = 0; i !== n; ++i) {\n    textures.setTexture3D(v[i] || empty3dTexture, units[i]);\n  }\n}\nfunction setValueT6Array(gl, v, textures) {\n  const cache = this.cache;\n  const n = v.length;\n  const units = allocTexUnits(textures, n);\n  if (!arraysEqual(cache, units)) {\n    gl.uniform1iv(this.addr, units);\n    copyArray(cache, units);\n  }\n  for (let i = 0; i !== n; ++i) {\n    textures.setTextureCube(v[i] || emptyCubeTexture, units[i]);\n  }\n}\nfunction setValueT2DArrayArray(gl, v, textures) {\n  const cache = this.cache;\n  const n = v.length;\n  const units = allocTexUnits(textures, n);\n  if (!arraysEqual(cache, units)) {\n    gl.uniform1iv(this.addr, units);\n    copyArray(cache, units);\n  }\n  for (let i = 0; i !== n; ++i) {\n    textures.setTexture2DArray(v[i] || emptyArrayTexture, units[i]);\n  }\n}\n\n// Helper to pick the right setter for a pure (bottom-level) array\n\nfunction getPureArraySetter(type) {\n  switch (type) {\n    case 0x1406:\n      return setValueV1fArray;\n    // FLOAT\n    case 0x8b50:\n      return setValueV2fArray;\n    // _VEC2\n    case 0x8b51:\n      return setValueV3fArray;\n    // _VEC3\n    case 0x8b52:\n      return setValueV4fArray;\n    // _VEC4\n\n    case 0x8b5a:\n      return setValueM2Array;\n    // _MAT2\n    case 0x8b5b:\n      return setValueM3Array;\n    // _MAT3\n    case 0x8b5c:\n      return setValueM4Array;\n    // _MAT4\n\n    case 0x1404:\n    case 0x8b56:\n      return setValueV1iArray;\n    // INT, BOOL\n    case 0x8b53:\n    case 0x8b57:\n      return setValueV2iArray;\n    // _VEC2\n    case 0x8b54:\n    case 0x8b58:\n      return setValueV3iArray;\n    // _VEC3\n    case 0x8b55:\n    case 0x8b59:\n      return setValueV4iArray;\n    // _VEC4\n\n    case 0x1405:\n      return setValueV1uiArray;\n    // UINT\n    case 0x8dc6:\n      return setValueV2uiArray;\n    // _VEC2\n    case 0x8dc7:\n      return setValueV3uiArray;\n    // _VEC3\n    case 0x8dc8:\n      return setValueV4uiArray;\n    // _VEC4\n\n    case 0x8b5e: // SAMPLER_2D\n    case 0x8d66: // SAMPLER_EXTERNAL_OES\n    case 0x8dca: // INT_SAMPLER_2D\n    case 0x8dd2: // UNSIGNED_INT_SAMPLER_2D\n    case 0x8b62:\n      // SAMPLER_2D_SHADOW\n      return setValueT1Array;\n    case 0x8b5f: // SAMPLER_3D\n    case 0x8dcb: // INT_SAMPLER_3D\n    case 0x8dd3:\n      // UNSIGNED_INT_SAMPLER_3D\n      return setValueT3DArray;\n    case 0x8b60: // SAMPLER_CUBE\n    case 0x8dcc: // INT_SAMPLER_CUBE\n    case 0x8dd4: // UNSIGNED_INT_SAMPLER_CUBE\n    case 0x8dc5:\n      // SAMPLER_CUBE_SHADOW\n      return setValueT6Array;\n    case 0x8dc1: // SAMPLER_2D_ARRAY\n    case 0x8dcf: // INT_SAMPLER_2D_ARRAY\n    case 0x8dd7: // UNSIGNED_INT_SAMPLER_2D_ARRAY\n    case 0x8dc4:\n      // SAMPLER_2D_ARRAY_SHADOW\n      return setValueT2DArrayArray;\n  }\n}\n\n// --- Uniform Classes ---\n\nclass SingleUniform {\n  constructor(id, activeInfo, addr) {\n    this.id = id;\n    this.addr = addr;\n    this.cache = [];\n    this.type = activeInfo.type;\n    this.setValue = getSingularSetter(activeInfo.type);\n\n    // this.path = activeInfo.name; // DEBUG\n  }\n}\nclass PureArrayUniform {\n  constructor(id, activeInfo, addr) {\n    this.id = id;\n    this.addr = addr;\n    this.cache = [];\n    this.type = activeInfo.type;\n    this.size = activeInfo.size;\n    this.setValue = getPureArraySetter(activeInfo.type);\n\n    // this.path = activeInfo.name; // DEBUG\n  }\n}\nclass StructuredUniform {\n  constructor(id) {\n    this.id = id;\n    this.seq = [];\n    this.map = {};\n  }\n  setValue(gl, value, textures) {\n    const seq = this.seq;\n    for (let i = 0, n = seq.length; i !== n; ++i) {\n      const u = seq[i];\n      u.setValue(gl, value[u.id], textures);\n    }\n  }\n}\n\n// --- Top-level ---\n\n// Parser - builds up the property tree from the path strings\n\nconst RePathPart = /(\\w+)(\\])?(\\[|\\.)?/g;\n\n// extracts\n// \t- the identifier (member name or array index)\n//  - followed by an optional right bracket (found when array index)\n//  - followed by an optional left bracket or dot (type of subscript)\n//\n// Note: These portions can be read in a non-overlapping fashion and\n// allow straightforward parsing of the hierarchy that WebGL encodes\n// in the uniform names.\n\nfunction addUniform(container, uniformObject) {\n  container.seq.push(uniformObject);\n  container.map[uniformObject.id] = uniformObject;\n}\nfunction parseUniform(activeInfo, addr, container) {\n  const path = activeInfo.name,\n    pathLength = path.length;\n\n  // reset RegExp object, because of the early exit of a previous run\n  RePathPart.lastIndex = 0;\n  while (true) {\n    const match = RePathPart.exec(path),\n      matchEnd = RePathPart.lastIndex;\n    let id = match[1];\n    const idIsIndex = match[2] === ']',\n      subscript = match[3];\n    if (idIsIndex) id = id | 0; // convert to integer\n\n    if (subscript === undefined || subscript === '[' && matchEnd + 2 === pathLength) {\n      // bare name or \"pure\" bottom-level array \"[0]\" suffix\n\n      addUniform(container, subscript === undefined ? new SingleUniform(id, activeInfo, addr) : new PureArrayUniform(id, activeInfo, addr));\n      break;\n    } else {\n      // step into inner node / create it in case it doesn't exist\n\n      const map = container.map;\n      let next = map[id];\n      if (next === undefined) {\n        next = new StructuredUniform(id);\n        addUniform(container, next);\n      }\n      container = next;\n    }\n  }\n}\n\n// Root Container\n\nclass WebGLUniforms {\n  constructor(gl, program) {\n    this.seq = [];\n    this.map = {};\n    const n = gl.getProgramParameter(program, gl.ACTIVE_UNIFORMS);\n    for (let i = 0; i < n; ++i) {\n      const info = gl.getActiveUniform(program, i),\n        addr = gl.getUniformLocation(program, info.name);\n      parseUniform(info, addr, this);\n    }\n  }\n  setValue(gl, name, value, textures) {\n    const u = this.map[name];\n    if (u !== undefined) u.setValue(gl, value, textures);\n  }\n  setOptional(gl, object, name) {\n    const v = object[name];\n    if (v !== undefined) this.setValue(gl, name, v);\n  }\n  static upload(gl, seq, values, textures) {\n    for (let i = 0, n = seq.length; i !== n; ++i) {\n      const u = seq[i],\n        v = values[u.id];\n      if (v.needsUpdate !== false) {\n        // note: always updating when .needsUpdate is undefined\n        u.setValue(gl, v.value, textures);\n      }\n    }\n  }\n  static seqWithValue(seq, values) {\n    const r = [];\n    for (let i = 0, n = seq.length; i !== n; ++i) {\n      const u = seq[i];\n      if (u.id in values) r.push(u);\n    }\n    return r;\n  }\n}\nfunction WebGLShader(gl, type, string) {\n  const shader = gl.createShader(type);\n  gl.shaderSource(shader, string);\n  gl.compileShader(shader);\n  return shader;\n}\n\n// From https://www.khronos.org/registry/webgl/extensions/KHR_parallel_shader_compile/\nconst COMPLETION_STATUS_KHR = 0x91B1;\nlet programIdCount = 0;\nfunction handleSource(string, errorLine) {\n  const lines = string.split('\\n');\n  const lines2 = [];\n  const from = Math.max(errorLine - 6, 0);\n  const to = Math.min(errorLine + 6, lines.length);\n  for (let i = from; i < to; i++) {\n    const line = i + 1;\n    lines2.push(`${line === errorLine ? '>' : ' '} ${line}: ${lines[i]}`);\n  }\n  return lines2.join('\\n');\n}\nfunction getEncodingComponents(colorSpace) {\n  const workingPrimaries = ColorManagement.getPrimaries(ColorManagement.workingColorSpace);\n  const encodingPrimaries = ColorManagement.getPrimaries(colorSpace);\n  let gamutMapping;\n  if (workingPrimaries === encodingPrimaries) {\n    gamutMapping = '';\n  } else if (workingPrimaries === P3Primaries && encodingPrimaries === Rec709Primaries) {\n    gamutMapping = 'LinearDisplayP3ToLinearSRGB';\n  } else if (workingPrimaries === Rec709Primaries && encodingPrimaries === P3Primaries) {\n    gamutMapping = 'LinearSRGBToLinearDisplayP3';\n  }\n  switch (colorSpace) {\n    case LinearSRGBColorSpace:\n    case LinearDisplayP3ColorSpace:\n      return [gamutMapping, 'LinearTransferOETF'];\n    case SRGBColorSpace:\n    case DisplayP3ColorSpace:\n      return [gamutMapping, 'sRGBTransferOETF'];\n    default:\n      console.warn('THREE.WebGLProgram: Unsupported color space:', colorSpace);\n      return [gamutMapping, 'LinearTransferOETF'];\n  }\n}\nfunction getShaderErrors(gl, shader, type) {\n  const status = gl.getShaderParameter(shader, gl.COMPILE_STATUS);\n  const errors = gl.getShaderInfoLog(shader).trim();\n  if (status && errors === '') return '';\n  const errorMatches = /ERROR: 0:(\\d+)/.exec(errors);\n  if (errorMatches) {\n    // --enable-privileged-webgl-extension\n    // console.log( '**' + type + '**', gl.getExtension( 'WEBGL_debug_shaders' ).getTranslatedShaderSource( shader ) );\n\n    const errorLine = parseInt(errorMatches[1]);\n    return type.toUpperCase() + '\\n\\n' + errors + '\\n\\n' + handleSource(gl.getShaderSource(shader), errorLine);\n  } else {\n    return errors;\n  }\n}\nfunction getTexelEncodingFunction(functionName, colorSpace) {\n  const components = getEncodingComponents(colorSpace);\n  return `vec4 ${functionName}( vec4 value ) { return ${components[0]}( ${components[1]}( value ) ); }`;\n}\nfunction getToneMappingFunction(functionName, toneMapping) {\n  let toneMappingName;\n  switch (toneMapping) {\n    case LinearToneMapping:\n      toneMappingName = 'Linear';\n      break;\n    case ReinhardToneMapping:\n      toneMappingName = 'Reinhard';\n      break;\n    case CineonToneMapping:\n      toneMappingName = 'Cineon';\n      break;\n    case ACESFilmicToneMapping:\n      toneMappingName = 'ACESFilmic';\n      break;\n    case AgXToneMapping:\n      toneMappingName = 'AgX';\n      break;\n    case NeutralToneMapping:\n      toneMappingName = 'Neutral';\n      break;\n    case CustomToneMapping:\n      toneMappingName = 'Custom';\n      break;\n    default:\n      console.warn('THREE.WebGLProgram: Unsupported toneMapping:', toneMapping);\n      toneMappingName = 'Linear';\n  }\n  return 'vec3 ' + functionName + '( vec3 color ) { return ' + toneMappingName + 'ToneMapping( color ); }';\n}\nconst _v0$1 = /*@__PURE__*/new Vector3();\nfunction getLuminanceFunction() {\n  ColorManagement.getLuminanceCoefficients(_v0$1);\n  const r = _v0$1.x.toFixed(4);\n  const g = _v0$1.y.toFixed(4);\n  const b = _v0$1.z.toFixed(4);\n  return ['float luminance( const in vec3 rgb ) {', `\tconst vec3 weights = vec3( ${r}, ${g}, ${b} );`, '\treturn dot( weights, rgb );', '}'].join('\\n');\n}\nfunction generateVertexExtensions(parameters) {\n  const chunks = [parameters.extensionClipCullDistance ? '#extension GL_ANGLE_clip_cull_distance : require' : '', parameters.extensionMultiDraw ? '#extension GL_ANGLE_multi_draw : require' : ''];\n  return chunks.filter(filterEmptyLine).join('\\n');\n}\nfunction generateDefines(defines) {\n  const chunks = [];\n  for (const name in defines) {\n    const value = defines[name];\n    if (value === false) continue;\n    chunks.push('#define ' + name + ' ' + value);\n  }\n  return chunks.join('\\n');\n}\nfunction fetchAttributeLocations(gl, program) {\n  const attributes = {};\n  const n = gl.getProgramParameter(program, gl.ACTIVE_ATTRIBUTES);\n  for (let i = 0; i < n; i++) {\n    const info = gl.getActiveAttrib(program, i);\n    const name = info.name;\n    let locationSize = 1;\n    if (info.type === gl.FLOAT_MAT2) locationSize = 2;\n    if (info.type === gl.FLOAT_MAT3) locationSize = 3;\n    if (info.type === gl.FLOAT_MAT4) locationSize = 4;\n\n    // console.log( 'THREE.WebGLProgram: ACTIVE VERTEX ATTRIBUTE:', name, i );\n\n    attributes[name] = {\n      type: info.type,\n      location: gl.getAttribLocation(program, name),\n      locationSize: locationSize\n    };\n  }\n  return attributes;\n}\nfunction filterEmptyLine(string) {\n  return string !== '';\n}\nfunction replaceLightNums(string, parameters) {\n  const numSpotLightCoords = parameters.numSpotLightShadows + parameters.numSpotLightMaps - parameters.numSpotLightShadowsWithMaps;\n  return string.replace(/NUM_DIR_LIGHTS/g, parameters.numDirLights).replace(/NUM_SPOT_LIGHTS/g, parameters.numSpotLights).replace(/NUM_SPOT_LIGHT_MAPS/g, parameters.numSpotLightMaps).replace(/NUM_SPOT_LIGHT_COORDS/g, numSpotLightCoords).replace(/NUM_RECT_AREA_LIGHTS/g, parameters.numRectAreaLights).replace(/NUM_POINT_LIGHTS/g, parameters.numPointLights).replace(/NUM_HEMI_LIGHTS/g, parameters.numHemiLights).replace(/NUM_DIR_LIGHT_SHADOWS/g, parameters.numDirLightShadows).replace(/NUM_SPOT_LIGHT_SHADOWS_WITH_MAPS/g, parameters.numSpotLightShadowsWithMaps).replace(/NUM_SPOT_LIGHT_SHADOWS/g, parameters.numSpotLightShadows).replace(/NUM_POINT_LIGHT_SHADOWS/g, parameters.numPointLightShadows);\n}\nfunction replaceClippingPlaneNums(string, parameters) {\n  return string.replace(/NUM_CLIPPING_PLANES/g, parameters.numClippingPlanes).replace(/UNION_CLIPPING_PLANES/g, parameters.numClippingPlanes - parameters.numClipIntersection);\n}\n\n// Resolve Includes\n\nconst includePattern = /^[ \\t]*#include +<([\\w\\d./]+)>/gm;\nfunction resolveIncludes(string) {\n  return string.replace(includePattern, includeReplacer);\n}\nconst shaderChunkMap = new Map();\nfunction includeReplacer(match, include) {\n  let string = ShaderChunk[include];\n  if (string === undefined) {\n    const newInclude = shaderChunkMap.get(include);\n    if (newInclude !== undefined) {\n      string = ShaderChunk[newInclude];\n      console.warn('THREE.WebGLRenderer: Shader chunk \"%s\" has been deprecated. Use \"%s\" instead.', include, newInclude);\n    } else {\n      throw new Error('Can not resolve #include <' + include + '>');\n    }\n  }\n  return resolveIncludes(string);\n}\n\n// Unroll Loops\n\nconst unrollLoopPattern = /#pragma unroll_loop_start\\s+for\\s*\\(\\s*int\\s+i\\s*=\\s*(\\d+)\\s*;\\s*i\\s*<\\s*(\\d+)\\s*;\\s*i\\s*\\+\\+\\s*\\)\\s*{([\\s\\S]+?)}\\s+#pragma unroll_loop_end/g;\nfunction unrollLoops(string) {\n  return string.replace(unrollLoopPattern, loopReplacer);\n}\nfunction loopReplacer(match, start, end, snippet) {\n  let string = '';\n  for (let i = parseInt(start); i < parseInt(end); i++) {\n    string += snippet.replace(/\\[\\s*i\\s*\\]/g, '[ ' + i + ' ]').replace(/UNROLLED_LOOP_INDEX/g, i);\n  }\n  return string;\n}\n\n//\n\nfunction generatePrecision(parameters) {\n  let precisionstring = `precision ${parameters.precision} float;\n\tprecision ${parameters.precision} int;\n\tprecision ${parameters.precision} sampler2D;\n\tprecision ${parameters.precision} samplerCube;\n\tprecision ${parameters.precision} sampler3D;\n\tprecision ${parameters.precision} sampler2DArray;\n\tprecision ${parameters.precision} sampler2DShadow;\n\tprecision ${parameters.precision} samplerCubeShadow;\n\tprecision ${parameters.precision} sampler2DArrayShadow;\n\tprecision ${parameters.precision} isampler2D;\n\tprecision ${parameters.precision} isampler3D;\n\tprecision ${parameters.precision} isamplerCube;\n\tprecision ${parameters.precision} isampler2DArray;\n\tprecision ${parameters.precision} usampler2D;\n\tprecision ${parameters.precision} usampler3D;\n\tprecision ${parameters.precision} usamplerCube;\n\tprecision ${parameters.precision} usampler2DArray;\n\t`;\n  if (parameters.precision === 'highp') {\n    precisionstring += '\\n#define HIGH_PRECISION';\n  } else if (parameters.precision === 'mediump') {\n    precisionstring += '\\n#define MEDIUM_PRECISION';\n  } else if (parameters.precision === 'lowp') {\n    precisionstring += '\\n#define LOW_PRECISION';\n  }\n  return precisionstring;\n}\nfunction generateShadowMapTypeDefine(parameters) {\n  let shadowMapTypeDefine = 'SHADOWMAP_TYPE_BASIC';\n  if (parameters.shadowMapType === PCFShadowMap) {\n    shadowMapTypeDefine = 'SHADOWMAP_TYPE_PCF';\n  } else if (parameters.shadowMapType === PCFSoftShadowMap) {\n    shadowMapTypeDefine = 'SHADOWMAP_TYPE_PCF_SOFT';\n  } else if (parameters.shadowMapType === VSMShadowMap) {\n    shadowMapTypeDefine = 'SHADOWMAP_TYPE_VSM';\n  }\n  return shadowMapTypeDefine;\n}\nfunction generateEnvMapTypeDefine(parameters) {\n  let envMapTypeDefine = 'ENVMAP_TYPE_CUBE';\n  if (parameters.envMap) {\n    switch (parameters.envMapMode) {\n      case CubeReflectionMapping:\n      case CubeRefractionMapping:\n        envMapTypeDefine = 'ENVMAP_TYPE_CUBE';\n        break;\n      case CubeUVReflectionMapping:\n        envMapTypeDefine = 'ENVMAP_TYPE_CUBE_UV';\n        break;\n    }\n  }\n  return envMapTypeDefine;\n}\nfunction generateEnvMapModeDefine(parameters) {\n  let envMapModeDefine = 'ENVMAP_MODE_REFLECTION';\n  if (parameters.envMap) {\n    switch (parameters.envMapMode) {\n      case CubeRefractionMapping:\n        envMapModeDefine = 'ENVMAP_MODE_REFRACTION';\n        break;\n    }\n  }\n  return envMapModeDefine;\n}\nfunction generateEnvMapBlendingDefine(parameters) {\n  let envMapBlendingDefine = 'ENVMAP_BLENDING_NONE';\n  if (parameters.envMap) {\n    switch (parameters.combine) {\n      case MultiplyOperation:\n        envMapBlendingDefine = 'ENVMAP_BLENDING_MULTIPLY';\n        break;\n      case MixOperation:\n        envMapBlendingDefine = 'ENVMAP_BLENDING_MIX';\n        break;\n      case AddOperation:\n        envMapBlendingDefine = 'ENVMAP_BLENDING_ADD';\n        break;\n    }\n  }\n  return envMapBlendingDefine;\n}\nfunction generateCubeUVSize(parameters) {\n  const imageHeight = parameters.envMapCubeUVHeight;\n  if (imageHeight === null) return null;\n  const maxMip = Math.log2(imageHeight) - 2;\n  const texelHeight = 1.0 / imageHeight;\n  const texelWidth = 1.0 / (3 * Math.max(Math.pow(2, maxMip), 7 * 16));\n  return {\n    texelWidth,\n    texelHeight,\n    maxMip\n  };\n}\nfunction WebGLProgram(renderer, cacheKey, parameters, bindingStates) {\n  // TODO Send this event to Three.js DevTools\n  // console.log( 'WebGLProgram', cacheKey );\n\n  const gl = renderer.getContext();\n  const defines = parameters.defines;\n  let vertexShader = parameters.vertexShader;\n  let fragmentShader = parameters.fragmentShader;\n  const shadowMapTypeDefine = generateShadowMapTypeDefine(parameters);\n  const envMapTypeDefine = generateEnvMapTypeDefine(parameters);\n  const envMapModeDefine = generateEnvMapModeDefine(parameters);\n  const envMapBlendingDefine = generateEnvMapBlendingDefine(parameters);\n  const envMapCubeUVSize = generateCubeUVSize(parameters);\n  const customVertexExtensions = generateVertexExtensions(parameters);\n  const customDefines = generateDefines(defines);\n  const program = gl.createProgram();\n  let prefixVertex, prefixFragment;\n  let versionString = parameters.glslVersion ? '#version ' + parameters.glslVersion + '\\n' : '';\n  if (parameters.isRawShaderMaterial) {\n    prefixVertex = ['#define SHADER_TYPE ' + parameters.shaderType, '#define SHADER_NAME ' + parameters.shaderName, customDefines].filter(filterEmptyLine).join('\\n');\n    if (prefixVertex.length > 0) {\n      prefixVertex += '\\n';\n    }\n    prefixFragment = ['#define SHADER_TYPE ' + parameters.shaderType, '#define SHADER_NAME ' + parameters.shaderName, customDefines].filter(filterEmptyLine).join('\\n');\n    if (prefixFragment.length > 0) {\n      prefixFragment += '\\n';\n    }\n  } else {\n    prefixVertex = [generatePrecision(parameters), '#define SHADER_TYPE ' + parameters.shaderType, '#define SHADER_NAME ' + parameters.shaderName, customDefines, parameters.extensionClipCullDistance ? '#define USE_CLIP_DISTANCE' : '', parameters.batching ? '#define USE_BATCHING' : '', parameters.batchingColor ? '#define USE_BATCHING_COLOR' : '', parameters.instancing ? '#define USE_INSTANCING' : '', parameters.instancingColor ? '#define USE_INSTANCING_COLOR' : '', parameters.instancingMorph ? '#define USE_INSTANCING_MORPH' : '', parameters.useFog && parameters.fog ? '#define USE_FOG' : '', parameters.useFog && parameters.fogExp2 ? '#define FOG_EXP2' : '', parameters.map ? '#define USE_MAP' : '', parameters.envMap ? '#define USE_ENVMAP' : '', parameters.envMap ? '#define ' + envMapModeDefine : '', parameters.lightMap ? '#define USE_LIGHTMAP' : '', parameters.aoMap ? '#define USE_AOMAP' : '', parameters.bumpMap ? '#define USE_BUMPMAP' : '', parameters.normalMap ? '#define USE_NORMALMAP' : '', parameters.normalMapObjectSpace ? '#define USE_NORMALMAP_OBJECTSPACE' : '', parameters.normalMapTangentSpace ? '#define USE_NORMALMAP_TANGENTSPACE' : '', parameters.displacementMap ? '#define USE_DISPLACEMENTMAP' : '', parameters.emissiveMap ? '#define USE_EMISSIVEMAP' : '', parameters.anisotropy ? '#define USE_ANISOTROPY' : '', parameters.anisotropyMap ? '#define USE_ANISOTROPYMAP' : '', parameters.clearcoatMap ? '#define USE_CLEARCOATMAP' : '', parameters.clearcoatRoughnessMap ? '#define USE_CLEARCOAT_ROUGHNESSMAP' : '', parameters.clearcoatNormalMap ? '#define USE_CLEARCOAT_NORMALMAP' : '', parameters.iridescenceMap ? '#define USE_IRIDESCENCEMAP' : '', parameters.iridescenceThicknessMap ? '#define USE_IRIDESCENCE_THICKNESSMAP' : '', parameters.specularMap ? '#define USE_SPECULARMAP' : '', parameters.specularColorMap ? '#define USE_SPECULAR_COLORMAP' : '', parameters.specularIntensityMap ? '#define USE_SPECULAR_INTENSITYMAP' : '', parameters.roughnessMap ? '#define USE_ROUGHNESSMAP' : '', parameters.metalnessMap ? '#define USE_METALNESSMAP' : '', parameters.alphaMap ? '#define USE_ALPHAMAP' : '', parameters.alphaHash ? '#define USE_ALPHAHASH' : '', parameters.transmission ? '#define USE_TRANSMISSION' : '', parameters.transmissionMap ? '#define USE_TRANSMISSIONMAP' : '', parameters.thicknessMap ? '#define USE_THICKNESSMAP' : '', parameters.sheenColorMap ? '#define USE_SHEEN_COLORMAP' : '', parameters.sheenRoughnessMap ? '#define USE_SHEEN_ROUGHNESSMAP' : '',\n    //\n\n    parameters.mapUv ? '#define MAP_UV ' + parameters.mapUv : '', parameters.alphaMapUv ? '#define ALPHAMAP_UV ' + parameters.alphaMapUv : '', parameters.lightMapUv ? '#define LIGHTMAP_UV ' + parameters.lightMapUv : '', parameters.aoMapUv ? '#define AOMAP_UV ' + parameters.aoMapUv : '', parameters.emissiveMapUv ? '#define EMISSIVEMAP_UV ' + parameters.emissiveMapUv : '', parameters.bumpMapUv ? '#define BUMPMAP_UV ' + parameters.bumpMapUv : '', parameters.normalMapUv ? '#define NORMALMAP_UV ' + parameters.normalMapUv : '', parameters.displacementMapUv ? '#define DISPLACEMENTMAP_UV ' + parameters.displacementMapUv : '', parameters.metalnessMapUv ? '#define METALNESSMAP_UV ' + parameters.metalnessMapUv : '', parameters.roughnessMapUv ? '#define ROUGHNESSMAP_UV ' + parameters.roughnessMapUv : '', parameters.anisotropyMapUv ? '#define ANISOTROPYMAP_UV ' + parameters.anisotropyMapUv : '', parameters.clearcoatMapUv ? '#define CLEARCOATMAP_UV ' + parameters.clearcoatMapUv : '', parameters.clearcoatNormalMapUv ? '#define CLEARCOAT_NORMALMAP_UV ' + parameters.clearcoatNormalMapUv : '', parameters.clearcoatRoughnessMapUv ? '#define CLEARCOAT_ROUGHNESSMAP_UV ' + parameters.clearcoatRoughnessMapUv : '', parameters.iridescenceMapUv ? '#define IRIDESCENCEMAP_UV ' + parameters.iridescenceMapUv : '', parameters.iridescenceThicknessMapUv ? '#define IRIDESCENCE_THICKNESSMAP_UV ' + parameters.iridescenceThicknessMapUv : '', parameters.sheenColorMapUv ? '#define SHEEN_COLORMAP_UV ' + parameters.sheenColorMapUv : '', parameters.sheenRoughnessMapUv ? '#define SHEEN_ROUGHNESSMAP_UV ' + parameters.sheenRoughnessMapUv : '', parameters.specularMapUv ? '#define SPECULARMAP_UV ' + parameters.specularMapUv : '', parameters.specularColorMapUv ? '#define SPECULAR_COLORMAP_UV ' + parameters.specularColorMapUv : '', parameters.specularIntensityMapUv ? '#define SPECULAR_INTENSITYMAP_UV ' + parameters.specularIntensityMapUv : '', parameters.transmissionMapUv ? '#define TRANSMISSIONMAP_UV ' + parameters.transmissionMapUv : '', parameters.thicknessMapUv ? '#define THICKNESSMAP_UV ' + parameters.thicknessMapUv : '',\n    //\n\n    parameters.vertexTangents && parameters.flatShading === false ? '#define USE_TANGENT' : '', parameters.vertexColors ? '#define USE_COLOR' : '', parameters.vertexAlphas ? '#define USE_COLOR_ALPHA' : '', parameters.vertexUv1s ? '#define USE_UV1' : '', parameters.vertexUv2s ? '#define USE_UV2' : '', parameters.vertexUv3s ? '#define USE_UV3' : '', parameters.pointsUvs ? '#define USE_POINTS_UV' : '', parameters.flatShading ? '#define FLAT_SHADED' : '', parameters.skinning ? '#define USE_SKINNING' : '', parameters.morphTargets ? '#define USE_MORPHTARGETS' : '', parameters.morphNormals && parameters.flatShading === false ? '#define USE_MORPHNORMALS' : '', parameters.morphColors ? '#define USE_MORPHCOLORS' : '', parameters.morphTargetsCount > 0 ? '#define MORPHTARGETS_TEXTURE_STRIDE ' + parameters.morphTextureStride : '', parameters.morphTargetsCount > 0 ? '#define MORPHTARGETS_COUNT ' + parameters.morphTargetsCount : '', parameters.doubleSided ? '#define DOUBLE_SIDED' : '', parameters.flipSided ? '#define FLIP_SIDED' : '', parameters.shadowMapEnabled ? '#define USE_SHADOWMAP' : '', parameters.shadowMapEnabled ? '#define ' + shadowMapTypeDefine : '', parameters.sizeAttenuation ? '#define USE_SIZEATTENUATION' : '', parameters.numLightProbes > 0 ? '#define USE_LIGHT_PROBES' : '', parameters.logarithmicDepthBuffer ? '#define USE_LOGDEPTHBUF' : '', parameters.reverseDepthBuffer ? '#define USE_REVERSEDEPTHBUF' : '', 'uniform mat4 modelMatrix;', 'uniform mat4 modelViewMatrix;', 'uniform mat4 projectionMatrix;', 'uniform mat4 viewMatrix;', 'uniform mat3 normalMatrix;', 'uniform vec3 cameraPosition;', 'uniform bool isOrthographic;', '#ifdef USE_INSTANCING', '\tattribute mat4 instanceMatrix;', '#endif', '#ifdef USE_INSTANCING_COLOR', '\tattribute vec3 instanceColor;', '#endif', '#ifdef USE_INSTANCING_MORPH', '\tuniform sampler2D morphTexture;', '#endif', 'attribute vec3 position;', 'attribute vec3 normal;', 'attribute vec2 uv;', '#ifdef USE_UV1', '\tattribute vec2 uv1;', '#endif', '#ifdef USE_UV2', '\tattribute vec2 uv2;', '#endif', '#ifdef USE_UV3', '\tattribute vec2 uv3;', '#endif', '#ifdef USE_TANGENT', '\tattribute vec4 tangent;', '#endif', '#if defined( USE_COLOR_ALPHA )', '\tattribute vec4 color;', '#elif defined( USE_COLOR )', '\tattribute vec3 color;', '#endif', '#ifdef USE_SKINNING', '\tattribute vec4 skinIndex;', '\tattribute vec4 skinWeight;', '#endif', '\\n'].filter(filterEmptyLine).join('\\n');\n    prefixFragment = [generatePrecision(parameters), '#define SHADER_TYPE ' + parameters.shaderType, '#define SHADER_NAME ' + parameters.shaderName, customDefines, parameters.useFog && parameters.fog ? '#define USE_FOG' : '', parameters.useFog && parameters.fogExp2 ? '#define FOG_EXP2' : '', parameters.alphaToCoverage ? '#define ALPHA_TO_COVERAGE' : '', parameters.map ? '#define USE_MAP' : '', parameters.matcap ? '#define USE_MATCAP' : '', parameters.envMap ? '#define USE_ENVMAP' : '', parameters.envMap ? '#define ' + envMapTypeDefine : '', parameters.envMap ? '#define ' + envMapModeDefine : '', parameters.envMap ? '#define ' + envMapBlendingDefine : '', envMapCubeUVSize ? '#define CUBEUV_TEXEL_WIDTH ' + envMapCubeUVSize.texelWidth : '', envMapCubeUVSize ? '#define CUBEUV_TEXEL_HEIGHT ' + envMapCubeUVSize.texelHeight : '', envMapCubeUVSize ? '#define CUBEUV_MAX_MIP ' + envMapCubeUVSize.maxMip + '.0' : '', parameters.lightMap ? '#define USE_LIGHTMAP' : '', parameters.aoMap ? '#define USE_AOMAP' : '', parameters.bumpMap ? '#define USE_BUMPMAP' : '', parameters.normalMap ? '#define USE_NORMALMAP' : '', parameters.normalMapObjectSpace ? '#define USE_NORMALMAP_OBJECTSPACE' : '', parameters.normalMapTangentSpace ? '#define USE_NORMALMAP_TANGENTSPACE' : '', parameters.emissiveMap ? '#define USE_EMISSIVEMAP' : '', parameters.anisotropy ? '#define USE_ANISOTROPY' : '', parameters.anisotropyMap ? '#define USE_ANISOTROPYMAP' : '', parameters.clearcoat ? '#define USE_CLEARCOAT' : '', parameters.clearcoatMap ? '#define USE_CLEARCOATMAP' : '', parameters.clearcoatRoughnessMap ? '#define USE_CLEARCOAT_ROUGHNESSMAP' : '', parameters.clearcoatNormalMap ? '#define USE_CLEARCOAT_NORMALMAP' : '', parameters.dispersion ? '#define USE_DISPERSION' : '', parameters.iridescence ? '#define USE_IRIDESCENCE' : '', parameters.iridescenceMap ? '#define USE_IRIDESCENCEMAP' : '', parameters.iridescenceThicknessMap ? '#define USE_IRIDESCENCE_THICKNESSMAP' : '', parameters.specularMap ? '#define USE_SPECULARMAP' : '', parameters.specularColorMap ? '#define USE_SPECULAR_COLORMAP' : '', parameters.specularIntensityMap ? '#define USE_SPECULAR_INTENSITYMAP' : '', parameters.roughnessMap ? '#define USE_ROUGHNESSMAP' : '', parameters.metalnessMap ? '#define USE_METALNESSMAP' : '', parameters.alphaMap ? '#define USE_ALPHAMAP' : '', parameters.alphaTest ? '#define USE_ALPHATEST' : '', parameters.alphaHash ? '#define USE_ALPHAHASH' : '', parameters.sheen ? '#define USE_SHEEN' : '', parameters.sheenColorMap ? '#define USE_SHEEN_COLORMAP' : '', parameters.sheenRoughnessMap ? '#define USE_SHEEN_ROUGHNESSMAP' : '', parameters.transmission ? '#define USE_TRANSMISSION' : '', parameters.transmissionMap ? '#define USE_TRANSMISSIONMAP' : '', parameters.thicknessMap ? '#define USE_THICKNESSMAP' : '', parameters.vertexTangents && parameters.flatShading === false ? '#define USE_TANGENT' : '', parameters.vertexColors || parameters.instancingColor || parameters.batchingColor ? '#define USE_COLOR' : '', parameters.vertexAlphas ? '#define USE_COLOR_ALPHA' : '', parameters.vertexUv1s ? '#define USE_UV1' : '', parameters.vertexUv2s ? '#define USE_UV2' : '', parameters.vertexUv3s ? '#define USE_UV3' : '', parameters.pointsUvs ? '#define USE_POINTS_UV' : '', parameters.gradientMap ? '#define USE_GRADIENTMAP' : '', parameters.flatShading ? '#define FLAT_SHADED' : '', parameters.doubleSided ? '#define DOUBLE_SIDED' : '', parameters.flipSided ? '#define FLIP_SIDED' : '', parameters.shadowMapEnabled ? '#define USE_SHADOWMAP' : '', parameters.shadowMapEnabled ? '#define ' + shadowMapTypeDefine : '', parameters.premultipliedAlpha ? '#define PREMULTIPLIED_ALPHA' : '', parameters.numLightProbes > 0 ? '#define USE_LIGHT_PROBES' : '', parameters.decodeVideoTexture ? '#define DECODE_VIDEO_TEXTURE' : '', parameters.logarithmicDepthBuffer ? '#define USE_LOGDEPTHBUF' : '', parameters.reverseDepthBuffer ? '#define USE_REVERSEDEPTHBUF' : '', 'uniform mat4 viewMatrix;', 'uniform vec3 cameraPosition;', 'uniform bool isOrthographic;', parameters.toneMapping !== NoToneMapping ? '#define TONE_MAPPING' : '', parameters.toneMapping !== NoToneMapping ? ShaderChunk['tonemapping_pars_fragment'] : '',\n    // this code is required here because it is used by the toneMapping() function defined below\n    parameters.toneMapping !== NoToneMapping ? getToneMappingFunction('toneMapping', parameters.toneMapping) : '', parameters.dithering ? '#define DITHERING' : '', parameters.opaque ? '#define OPAQUE' : '', ShaderChunk['colorspace_pars_fragment'],\n    // this code is required here because it is used by the various encoding/decoding function defined below\n    getTexelEncodingFunction('linearToOutputTexel', parameters.outputColorSpace), getLuminanceFunction(), parameters.useDepthPacking ? '#define DEPTH_PACKING ' + parameters.depthPacking : '', '\\n'].filter(filterEmptyLine).join('\\n');\n  }\n  vertexShader = resolveIncludes(vertexShader);\n  vertexShader = replaceLightNums(vertexShader, parameters);\n  vertexShader = replaceClippingPlaneNums(vertexShader, parameters);\n  fragmentShader = resolveIncludes(fragmentShader);\n  fragmentShader = replaceLightNums(fragmentShader, parameters);\n  fragmentShader = replaceClippingPlaneNums(fragmentShader, parameters);\n  vertexShader = unrollLoops(vertexShader);\n  fragmentShader = unrollLoops(fragmentShader);\n  if (parameters.isRawShaderMaterial !== true) {\n    // GLSL 3.0 conversion for built-in materials and ShaderMaterial\n\n    versionString = '#version 300 es\\n';\n    prefixVertex = [customVertexExtensions, '#define attribute in', '#define varying out', '#define texture2D texture'].join('\\n') + '\\n' + prefixVertex;\n    prefixFragment = ['#define varying in', parameters.glslVersion === GLSL3 ? '' : 'layout(location = 0) out highp vec4 pc_fragColor;', parameters.glslVersion === GLSL3 ? '' : '#define gl_FragColor pc_fragColor', '#define gl_FragDepthEXT gl_FragDepth', '#define texture2D texture', '#define textureCube texture', '#define texture2DProj textureProj', '#define texture2DLodEXT textureLod', '#define texture2DProjLodEXT textureProjLod', '#define textureCubeLodEXT textureLod', '#define texture2DGradEXT textureGrad', '#define texture2DProjGradEXT textureProjGrad', '#define textureCubeGradEXT textureGrad'].join('\\n') + '\\n' + prefixFragment;\n  }\n  const vertexGlsl = versionString + prefixVertex + vertexShader;\n  const fragmentGlsl = versionString + prefixFragment + fragmentShader;\n\n  // console.log( '*VERTEX*', vertexGlsl );\n  // console.log( '*FRAGMENT*', fragmentGlsl );\n\n  const glVertexShader = WebGLShader(gl, gl.VERTEX_SHADER, vertexGlsl);\n  const glFragmentShader = WebGLShader(gl, gl.FRAGMENT_SHADER, fragmentGlsl);\n  gl.attachShader(program, glVertexShader);\n  gl.attachShader(program, glFragmentShader);\n\n  // Force a particular attribute to index 0.\n\n  if (parameters.index0AttributeName !== undefined) {\n    gl.bindAttribLocation(program, 0, parameters.index0AttributeName);\n  } else if (parameters.morphTargets === true) {\n    // programs with morphTargets displace position out of attribute 0\n    gl.bindAttribLocation(program, 0, 'position');\n  }\n  gl.linkProgram(program);\n  function onFirstUse(self) {\n    // check for link errors\n    if (renderer.debug.checkShaderErrors) {\n      const programLog = gl.getProgramInfoLog(program).trim();\n      const vertexLog = gl.getShaderInfoLog(glVertexShader).trim();\n      const fragmentLog = gl.getShaderInfoLog(glFragmentShader).trim();\n      let runnable = true;\n      let haveDiagnostics = true;\n      if (gl.getProgramParameter(program, gl.LINK_STATUS) === false) {\n        runnable = false;\n        if (typeof renderer.debug.onShaderError === 'function') {\n          renderer.debug.onShaderError(gl, program, glVertexShader, glFragmentShader);\n        } else {\n          // default error reporting\n\n          const vertexErrors = getShaderErrors(gl, glVertexShader, 'vertex');\n          const fragmentErrors = getShaderErrors(gl, glFragmentShader, 'fragment');\n          console.error('THREE.WebGLProgram: Shader Error ' + gl.getError() + ' - ' + 'VALIDATE_STATUS ' + gl.getProgramParameter(program, gl.VALIDATE_STATUS) + '\\n\\n' + 'Material Name: ' + self.name + '\\n' + 'Material Type: ' + self.type + '\\n\\n' + 'Program Info Log: ' + programLog + '\\n' + vertexErrors + '\\n' + fragmentErrors);\n        }\n      } else if (programLog !== '') {\n        console.warn('THREE.WebGLProgram: Program Info Log:', programLog);\n      } else if (vertexLog === '' || fragmentLog === '') {\n        haveDiagnostics = false;\n      }\n      if (haveDiagnostics) {\n        self.diagnostics = {\n          runnable: runnable,\n          programLog: programLog,\n          vertexShader: {\n            log: vertexLog,\n            prefix: prefixVertex\n          },\n          fragmentShader: {\n            log: fragmentLog,\n            prefix: prefixFragment\n          }\n        };\n      }\n    }\n\n    // Clean up\n\n    // Crashes in iOS9 and iOS10. #18402\n    // gl.detachShader( program, glVertexShader );\n    // gl.detachShader( program, glFragmentShader );\n\n    gl.deleteShader(glVertexShader);\n    gl.deleteShader(glFragmentShader);\n    cachedUniforms = new WebGLUniforms(gl, program);\n    cachedAttributes = fetchAttributeLocations(gl, program);\n  }\n\n  // set up caching for uniform locations\n\n  let cachedUniforms;\n  this.getUniforms = function () {\n    if (cachedUniforms === undefined) {\n      // Populates cachedUniforms and cachedAttributes\n      onFirstUse(this);\n    }\n    return cachedUniforms;\n  };\n\n  // set up caching for attribute locations\n\n  let cachedAttributes;\n  this.getAttributes = function () {\n    if (cachedAttributes === undefined) {\n      // Populates cachedAttributes and cachedUniforms\n      onFirstUse(this);\n    }\n    return cachedAttributes;\n  };\n\n  // indicate when the program is ready to be used. if the KHR_parallel_shader_compile extension isn't supported,\n  // flag the program as ready immediately. It may cause a stall when it's first used.\n\n  let programReady = parameters.rendererExtensionParallelShaderCompile === false;\n  this.isReady = function () {\n    if (programReady === false) {\n      programReady = gl.getProgramParameter(program, COMPLETION_STATUS_KHR);\n    }\n    return programReady;\n  };\n\n  // free resource\n\n  this.destroy = function () {\n    bindingStates.releaseStatesOfProgram(this);\n    gl.deleteProgram(program);\n    this.program = undefined;\n  };\n\n  //\n\n  this.type = parameters.shaderType;\n  this.name = parameters.shaderName;\n  this.id = programIdCount++;\n  this.cacheKey = cacheKey;\n  this.usedTimes = 1;\n  this.program = program;\n  this.vertexShader = glVertexShader;\n  this.fragmentShader = glFragmentShader;\n  return this;\n}\nlet _id$1 = 0;\nclass WebGLShaderCache {\n  constructor() {\n    this.shaderCache = new Map();\n    this.materialCache = new Map();\n  }\n  update(material) {\n    const vertexShader = material.vertexShader;\n    const fragmentShader = material.fragmentShader;\n    const vertexShaderStage = this._getShaderStage(vertexShader);\n    const fragmentShaderStage = this._getShaderStage(fragmentShader);\n    const materialShaders = this._getShaderCacheForMaterial(material);\n    if (materialShaders.has(vertexShaderStage) === false) {\n      materialShaders.add(vertexShaderStage);\n      vertexShaderStage.usedTimes++;\n    }\n    if (materialShaders.has(fragmentShaderStage) === false) {\n      materialShaders.add(fragmentShaderStage);\n      fragmentShaderStage.usedTimes++;\n    }\n    return this;\n  }\n  remove(material) {\n    const materialShaders = this.materialCache.get(material);\n    for (const shaderStage of materialShaders) {\n      shaderStage.usedTimes--;\n      if (shaderStage.usedTimes === 0) this.shaderCache.delete(shaderStage.code);\n    }\n    this.materialCache.delete(material);\n    return this;\n  }\n  getVertexShaderID(material) {\n    return this._getShaderStage(material.vertexShader).id;\n  }\n  getFragmentShaderID(material) {\n    return this._getShaderStage(material.fragmentShader).id;\n  }\n  dispose() {\n    this.shaderCache.clear();\n    this.materialCache.clear();\n  }\n  _getShaderCacheForMaterial(material) {\n    const cache = this.materialCache;\n    let set = cache.get(material);\n    if (set === undefined) {\n      set = new Set();\n      cache.set(material, set);\n    }\n    return set;\n  }\n  _getShaderStage(code) {\n    const cache = this.shaderCache;\n    let stage = cache.get(code);\n    if (stage === undefined) {\n      stage = new WebGLShaderStage(code);\n      cache.set(code, stage);\n    }\n    return stage;\n  }\n}\nclass WebGLShaderStage {\n  constructor(code) {\n    this.id = _id$1++;\n    this.code = code;\n    this.usedTimes = 0;\n  }\n}\nfunction WebGLPrograms(renderer, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping) {\n  const _programLayers = new Layers();\n  const _customShaders = new WebGLShaderCache();\n  const _activeChannels = new Set();\n  const programs = [];\n  const logarithmicDepthBuffer = capabilities.logarithmicDepthBuffer;\n  const reverseDepthBuffer = capabilities.reverseDepthBuffer;\n  const SUPPORTS_VERTEX_TEXTURES = capabilities.vertexTextures;\n  let precision = capabilities.precision;\n  const shaderIDs = {\n    MeshDepthMaterial: 'depth',\n    MeshDistanceMaterial: 'distanceRGBA',\n    MeshNormalMaterial: 'normal',\n    MeshBasicMaterial: 'basic',\n    MeshLambertMaterial: 'lambert',\n    MeshPhongMaterial: 'phong',\n    MeshToonMaterial: 'toon',\n    MeshStandardMaterial: 'physical',\n    MeshPhysicalMaterial: 'physical',\n    MeshMatcapMaterial: 'matcap',\n    LineBasicMaterial: 'basic',\n    LineDashedMaterial: 'dashed',\n    PointsMaterial: 'points',\n    ShadowMaterial: 'shadow',\n    SpriteMaterial: 'sprite'\n  };\n  function getChannel(value) {\n    _activeChannels.add(value);\n    if (value === 0) return 'uv';\n    return `uv${value}`;\n  }\n  function getParameters(material, lights, shadows, scene, object) {\n    const fog = scene.fog;\n    const geometry = object.geometry;\n    const environment = material.isMeshStandardMaterial ? scene.environment : null;\n    const envMap = (material.isMeshStandardMaterial ? cubeuvmaps : cubemaps).get(material.envMap || environment);\n    const envMapCubeUVHeight = !!envMap && envMap.mapping === CubeUVReflectionMapping ? envMap.image.height : null;\n    const shaderID = shaderIDs[material.type];\n\n    // heuristics to create shader parameters according to lights in the scene\n    // (not to blow over maxLights budget)\n\n    if (material.precision !== null) {\n      precision = capabilities.getMaxPrecision(material.precision);\n      if (precision !== material.precision) {\n        console.warn('THREE.WebGLProgram.getParameters:', material.precision, 'not supported, using', precision, 'instead.');\n      }\n    }\n\n    //\n\n    const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;\n    const morphTargetsCount = morphAttribute !== undefined ? morphAttribute.length : 0;\n    let morphTextureStride = 0;\n    if (geometry.morphAttributes.position !== undefined) morphTextureStride = 1;\n    if (geometry.morphAttributes.normal !== undefined) morphTextureStride = 2;\n    if (geometry.morphAttributes.color !== undefined) morphTextureStride = 3;\n\n    //\n\n    let vertexShader, fragmentShader;\n    let customVertexShaderID, customFragmentShaderID;\n    if (shaderID) {\n      const shader = ShaderLib[shaderID];\n      vertexShader = shader.vertexShader;\n      fragmentShader = shader.fragmentShader;\n    } else {\n      vertexShader = material.vertexShader;\n      fragmentShader = material.fragmentShader;\n      _customShaders.update(material);\n      customVertexShaderID = _customShaders.getVertexShaderID(material);\n      customFragmentShaderID = _customShaders.getFragmentShaderID(material);\n    }\n    const currentRenderTarget = renderer.getRenderTarget();\n    const IS_INSTANCEDMESH = object.isInstancedMesh === true;\n    const IS_BATCHEDMESH = object.isBatchedMesh === true;\n    const HAS_MAP = !!material.map;\n    const HAS_MATCAP = !!material.matcap;\n    const HAS_ENVMAP = !!envMap;\n    const HAS_AOMAP = !!material.aoMap;\n    const HAS_LIGHTMAP = !!material.lightMap;\n    const HAS_BUMPMAP = !!material.bumpMap;\n    const HAS_NORMALMAP = !!material.normalMap;\n    const HAS_DISPLACEMENTMAP = !!material.displacementMap;\n    const HAS_EMISSIVEMAP = !!material.emissiveMap;\n    const HAS_METALNESSMAP = !!material.metalnessMap;\n    const HAS_ROUGHNESSMAP = !!material.roughnessMap;\n    const HAS_ANISOTROPY = material.anisotropy > 0;\n    const HAS_CLEARCOAT = material.clearcoat > 0;\n    const HAS_DISPERSION = material.dispersion > 0;\n    const HAS_IRIDESCENCE = material.iridescence > 0;\n    const HAS_SHEEN = material.sheen > 0;\n    const HAS_TRANSMISSION = material.transmission > 0;\n    const HAS_ANISOTROPYMAP = HAS_ANISOTROPY && !!material.anisotropyMap;\n    const HAS_CLEARCOATMAP = HAS_CLEARCOAT && !!material.clearcoatMap;\n    const HAS_CLEARCOAT_NORMALMAP = HAS_CLEARCOAT && !!material.clearcoatNormalMap;\n    const HAS_CLEARCOAT_ROUGHNESSMAP = HAS_CLEARCOAT && !!material.clearcoatRoughnessMap;\n    const HAS_IRIDESCENCEMAP = HAS_IRIDESCENCE && !!material.iridescenceMap;\n    const HAS_IRIDESCENCE_THICKNESSMAP = HAS_IRIDESCENCE && !!material.iridescenceThicknessMap;\n    const HAS_SHEEN_COLORMAP = HAS_SHEEN && !!material.sheenColorMap;\n    const HAS_SHEEN_ROUGHNESSMAP = HAS_SHEEN && !!material.sheenRoughnessMap;\n    const HAS_SPECULARMAP = !!material.specularMap;\n    const HAS_SPECULAR_COLORMAP = !!material.specularColorMap;\n    const HAS_SPECULAR_INTENSITYMAP = !!material.specularIntensityMap;\n    const HAS_TRANSMISSIONMAP = HAS_TRANSMISSION && !!material.transmissionMap;\n    const HAS_THICKNESSMAP = HAS_TRANSMISSION && !!material.thicknessMap;\n    const HAS_GRADIENTMAP = !!material.gradientMap;\n    const HAS_ALPHAMAP = !!material.alphaMap;\n    const HAS_ALPHATEST = material.alphaTest > 0;\n    const HAS_ALPHAHASH = !!material.alphaHash;\n    const HAS_EXTENSIONS = !!material.extensions;\n    let toneMapping = NoToneMapping;\n    if (material.toneMapped) {\n      if (currentRenderTarget === null || currentRenderTarget.isXRRenderTarget === true) {\n        toneMapping = renderer.toneMapping;\n      }\n    }\n    const parameters = {\n      shaderID: shaderID,\n      shaderType: material.type,\n      shaderName: material.name,\n      vertexShader: vertexShader,\n      fragmentShader: fragmentShader,\n      defines: material.defines,\n      customVertexShaderID: customVertexShaderID,\n      customFragmentShaderID: customFragmentShaderID,\n      isRawShaderMaterial: material.isRawShaderMaterial === true,\n      glslVersion: material.glslVersion,\n      precision: precision,\n      batching: IS_BATCHEDMESH,\n      batchingColor: IS_BATCHEDMESH && object._colorsTexture !== null,\n      instancing: IS_INSTANCEDMESH,\n      instancingColor: IS_INSTANCEDMESH && object.instanceColor !== null,\n      instancingMorph: IS_INSTANCEDMESH && object.morphTexture !== null,\n      supportsVertexTextures: SUPPORTS_VERTEX_TEXTURES,\n      outputColorSpace: currentRenderTarget === null ? renderer.outputColorSpace : currentRenderTarget.isXRRenderTarget === true ? currentRenderTarget.texture.colorSpace : LinearSRGBColorSpace,\n      alphaToCoverage: !!material.alphaToCoverage,\n      map: HAS_MAP,\n      matcap: HAS_MATCAP,\n      envMap: HAS_ENVMAP,\n      envMapMode: HAS_ENVMAP && envMap.mapping,\n      envMapCubeUVHeight: envMapCubeUVHeight,\n      aoMap: HAS_AOMAP,\n      lightMap: HAS_LIGHTMAP,\n      bumpMap: HAS_BUMPMAP,\n      normalMap: HAS_NORMALMAP,\n      displacementMap: SUPPORTS_VERTEX_TEXTURES && HAS_DISPLACEMENTMAP,\n      emissiveMap: HAS_EMISSIVEMAP,\n      normalMapObjectSpace: HAS_NORMALMAP && material.normalMapType === ObjectSpaceNormalMap,\n      normalMapTangentSpace: HAS_NORMALMAP && material.normalMapType === TangentSpaceNormalMap,\n      metalnessMap: HAS_METALNESSMAP,\n      roughnessMap: HAS_ROUGHNESSMAP,\n      anisotropy: HAS_ANISOTROPY,\n      anisotropyMap: HAS_ANISOTROPYMAP,\n      clearcoat: HAS_CLEARCOAT,\n      clearcoatMap: HAS_CLEARCOATMAP,\n      clearcoatNormalMap: HAS_CLEARCOAT_NORMALMAP,\n      clearcoatRoughnessMap: HAS_CLEARCOAT_ROUGHNESSMAP,\n      dispersion: HAS_DISPERSION,\n      iridescence: HAS_IRIDESCENCE,\n      iridescenceMap: HAS_IRIDESCENCEMAP,\n      iridescenceThicknessMap: HAS_IRIDESCENCE_THICKNESSMAP,\n      sheen: HAS_SHEEN,\n      sheenColorMap: HAS_SHEEN_COLORMAP,\n      sheenRoughnessMap: HAS_SHEEN_ROUGHNESSMAP,\n      specularMap: HAS_SPECULARMAP,\n      specularColorMap: HAS_SPECULAR_COLORMAP,\n      specularIntensityMap: HAS_SPECULAR_INTENSITYMAP,\n      transmission: HAS_TRANSMISSION,\n      transmissionMap: HAS_TRANSMISSIONMAP,\n      thicknessMap: HAS_THICKNESSMAP,\n      gradientMap: HAS_GRADIENTMAP,\n      opaque: material.transparent === false && material.blending === NormalBlending && material.alphaToCoverage === false,\n      alphaMap: HAS_ALPHAMAP,\n      alphaTest: HAS_ALPHATEST,\n      alphaHash: HAS_ALPHAHASH,\n      combine: material.combine,\n      //\n\n      mapUv: HAS_MAP && getChannel(material.map.channel),\n      aoMapUv: HAS_AOMAP && getChannel(material.aoMap.channel),\n      lightMapUv: HAS_LIGHTMAP && getChannel(material.lightMap.channel),\n      bumpMapUv: HAS_BUMPMAP && getChannel(material.bumpMap.channel),\n      normalMapUv: HAS_NORMALMAP && getChannel(material.normalMap.channel),\n      displacementMapUv: HAS_DISPLACEMENTMAP && getChannel(material.displacementMap.channel),\n      emissiveMapUv: HAS_EMISSIVEMAP && getChannel(material.emissiveMap.channel),\n      metalnessMapUv: HAS_METALNESSMAP && getChannel(material.metalnessMap.channel),\n      roughnessMapUv: HAS_ROUGHNESSMAP && getChannel(material.roughnessMap.channel),\n      anisotropyMapUv: HAS_ANISOTROPYMAP && getChannel(material.anisotropyMap.channel),\n      clearcoatMapUv: HAS_CLEARCOATMAP && getChannel(material.clearcoatMap.channel),\n      clearcoatNormalMapUv: HAS_CLEARCOAT_NORMALMAP && getChannel(material.clearcoatNormalMap.channel),\n      clearcoatRoughnessMapUv: HAS_CLEARCOAT_ROUGHNESSMAP && getChannel(material.clearcoatRoughnessMap.channel),\n      iridescenceMapUv: HAS_IRIDESCENCEMAP && getChannel(material.iridescenceMap.channel),\n      iridescenceThicknessMapUv: HAS_IRIDESCENCE_THICKNESSMAP && getChannel(material.iridescenceThicknessMap.channel),\n      sheenColorMapUv: HAS_SHEEN_COLORMAP && getChannel(material.sheenColorMap.channel),\n      sheenRoughnessMapUv: HAS_SHEEN_ROUGHNESSMAP && getChannel(material.sheenRoughnessMap.channel),\n      specularMapUv: HAS_SPECULARMAP && getChannel(material.specularMap.channel),\n      specularColorMapUv: HAS_SPECULAR_COLORMAP && getChannel(material.specularColorMap.channel),\n      specularIntensityMapUv: HAS_SPECULAR_INTENSITYMAP && getChannel(material.specularIntensityMap.channel),\n      transmissionMapUv: HAS_TRANSMISSIONMAP && getChannel(material.transmissionMap.channel),\n      thicknessMapUv: HAS_THICKNESSMAP && getChannel(material.thicknessMap.channel),\n      alphaMapUv: HAS_ALPHAMAP && getChannel(material.alphaMap.channel),\n      //\n\n      vertexTangents: !!geometry.attributes.tangent && (HAS_NORMALMAP || HAS_ANISOTROPY),\n      vertexColors: material.vertexColors,\n      vertexAlphas: material.vertexColors === true && !!geometry.attributes.color && geometry.attributes.color.itemSize === 4,\n      pointsUvs: object.isPoints === true && !!geometry.attributes.uv && (HAS_MAP || HAS_ALPHAMAP),\n      fog: !!fog,\n      useFog: material.fog === true,\n      fogExp2: !!fog && fog.isFogExp2,\n      flatShading: material.flatShading === true,\n      sizeAttenuation: material.sizeAttenuation === true,\n      logarithmicDepthBuffer: logarithmicDepthBuffer,\n      reverseDepthBuffer: reverseDepthBuffer,\n      skinning: object.isSkinnedMesh === true,\n      morphTargets: geometry.morphAttributes.position !== undefined,\n      morphNormals: geometry.morphAttributes.normal !== undefined,\n      morphColors: geometry.morphAttributes.color !== undefined,\n      morphTargetsCount: morphTargetsCount,\n      morphTextureStride: morphTextureStride,\n      numDirLights: lights.directional.length,\n      numPointLights: lights.point.length,\n      numSpotLights: lights.spot.length,\n      numSpotLightMaps: lights.spotLightMap.length,\n      numRectAreaLights: lights.rectArea.length,\n      numHemiLights: lights.hemi.length,\n      numDirLightShadows: lights.directionalShadowMap.length,\n      numPointLightShadows: lights.pointShadowMap.length,\n      numSpotLightShadows: lights.spotShadowMap.length,\n      numSpotLightShadowsWithMaps: lights.numSpotLightShadowsWithMaps,\n      numLightProbes: lights.numLightProbes,\n      numClippingPlanes: clipping.numPlanes,\n      numClipIntersection: clipping.numIntersection,\n      dithering: material.dithering,\n      shadowMapEnabled: renderer.shadowMap.enabled && shadows.length > 0,\n      shadowMapType: renderer.shadowMap.type,\n      toneMapping: toneMapping,\n      decodeVideoTexture: HAS_MAP && material.map.isVideoTexture === true && ColorManagement.getTransfer(material.map.colorSpace) === SRGBTransfer,\n      premultipliedAlpha: material.premultipliedAlpha,\n      doubleSided: material.side === DoubleSide,\n      flipSided: material.side === BackSide,\n      useDepthPacking: material.depthPacking >= 0,\n      depthPacking: material.depthPacking || 0,\n      index0AttributeName: material.index0AttributeName,\n      extensionClipCullDistance: HAS_EXTENSIONS && material.extensions.clipCullDistance === true && extensions.has('WEBGL_clip_cull_distance'),\n      extensionMultiDraw: (HAS_EXTENSIONS && material.extensions.multiDraw === true || IS_BATCHEDMESH) && extensions.has('WEBGL_multi_draw'),\n      rendererExtensionParallelShaderCompile: extensions.has('KHR_parallel_shader_compile'),\n      customProgramCacheKey: material.customProgramCacheKey()\n    };\n\n    // the usage of getChannel() determines the active texture channels for this shader\n\n    parameters.vertexUv1s = _activeChannels.has(1);\n    parameters.vertexUv2s = _activeChannels.has(2);\n    parameters.vertexUv3s = _activeChannels.has(3);\n    _activeChannels.clear();\n    return parameters;\n  }\n  function getProgramCacheKey(parameters) {\n    const array = [];\n    if (parameters.shaderID) {\n      array.push(parameters.shaderID);\n    } else {\n      array.push(parameters.customVertexShaderID);\n      array.push(parameters.customFragmentShaderID);\n    }\n    if (parameters.defines !== undefined) {\n      for (const name in parameters.defines) {\n        array.push(name);\n        array.push(parameters.defines[name]);\n      }\n    }\n    if (parameters.isRawShaderMaterial === false) {\n      getProgramCacheKeyParameters(array, parameters);\n      getProgramCacheKeyBooleans(array, parameters);\n      array.push(renderer.outputColorSpace);\n    }\n    array.push(parameters.customProgramCacheKey);\n    return array.join();\n  }\n  function getProgramCacheKeyParameters(array, parameters) {\n    array.push(parameters.precision);\n    array.push(parameters.outputColorSpace);\n    array.push(parameters.envMapMode);\n    array.push(parameters.envMapCubeUVHeight);\n    array.push(parameters.mapUv);\n    array.push(parameters.alphaMapUv);\n    array.push(parameters.lightMapUv);\n    array.push(parameters.aoMapUv);\n    array.push(parameters.bumpMapUv);\n    array.push(parameters.normalMapUv);\n    array.push(parameters.displacementMapUv);\n    array.push(parameters.emissiveMapUv);\n    array.push(parameters.metalnessMapUv);\n    array.push(parameters.roughnessMapUv);\n    array.push(parameters.anisotropyMapUv);\n    array.push(parameters.clearcoatMapUv);\n    array.push(parameters.clearcoatNormalMapUv);\n    array.push(parameters.clearcoatRoughnessMapUv);\n    array.push(parameters.iridescenceMapUv);\n    array.push(parameters.iridescenceThicknessMapUv);\n    array.push(parameters.sheenColorMapUv);\n    array.push(parameters.sheenRoughnessMapUv);\n    array.push(parameters.specularMapUv);\n    array.push(parameters.specularColorMapUv);\n    array.push(parameters.specularIntensityMapUv);\n    array.push(parameters.transmissionMapUv);\n    array.push(parameters.thicknessMapUv);\n    array.push(parameters.combine);\n    array.push(parameters.fogExp2);\n    array.push(parameters.sizeAttenuation);\n    array.push(parameters.morphTargetsCount);\n    array.push(parameters.morphAttributeCount);\n    array.push(parameters.numDirLights);\n    array.push(parameters.numPointLights);\n    array.push(parameters.numSpotLights);\n    array.push(parameters.numSpotLightMaps);\n    array.push(parameters.numHemiLights);\n    array.push(parameters.numRectAreaLights);\n    array.push(parameters.numDirLightShadows);\n    array.push(parameters.numPointLightShadows);\n    array.push(parameters.numSpotLightShadows);\n    array.push(parameters.numSpotLightShadowsWithMaps);\n    array.push(parameters.numLightProbes);\n    array.push(parameters.shadowMapType);\n    array.push(parameters.toneMapping);\n    array.push(parameters.numClippingPlanes);\n    array.push(parameters.numClipIntersection);\n    array.push(parameters.depthPacking);\n  }\n  function getProgramCacheKeyBooleans(array, parameters) {\n    _programLayers.disableAll();\n    if (parameters.supportsVertexTextures) _programLayers.enable(0);\n    if (parameters.instancing) _programLayers.enable(1);\n    if (parameters.instancingColor) _programLayers.enable(2);\n    if (parameters.instancingMorph) _programLayers.enable(3);\n    if (parameters.matcap) _programLayers.enable(4);\n    if (parameters.envMap) _programLayers.enable(5);\n    if (parameters.normalMapObjectSpace) _programLayers.enable(6);\n    if (parameters.normalMapTangentSpace) _programLayers.enable(7);\n    if (parameters.clearcoat) _programLayers.enable(8);\n    if (parameters.iridescence) _programLayers.enable(9);\n    if (parameters.alphaTest) _programLayers.enable(10);\n    if (parameters.vertexColors) _programLayers.enable(11);\n    if (parameters.vertexAlphas) _programLayers.enable(12);\n    if (parameters.vertexUv1s) _programLayers.enable(13);\n    if (parameters.vertexUv2s) _programLayers.enable(14);\n    if (parameters.vertexUv3s) _programLayers.enable(15);\n    if (parameters.vertexTangents) _programLayers.enable(16);\n    if (parameters.anisotropy) _programLayers.enable(17);\n    if (parameters.alphaHash) _programLayers.enable(18);\n    if (parameters.batching) _programLayers.enable(19);\n    if (parameters.dispersion) _programLayers.enable(20);\n    if (parameters.batchingColor) _programLayers.enable(21);\n    array.push(_programLayers.mask);\n    _programLayers.disableAll();\n    if (parameters.fog) _programLayers.enable(0);\n    if (parameters.useFog) _programLayers.enable(1);\n    if (parameters.flatShading) _programLayers.enable(2);\n    if (parameters.logarithmicDepthBuffer) _programLayers.enable(3);\n    if (parameters.reverseDepthBuffer) _programLayers.enable(4);\n    if (parameters.skinning) _programLayers.enable(5);\n    if (parameters.morphTargets) _programLayers.enable(6);\n    if (parameters.morphNormals) _programLayers.enable(7);\n    if (parameters.morphColors) _programLayers.enable(8);\n    if (parameters.premultipliedAlpha) _programLayers.enable(9);\n    if (parameters.shadowMapEnabled) _programLayers.enable(10);\n    if (parameters.doubleSided) _programLayers.enable(11);\n    if (parameters.flipSided) _programLayers.enable(12);\n    if (parameters.useDepthPacking) _programLayers.enable(13);\n    if (parameters.dithering) _programLayers.enable(14);\n    if (parameters.transmission) _programLayers.enable(15);\n    if (parameters.sheen) _programLayers.enable(16);\n    if (parameters.opaque) _programLayers.enable(17);\n    if (parameters.pointsUvs) _programLayers.enable(18);\n    if (parameters.decodeVideoTexture) _programLayers.enable(19);\n    if (parameters.alphaToCoverage) _programLayers.enable(20);\n    array.push(_programLayers.mask);\n  }\n  function getUniforms(material) {\n    const shaderID = shaderIDs[material.type];\n    let uniforms;\n    if (shaderID) {\n      const shader = ShaderLib[shaderID];\n      uniforms = UniformsUtils.clone(shader.uniforms);\n    } else {\n      uniforms = material.uniforms;\n    }\n    return uniforms;\n  }\n  function acquireProgram(parameters, cacheKey) {\n    let program;\n\n    // Check if code has been already compiled\n    for (let p = 0, pl = programs.length; p < pl; p++) {\n      const preexistingProgram = programs[p];\n      if (preexistingProgram.cacheKey === cacheKey) {\n        program = preexistingProgram;\n        ++program.usedTimes;\n        break;\n      }\n    }\n    if (program === undefined) {\n      program = new WebGLProgram(renderer, cacheKey, parameters, bindingStates);\n      programs.push(program);\n    }\n    return program;\n  }\n  function releaseProgram(program) {\n    if (--program.usedTimes === 0) {\n      // Remove from unordered set\n      const i = programs.indexOf(program);\n      programs[i] = programs[programs.length - 1];\n      programs.pop();\n\n      // Free WebGL resources\n      program.destroy();\n    }\n  }\n  function releaseShaderCache(material) {\n    _customShaders.remove(material);\n  }\n  function dispose() {\n    _customShaders.dispose();\n  }\n  return {\n    getParameters: getParameters,\n    getProgramCacheKey: getProgramCacheKey,\n    getUniforms: getUniforms,\n    acquireProgram: acquireProgram,\n    releaseProgram: releaseProgram,\n    releaseShaderCache: releaseShaderCache,\n    // Exposed for resource monitoring & error feedback via renderer.info:\n    programs: programs,\n    dispose: dispose\n  };\n}\nfunction WebGLProperties() {\n  let properties = new WeakMap();\n  function has(object) {\n    return properties.has(object);\n  }\n  function get(object) {\n    let map = properties.get(object);\n    if (map === undefined) {\n      map = {};\n      properties.set(object, map);\n    }\n    return map;\n  }\n  function remove(object) {\n    properties.delete(object);\n  }\n  function update(object, key, value) {\n    properties.get(object)[key] = value;\n  }\n  function dispose() {\n    properties = new WeakMap();\n  }\n  return {\n    has: has,\n    get: get,\n    remove: remove,\n    update: update,\n    dispose: dispose\n  };\n}\nfunction painterSortStable(a, b) {\n  if (a.groupOrder !== b.groupOrder) {\n    return a.groupOrder - b.groupOrder;\n  } else if (a.renderOrder !== b.renderOrder) {\n    return a.renderOrder - b.renderOrder;\n  } else if (a.material.id !== b.material.id) {\n    return a.material.id - b.material.id;\n  } else if (a.z !== b.z) {\n    return a.z - b.z;\n  } else {\n    return a.id - b.id;\n  }\n}\nfunction reversePainterSortStable(a, b) {\n  if (a.groupOrder !== b.groupOrder) {\n    return a.groupOrder - b.groupOrder;\n  } else if (a.renderOrder !== b.renderOrder) {\n    return a.renderOrder - b.renderOrder;\n  } else if (a.z !== b.z) {\n    return b.z - a.z;\n  } else {\n    return a.id - b.id;\n  }\n}\nfunction WebGLRenderList() {\n  const renderItems = [];\n  let renderItemsIndex = 0;\n  const opaque = [];\n  const transmissive = [];\n  const transparent = [];\n  function init() {\n    renderItemsIndex = 0;\n    opaque.length = 0;\n    transmissive.length = 0;\n    transparent.length = 0;\n  }\n  function getNextRenderItem(object, geometry, material, groupOrder, z, group) {\n    let renderItem = renderItems[renderItemsIndex];\n    if (renderItem === undefined) {\n      renderItem = {\n        id: object.id,\n        object: object,\n        geometry: geometry,\n        material: material,\n        groupOrder: groupOrder,\n        renderOrder: object.renderOrder,\n        z: z,\n        group: group\n      };\n      renderItems[renderItemsIndex] = renderItem;\n    } else {\n      renderItem.id = object.id;\n      renderItem.object = object;\n      renderItem.geometry = geometry;\n      renderItem.material = material;\n      renderItem.groupOrder = groupOrder;\n      renderItem.renderOrder = object.renderOrder;\n      renderItem.z = z;\n      renderItem.group = group;\n    }\n    renderItemsIndex++;\n    return renderItem;\n  }\n  function push(object, geometry, material, groupOrder, z, group) {\n    const renderItem = getNextRenderItem(object, geometry, material, groupOrder, z, group);\n    if (material.transmission > 0.0) {\n      transmissive.push(renderItem);\n    } else if (material.transparent === true) {\n      transparent.push(renderItem);\n    } else {\n      opaque.push(renderItem);\n    }\n  }\n  function unshift(object, geometry, material, groupOrder, z, group) {\n    const renderItem = getNextRenderItem(object, geometry, material, groupOrder, z, group);\n    if (material.transmission > 0.0) {\n      transmissive.unshift(renderItem);\n    } else if (material.transparent === true) {\n      transparent.unshift(renderItem);\n    } else {\n      opaque.unshift(renderItem);\n    }\n  }\n  function sort(customOpaqueSort, customTransparentSort) {\n    if (opaque.length > 1) opaque.sort(customOpaqueSort || painterSortStable);\n    if (transmissive.length > 1) transmissive.sort(customTransparentSort || reversePainterSortStable);\n    if (transparent.length > 1) transparent.sort(customTransparentSort || reversePainterSortStable);\n  }\n  function finish() {\n    // Clear references from inactive renderItems in the list\n\n    for (let i = renderItemsIndex, il = renderItems.length; i < il; i++) {\n      const renderItem = renderItems[i];\n      if (renderItem.id === null) break;\n      renderItem.id = null;\n      renderItem.object = null;\n      renderItem.geometry = null;\n      renderItem.material = null;\n      renderItem.group = null;\n    }\n  }\n  return {\n    opaque: opaque,\n    transmissive: transmissive,\n    transparent: transparent,\n    init: init,\n    push: push,\n    unshift: unshift,\n    finish: finish,\n    sort: sort\n  };\n}\nfunction WebGLRenderLists() {\n  let lists = new WeakMap();\n  function get(scene, renderCallDepth) {\n    const listArray = lists.get(scene);\n    let list;\n    if (listArray === undefined) {\n      list = new WebGLRenderList();\n      lists.set(scene, [list]);\n    } else {\n      if (renderCallDepth >= listArray.length) {\n        list = new WebGLRenderList();\n        listArray.push(list);\n      } else {\n        list = listArray[renderCallDepth];\n      }\n    }\n    return list;\n  }\n  function dispose() {\n    lists = new WeakMap();\n  }\n  return {\n    get: get,\n    dispose: dispose\n  };\n}\nfunction UniformsCache() {\n  const lights = {};\n  return {\n    get: function (light) {\n      if (lights[light.id] !== undefined) {\n        return lights[light.id];\n      }\n      let uniforms;\n      switch (light.type) {\n        case 'DirectionalLight':\n          uniforms = {\n            direction: new Vector3(),\n            color: new Color()\n          };\n          break;\n        case 'SpotLight':\n          uniforms = {\n            position: new Vector3(),\n            direction: new Vector3(),\n            color: new Color(),\n            distance: 0,\n            coneCos: 0,\n            penumbraCos: 0,\n            decay: 0\n          };\n          break;\n        case 'PointLight':\n          uniforms = {\n            position: new Vector3(),\n            color: new Color(),\n            distance: 0,\n            decay: 0\n          };\n          break;\n        case 'HemisphereLight':\n          uniforms = {\n            direction: new Vector3(),\n            skyColor: new Color(),\n            groundColor: new Color()\n          };\n          break;\n        case 'RectAreaLight':\n          uniforms = {\n            color: new Color(),\n            position: new Vector3(),\n            halfWidth: new Vector3(),\n            halfHeight: new Vector3()\n          };\n          break;\n      }\n      lights[light.id] = uniforms;\n      return uniforms;\n    }\n  };\n}\nfunction ShadowUniformsCache() {\n  const lights = {};\n  return {\n    get: function (light) {\n      if (lights[light.id] !== undefined) {\n        return lights[light.id];\n      }\n      let uniforms;\n      switch (light.type) {\n        case 'DirectionalLight':\n          uniforms = {\n            shadowIntensity: 1,\n            shadowBias: 0,\n            shadowNormalBias: 0,\n            shadowRadius: 1,\n            shadowMapSize: new Vector2()\n          };\n          break;\n        case 'SpotLight':\n          uniforms = {\n            shadowIntensity: 1,\n            shadowBias: 0,\n            shadowNormalBias: 0,\n            shadowRadius: 1,\n            shadowMapSize: new Vector2()\n          };\n          break;\n        case 'PointLight':\n          uniforms = {\n            shadowIntensity: 1,\n            shadowBias: 0,\n            shadowNormalBias: 0,\n            shadowRadius: 1,\n            shadowMapSize: new Vector2(),\n            shadowCameraNear: 1,\n            shadowCameraFar: 1000\n          };\n          break;\n\n        // TODO (abelnation): set RectAreaLight shadow uniforms\n      }\n      lights[light.id] = uniforms;\n      return uniforms;\n    }\n  };\n}\nlet nextVersion = 0;\nfunction shadowCastingAndTexturingLightsFirst(lightA, lightB) {\n  return (lightB.castShadow ? 2 : 0) - (lightA.castShadow ? 2 : 0) + (lightB.map ? 1 : 0) - (lightA.map ? 1 : 0);\n}\nfunction WebGLLights(extensions) {\n  const cache = new UniformsCache();\n  const shadowCache = ShadowUniformsCache();\n  const state = {\n    version: 0,\n    hash: {\n      directionalLength: -1,\n      pointLength: -1,\n      spotLength: -1,\n      rectAreaLength: -1,\n      hemiLength: -1,\n      numDirectionalShadows: -1,\n      numPointShadows: -1,\n      numSpotShadows: -1,\n      numSpotMaps: -1,\n      numLightProbes: -1\n    },\n    ambient: [0, 0, 0],\n    probe: [],\n    directional: [],\n    directionalShadow: [],\n    directionalShadowMap: [],\n    directionalShadowMatrix: [],\n    spot: [],\n    spotLightMap: [],\n    spotShadow: [],\n    spotShadowMap: [],\n    spotLightMatrix: [],\n    rectArea: [],\n    rectAreaLTC1: null,\n    rectAreaLTC2: null,\n    point: [],\n    pointShadow: [],\n    pointShadowMap: [],\n    pointShadowMatrix: [],\n    hemi: [],\n    numSpotLightShadowsWithMaps: 0,\n    numLightProbes: 0\n  };\n  for (let i = 0; i < 9; i++) state.probe.push(new Vector3());\n  const vector3 = new Vector3();\n  const matrix4 = new Matrix4();\n  const matrix42 = new Matrix4();\n  function setup(lights) {\n    let r = 0,\n      g = 0,\n      b = 0;\n    for (let i = 0; i < 9; i++) state.probe[i].set(0, 0, 0);\n    let directionalLength = 0;\n    let pointLength = 0;\n    let spotLength = 0;\n    let rectAreaLength = 0;\n    let hemiLength = 0;\n    let numDirectionalShadows = 0;\n    let numPointShadows = 0;\n    let numSpotShadows = 0;\n    let numSpotMaps = 0;\n    let numSpotShadowsWithMaps = 0;\n    let numLightProbes = 0;\n\n    // ordering : [shadow casting + map texturing, map texturing, shadow casting, none ]\n    lights.sort(shadowCastingAndTexturingLightsFirst);\n    for (let i = 0, l = lights.length; i < l; i++) {\n      const light = lights[i];\n      const color = light.color;\n      const intensity = light.intensity;\n      const distance = light.distance;\n      const shadowMap = light.shadow && light.shadow.map ? light.shadow.map.texture : null;\n      if (light.isAmbientLight) {\n        r += color.r * intensity;\n        g += color.g * intensity;\n        b += color.b * intensity;\n      } else if (light.isLightProbe) {\n        for (let j = 0; j < 9; j++) {\n          state.probe[j].addScaledVector(light.sh.coefficients[j], intensity);\n        }\n        numLightProbes++;\n      } else if (light.isDirectionalLight) {\n        const uniforms = cache.get(light);\n        uniforms.color.copy(light.color).multiplyScalar(light.intensity);\n        if (light.castShadow) {\n          const shadow = light.shadow;\n          const shadowUniforms = shadowCache.get(light);\n          shadowUniforms.shadowIntensity = shadow.intensity;\n          shadowUniforms.shadowBias = shadow.bias;\n          shadowUniforms.shadowNormalBias = shadow.normalBias;\n          shadowUniforms.shadowRadius = shadow.radius;\n          shadowUniforms.shadowMapSize = shadow.mapSize;\n          state.directionalShadow[directionalLength] = shadowUniforms;\n          state.directionalShadowMap[directionalLength] = shadowMap;\n          state.directionalShadowMatrix[directionalLength] = light.shadow.matrix;\n          numDirectionalShadows++;\n        }\n        state.directional[directionalLength] = uniforms;\n        directionalLength++;\n      } else if (light.isSpotLight) {\n        const uniforms = cache.get(light);\n        uniforms.position.setFromMatrixPosition(light.matrixWorld);\n        uniforms.color.copy(color).multiplyScalar(intensity);\n        uniforms.distance = distance;\n        uniforms.coneCos = Math.cos(light.angle);\n        uniforms.penumbraCos = Math.cos(light.angle * (1 - light.penumbra));\n        uniforms.decay = light.decay;\n        state.spot[spotLength] = uniforms;\n        const shadow = light.shadow;\n        if (light.map) {\n          state.spotLightMap[numSpotMaps] = light.map;\n          numSpotMaps++;\n\n          // make sure the lightMatrix is up to date\n          // TODO : do it if required only\n          shadow.updateMatrices(light);\n          if (light.castShadow) numSpotShadowsWithMaps++;\n        }\n        state.spotLightMatrix[spotLength] = shadow.matrix;\n        if (light.castShadow) {\n          const shadowUniforms = shadowCache.get(light);\n          shadowUniforms.shadowIntensity = shadow.intensity;\n          shadowUniforms.shadowBias = shadow.bias;\n          shadowUniforms.shadowNormalBias = shadow.normalBias;\n          shadowUniforms.shadowRadius = shadow.radius;\n          shadowUniforms.shadowMapSize = shadow.mapSize;\n          state.spotShadow[spotLength] = shadowUniforms;\n          state.spotShadowMap[spotLength] = shadowMap;\n          numSpotShadows++;\n        }\n        spotLength++;\n      } else if (light.isRectAreaLight) {\n        const uniforms = cache.get(light);\n        uniforms.color.copy(color).multiplyScalar(intensity);\n        uniforms.halfWidth.set(light.width * 0.5, 0.0, 0.0);\n        uniforms.halfHeight.set(0.0, light.height * 0.5, 0.0);\n        state.rectArea[rectAreaLength] = uniforms;\n        rectAreaLength++;\n      } else if (light.isPointLight) {\n        const uniforms = cache.get(light);\n        uniforms.color.copy(light.color).multiplyScalar(light.intensity);\n        uniforms.distance = light.distance;\n        uniforms.decay = light.decay;\n        if (light.castShadow) {\n          const shadow = light.shadow;\n          const shadowUniforms = shadowCache.get(light);\n          shadowUniforms.shadowIntensity = shadow.intensity;\n          shadowUniforms.shadowBias = shadow.bias;\n          shadowUniforms.shadowNormalBias = shadow.normalBias;\n          shadowUniforms.shadowRadius = shadow.radius;\n          shadowUniforms.shadowMapSize = shadow.mapSize;\n          shadowUniforms.shadowCameraNear = shadow.camera.near;\n          shadowUniforms.shadowCameraFar = shadow.camera.far;\n          state.pointShadow[pointLength] = shadowUniforms;\n          state.pointShadowMap[pointLength] = shadowMap;\n          state.pointShadowMatrix[pointLength] = light.shadow.matrix;\n          numPointShadows++;\n        }\n        state.point[pointLength] = uniforms;\n        pointLength++;\n      } else if (light.isHemisphereLight) {\n        const uniforms = cache.get(light);\n        uniforms.skyColor.copy(light.color).multiplyScalar(intensity);\n        uniforms.groundColor.copy(light.groundColor).multiplyScalar(intensity);\n        state.hemi[hemiLength] = uniforms;\n        hemiLength++;\n      }\n    }\n    if (rectAreaLength > 0) {\n      if (extensions.has('OES_texture_float_linear') === true) {\n        state.rectAreaLTC1 = UniformsLib.LTC_FLOAT_1;\n        state.rectAreaLTC2 = UniformsLib.LTC_FLOAT_2;\n      } else {\n        state.rectAreaLTC1 = UniformsLib.LTC_HALF_1;\n        state.rectAreaLTC2 = UniformsLib.LTC_HALF_2;\n      }\n    }\n    state.ambient[0] = r;\n    state.ambient[1] = g;\n    state.ambient[2] = b;\n    const hash = state.hash;\n    if (hash.directionalLength !== directionalLength || hash.pointLength !== pointLength || hash.spotLength !== spotLength || hash.rectAreaLength !== rectAreaLength || hash.hemiLength !== hemiLength || hash.numDirectionalShadows !== numDirectionalShadows || hash.numPointShadows !== numPointShadows || hash.numSpotShadows !== numSpotShadows || hash.numSpotMaps !== numSpotMaps || hash.numLightProbes !== numLightProbes) {\n      state.directional.length = directionalLength;\n      state.spot.length = spotLength;\n      state.rectArea.length = rectAreaLength;\n      state.point.length = pointLength;\n      state.hemi.length = hemiLength;\n      state.directionalShadow.length = numDirectionalShadows;\n      state.directionalShadowMap.length = numDirectionalShadows;\n      state.pointShadow.length = numPointShadows;\n      state.pointShadowMap.length = numPointShadows;\n      state.spotShadow.length = numSpotShadows;\n      state.spotShadowMap.length = numSpotShadows;\n      state.directionalShadowMatrix.length = numDirectionalShadows;\n      state.pointShadowMatrix.length = numPointShadows;\n      state.spotLightMatrix.length = numSpotShadows + numSpotMaps - numSpotShadowsWithMaps;\n      state.spotLightMap.length = numSpotMaps;\n      state.numSpotLightShadowsWithMaps = numSpotShadowsWithMaps;\n      state.numLightProbes = numLightProbes;\n      hash.directionalLength = directionalLength;\n      hash.pointLength = pointLength;\n      hash.spotLength = spotLength;\n      hash.rectAreaLength = rectAreaLength;\n      hash.hemiLength = hemiLength;\n      hash.numDirectionalShadows = numDirectionalShadows;\n      hash.numPointShadows = numPointShadows;\n      hash.numSpotShadows = numSpotShadows;\n      hash.numSpotMaps = numSpotMaps;\n      hash.numLightProbes = numLightProbes;\n      state.version = nextVersion++;\n    }\n  }\n  function setupView(lights, camera) {\n    let directionalLength = 0;\n    let pointLength = 0;\n    let spotLength = 0;\n    let rectAreaLength = 0;\n    let hemiLength = 0;\n    const viewMatrix = camera.matrixWorldInverse;\n    for (let i = 0, l = lights.length; i < l; i++) {\n      const light = lights[i];\n      if (light.isDirectionalLight) {\n        const uniforms = state.directional[directionalLength];\n        uniforms.direction.setFromMatrixPosition(light.matrixWorld);\n        vector3.setFromMatrixPosition(light.target.matrixWorld);\n        uniforms.direction.sub(vector3);\n        uniforms.direction.transformDirection(viewMatrix);\n        directionalLength++;\n      } else if (light.isSpotLight) {\n        const uniforms = state.spot[spotLength];\n        uniforms.position.setFromMatrixPosition(light.matrixWorld);\n        uniforms.position.applyMatrix4(viewMatrix);\n        uniforms.direction.setFromMatrixPosition(light.matrixWorld);\n        vector3.setFromMatrixPosition(light.target.matrixWorld);\n        uniforms.direction.sub(vector3);\n        uniforms.direction.transformDirection(viewMatrix);\n        spotLength++;\n      } else if (light.isRectAreaLight) {\n        const uniforms = state.rectArea[rectAreaLength];\n        uniforms.position.setFromMatrixPosition(light.matrixWorld);\n        uniforms.position.applyMatrix4(viewMatrix);\n\n        // extract local rotation of light to derive width/height half vectors\n        matrix42.identity();\n        matrix4.copy(light.matrixWorld);\n        matrix4.premultiply(viewMatrix);\n        matrix42.extractRotation(matrix4);\n        uniforms.halfWidth.set(light.width * 0.5, 0.0, 0.0);\n        uniforms.halfHeight.set(0.0, light.height * 0.5, 0.0);\n        uniforms.halfWidth.applyMatrix4(matrix42);\n        uniforms.halfHeight.applyMatrix4(matrix42);\n        rectAreaLength++;\n      } else if (light.isPointLight) {\n        const uniforms = state.point[pointLength];\n        uniforms.position.setFromMatrixPosition(light.matrixWorld);\n        uniforms.position.applyMatrix4(viewMatrix);\n        pointLength++;\n      } else if (light.isHemisphereLight) {\n        const uniforms = state.hemi[hemiLength];\n        uniforms.direction.setFromMatrixPosition(light.matrixWorld);\n        uniforms.direction.transformDirection(viewMatrix);\n        hemiLength++;\n      }\n    }\n  }\n  return {\n    setup: setup,\n    setupView: setupView,\n    state: state\n  };\n}\nfunction WebGLRenderState(extensions) {\n  const lights = new WebGLLights(extensions);\n  const lightsArray = [];\n  const shadowsArray = [];\n  function init(camera) {\n    state.camera = camera;\n    lightsArray.length = 0;\n    shadowsArray.length = 0;\n  }\n  function pushLight(light) {\n    lightsArray.push(light);\n  }\n  function pushShadow(shadowLight) {\n    shadowsArray.push(shadowLight);\n  }\n  function setupLights() {\n    lights.setup(lightsArray);\n  }\n  function setupLightsView(camera) {\n    lights.setupView(lightsArray, camera);\n  }\n  const state = {\n    lightsArray: lightsArray,\n    shadowsArray: shadowsArray,\n    camera: null,\n    lights: lights,\n    transmissionRenderTarget: {}\n  };\n  return {\n    init: init,\n    state: state,\n    setupLights: setupLights,\n    setupLightsView: setupLightsView,\n    pushLight: pushLight,\n    pushShadow: pushShadow\n  };\n}\nfunction WebGLRenderStates(extensions) {\n  let renderStates = new WeakMap();\n  function get(scene, renderCallDepth = 0) {\n    const renderStateArray = renderStates.get(scene);\n    let renderState;\n    if (renderStateArray === undefined) {\n      renderState = new WebGLRenderState(extensions);\n      renderStates.set(scene, [renderState]);\n    } else {\n      if (renderCallDepth >= renderStateArray.length) {\n        renderState = new WebGLRenderState(extensions);\n        renderStateArray.push(renderState);\n      } else {\n        renderState = renderStateArray[renderCallDepth];\n      }\n    }\n    return renderState;\n  }\n  function dispose() {\n    renderStates = new WeakMap();\n  }\n  return {\n    get: get,\n    dispose: dispose\n  };\n}\nclass MeshDepthMaterial extends Material$1 {\n  constructor(parameters) {\n    super();\n    this.isMeshDepthMaterial = true;\n    this.type = 'MeshDepthMaterial';\n    this.depthPacking = BasicDepthPacking;\n    this.map = null;\n    this.alphaMap = null;\n    this.displacementMap = null;\n    this.displacementScale = 1;\n    this.displacementBias = 0;\n    this.wireframe = false;\n    this.wireframeLinewidth = 1;\n    this.setValues(parameters);\n  }\n  copy(source) {\n    super.copy(source);\n    this.depthPacking = source.depthPacking;\n    this.map = source.map;\n    this.alphaMap = source.alphaMap;\n    this.displacementMap = source.displacementMap;\n    this.displacementScale = source.displacementScale;\n    this.displacementBias = source.displacementBias;\n    this.wireframe = source.wireframe;\n    this.wireframeLinewidth = source.wireframeLinewidth;\n    return this;\n  }\n}\nclass MeshDistanceMaterial extends Material$1 {\n  constructor(parameters) {\n    super();\n    this.isMeshDistanceMaterial = true;\n    this.type = 'MeshDistanceMaterial';\n    this.map = null;\n    this.alphaMap = null;\n    this.displacementMap = null;\n    this.displacementScale = 1;\n    this.displacementBias = 0;\n    this.setValues(parameters);\n  }\n  copy(source) {\n    super.copy(source);\n    this.map = source.map;\n    this.alphaMap = source.alphaMap;\n    this.displacementMap = source.displacementMap;\n    this.displacementScale = source.displacementScale;\n    this.displacementBias = source.displacementBias;\n    return this;\n  }\n}\nconst vertex = \"void main() {\\n\\tgl_Position = vec4( position, 1.0 );\\n}\";\nconst fragment = \"uniform sampler2D shadow_pass;\\nuniform vec2 resolution;\\nuniform float radius;\\n#include <packing>\\nvoid main() {\\n\\tconst float samples = float( VSM_SAMPLES );\\n\\tfloat mean = 0.0;\\n\\tfloat squared_mean = 0.0;\\n\\tfloat uvStride = samples <= 1.0 ? 0.0 : 2.0 / ( samples - 1.0 );\\n\\tfloat uvStart = samples <= 1.0 ? 0.0 : - 1.0;\\n\\tfor ( float i = 0.0; i < samples; i ++ ) {\\n\\t\\tfloat uvOffset = uvStart + i * uvStride;\\n\\t\\t#ifdef HORIZONTAL_PASS\\n\\t\\t\\tvec2 distribution = unpackRGBATo2Half( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( uvOffset, 0.0 ) * radius ) / resolution ) );\\n\\t\\t\\tmean += distribution.x;\\n\\t\\t\\tsquared_mean += distribution.y * distribution.y + distribution.x * distribution.x;\\n\\t\\t#else\\n\\t\\t\\tfloat depth = unpackRGBAToDepth( texture2D( shadow_pass, ( gl_FragCoord.xy + vec2( 0.0, uvOffset ) * radius ) / resolution ) );\\n\\t\\t\\tmean += depth;\\n\\t\\t\\tsquared_mean += depth * depth;\\n\\t\\t#endif\\n\\t}\\n\\tmean = mean / samples;\\n\\tsquared_mean = squared_mean / samples;\\n\\tfloat std_dev = sqrt( squared_mean - mean * mean );\\n\\tgl_FragColor = pack2HalfToRGBA( vec2( mean, std_dev ) );\\n}\";\nfunction WebGLShadowMap(renderer, objects, capabilities) {\n  let _frustum = new Frustum();\n  const _shadowMapSize = new Vector2(),\n    _viewportSize = new Vector2(),\n    _viewport = new Vector4(),\n    _depthMaterial = new MeshDepthMaterial({\n      depthPacking: RGBADepthPacking\n    }),\n    _distanceMaterial = new MeshDistanceMaterial(),\n    _materialCache = {},\n    _maxTextureSize = capabilities.maxTextureSize;\n  const shadowSide = {\n    [FrontSide]: BackSide,\n    [BackSide]: FrontSide,\n    [DoubleSide]: DoubleSide\n  };\n  const shadowMaterialVertical = new ShaderMaterial({\n    defines: {\n      VSM_SAMPLES: 8\n    },\n    uniforms: {\n      shadow_pass: {\n        value: null\n      },\n      resolution: {\n        value: new Vector2()\n      },\n      radius: {\n        value: 4.0\n      }\n    },\n    vertexShader: vertex,\n    fragmentShader: fragment\n  });\n  const shadowMaterialHorizontal = shadowMaterialVertical.clone();\n  shadowMaterialHorizontal.defines.HORIZONTAL_PASS = 1;\n  const fullScreenTri = new BufferGeometry();\n  fullScreenTri.setAttribute('position', new BufferAttribute(new Float32Array([-1, -1, 0.5, 3, -1, 0.5, -1, 3, 0.5]), 3));\n  const fullScreenMesh = new Mesh(fullScreenTri, shadowMaterialVertical);\n  const scope = this;\n  this.enabled = false;\n  this.autoUpdate = true;\n  this.needsUpdate = false;\n  this.type = PCFShadowMap;\n  let _previousType = this.type;\n  this.render = function (lights, scene, camera) {\n    if (scope.enabled === false) return;\n    if (scope.autoUpdate === false && scope.needsUpdate === false) return;\n    if (lights.length === 0) return;\n    const currentRenderTarget = renderer.getRenderTarget();\n    const activeCubeFace = renderer.getActiveCubeFace();\n    const activeMipmapLevel = renderer.getActiveMipmapLevel();\n    const _state = renderer.state;\n\n    // Set GL state for depth map.\n    _state.setBlending(NoBlending);\n    _state.buffers.color.setClear(1, 1, 1, 1);\n    _state.buffers.depth.setTest(true);\n    _state.setScissorTest(false);\n\n    // check for shadow map type changes\n\n    const toVSM = _previousType !== VSMShadowMap && this.type === VSMShadowMap;\n    const fromVSM = _previousType === VSMShadowMap && this.type !== VSMShadowMap;\n\n    // render depth map\n\n    for (let i = 0, il = lights.length; i < il; i++) {\n      const light = lights[i];\n      const shadow = light.shadow;\n      if (shadow === undefined) {\n        console.warn('THREE.WebGLShadowMap:', light, 'has no shadow.');\n        continue;\n      }\n      if (shadow.autoUpdate === false && shadow.needsUpdate === false) continue;\n      _shadowMapSize.copy(shadow.mapSize);\n      const shadowFrameExtents = shadow.getFrameExtents();\n      _shadowMapSize.multiply(shadowFrameExtents);\n      _viewportSize.copy(shadow.mapSize);\n      if (_shadowMapSize.x > _maxTextureSize || _shadowMapSize.y > _maxTextureSize) {\n        if (_shadowMapSize.x > _maxTextureSize) {\n          _viewportSize.x = Math.floor(_maxTextureSize / shadowFrameExtents.x);\n          _shadowMapSize.x = _viewportSize.x * shadowFrameExtents.x;\n          shadow.mapSize.x = _viewportSize.x;\n        }\n        if (_shadowMapSize.y > _maxTextureSize) {\n          _viewportSize.y = Math.floor(_maxTextureSize / shadowFrameExtents.y);\n          _shadowMapSize.y = _viewportSize.y * shadowFrameExtents.y;\n          shadow.mapSize.y = _viewportSize.y;\n        }\n      }\n      if (shadow.map === null || toVSM === true || fromVSM === true) {\n        const pars = this.type !== VSMShadowMap ? {\n          minFilter: NearestFilter,\n          magFilter: NearestFilter\n        } : {};\n        if (shadow.map !== null) {\n          shadow.map.dispose();\n        }\n        shadow.map = new WebGLRenderTarget(_shadowMapSize.x, _shadowMapSize.y, pars);\n        shadow.map.texture.name = light.name + '.shadowMap';\n        shadow.camera.updateProjectionMatrix();\n      }\n      renderer.setRenderTarget(shadow.map);\n      renderer.clear();\n      const viewportCount = shadow.getViewportCount();\n      for (let vp = 0; vp < viewportCount; vp++) {\n        const viewport = shadow.getViewport(vp);\n        _viewport.set(_viewportSize.x * viewport.x, _viewportSize.y * viewport.y, _viewportSize.x * viewport.z, _viewportSize.y * viewport.w);\n        _state.viewport(_viewport);\n        shadow.updateMatrices(light, vp);\n        _frustum = shadow.getFrustum();\n        renderObject(scene, camera, shadow.camera, light, this.type);\n      }\n\n      // do blur pass for VSM\n\n      if (shadow.isPointLightShadow !== true && this.type === VSMShadowMap) {\n        VSMPass(shadow, camera);\n      }\n      shadow.needsUpdate = false;\n    }\n    _previousType = this.type;\n    scope.needsUpdate = false;\n    renderer.setRenderTarget(currentRenderTarget, activeCubeFace, activeMipmapLevel);\n  };\n  function VSMPass(shadow, camera) {\n    const geometry = objects.update(fullScreenMesh);\n    if (shadowMaterialVertical.defines.VSM_SAMPLES !== shadow.blurSamples) {\n      shadowMaterialVertical.defines.VSM_SAMPLES = shadow.blurSamples;\n      shadowMaterialHorizontal.defines.VSM_SAMPLES = shadow.blurSamples;\n      shadowMaterialVertical.needsUpdate = true;\n      shadowMaterialHorizontal.needsUpdate = true;\n    }\n    if (shadow.mapPass === null) {\n      shadow.mapPass = new WebGLRenderTarget(_shadowMapSize.x, _shadowMapSize.y);\n    }\n\n    // vertical pass\n\n    shadowMaterialVertical.uniforms.shadow_pass.value = shadow.map.texture;\n    shadowMaterialVertical.uniforms.resolution.value = shadow.mapSize;\n    shadowMaterialVertical.uniforms.radius.value = shadow.radius;\n    renderer.setRenderTarget(shadow.mapPass);\n    renderer.clear();\n    renderer.renderBufferDirect(camera, null, geometry, shadowMaterialVertical, fullScreenMesh, null);\n\n    // horizontal pass\n\n    shadowMaterialHorizontal.uniforms.shadow_pass.value = shadow.mapPass.texture;\n    shadowMaterialHorizontal.uniforms.resolution.value = shadow.mapSize;\n    shadowMaterialHorizontal.uniforms.radius.value = shadow.radius;\n    renderer.setRenderTarget(shadow.map);\n    renderer.clear();\n    renderer.renderBufferDirect(camera, null, geometry, shadowMaterialHorizontal, fullScreenMesh, null);\n  }\n  function getDepthMaterial(object, material, light, type) {\n    let result = null;\n    const customMaterial = light.isPointLight === true ? object.customDistanceMaterial : object.customDepthMaterial;\n    if (customMaterial !== undefined) {\n      result = customMaterial;\n    } else {\n      result = light.isPointLight === true ? _distanceMaterial : _depthMaterial;\n      if (renderer.localClippingEnabled && material.clipShadows === true && Array.isArray(material.clippingPlanes) && material.clippingPlanes.length !== 0 || material.displacementMap && material.displacementScale !== 0 || material.alphaMap && material.alphaTest > 0 || material.map && material.alphaTest > 0) {\n        // in this case we need a unique material instance reflecting the\n        // appropriate state\n\n        const keyA = result.uuid,\n          keyB = material.uuid;\n        let materialsForVariant = _materialCache[keyA];\n        if (materialsForVariant === undefined) {\n          materialsForVariant = {};\n          _materialCache[keyA] = materialsForVariant;\n        }\n        let cachedMaterial = materialsForVariant[keyB];\n        if (cachedMaterial === undefined) {\n          cachedMaterial = result.clone();\n          materialsForVariant[keyB] = cachedMaterial;\n          material.addEventListener('dispose', onMaterialDispose);\n        }\n        result = cachedMaterial;\n      }\n    }\n    result.visible = material.visible;\n    result.wireframe = material.wireframe;\n    if (type === VSMShadowMap) {\n      result.side = material.shadowSide !== null ? material.shadowSide : material.side;\n    } else {\n      result.side = material.shadowSide !== null ? material.shadowSide : shadowSide[material.side];\n    }\n    result.alphaMap = material.alphaMap;\n    result.alphaTest = material.alphaTest;\n    result.map = material.map;\n    result.clipShadows = material.clipShadows;\n    result.clippingPlanes = material.clippingPlanes;\n    result.clipIntersection = material.clipIntersection;\n    result.displacementMap = material.displacementMap;\n    result.displacementScale = material.displacementScale;\n    result.displacementBias = material.displacementBias;\n    result.wireframeLinewidth = material.wireframeLinewidth;\n    result.linewidth = material.linewidth;\n    if (light.isPointLight === true && result.isMeshDistanceMaterial === true) {\n      const materialProperties = renderer.properties.get(result);\n      materialProperties.light = light;\n    }\n    return result;\n  }\n  function renderObject(object, camera, shadowCamera, light, type) {\n    if (object.visible === false) return;\n    const visible = object.layers.test(camera.layers);\n    if (visible && (object.isMesh || object.isLine || object.isPoints)) {\n      if ((object.castShadow || object.receiveShadow && type === VSMShadowMap) && (!object.frustumCulled || _frustum.intersectsObject(object))) {\n        object.modelViewMatrix.multiplyMatrices(shadowCamera.matrixWorldInverse, object.matrixWorld);\n        const geometry = objects.update(object);\n        const material = object.material;\n        if (Array.isArray(material)) {\n          const groups = geometry.groups;\n          for (let k = 0, kl = groups.length; k < kl; k++) {\n            const group = groups[k];\n            const groupMaterial = material[group.materialIndex];\n            if (groupMaterial && groupMaterial.visible) {\n              const depthMaterial = getDepthMaterial(object, groupMaterial, light, type);\n              object.onBeforeShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, group);\n              renderer.renderBufferDirect(shadowCamera, null, geometry, depthMaterial, object, group);\n              object.onAfterShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, group);\n            }\n          }\n        } else if (material.visible) {\n          const depthMaterial = getDepthMaterial(object, material, light, type);\n          object.onBeforeShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, null);\n          renderer.renderBufferDirect(shadowCamera, null, geometry, depthMaterial, object, null);\n          object.onAfterShadow(renderer, object, camera, shadowCamera, geometry, depthMaterial, null);\n        }\n      }\n    }\n    const children = object.children;\n    for (let i = 0, l = children.length; i < l; i++) {\n      renderObject(children[i], camera, shadowCamera, light, type);\n    }\n  }\n  function onMaterialDispose(event) {\n    const material = event.target;\n    material.removeEventListener('dispose', onMaterialDispose);\n\n    // make sure to remove the unique distance/depth materials used for shadow map rendering\n\n    for (const id in _materialCache) {\n      const cache = _materialCache[id];\n      const uuid = event.target.uuid;\n      if (uuid in cache) {\n        const shadowMaterial = cache[uuid];\n        shadowMaterial.dispose();\n        delete cache[uuid];\n      }\n    }\n  }\n}\nconst reversedFuncs = {\n  [NeverDepth]: AlwaysDepth,\n  [LessDepth]: GreaterDepth,\n  [EqualDepth]: NotEqualDepth,\n  [LessEqualDepth]: GreaterEqualDepth,\n  [AlwaysDepth]: NeverDepth,\n  [GreaterDepth]: LessDepth,\n  [NotEqualDepth]: EqualDepth,\n  [GreaterEqualDepth]: LessEqualDepth\n};\nfunction WebGLState(gl) {\n  function ColorBuffer() {\n    let locked = false;\n    const color = new Vector4();\n    let currentColorMask = null;\n    const currentColorClear = new Vector4(0, 0, 0, 0);\n    return {\n      setMask: function (colorMask) {\n        if (currentColorMask !== colorMask && !locked) {\n          gl.colorMask(colorMask, colorMask, colorMask, colorMask);\n          currentColorMask = colorMask;\n        }\n      },\n      setLocked: function (lock) {\n        locked = lock;\n      },\n      setClear: function (r, g, b, a, premultipliedAlpha) {\n        if (premultipliedAlpha === true) {\n          r *= a;\n          g *= a;\n          b *= a;\n        }\n        color.set(r, g, b, a);\n        if (currentColorClear.equals(color) === false) {\n          gl.clearColor(r, g, b, a);\n          currentColorClear.copy(color);\n        }\n      },\n      reset: function () {\n        locked = false;\n        currentColorMask = null;\n        currentColorClear.set(-1, 0, 0, 0); // set to invalid state\n      }\n    };\n  }\n  function DepthBuffer() {\n    let locked = false;\n    let reversed = false;\n    let currentDepthMask = null;\n    let currentDepthFunc = null;\n    let currentDepthClear = null;\n    return {\n      setReversed: function (value) {\n        reversed = value;\n      },\n      setTest: function (depthTest) {\n        if (depthTest) {\n          enable(gl.DEPTH_TEST);\n        } else {\n          disable(gl.DEPTH_TEST);\n        }\n      },\n      setMask: function (depthMask) {\n        if (currentDepthMask !== depthMask && !locked) {\n          gl.depthMask(depthMask);\n          currentDepthMask = depthMask;\n        }\n      },\n      setFunc: function (depthFunc) {\n        if (reversed) depthFunc = reversedFuncs[depthFunc];\n        if (currentDepthFunc !== depthFunc) {\n          switch (depthFunc) {\n            case NeverDepth:\n              gl.depthFunc(gl.NEVER);\n              break;\n            case AlwaysDepth:\n              gl.depthFunc(gl.ALWAYS);\n              break;\n            case LessDepth:\n              gl.depthFunc(gl.LESS);\n              break;\n            case LessEqualDepth:\n              gl.depthFunc(gl.LEQUAL);\n              break;\n            case EqualDepth:\n              gl.depthFunc(gl.EQUAL);\n              break;\n            case GreaterEqualDepth:\n              gl.depthFunc(gl.GEQUAL);\n              break;\n            case GreaterDepth:\n              gl.depthFunc(gl.GREATER);\n              break;\n            case NotEqualDepth:\n              gl.depthFunc(gl.NOTEQUAL);\n              break;\n            default:\n              gl.depthFunc(gl.LEQUAL);\n          }\n          currentDepthFunc = depthFunc;\n        }\n      },\n      setLocked: function (lock) {\n        locked = lock;\n      },\n      setClear: function (depth) {\n        if (currentDepthClear !== depth) {\n          gl.clearDepth(depth);\n          currentDepthClear = depth;\n        }\n      },\n      reset: function () {\n        locked = false;\n        currentDepthMask = null;\n        currentDepthFunc = null;\n        currentDepthClear = null;\n      }\n    };\n  }\n  function StencilBuffer() {\n    let locked = false;\n    let currentStencilMask = null;\n    let currentStencilFunc = null;\n    let currentStencilRef = null;\n    let currentStencilFuncMask = null;\n    let currentStencilFail = null;\n    let currentStencilZFail = null;\n    let currentStencilZPass = null;\n    let currentStencilClear = null;\n    return {\n      setTest: function (stencilTest) {\n        if (!locked) {\n          if (stencilTest) {\n            enable(gl.STENCIL_TEST);\n          } else {\n            disable(gl.STENCIL_TEST);\n          }\n        }\n      },\n      setMask: function (stencilMask) {\n        if (currentStencilMask !== stencilMask && !locked) {\n          gl.stencilMask(stencilMask);\n          currentStencilMask = stencilMask;\n        }\n      },\n      setFunc: function (stencilFunc, stencilRef, stencilMask) {\n        if (currentStencilFunc !== stencilFunc || currentStencilRef !== stencilRef || currentStencilFuncMask !== stencilMask) {\n          gl.stencilFunc(stencilFunc, stencilRef, stencilMask);\n          currentStencilFunc = stencilFunc;\n          currentStencilRef = stencilRef;\n          currentStencilFuncMask = stencilMask;\n        }\n      },\n      setOp: function (stencilFail, stencilZFail, stencilZPass) {\n        if (currentStencilFail !== stencilFail || currentStencilZFail !== stencilZFail || currentStencilZPass !== stencilZPass) {\n          gl.stencilOp(stencilFail, stencilZFail, stencilZPass);\n          currentStencilFail = stencilFail;\n          currentStencilZFail = stencilZFail;\n          currentStencilZPass = stencilZPass;\n        }\n      },\n      setLocked: function (lock) {\n        locked = lock;\n      },\n      setClear: function (stencil) {\n        if (currentStencilClear !== stencil) {\n          gl.clearStencil(stencil);\n          currentStencilClear = stencil;\n        }\n      },\n      reset: function () {\n        locked = false;\n        currentStencilMask = null;\n        currentStencilFunc = null;\n        currentStencilRef = null;\n        currentStencilFuncMask = null;\n        currentStencilFail = null;\n        currentStencilZFail = null;\n        currentStencilZPass = null;\n        currentStencilClear = null;\n      }\n    };\n  }\n\n  //\n\n  const colorBuffer = new ColorBuffer();\n  const depthBuffer = new DepthBuffer();\n  const stencilBuffer = new StencilBuffer();\n  const uboBindings = new WeakMap();\n  const uboProgramMap = new WeakMap();\n  let enabledCapabilities = {};\n  let currentBoundFramebuffers = {};\n  let currentDrawbuffers = new WeakMap();\n  let defaultDrawbuffers = [];\n  let currentProgram = null;\n  let currentBlendingEnabled = false;\n  let currentBlending = null;\n  let currentBlendEquation = null;\n  let currentBlendSrc = null;\n  let currentBlendDst = null;\n  let currentBlendEquationAlpha = null;\n  let currentBlendSrcAlpha = null;\n  let currentBlendDstAlpha = null;\n  let currentBlendColor = new Color(0, 0, 0);\n  let currentBlendAlpha = 0;\n  let currentPremultipledAlpha = false;\n  let currentFlipSided = null;\n  let currentCullFace = null;\n  let currentLineWidth = null;\n  let currentPolygonOffsetFactor = null;\n  let currentPolygonOffsetUnits = null;\n  const maxTextures = gl.getParameter(gl.MAX_COMBINED_TEXTURE_IMAGE_UNITS);\n  let lineWidthAvailable = false;\n  let version = 0;\n  const glVersion = gl.getParameter(gl.VERSION);\n  if (glVersion.indexOf('WebGL') !== -1) {\n    version = parseFloat(/^WebGL (\\d)/.exec(glVersion)[1]);\n    lineWidthAvailable = version >= 1.0;\n  } else if (glVersion.indexOf('OpenGL ES') !== -1) {\n    version = parseFloat(/^OpenGL ES (\\d)/.exec(glVersion)[1]);\n    lineWidthAvailable = version >= 2.0;\n  }\n  let currentTextureSlot = null;\n  let currentBoundTextures = {};\n  const scissorParam = gl.getParameter(gl.SCISSOR_BOX);\n  const viewportParam = gl.getParameter(gl.VIEWPORT);\n  const currentScissor = new Vector4().fromArray(scissorParam);\n  const currentViewport = new Vector4().fromArray(viewportParam);\n  function createTexture(type, target, count, dimensions) {\n    const data = new Uint8Array(4); // 4 is required to match default unpack alignment of 4.\n    const texture = gl.createTexture();\n    gl.bindTexture(type, texture);\n    gl.texParameteri(type, gl.TEXTURE_MIN_FILTER, gl.NEAREST);\n    gl.texParameteri(type, gl.TEXTURE_MAG_FILTER, gl.NEAREST);\n    for (let i = 0; i < count; i++) {\n      if (type === gl.TEXTURE_3D || type === gl.TEXTURE_2D_ARRAY) {\n        gl.texImage3D(target, 0, gl.RGBA, 1, 1, dimensions, 0, gl.RGBA, gl.UNSIGNED_BYTE, data);\n      } else {\n        gl.texImage2D(target + i, 0, gl.RGBA, 1, 1, 0, gl.RGBA, gl.UNSIGNED_BYTE, data);\n      }\n    }\n    return texture;\n  }\n  const emptyTextures = {};\n  emptyTextures[gl.TEXTURE_2D] = createTexture(gl.TEXTURE_2D, gl.TEXTURE_2D, 1);\n  emptyTextures[gl.TEXTURE_CUBE_MAP] = createTexture(gl.TEXTURE_CUBE_MAP, gl.TEXTURE_CUBE_MAP_POSITIVE_X, 6);\n  emptyTextures[gl.TEXTURE_2D_ARRAY] = createTexture(gl.TEXTURE_2D_ARRAY, gl.TEXTURE_2D_ARRAY, 1, 1);\n  emptyTextures[gl.TEXTURE_3D] = createTexture(gl.TEXTURE_3D, gl.TEXTURE_3D, 1, 1);\n\n  // init\n\n  colorBuffer.setClear(0, 0, 0, 1);\n  depthBuffer.setClear(1);\n  stencilBuffer.setClear(0);\n  enable(gl.DEPTH_TEST);\n  depthBuffer.setFunc(LessEqualDepth);\n  setFlipSided(false);\n  setCullFace(CullFaceBack);\n  enable(gl.CULL_FACE);\n  setBlending(NoBlending);\n\n  //\n\n  function enable(id) {\n    if (enabledCapabilities[id] !== true) {\n      gl.enable(id);\n      enabledCapabilities[id] = true;\n    }\n  }\n  function disable(id) {\n    if (enabledCapabilities[id] !== false) {\n      gl.disable(id);\n      enabledCapabilities[id] = false;\n    }\n  }\n  function bindFramebuffer(target, framebuffer) {\n    if (currentBoundFramebuffers[target] !== framebuffer) {\n      gl.bindFramebuffer(target, framebuffer);\n      currentBoundFramebuffers[target] = framebuffer;\n\n      // gl.DRAW_FRAMEBUFFER is equivalent to gl.FRAMEBUFFER\n\n      if (target === gl.DRAW_FRAMEBUFFER) {\n        currentBoundFramebuffers[gl.FRAMEBUFFER] = framebuffer;\n      }\n      if (target === gl.FRAMEBUFFER) {\n        currentBoundFramebuffers[gl.DRAW_FRAMEBUFFER] = framebuffer;\n      }\n      return true;\n    }\n    return false;\n  }\n  function drawBuffers(renderTarget, framebuffer) {\n    let drawBuffers = defaultDrawbuffers;\n    let needsUpdate = false;\n    if (renderTarget) {\n      drawBuffers = currentDrawbuffers.get(framebuffer);\n      if (drawBuffers === undefined) {\n        drawBuffers = [];\n        currentDrawbuffers.set(framebuffer, drawBuffers);\n      }\n      const textures = renderTarget.textures;\n      if (drawBuffers.length !== textures.length || drawBuffers[0] !== gl.COLOR_ATTACHMENT0) {\n        for (let i = 0, il = textures.length; i < il; i++) {\n          drawBuffers[i] = gl.COLOR_ATTACHMENT0 + i;\n        }\n        drawBuffers.length = textures.length;\n        needsUpdate = true;\n      }\n    } else {\n      if (drawBuffers[0] !== gl.BACK) {\n        drawBuffers[0] = gl.BACK;\n        needsUpdate = true;\n      }\n    }\n    if (needsUpdate) {\n      gl.drawBuffers(drawBuffers);\n    }\n  }\n  function useProgram(program) {\n    if (currentProgram !== program) {\n      gl.useProgram(program);\n      currentProgram = program;\n      return true;\n    }\n    return false;\n  }\n  const equationToGL = {\n    [AddEquation]: gl.FUNC_ADD,\n    [SubtractEquation]: gl.FUNC_SUBTRACT,\n    [ReverseSubtractEquation]: gl.FUNC_REVERSE_SUBTRACT\n  };\n  equationToGL[MinEquation] = gl.MIN;\n  equationToGL[MaxEquation] = gl.MAX;\n  const factorToGL = {\n    [ZeroFactor]: gl.ZERO,\n    [OneFactor]: gl.ONE,\n    [SrcColorFactor]: gl.SRC_COLOR,\n    [SrcAlphaFactor]: gl.SRC_ALPHA,\n    [SrcAlphaSaturateFactor]: gl.SRC_ALPHA_SATURATE,\n    [DstColorFactor]: gl.DST_COLOR,\n    [DstAlphaFactor]: gl.DST_ALPHA,\n    [OneMinusSrcColorFactor]: gl.ONE_MINUS_SRC_COLOR,\n    [OneMinusSrcAlphaFactor]: gl.ONE_MINUS_SRC_ALPHA,\n    [OneMinusDstColorFactor]: gl.ONE_MINUS_DST_COLOR,\n    [OneMinusDstAlphaFactor]: gl.ONE_MINUS_DST_ALPHA,\n    [ConstantColorFactor]: gl.CONSTANT_COLOR,\n    [OneMinusConstantColorFactor]: gl.ONE_MINUS_CONSTANT_COLOR,\n    [ConstantAlphaFactor]: gl.CONSTANT_ALPHA,\n    [OneMinusConstantAlphaFactor]: gl.ONE_MINUS_CONSTANT_ALPHA\n  };\n  function setBlending(blending, blendEquation, blendSrc, blendDst, blendEquationAlpha, blendSrcAlpha, blendDstAlpha, blendColor, blendAlpha, premultipliedAlpha) {\n    if (blending === NoBlending) {\n      if (currentBlendingEnabled === true) {\n        disable(gl.BLEND);\n        currentBlendingEnabled = false;\n      }\n      return;\n    }\n    if (currentBlendingEnabled === false) {\n      enable(gl.BLEND);\n      currentBlendingEnabled = true;\n    }\n    if (blending !== CustomBlending) {\n      if (blending !== currentBlending || premultipliedAlpha !== currentPremultipledAlpha) {\n        if (currentBlendEquation !== AddEquation || currentBlendEquationAlpha !== AddEquation) {\n          gl.blendEquation(gl.FUNC_ADD);\n          currentBlendEquation = AddEquation;\n          currentBlendEquationAlpha = AddEquation;\n        }\n        if (premultipliedAlpha) {\n          switch (blending) {\n            case NormalBlending:\n              gl.blendFuncSeparate(gl.ONE, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ONE_MINUS_SRC_ALPHA);\n              break;\n            case AdditiveBlending:\n              gl.blendFunc(gl.ONE, gl.ONE);\n              break;\n            case SubtractiveBlending:\n              gl.blendFuncSeparate(gl.ZERO, gl.ONE_MINUS_SRC_COLOR, gl.ZERO, gl.ONE);\n              break;\n            case MultiplyBlending:\n              gl.blendFuncSeparate(gl.ZERO, gl.SRC_COLOR, gl.ZERO, gl.SRC_ALPHA);\n              break;\n            default:\n              console.error('THREE.WebGLState: Invalid blending: ', blending);\n              break;\n          }\n        } else {\n          switch (blending) {\n            case NormalBlending:\n              gl.blendFuncSeparate(gl.SRC_ALPHA, gl.ONE_MINUS_SRC_ALPHA, gl.ONE, gl.ONE_MINUS_SRC_ALPHA);\n              break;\n            case AdditiveBlending:\n              gl.blendFunc(gl.SRC_ALPHA, gl.ONE);\n              break;\n            case SubtractiveBlending:\n              gl.blendFuncSeparate(gl.ZERO, gl.ONE_MINUS_SRC_COLOR, gl.ZERO, gl.ONE);\n              break;\n            case MultiplyBlending:\n              gl.blendFunc(gl.ZERO, gl.SRC_COLOR);\n              break;\n            default:\n              console.error('THREE.WebGLState: Invalid blending: ', blending);\n              break;\n          }\n        }\n        currentBlendSrc = null;\n        currentBlendDst = null;\n        currentBlendSrcAlpha = null;\n        currentBlendDstAlpha = null;\n        currentBlendColor.set(0, 0, 0);\n        currentBlendAlpha = 0;\n        currentBlending = blending;\n        currentPremultipledAlpha = premultipliedAlpha;\n      }\n      return;\n    }\n\n    // custom blending\n\n    blendEquationAlpha = blendEquationAlpha || blendEquation;\n    blendSrcAlpha = blendSrcAlpha || blendSrc;\n    blendDstAlpha = blendDstAlpha || blendDst;\n    if (blendEquation !== currentBlendEquation || blendEquationAlpha !== currentBlendEquationAlpha) {\n      gl.blendEquationSeparate(equationToGL[blendEquation], equationToGL[blendEquationAlpha]);\n      currentBlendEquation = blendEquation;\n      currentBlendEquationAlpha = blendEquationAlpha;\n    }\n    if (blendSrc !== currentBlendSrc || blendDst !== currentBlendDst || blendSrcAlpha !== currentBlendSrcAlpha || blendDstAlpha !== currentBlendDstAlpha) {\n      gl.blendFuncSeparate(factorToGL[blendSrc], factorToGL[blendDst], factorToGL[blendSrcAlpha], factorToGL[blendDstAlpha]);\n      currentBlendSrc = blendSrc;\n      currentBlendDst = blendDst;\n      currentBlendSrcAlpha = blendSrcAlpha;\n      currentBlendDstAlpha = blendDstAlpha;\n    }\n    if (blendColor.equals(currentBlendColor) === false || blendAlpha !== currentBlendAlpha) {\n      gl.blendColor(blendColor.r, blendColor.g, blendColor.b, blendAlpha);\n      currentBlendColor.copy(blendColor);\n      currentBlendAlpha = blendAlpha;\n    }\n    currentBlending = blending;\n    currentPremultipledAlpha = false;\n  }\n  function setMaterial(material, frontFaceCW) {\n    material.side === DoubleSide ? disable(gl.CULL_FACE) : enable(gl.CULL_FACE);\n    let flipSided = material.side === BackSide;\n    if (frontFaceCW) flipSided = !flipSided;\n    setFlipSided(flipSided);\n    material.blending === NormalBlending && material.transparent === false ? setBlending(NoBlending) : setBlending(material.blending, material.blendEquation, material.blendSrc, material.blendDst, material.blendEquationAlpha, material.blendSrcAlpha, material.blendDstAlpha, material.blendColor, material.blendAlpha, material.premultipliedAlpha);\n    depthBuffer.setFunc(material.depthFunc);\n    depthBuffer.setTest(material.depthTest);\n    depthBuffer.setMask(material.depthWrite);\n    colorBuffer.setMask(material.colorWrite);\n    const stencilWrite = material.stencilWrite;\n    stencilBuffer.setTest(stencilWrite);\n    if (stencilWrite) {\n      stencilBuffer.setMask(material.stencilWriteMask);\n      stencilBuffer.setFunc(material.stencilFunc, material.stencilRef, material.stencilFuncMask);\n      stencilBuffer.setOp(material.stencilFail, material.stencilZFail, material.stencilZPass);\n    }\n    setPolygonOffset(material.polygonOffset, material.polygonOffsetFactor, material.polygonOffsetUnits);\n    material.alphaToCoverage === true ? enable(gl.SAMPLE_ALPHA_TO_COVERAGE) : disable(gl.SAMPLE_ALPHA_TO_COVERAGE);\n  }\n\n  //\n\n  function setFlipSided(flipSided) {\n    if (currentFlipSided !== flipSided) {\n      if (flipSided) {\n        gl.frontFace(gl.CW);\n      } else {\n        gl.frontFace(gl.CCW);\n      }\n      currentFlipSided = flipSided;\n    }\n  }\n  function setCullFace(cullFace) {\n    if (cullFace !== CullFaceNone) {\n      enable(gl.CULL_FACE);\n      if (cullFace !== currentCullFace) {\n        if (cullFace === CullFaceBack) {\n          gl.cullFace(gl.BACK);\n        } else if (cullFace === CullFaceFront) {\n          gl.cullFace(gl.FRONT);\n        } else {\n          gl.cullFace(gl.FRONT_AND_BACK);\n        }\n      }\n    } else {\n      disable(gl.CULL_FACE);\n    }\n    currentCullFace = cullFace;\n  }\n  function setLineWidth(width) {\n    if (width !== currentLineWidth) {\n      if (lineWidthAvailable) gl.lineWidth(width);\n      currentLineWidth = width;\n    }\n  }\n  function setPolygonOffset(polygonOffset, factor, units) {\n    if (polygonOffset) {\n      enable(gl.POLYGON_OFFSET_FILL);\n      if (currentPolygonOffsetFactor !== factor || currentPolygonOffsetUnits !== units) {\n        gl.polygonOffset(factor, units);\n        currentPolygonOffsetFactor = factor;\n        currentPolygonOffsetUnits = units;\n      }\n    } else {\n      disable(gl.POLYGON_OFFSET_FILL);\n    }\n  }\n  function setScissorTest(scissorTest) {\n    if (scissorTest) {\n      enable(gl.SCISSOR_TEST);\n    } else {\n      disable(gl.SCISSOR_TEST);\n    }\n  }\n\n  // texture\n\n  function activeTexture(webglSlot) {\n    if (webglSlot === undefined) webglSlot = gl.TEXTURE0 + maxTextures - 1;\n    if (currentTextureSlot !== webglSlot) {\n      gl.activeTexture(webglSlot);\n      currentTextureSlot = webglSlot;\n    }\n  }\n  function bindTexture(webglType, webglTexture, webglSlot) {\n    if (webglSlot === undefined) {\n      if (currentTextureSlot === null) {\n        webglSlot = gl.TEXTURE0 + maxTextures - 1;\n      } else {\n        webglSlot = currentTextureSlot;\n      }\n    }\n    let boundTexture = currentBoundTextures[webglSlot];\n    if (boundTexture === undefined) {\n      boundTexture = {\n        type: undefined,\n        texture: undefined\n      };\n      currentBoundTextures[webglSlot] = boundTexture;\n    }\n    if (boundTexture.type !== webglType || boundTexture.texture !== webglTexture) {\n      if (currentTextureSlot !== webglSlot) {\n        gl.activeTexture(webglSlot);\n        currentTextureSlot = webglSlot;\n      }\n      gl.bindTexture(webglType, webglTexture || emptyTextures[webglType]);\n      boundTexture.type = webglType;\n      boundTexture.texture = webglTexture;\n    }\n  }\n  function unbindTexture() {\n    const boundTexture = currentBoundTextures[currentTextureSlot];\n    if (boundTexture !== undefined && boundTexture.type !== undefined) {\n      gl.bindTexture(boundTexture.type, null);\n      boundTexture.type = undefined;\n      boundTexture.texture = undefined;\n    }\n  }\n  function compressedTexImage2D() {\n    try {\n      gl.compressedTexImage2D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function compressedTexImage3D() {\n    try {\n      gl.compressedTexImage3D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function texSubImage2D() {\n    try {\n      gl.texSubImage2D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function texSubImage3D() {\n    try {\n      gl.texSubImage3D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function compressedTexSubImage2D() {\n    try {\n      gl.compressedTexSubImage2D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function compressedTexSubImage3D() {\n    try {\n      gl.compressedTexSubImage3D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function texStorage2D() {\n    try {\n      gl.texStorage2D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function texStorage3D() {\n    try {\n      gl.texStorage3D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function texImage2D() {\n    try {\n      gl.texImage2D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n  function texImage3D() {\n    try {\n      gl.texImage3D.apply(gl, arguments);\n    } catch (error) {\n      console.error('THREE.WebGLState:', error);\n    }\n  }\n\n  //\n\n  function scissor(scissor) {\n    if (currentScissor.equals(scissor) === false) {\n      gl.scissor(scissor.x, scissor.y, scissor.z, scissor.w);\n      currentScissor.copy(scissor);\n    }\n  }\n  function viewport(viewport) {\n    if (currentViewport.equals(viewport) === false) {\n      gl.viewport(viewport.x, viewport.y, viewport.z, viewport.w);\n      currentViewport.copy(viewport);\n    }\n  }\n  function updateUBOMapping(uniformsGroup, program) {\n    let mapping = uboProgramMap.get(program);\n    if (mapping === undefined) {\n      mapping = new WeakMap();\n      uboProgramMap.set(program, mapping);\n    }\n    let blockIndex = mapping.get(uniformsGroup);\n    if (blockIndex === undefined) {\n      blockIndex = gl.getUniformBlockIndex(program, uniformsGroup.name);\n      mapping.set(uniformsGroup, blockIndex);\n    }\n  }\n  function uniformBlockBinding(uniformsGroup, program) {\n    const mapping = uboProgramMap.get(program);\n    const blockIndex = mapping.get(uniformsGroup);\n    if (uboBindings.get(program) !== blockIndex) {\n      // bind shader specific block index to global block point\n      gl.uniformBlockBinding(program, blockIndex, uniformsGroup.__bindingPointIndex);\n      uboBindings.set(program, blockIndex);\n    }\n  }\n\n  //\n\n  function reset() {\n    // reset state\n\n    gl.disable(gl.BLEND);\n    gl.disable(gl.CULL_FACE);\n    gl.disable(gl.DEPTH_TEST);\n    gl.disable(gl.POLYGON_OFFSET_FILL);\n    gl.disable(gl.SCISSOR_TEST);\n    gl.disable(gl.STENCIL_TEST);\n    gl.disable(gl.SAMPLE_ALPHA_TO_COVERAGE);\n    gl.blendEquation(gl.FUNC_ADD);\n    gl.blendFunc(gl.ONE, gl.ZERO);\n    gl.blendFuncSeparate(gl.ONE, gl.ZERO, gl.ONE, gl.ZERO);\n    gl.blendColor(0, 0, 0, 0);\n    gl.colorMask(true, true, true, true);\n    gl.clearColor(0, 0, 0, 0);\n    gl.depthMask(true);\n    gl.depthFunc(gl.LESS);\n    gl.clearDepth(1);\n    gl.stencilMask(0xffffffff);\n    gl.stencilFunc(gl.ALWAYS, 0, 0xffffffff);\n    gl.stencilOp(gl.KEEP, gl.KEEP, gl.KEEP);\n    gl.clearStencil(0);\n    gl.cullFace(gl.BACK);\n    gl.frontFace(gl.CCW);\n    gl.polygonOffset(0, 0);\n    gl.activeTexture(gl.TEXTURE0);\n    gl.bindFramebuffer(gl.FRAMEBUFFER, null);\n    gl.bindFramebuffer(gl.DRAW_FRAMEBUFFER, null);\n    gl.bindFramebuffer(gl.READ_FRAMEBUFFER, null);\n    gl.useProgram(null);\n    gl.lineWidth(1);\n    gl.scissor(0, 0, gl.canvas.width, gl.canvas.height);\n    gl.viewport(0, 0, gl.canvas.width, gl.canvas.height);\n\n    // reset internals\n\n    enabledCapabilities = {};\n    currentTextureSlot = null;\n    currentBoundTextures = {};\n    currentBoundFramebuffers = {};\n    currentDrawbuffers = new WeakMap();\n    defaultDrawbuffers = [];\n    currentProgram = null;\n    currentBlendingEnabled = false;\n    currentBlending = null;\n    currentBlendEquation = null;\n    currentBlendSrc = null;\n    currentBlendDst = null;\n    currentBlendEquationAlpha = null;\n    currentBlendSrcAlpha = null;\n    currentBlendDstAlpha = null;\n    currentBlendColor = new Color(0, 0, 0);\n    currentBlendAlpha = 0;\n    currentPremultipledAlpha = false;\n    currentFlipSided = null;\n    currentCullFace = null;\n    currentLineWidth = null;\n    currentPolygonOffsetFactor = null;\n    currentPolygonOffsetUnits = null;\n    currentScissor.set(0, 0, gl.canvas.width, gl.canvas.height);\n    currentViewport.set(0, 0, gl.canvas.width, gl.canvas.height);\n    colorBuffer.reset();\n    depthBuffer.reset();\n    stencilBuffer.reset();\n  }\n  return {\n    buffers: {\n      color: colorBuffer,\n      depth: depthBuffer,\n      stencil: stencilBuffer\n    },\n    enable: enable,\n    disable: disable,\n    bindFramebuffer: bindFramebuffer,\n    drawBuffers: drawBuffers,\n    useProgram: useProgram,\n    setBlending: setBlending,\n    setMaterial: setMaterial,\n    setFlipSided: setFlipSided,\n    setCullFace: setCullFace,\n    setLineWidth: setLineWidth,\n    setPolygonOffset: setPolygonOffset,\n    setScissorTest: setScissorTest,\n    activeTexture: activeTexture,\n    bindTexture: bindTexture,\n    unbindTexture: unbindTexture,\n    compressedTexImage2D: compressedTexImage2D,\n    compressedTexImage3D: compressedTexImage3D,\n    texImage2D: texImage2D,\n    texImage3D: texImage3D,\n    updateUBOMapping: updateUBOMapping,\n    uniformBlockBinding: uniformBlockBinding,\n    texStorage2D: texStorage2D,\n    texStorage3D: texStorage3D,\n    texSubImage2D: texSubImage2D,\n    texSubImage3D: texSubImage3D,\n    compressedTexSubImage2D: compressedTexSubImage2D,\n    compressedTexSubImage3D: compressedTexSubImage3D,\n    scissor: scissor,\n    viewport: viewport,\n    reset: reset\n  };\n}\n\n/**\n * Given the width, height, format, and type of a texture. Determines how many\n * bytes must be used to represent the texture.\n */\nfunction getByteLength(width, height, format, type) {\n  const typeByteLength = getTextureTypeByteLength(type);\n  switch (format) {\n    // https://registry.khronos.org/OpenGL-Refpages/es3.0/html/glTexImage2D.xhtml\n    case AlphaFormat:\n      return width * height;\n    case LuminanceFormat:\n      return width * height;\n    case LuminanceAlphaFormat:\n      return width * height * 2;\n    case RedFormat:\n      return width * height / typeByteLength.components * typeByteLength.byteLength;\n    case RedIntegerFormat:\n      return width * height / typeByteLength.components * typeByteLength.byteLength;\n    case RGFormat:\n      return width * height * 2 / typeByteLength.components * typeByteLength.byteLength;\n    case RGIntegerFormat:\n      return width * height * 2 / typeByteLength.components * typeByteLength.byteLength;\n    case RGBFormat:\n      return width * height * 3 / typeByteLength.components * typeByteLength.byteLength;\n    case RGBAFormat:\n      return width * height * 4 / typeByteLength.components * typeByteLength.byteLength;\n    case RGBAIntegerFormat:\n      return width * height * 4 / typeByteLength.components * typeByteLength.byteLength;\n\n    // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_s3tc_srgb/\n    case RGB_S3TC_DXT1_Format:\n    case RGBA_S3TC_DXT1_Format:\n      return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 8;\n    case RGBA_S3TC_DXT3_Format:\n    case RGBA_S3TC_DXT5_Format:\n      return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 16;\n\n    // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_pvrtc/\n    case RGB_PVRTC_2BPPV1_Format:\n    case RGBA_PVRTC_2BPPV1_Format:\n      return Math.max(width, 16) * Math.max(height, 8) / 4;\n    case RGB_PVRTC_4BPPV1_Format:\n    case RGBA_PVRTC_4BPPV1_Format:\n      return Math.max(width, 8) * Math.max(height, 8) / 2;\n\n    // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_etc/\n    case RGB_ETC1_Format:\n    case RGB_ETC2_Format:\n      return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 8;\n    case RGBA_ETC2_EAC_Format:\n      return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 16;\n\n    // https://registry.khronos.org/webgl/extensions/WEBGL_compressed_texture_astc/\n    case RGBA_ASTC_4x4_Format:\n      return Math.floor((width + 3) / 4) * Math.floor((height + 3) / 4) * 16;\n    case RGBA_ASTC_5x4_Format:\n      return Math.floor((width + 4) / 5) * Math.floor((height + 3) / 4) * 16;\n    case RGBA_ASTC_5x5_Format:\n      return Math.floor((width + 4) / 5) * Math.floor((height + 4) / 5) * 16;\n    case RGBA_ASTC_6x5_Format:\n      return Math.floor((width + 5) / 6) * Math.floor((height + 4) / 5) * 16;\n    case RGBA_ASTC_6x6_Format:\n      return Math.floor((width + 5) / 6) * Math.floor((height + 5) / 6) * 16;\n    case RGBA_ASTC_8x5_Format:\n      return Math.floor((width + 7) / 8) * Math.floor((height + 4) / 5) * 16;\n    case RGBA_ASTC_8x6_Format:\n      return Math.floor((width + 7) / 8) * Math.floor((height + 5) / 6) * 16;\n    case RGBA_ASTC_8x8_Format:\n      return Math.floor((width + 7) / 8) * Math.floor((height + 7) / 8) * 16;\n    case RGBA_ASTC_10x5_Format:\n      return Math.floor((width + 9) / 10) * Math.floor((height + 4) / 5) * 16;\n    case RGBA_ASTC_10x6_Format:\n      return Math.floor((width + 9) / 10) * Math.floor((height + 5) / 6) * 16;\n    case RGBA_ASTC_10x8_Format:\n      return Math.floor((width + 9) / 10) * Math.floor((height + 7) / 8) * 16;\n    case RGBA_ASTC_10x10_Format:\n      return Math.floor((width + 9) / 10) * Math.floor((height + 9) / 10) * 16;\n    case RGBA_ASTC_12x10_Format:\n      return Math.floor((width + 11) / 12) * Math.floor((height + 9) / 10) * 16;\n    case RGBA_ASTC_12x12_Format:\n      return Math.floor((width + 11) / 12) * Math.floor((height + 11) / 12) * 16;\n\n    // https://registry.khronos.org/webgl/extensions/EXT_texture_compression_bptc/\n    case RGBA_BPTC_Format:\n    case RGB_BPTC_SIGNED_Format:\n    case RGB_BPTC_UNSIGNED_Format:\n      return Math.ceil(width / 4) * Math.ceil(height / 4) * 16;\n\n    // https://registry.khronos.org/webgl/extensions/EXT_texture_compression_rgtc/\n    case RED_RGTC1_Format:\n    case SIGNED_RED_RGTC1_Format:\n      return Math.ceil(width / 4) * Math.ceil(height / 4) * 8;\n    case RED_GREEN_RGTC2_Format:\n    case SIGNED_RED_GREEN_RGTC2_Format:\n      return Math.ceil(width / 4) * Math.ceil(height / 4) * 16;\n  }\n  throw new Error(`Unable to determine texture byte length for ${format} format.`);\n}\nfunction getTextureTypeByteLength(type) {\n  switch (type) {\n    case UnsignedByteType:\n    case ByteType:\n      return {\n        byteLength: 1,\n        components: 1\n      };\n    case UnsignedShortType:\n    case ShortType:\n    case HalfFloatType:\n      return {\n        byteLength: 2,\n        components: 1\n      };\n    case UnsignedShort4444Type:\n    case UnsignedShort5551Type:\n      return {\n        byteLength: 2,\n        components: 4\n      };\n    case UnsignedIntType:\n    case IntType:\n    case FloatType:\n      return {\n        byteLength: 4,\n        components: 1\n      };\n    case UnsignedInt5999Type:\n      return {\n        byteLength: 4,\n        components: 3\n      };\n  }\n  throw new Error(`Unknown texture type ${type}.`);\n}\nfunction WebGLTextures(_gl, extensions, state, properties, capabilities, utils, info) {\n  const multisampledRTTExt = extensions.has('WEBGL_multisampled_render_to_texture') ? extensions.get('WEBGL_multisampled_render_to_texture') : null;\n  const supportsInvalidateFramebuffer = typeof navigator === 'undefined' ? false : /OculusBrowser/g.test(navigator.userAgent);\n  const _imageDimensions = new Vector2();\n  const _videoTextures = new WeakMap();\n  let _canvas;\n  const _sources = new WeakMap(); // maps WebglTexture objects to instances of Source\n\n  // cordova iOS (as of 5.0) still uses UIWebView, which provides OffscreenCanvas,\n  // also OffscreenCanvas.getContext(\"webgl\"), but not OffscreenCanvas.getContext(\"2d\")!\n  // Some implementations may only implement OffscreenCanvas partially (e.g. lacking 2d).\n\n  let useOffscreenCanvas = false;\n  try {\n    useOffscreenCanvas = typeof OffscreenCanvas !== 'undefined'\n    // eslint-disable-next-line compat/compat\n    && new OffscreenCanvas(1, 1).getContext('2d') !== null;\n  } catch (err) {\n\n    // Ignore any errors\n  }\n  function createCanvas(width, height) {\n    // Use OffscreenCanvas when available. Specially needed in web workers\n\n    return useOffscreenCanvas ?\n    // eslint-disable-next-line compat/compat\n    new OffscreenCanvas(width, height) : createElementNS('canvas');\n  }\n  function resizeImage(image, needsNewCanvas, maxSize) {\n    let scale = 1;\n    const dimensions = getDimensions(image);\n\n    // handle case if texture exceeds max size\n\n    if (dimensions.width > maxSize || dimensions.height > maxSize) {\n      scale = maxSize / Math.max(dimensions.width, dimensions.height);\n    }\n\n    // only perform resize if necessary\n\n    if (scale < 1) {\n      // only perform resize for certain image types\n\n      if (typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement || typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap || typeof VideoFrame !== 'undefined' && image instanceof VideoFrame) {\n        const width = Math.floor(scale * dimensions.width);\n        const height = Math.floor(scale * dimensions.height);\n        if (_canvas === undefined) _canvas = createCanvas(width, height);\n\n        // cube textures can't reuse the same canvas\n\n        const canvas = needsNewCanvas ? createCanvas(width, height) : _canvas;\n        canvas.width = width;\n        canvas.height = height;\n        const context = canvas.getContext('2d');\n        context.drawImage(image, 0, 0, width, height);\n        console.warn('THREE.WebGLRenderer: Texture has been resized from (' + dimensions.width + 'x' + dimensions.height + ') to (' + width + 'x' + height + ').');\n        return canvas;\n      } else {\n        if ('data' in image) {\n          console.warn('THREE.WebGLRenderer: Image in DataTexture is too big (' + dimensions.width + 'x' + dimensions.height + ').');\n        }\n        return image;\n      }\n    }\n    return image;\n  }\n  function textureNeedsGenerateMipmaps(texture) {\n    return texture.generateMipmaps && texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter;\n  }\n  function generateMipmap(target) {\n    _gl.generateMipmap(target);\n  }\n  function getInternalFormat(internalFormatName, glFormat, glType, colorSpace, forceLinearTransfer = false) {\n    if (internalFormatName !== null) {\n      if (_gl[internalFormatName] !== undefined) return _gl[internalFormatName];\n      console.warn('THREE.WebGLRenderer: Attempt to use non-existing WebGL internal format \\'' + internalFormatName + '\\'');\n    }\n    let internalFormat = glFormat;\n    if (glFormat === _gl.RED) {\n      if (glType === _gl.FLOAT) internalFormat = _gl.R32F;\n      if (glType === _gl.HALF_FLOAT) internalFormat = _gl.R16F;\n      if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.R8;\n    }\n    if (glFormat === _gl.RED_INTEGER) {\n      if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.R8UI;\n      if (glType === _gl.UNSIGNED_SHORT) internalFormat = _gl.R16UI;\n      if (glType === _gl.UNSIGNED_INT) internalFormat = _gl.R32UI;\n      if (glType === _gl.BYTE) internalFormat = _gl.R8I;\n      if (glType === _gl.SHORT) internalFormat = _gl.R16I;\n      if (glType === _gl.INT) internalFormat = _gl.R32I;\n    }\n    if (glFormat === _gl.RG) {\n      if (glType === _gl.FLOAT) internalFormat = _gl.RG32F;\n      if (glType === _gl.HALF_FLOAT) internalFormat = _gl.RG16F;\n      if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.RG8;\n    }\n    if (glFormat === _gl.RG_INTEGER) {\n      if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.RG8UI;\n      if (glType === _gl.UNSIGNED_SHORT) internalFormat = _gl.RG16UI;\n      if (glType === _gl.UNSIGNED_INT) internalFormat = _gl.RG32UI;\n      if (glType === _gl.BYTE) internalFormat = _gl.RG8I;\n      if (glType === _gl.SHORT) internalFormat = _gl.RG16I;\n      if (glType === _gl.INT) internalFormat = _gl.RG32I;\n    }\n    if (glFormat === _gl.RGB_INTEGER) {\n      if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.RGB8UI;\n      if (glType === _gl.UNSIGNED_SHORT) internalFormat = _gl.RGB16UI;\n      if (glType === _gl.UNSIGNED_INT) internalFormat = _gl.RGB32UI;\n      if (glType === _gl.BYTE) internalFormat = _gl.RGB8I;\n      if (glType === _gl.SHORT) internalFormat = _gl.RGB16I;\n      if (glType === _gl.INT) internalFormat = _gl.RGB32I;\n    }\n    if (glFormat === _gl.RGBA_INTEGER) {\n      if (glType === _gl.UNSIGNED_BYTE) internalFormat = _gl.RGBA8UI;\n      if (glType === _gl.UNSIGNED_SHORT) internalFormat = _gl.RGBA16UI;\n      if (glType === _gl.UNSIGNED_INT) internalFormat = _gl.RGBA32UI;\n      if (glType === _gl.BYTE) internalFormat = _gl.RGBA8I;\n      if (glType === _gl.SHORT) internalFormat = _gl.RGBA16I;\n      if (glType === _gl.INT) internalFormat = _gl.RGBA32I;\n    }\n    if (glFormat === _gl.RGB) {\n      if (glType === _gl.UNSIGNED_INT_5_9_9_9_REV) internalFormat = _gl.RGB9_E5;\n    }\n    if (glFormat === _gl.RGBA) {\n      const transfer = forceLinearTransfer ? LinearTransfer : ColorManagement.getTransfer(colorSpace);\n      if (glType === _gl.FLOAT) internalFormat = _gl.RGBA32F;\n      if (glType === _gl.HALF_FLOAT) internalFormat = _gl.RGBA16F;\n      if (glType === _gl.UNSIGNED_BYTE) internalFormat = transfer === SRGBTransfer ? _gl.SRGB8_ALPHA8 : _gl.RGBA8;\n      if (glType === _gl.UNSIGNED_SHORT_4_4_4_4) internalFormat = _gl.RGBA4;\n      if (glType === _gl.UNSIGNED_SHORT_5_5_5_1) internalFormat = _gl.RGB5_A1;\n    }\n    if (internalFormat === _gl.R16F || internalFormat === _gl.R32F || internalFormat === _gl.RG16F || internalFormat === _gl.RG32F || internalFormat === _gl.RGBA16F || internalFormat === _gl.RGBA32F) {\n      extensions.get('EXT_color_buffer_float');\n    }\n    return internalFormat;\n  }\n  function getInternalDepthFormat(useStencil, depthType) {\n    let glInternalFormat;\n    if (useStencil) {\n      if (depthType === null || depthType === UnsignedIntType || depthType === UnsignedInt248Type) {\n        glInternalFormat = _gl.DEPTH24_STENCIL8;\n      } else if (depthType === FloatType) {\n        glInternalFormat = _gl.DEPTH32F_STENCIL8;\n      } else if (depthType === UnsignedShortType) {\n        glInternalFormat = _gl.DEPTH24_STENCIL8;\n        console.warn('DepthTexture: 16 bit depth attachment is not supported with stencil. Using 24-bit attachment.');\n      }\n    } else {\n      if (depthType === null || depthType === UnsignedIntType || depthType === UnsignedInt248Type) {\n        glInternalFormat = _gl.DEPTH_COMPONENT24;\n      } else if (depthType === FloatType) {\n        glInternalFormat = _gl.DEPTH_COMPONENT32F;\n      } else if (depthType === UnsignedShortType) {\n        glInternalFormat = _gl.DEPTH_COMPONENT16;\n      }\n    }\n    return glInternalFormat;\n  }\n  function getMipLevels(texture, image) {\n    if (textureNeedsGenerateMipmaps(texture) === true || texture.isFramebufferTexture && texture.minFilter !== NearestFilter && texture.minFilter !== LinearFilter) {\n      return Math.log2(Math.max(image.width, image.height)) + 1;\n    } else if (texture.mipmaps !== undefined && texture.mipmaps.length > 0) {\n      // user-defined mipmaps\n\n      return texture.mipmaps.length;\n    } else if (texture.isCompressedTexture && Array.isArray(texture.image)) {\n      return image.mipmaps.length;\n    } else {\n      // texture without mipmaps (only base level)\n\n      return 1;\n    }\n  }\n\n  //\n\n  function onTextureDispose(event) {\n    const texture = event.target;\n    texture.removeEventListener('dispose', onTextureDispose);\n    deallocateTexture(texture);\n    if (texture.isVideoTexture) {\n      _videoTextures.delete(texture);\n    }\n  }\n  function onRenderTargetDispose(event) {\n    const renderTarget = event.target;\n    renderTarget.removeEventListener('dispose', onRenderTargetDispose);\n    deallocateRenderTarget(renderTarget);\n  }\n\n  //\n\n  function deallocateTexture(texture) {\n    const textureProperties = properties.get(texture);\n    if (textureProperties.__webglInit === undefined) return;\n\n    // check if it's necessary to remove the WebGLTexture object\n\n    const source = texture.source;\n    const webglTextures = _sources.get(source);\n    if (webglTextures) {\n      const webglTexture = webglTextures[textureProperties.__cacheKey];\n      webglTexture.usedTimes--;\n\n      // the WebGLTexture object is not used anymore, remove it\n\n      if (webglTexture.usedTimes === 0) {\n        deleteTexture(texture);\n      }\n\n      // remove the weak map entry if no WebGLTexture uses the source anymore\n\n      if (Object.keys(webglTextures).length === 0) {\n        _sources.delete(source);\n      }\n    }\n    properties.remove(texture);\n  }\n  function deleteTexture(texture) {\n    const textureProperties = properties.get(texture);\n    _gl.deleteTexture(textureProperties.__webglTexture);\n    const source = texture.source;\n    const webglTextures = _sources.get(source);\n    delete webglTextures[textureProperties.__cacheKey];\n    info.memory.textures--;\n  }\n  function deallocateRenderTarget(renderTarget) {\n    const renderTargetProperties = properties.get(renderTarget);\n    if (renderTarget.depthTexture) {\n      renderTarget.depthTexture.dispose();\n    }\n    if (renderTarget.isWebGLCubeRenderTarget) {\n      for (let i = 0; i < 6; i++) {\n        if (Array.isArray(renderTargetProperties.__webglFramebuffer[i])) {\n          for (let level = 0; level < renderTargetProperties.__webglFramebuffer[i].length; level++) _gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer[i][level]);\n        } else {\n          _gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer[i]);\n        }\n        if (renderTargetProperties.__webglDepthbuffer) _gl.deleteRenderbuffer(renderTargetProperties.__webglDepthbuffer[i]);\n      }\n    } else {\n      if (Array.isArray(renderTargetProperties.__webglFramebuffer)) {\n        for (let level = 0; level < renderTargetProperties.__webglFramebuffer.length; level++) _gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer[level]);\n      } else {\n        _gl.deleteFramebuffer(renderTargetProperties.__webglFramebuffer);\n      }\n      if (renderTargetProperties.__webglDepthbuffer) _gl.deleteRenderbuffer(renderTargetProperties.__webglDepthbuffer);\n      if (renderTargetProperties.__webglMultisampledFramebuffer) _gl.deleteFramebuffer(renderTargetProperties.__webglMultisampledFramebuffer);\n      if (renderTargetProperties.__webglColorRenderbuffer) {\n        for (let i = 0; i < renderTargetProperties.__webglColorRenderbuffer.length; i++) {\n          if (renderTargetProperties.__webglColorRenderbuffer[i]) _gl.deleteRenderbuffer(renderTargetProperties.__webglColorRenderbuffer[i]);\n        }\n      }\n      if (renderTargetProperties.__webglDepthRenderbuffer) _gl.deleteRenderbuffer(renderTargetProperties.__webglDepthRenderbuffer);\n    }\n    const textures = renderTarget.textures;\n    for (let i = 0, il = textures.length; i < il; i++) {\n      const attachmentProperties = properties.get(textures[i]);\n      if (attachmentProperties.__webglTexture) {\n        _gl.deleteTexture(attachmentProperties.__webglTexture);\n        info.memory.textures--;\n      }\n      properties.remove(textures[i]);\n    }\n    properties.remove(renderTarget);\n  }\n\n  //\n\n  let textureUnits = 0;\n  function resetTextureUnits() {\n    textureUnits = 0;\n  }\n  function allocateTextureUnit() {\n    const textureUnit = textureUnits;\n    if (textureUnit >= capabilities.maxTextures) {\n      console.warn('THREE.WebGLTextures: Trying to use ' + textureUnit + ' texture units while this GPU supports only ' + capabilities.maxTextures);\n    }\n    textureUnits += 1;\n    return textureUnit;\n  }\n  function getTextureCacheKey(texture) {\n    const array = [];\n    array.push(texture.wrapS);\n    array.push(texture.wrapT);\n    array.push(texture.wrapR || 0);\n    array.push(texture.magFilter);\n    array.push(texture.minFilter);\n    array.push(texture.anisotropy);\n    array.push(texture.internalFormat);\n    array.push(texture.format);\n    array.push(texture.type);\n    array.push(texture.generateMipmaps);\n    array.push(texture.premultiplyAlpha);\n    array.push(texture.flipY);\n    array.push(texture.unpackAlignment);\n    array.push(texture.colorSpace);\n    return array.join();\n  }\n\n  //\n\n  function setTexture2D(texture, slot) {\n    const textureProperties = properties.get(texture);\n    if (texture.isVideoTexture) updateVideoTexture(texture);\n    if (texture.isRenderTargetTexture === false && texture.version > 0 && textureProperties.__version !== texture.version) {\n      const image = texture.image;\n      if (image === null) {\n        console.warn('THREE.WebGLRenderer: Texture marked for update but no image data found.');\n      } else if (image.complete === false) {\n        console.warn('THREE.WebGLRenderer: Texture marked for update but image is incomplete');\n      } else {\n        uploadTexture(textureProperties, texture, slot);\n        return;\n      }\n    }\n    state.bindTexture(_gl.TEXTURE_2D, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);\n  }\n  function setTexture2DArray(texture, slot) {\n    const textureProperties = properties.get(texture);\n    if (texture.version > 0 && textureProperties.__version !== texture.version) {\n      uploadTexture(textureProperties, texture, slot);\n      return;\n    }\n    state.bindTexture(_gl.TEXTURE_2D_ARRAY, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);\n  }\n  function setTexture3D(texture, slot) {\n    const textureProperties = properties.get(texture);\n    if (texture.version > 0 && textureProperties.__version !== texture.version) {\n      uploadTexture(textureProperties, texture, slot);\n      return;\n    }\n    state.bindTexture(_gl.TEXTURE_3D, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);\n  }\n  function setTextureCube(texture, slot) {\n    const textureProperties = properties.get(texture);\n    if (texture.version > 0 && textureProperties.__version !== texture.version) {\n      uploadCubeTexture(textureProperties, texture, slot);\n      return;\n    }\n    state.bindTexture(_gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);\n  }\n  const wrappingToGL = {\n    [RepeatWrapping]: _gl.REPEAT,\n    [ClampToEdgeWrapping]: _gl.CLAMP_TO_EDGE,\n    [MirroredRepeatWrapping]: _gl.MIRRORED_REPEAT\n  };\n  const filterToGL = {\n    [NearestFilter]: _gl.NEAREST,\n    [NearestMipmapNearestFilter]: _gl.NEAREST_MIPMAP_NEAREST,\n    [NearestMipmapLinearFilter]: _gl.NEAREST_MIPMAP_LINEAR,\n    [LinearFilter]: _gl.LINEAR,\n    [LinearMipmapNearestFilter]: _gl.LINEAR_MIPMAP_NEAREST,\n    [LinearMipmapLinearFilter]: _gl.LINEAR_MIPMAP_LINEAR\n  };\n  const compareToGL = {\n    [NeverCompare]: _gl.NEVER,\n    [AlwaysCompare]: _gl.ALWAYS,\n    [LessCompare]: _gl.LESS,\n    [LessEqualCompare]: _gl.LEQUAL,\n    [EqualCompare]: _gl.EQUAL,\n    [GreaterEqualCompare]: _gl.GEQUAL,\n    [GreaterCompare]: _gl.GREATER,\n    [NotEqualCompare]: _gl.NOTEQUAL\n  };\n  function setTextureParameters(textureType, texture) {\n    if (texture.type === FloatType && extensions.has('OES_texture_float_linear') === false && (texture.magFilter === LinearFilter || texture.magFilter === LinearMipmapNearestFilter || texture.magFilter === NearestMipmapLinearFilter || texture.magFilter === LinearMipmapLinearFilter || texture.minFilter === LinearFilter || texture.minFilter === LinearMipmapNearestFilter || texture.minFilter === NearestMipmapLinearFilter || texture.minFilter === LinearMipmapLinearFilter)) {\n      console.warn('THREE.WebGLRenderer: Unable to use linear filtering with floating point textures. OES_texture_float_linear not supported on this device.');\n    }\n    _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_S, wrappingToGL[texture.wrapS]);\n    _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_T, wrappingToGL[texture.wrapT]);\n    if (textureType === _gl.TEXTURE_3D || textureType === _gl.TEXTURE_2D_ARRAY) {\n      _gl.texParameteri(textureType, _gl.TEXTURE_WRAP_R, wrappingToGL[texture.wrapR]);\n    }\n    _gl.texParameteri(textureType, _gl.TEXTURE_MAG_FILTER, filterToGL[texture.magFilter]);\n    _gl.texParameteri(textureType, _gl.TEXTURE_MIN_FILTER, filterToGL[texture.minFilter]);\n    if (texture.compareFunction) {\n      _gl.texParameteri(textureType, _gl.TEXTURE_COMPARE_MODE, _gl.COMPARE_REF_TO_TEXTURE);\n      _gl.texParameteri(textureType, _gl.TEXTURE_COMPARE_FUNC, compareToGL[texture.compareFunction]);\n    }\n    if (extensions.has('EXT_texture_filter_anisotropic') === true) {\n      if (texture.magFilter === NearestFilter) return;\n      if (texture.minFilter !== NearestMipmapLinearFilter && texture.minFilter !== LinearMipmapLinearFilter) return;\n      if (texture.type === FloatType && extensions.has('OES_texture_float_linear') === false) return; // verify extension\n\n      if (texture.anisotropy > 1 || properties.get(texture).__currentAnisotropy) {\n        const extension = extensions.get('EXT_texture_filter_anisotropic');\n        _gl.texParameterf(textureType, extension.TEXTURE_MAX_ANISOTROPY_EXT, Math.min(texture.anisotropy, capabilities.getMaxAnisotropy()));\n        properties.get(texture).__currentAnisotropy = texture.anisotropy;\n      }\n    }\n  }\n  function initTexture(textureProperties, texture) {\n    let forceUpload = false;\n    if (textureProperties.__webglInit === undefined) {\n      textureProperties.__webglInit = true;\n      texture.addEventListener('dispose', onTextureDispose);\n    }\n\n    // create Source <-> WebGLTextures mapping if necessary\n\n    const source = texture.source;\n    let webglTextures = _sources.get(source);\n    if (webglTextures === undefined) {\n      webglTextures = {};\n      _sources.set(source, webglTextures);\n    }\n\n    // check if there is already a WebGLTexture object for the given texture parameters\n\n    const textureCacheKey = getTextureCacheKey(texture);\n    if (textureCacheKey !== textureProperties.__cacheKey) {\n      // if not, create a new instance of WebGLTexture\n\n      if (webglTextures[textureCacheKey] === undefined) {\n        // create new entry\n\n        webglTextures[textureCacheKey] = {\n          texture: _gl.createTexture(),\n          usedTimes: 0\n        };\n        info.memory.textures++;\n\n        // when a new instance of WebGLTexture was created, a texture upload is required\n        // even if the image contents are identical\n\n        forceUpload = true;\n      }\n      webglTextures[textureCacheKey].usedTimes++;\n\n      // every time the texture cache key changes, it's necessary to check if an instance of\n      // WebGLTexture can be deleted in order to avoid a memory leak.\n\n      const webglTexture = webglTextures[textureProperties.__cacheKey];\n      if (webglTexture !== undefined) {\n        webglTextures[textureProperties.__cacheKey].usedTimes--;\n        if (webglTexture.usedTimes === 0) {\n          deleteTexture(texture);\n        }\n      }\n\n      // store references to cache key and WebGLTexture object\n\n      textureProperties.__cacheKey = textureCacheKey;\n      textureProperties.__webglTexture = webglTextures[textureCacheKey].texture;\n    }\n    return forceUpload;\n  }\n  function uploadTexture(textureProperties, texture, slot) {\n    let textureType = _gl.TEXTURE_2D;\n    if (texture.isDataArrayTexture || texture.isCompressedArrayTexture) textureType = _gl.TEXTURE_2D_ARRAY;\n    if (texture.isData3DTexture) textureType = _gl.TEXTURE_3D;\n    const forceUpload = initTexture(textureProperties, texture);\n    const source = texture.source;\n    state.bindTexture(textureType, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);\n    const sourceProperties = properties.get(source);\n    if (source.version !== sourceProperties.__version || forceUpload === true) {\n      state.activeTexture(_gl.TEXTURE0 + slot);\n      const workingPrimaries = ColorManagement.getPrimaries(ColorManagement.workingColorSpace);\n      const texturePrimaries = texture.colorSpace === NoColorSpace ? null : ColorManagement.getPrimaries(texture.colorSpace);\n      const unpackConversion = texture.colorSpace === NoColorSpace || workingPrimaries === texturePrimaries ? _gl.NONE : _gl.BROWSER_DEFAULT_WEBGL;\n      _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, texture.flipY);\n      _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, texture.premultiplyAlpha);\n      _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, texture.unpackAlignment);\n      _gl.pixelStorei(_gl.UNPACK_COLORSPACE_CONVERSION_WEBGL, unpackConversion);\n      let image = resizeImage(texture.image, false, capabilities.maxTextureSize);\n      image = verifyColorSpace(texture, image);\n      const glFormat = utils.convert(texture.format, texture.colorSpace);\n      const glType = utils.convert(texture.type);\n      let glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace, texture.isVideoTexture);\n      setTextureParameters(textureType, texture);\n      let mipmap;\n      const mipmaps = texture.mipmaps;\n      const useTexStorage = texture.isVideoTexture !== true;\n      const allocateMemory = sourceProperties.__version === undefined || forceUpload === true;\n      const dataReady = source.dataReady;\n      const levels = getMipLevels(texture, image);\n      if (texture.isDepthTexture) {\n        glInternalFormat = getInternalDepthFormat(texture.format === DepthStencilFormat, texture.type);\n\n        //\n\n        if (allocateMemory) {\n          if (useTexStorage) {\n            state.texStorage2D(_gl.TEXTURE_2D, 1, glInternalFormat, image.width, image.height);\n          } else {\n            state.texImage2D(_gl.TEXTURE_2D, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, null);\n          }\n        }\n      } else if (texture.isDataTexture) {\n        // use manually created mipmaps if available\n        // if there are no manual mipmaps\n        // set 0 level mipmap and then use GL to generate other mipmap levels\n\n        if (mipmaps.length > 0) {\n          if (useTexStorage && allocateMemory) {\n            state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, mipmaps[0].width, mipmaps[0].height);\n          }\n          for (let i = 0, il = mipmaps.length; i < il; i++) {\n            mipmap = mipmaps[i];\n            if (useTexStorage) {\n              if (dataReady) {\n                state.texSubImage2D(_gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data);\n              }\n            } else {\n              state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);\n            }\n          }\n          texture.generateMipmaps = false;\n        } else {\n          if (useTexStorage) {\n            if (allocateMemory) {\n              state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, image.width, image.height);\n            }\n            if (dataReady) {\n              state.texSubImage2D(_gl.TEXTURE_2D, 0, 0, 0, image.width, image.height, glFormat, glType, image.data);\n            }\n          } else {\n            state.texImage2D(_gl.TEXTURE_2D, 0, glInternalFormat, image.width, image.height, 0, glFormat, glType, image.data);\n          }\n        }\n      } else if (texture.isCompressedTexture) {\n        if (texture.isCompressedArrayTexture) {\n          if (useTexStorage && allocateMemory) {\n            state.texStorage3D(_gl.TEXTURE_2D_ARRAY, levels, glInternalFormat, mipmaps[0].width, mipmaps[0].height, image.depth);\n          }\n          for (let i = 0, il = mipmaps.length; i < il; i++) {\n            mipmap = mipmaps[i];\n            if (texture.format !== RGBAFormat) {\n              if (glFormat !== null) {\n                if (useTexStorage) {\n                  if (dataReady) {\n                    if (texture.layerUpdates.size > 0) {\n                      const layerByteLength = getByteLength(mipmap.width, mipmap.height, texture.format, texture.type);\n                      for (const layerIndex of texture.layerUpdates) {\n                        const layerData = mipmap.data.subarray(layerIndex * layerByteLength / mipmap.data.BYTES_PER_ELEMENT, (layerIndex + 1) * layerByteLength / mipmap.data.BYTES_PER_ELEMENT);\n                        state.compressedTexSubImage3D(_gl.TEXTURE_2D_ARRAY, i, 0, 0, layerIndex, mipmap.width, mipmap.height, 1, glFormat, layerData, 0, 0);\n                      }\n                      texture.clearLayerUpdates();\n                    } else {\n                      state.compressedTexSubImage3D(_gl.TEXTURE_2D_ARRAY, i, 0, 0, 0, mipmap.width, mipmap.height, image.depth, glFormat, mipmap.data, 0, 0);\n                    }\n                  }\n                } else {\n                  state.compressedTexImage3D(_gl.TEXTURE_2D_ARRAY, i, glInternalFormat, mipmap.width, mipmap.height, image.depth, 0, mipmap.data, 0, 0);\n                }\n              } else {\n                console.warn('THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()');\n              }\n            } else {\n              if (useTexStorage) {\n                if (dataReady) {\n                  state.texSubImage3D(_gl.TEXTURE_2D_ARRAY, i, 0, 0, 0, mipmap.width, mipmap.height, image.depth, glFormat, glType, mipmap.data);\n                }\n              } else {\n                state.texImage3D(_gl.TEXTURE_2D_ARRAY, i, glInternalFormat, mipmap.width, mipmap.height, image.depth, 0, glFormat, glType, mipmap.data);\n              }\n            }\n          }\n        } else {\n          if (useTexStorage && allocateMemory) {\n            state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, mipmaps[0].width, mipmaps[0].height);\n          }\n          for (let i = 0, il = mipmaps.length; i < il; i++) {\n            mipmap = mipmaps[i];\n            if (texture.format !== RGBAFormat) {\n              if (glFormat !== null) {\n                if (useTexStorage) {\n                  if (dataReady) {\n                    state.compressedTexSubImage2D(_gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data);\n                  }\n                } else {\n                  state.compressedTexImage2D(_gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data);\n                }\n              } else {\n                console.warn('THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .uploadTexture()');\n              }\n            } else {\n              if (useTexStorage) {\n                if (dataReady) {\n                  state.texSubImage2D(_gl.TEXTURE_2D, i, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data);\n                }\n              } else {\n                state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);\n              }\n            }\n          }\n        }\n      } else if (texture.isDataArrayTexture) {\n        if (useTexStorage) {\n          if (allocateMemory) {\n            state.texStorage3D(_gl.TEXTURE_2D_ARRAY, levels, glInternalFormat, image.width, image.height, image.depth);\n          }\n          if (dataReady) {\n            if (texture.layerUpdates.size > 0) {\n              const layerByteLength = getByteLength(image.width, image.height, texture.format, texture.type);\n              for (const layerIndex of texture.layerUpdates) {\n                const layerData = image.data.subarray(layerIndex * layerByteLength / image.data.BYTES_PER_ELEMENT, (layerIndex + 1) * layerByteLength / image.data.BYTES_PER_ELEMENT);\n                state.texSubImage3D(_gl.TEXTURE_2D_ARRAY, 0, 0, 0, layerIndex, image.width, image.height, 1, glFormat, glType, layerData);\n              }\n              texture.clearLayerUpdates();\n            } else {\n              state.texSubImage3D(_gl.TEXTURE_2D_ARRAY, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data);\n            }\n          }\n        } else {\n          state.texImage3D(_gl.TEXTURE_2D_ARRAY, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data);\n        }\n      } else if (texture.isData3DTexture) {\n        if (useTexStorage) {\n          if (allocateMemory) {\n            state.texStorage3D(_gl.TEXTURE_3D, levels, glInternalFormat, image.width, image.height, image.depth);\n          }\n          if (dataReady) {\n            state.texSubImage3D(_gl.TEXTURE_3D, 0, 0, 0, 0, image.width, image.height, image.depth, glFormat, glType, image.data);\n          }\n        } else {\n          state.texImage3D(_gl.TEXTURE_3D, 0, glInternalFormat, image.width, image.height, image.depth, 0, glFormat, glType, image.data);\n        }\n      } else if (texture.isFramebufferTexture) {\n        if (allocateMemory) {\n          if (useTexStorage) {\n            state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, image.width, image.height);\n          } else {\n            let width = image.width,\n              height = image.height;\n            for (let i = 0; i < levels; i++) {\n              state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, width, height, 0, glFormat, glType, null);\n              width >>= 1;\n              height >>= 1;\n            }\n          }\n        }\n      } else {\n        // regular Texture (image, video, canvas)\n\n        // use manually created mipmaps if available\n        // if there are no manual mipmaps\n        // set 0 level mipmap and then use GL to generate other mipmap levels\n\n        if (mipmaps.length > 0) {\n          if (useTexStorage && allocateMemory) {\n            const dimensions = getDimensions(mipmaps[0]);\n            state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, dimensions.width, dimensions.height);\n          }\n          for (let i = 0, il = mipmaps.length; i < il; i++) {\n            mipmap = mipmaps[i];\n            if (useTexStorage) {\n              if (dataReady) {\n                state.texSubImage2D(_gl.TEXTURE_2D, i, 0, 0, glFormat, glType, mipmap);\n              }\n            } else {\n              state.texImage2D(_gl.TEXTURE_2D, i, glInternalFormat, glFormat, glType, mipmap);\n            }\n          }\n          texture.generateMipmaps = false;\n        } else {\n          if (useTexStorage) {\n            if (allocateMemory) {\n              const dimensions = getDimensions(image);\n              state.texStorage2D(_gl.TEXTURE_2D, levels, glInternalFormat, dimensions.width, dimensions.height);\n            }\n            if (dataReady) {\n              state.texSubImage2D(_gl.TEXTURE_2D, 0, 0, 0, glFormat, glType, image);\n            }\n          } else {\n            state.texImage2D(_gl.TEXTURE_2D, 0, glInternalFormat, glFormat, glType, image);\n          }\n        }\n      }\n      if (textureNeedsGenerateMipmaps(texture)) {\n        generateMipmap(textureType);\n      }\n      sourceProperties.__version = source.version;\n      if (texture.onUpdate) texture.onUpdate(texture);\n    }\n    textureProperties.__version = texture.version;\n  }\n  function uploadCubeTexture(textureProperties, texture, slot) {\n    if (texture.image.length !== 6) return;\n    const forceUpload = initTexture(textureProperties, texture);\n    const source = texture.source;\n    state.bindTexture(_gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture, _gl.TEXTURE0 + slot);\n    const sourceProperties = properties.get(source);\n    if (source.version !== sourceProperties.__version || forceUpload === true) {\n      state.activeTexture(_gl.TEXTURE0 + slot);\n      const workingPrimaries = ColorManagement.getPrimaries(ColorManagement.workingColorSpace);\n      const texturePrimaries = texture.colorSpace === NoColorSpace ? null : ColorManagement.getPrimaries(texture.colorSpace);\n      const unpackConversion = texture.colorSpace === NoColorSpace || workingPrimaries === texturePrimaries ? _gl.NONE : _gl.BROWSER_DEFAULT_WEBGL;\n      _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, texture.flipY);\n      _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, texture.premultiplyAlpha);\n      _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, texture.unpackAlignment);\n      _gl.pixelStorei(_gl.UNPACK_COLORSPACE_CONVERSION_WEBGL, unpackConversion);\n      const isCompressed = texture.isCompressedTexture || texture.image[0].isCompressedTexture;\n      const isDataTexture = texture.image[0] && texture.image[0].isDataTexture;\n      const cubeImage = [];\n      for (let i = 0; i < 6; i++) {\n        if (!isCompressed && !isDataTexture) {\n          cubeImage[i] = resizeImage(texture.image[i], true, capabilities.maxCubemapSize);\n        } else {\n          cubeImage[i] = isDataTexture ? texture.image[i].image : texture.image[i];\n        }\n        cubeImage[i] = verifyColorSpace(texture, cubeImage[i]);\n      }\n      const image = cubeImage[0],\n        glFormat = utils.convert(texture.format, texture.colorSpace),\n        glType = utils.convert(texture.type),\n        glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace);\n      const useTexStorage = texture.isVideoTexture !== true;\n      const allocateMemory = sourceProperties.__version === undefined || forceUpload === true;\n      const dataReady = source.dataReady;\n      let levels = getMipLevels(texture, image);\n      setTextureParameters(_gl.TEXTURE_CUBE_MAP, texture);\n      let mipmaps;\n      if (isCompressed) {\n        if (useTexStorage && allocateMemory) {\n          state.texStorage2D(_gl.TEXTURE_CUBE_MAP, levels, glInternalFormat, image.width, image.height);\n        }\n        for (let i = 0; i < 6; i++) {\n          mipmaps = cubeImage[i].mipmaps;\n          for (let j = 0; j < mipmaps.length; j++) {\n            const mipmap = mipmaps[j];\n            if (texture.format !== RGBAFormat) {\n              if (glFormat !== null) {\n                if (useTexStorage) {\n                  if (dataReady) {\n                    state.compressedTexSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, mipmap.data);\n                  }\n                } else {\n                  state.compressedTexImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, mipmap.data);\n                }\n              } else {\n                console.warn('THREE.WebGLRenderer: Attempt to load unsupported compressed texture format in .setTextureCube()');\n              }\n            } else {\n              if (useTexStorage) {\n                if (dataReady) {\n                  state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, 0, 0, mipmap.width, mipmap.height, glFormat, glType, mipmap.data);\n                }\n              } else {\n                state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j, glInternalFormat, mipmap.width, mipmap.height, 0, glFormat, glType, mipmap.data);\n              }\n            }\n          }\n        }\n      } else {\n        mipmaps = texture.mipmaps;\n        if (useTexStorage && allocateMemory) {\n          // TODO: Uniformly handle mipmap definitions\n          // Normal textures and compressed cube textures define base level + mips with their mipmap array\n          // Uncompressed cube textures use their mipmap array only for mips (no base level)\n\n          if (mipmaps.length > 0) levels++;\n          const dimensions = getDimensions(cubeImage[0]);\n          state.texStorage2D(_gl.TEXTURE_CUBE_MAP, levels, glInternalFormat, dimensions.width, dimensions.height);\n        }\n        for (let i = 0; i < 6; i++) {\n          if (isDataTexture) {\n            if (useTexStorage) {\n              if (dataReady) {\n                state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, 0, 0, cubeImage[i].width, cubeImage[i].height, glFormat, glType, cubeImage[i].data);\n              }\n            } else {\n              state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glInternalFormat, cubeImage[i].width, cubeImage[i].height, 0, glFormat, glType, cubeImage[i].data);\n            }\n            for (let j = 0; j < mipmaps.length; j++) {\n              const mipmap = mipmaps[j];\n              const mipmapImage = mipmap.image[i].image;\n              if (useTexStorage) {\n                if (dataReady) {\n                  state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, 0, 0, mipmapImage.width, mipmapImage.height, glFormat, glType, mipmapImage.data);\n                }\n              } else {\n                state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, glInternalFormat, mipmapImage.width, mipmapImage.height, 0, glFormat, glType, mipmapImage.data);\n              }\n            }\n          } else {\n            if (useTexStorage) {\n              if (dataReady) {\n                state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, 0, 0, glFormat, glType, cubeImage[i]);\n              }\n            } else {\n              state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0, glInternalFormat, glFormat, glType, cubeImage[i]);\n            }\n            for (let j = 0; j < mipmaps.length; j++) {\n              const mipmap = mipmaps[j];\n              if (useTexStorage) {\n                if (dataReady) {\n                  state.texSubImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, 0, 0, glFormat, glType, mipmap.image[i]);\n                }\n              } else {\n                state.texImage2D(_gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, j + 1, glInternalFormat, glFormat, glType, mipmap.image[i]);\n              }\n            }\n          }\n        }\n      }\n      if (textureNeedsGenerateMipmaps(texture)) {\n        // We assume images for cube map have the same size.\n        generateMipmap(_gl.TEXTURE_CUBE_MAP);\n      }\n      sourceProperties.__version = source.version;\n      if (texture.onUpdate) texture.onUpdate(texture);\n    }\n    textureProperties.__version = texture.version;\n  }\n\n  // Render targets\n\n  // Setup storage for target texture and bind it to correct framebuffer\n  function setupFrameBufferTexture(framebuffer, renderTarget, texture, attachment, textureTarget, level) {\n    const glFormat = utils.convert(texture.format, texture.colorSpace);\n    const glType = utils.convert(texture.type);\n    const glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace);\n    const renderTargetProperties = properties.get(renderTarget);\n    if (!renderTargetProperties.__hasExternalTextures) {\n      const width = Math.max(1, renderTarget.width >> level);\n      const height = Math.max(1, renderTarget.height >> level);\n      if (textureTarget === _gl.TEXTURE_3D || textureTarget === _gl.TEXTURE_2D_ARRAY) {\n        state.texImage3D(textureTarget, level, glInternalFormat, width, height, renderTarget.depth, 0, glFormat, glType, null);\n      } else {\n        state.texImage2D(textureTarget, level, glInternalFormat, width, height, 0, glFormat, glType, null);\n      }\n    }\n    state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);\n    if (useMultisampledRTT(renderTarget)) {\n      multisampledRTTExt.framebufferTexture2DMultisampleEXT(_gl.FRAMEBUFFER, attachment, textureTarget, properties.get(texture).__webglTexture, 0, getRenderTargetSamples(renderTarget));\n    } else if (textureTarget === _gl.TEXTURE_2D || textureTarget >= _gl.TEXTURE_CUBE_MAP_POSITIVE_X && textureTarget <= _gl.TEXTURE_CUBE_MAP_NEGATIVE_Z) {\n      // see #24753\n\n      _gl.framebufferTexture2D(_gl.FRAMEBUFFER, attachment, textureTarget, properties.get(texture).__webglTexture, level);\n    }\n    state.bindFramebuffer(_gl.FRAMEBUFFER, null);\n  }\n\n  // Setup storage for internal depth/stencil buffers and bind to correct framebuffer\n  function setupRenderBufferStorage(renderbuffer, renderTarget, isMultisample) {\n    _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderbuffer);\n    if (renderTarget.depthBuffer) {\n      // retrieve the depth attachment types\n      const depthTexture = renderTarget.depthTexture;\n      const depthType = depthTexture && depthTexture.isDepthTexture ? depthTexture.type : null;\n      const glInternalFormat = getInternalDepthFormat(renderTarget.stencilBuffer, depthType);\n      const glAttachmentType = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;\n\n      // set up the attachment\n      const samples = getRenderTargetSamples(renderTarget);\n      const isUseMultisampledRTT = useMultisampledRTT(renderTarget);\n      if (isUseMultisampledRTT) {\n        multisampledRTTExt.renderbufferStorageMultisampleEXT(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);\n      } else if (isMultisample) {\n        _gl.renderbufferStorageMultisample(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);\n      } else {\n        _gl.renderbufferStorage(_gl.RENDERBUFFER, glInternalFormat, renderTarget.width, renderTarget.height);\n      }\n      _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, glAttachmentType, _gl.RENDERBUFFER, renderbuffer);\n    } else {\n      const textures = renderTarget.textures;\n      for (let i = 0; i < textures.length; i++) {\n        const texture = textures[i];\n        const glFormat = utils.convert(texture.format, texture.colorSpace);\n        const glType = utils.convert(texture.type);\n        const glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace);\n        const samples = getRenderTargetSamples(renderTarget);\n        if (isMultisample && useMultisampledRTT(renderTarget) === false) {\n          _gl.renderbufferStorageMultisample(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);\n        } else if (useMultisampledRTT(renderTarget)) {\n          multisampledRTTExt.renderbufferStorageMultisampleEXT(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);\n        } else {\n          _gl.renderbufferStorage(_gl.RENDERBUFFER, glInternalFormat, renderTarget.width, renderTarget.height);\n        }\n      }\n    }\n    _gl.bindRenderbuffer(_gl.RENDERBUFFER, null);\n  }\n\n  // Setup resources for a Depth Texture for a FBO (needs an extension)\n  function setupDepthTexture(framebuffer, renderTarget) {\n    const isCube = renderTarget && renderTarget.isWebGLCubeRenderTarget;\n    if (isCube) throw new Error('Depth Texture with cube render targets is not supported');\n    state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);\n    if (!(renderTarget.depthTexture && renderTarget.depthTexture.isDepthTexture)) {\n      throw new Error('renderTarget.depthTexture must be an instance of THREE.DepthTexture');\n    }\n\n    // upload an empty depth texture with framebuffer size\n    if (!properties.get(renderTarget.depthTexture).__webglTexture || renderTarget.depthTexture.image.width !== renderTarget.width || renderTarget.depthTexture.image.height !== renderTarget.height) {\n      renderTarget.depthTexture.image.width = renderTarget.width;\n      renderTarget.depthTexture.image.height = renderTarget.height;\n      renderTarget.depthTexture.needsUpdate = true;\n    }\n    setTexture2D(renderTarget.depthTexture, 0);\n    const webglDepthTexture = properties.get(renderTarget.depthTexture).__webglTexture;\n    const samples = getRenderTargetSamples(renderTarget);\n    if (renderTarget.depthTexture.format === DepthFormat) {\n      if (useMultisampledRTT(renderTarget)) {\n        multisampledRTTExt.framebufferTexture2DMultisampleEXT(_gl.FRAMEBUFFER, _gl.DEPTH_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0, samples);\n      } else {\n        _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.DEPTH_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0);\n      }\n    } else if (renderTarget.depthTexture.format === DepthStencilFormat) {\n      if (useMultisampledRTT(renderTarget)) {\n        multisampledRTTExt.framebufferTexture2DMultisampleEXT(_gl.FRAMEBUFFER, _gl.DEPTH_STENCIL_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0, samples);\n      } else {\n        _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.DEPTH_STENCIL_ATTACHMENT, _gl.TEXTURE_2D, webglDepthTexture, 0);\n      }\n    } else {\n      throw new Error('Unknown depthTexture format');\n    }\n  }\n\n  // Setup GL resources for a non-texture depth buffer\n  function setupDepthRenderbuffer(renderTarget) {\n    const renderTargetProperties = properties.get(renderTarget);\n    const isCube = renderTarget.isWebGLCubeRenderTarget === true;\n\n    // if the bound depth texture has changed\n    if (renderTargetProperties.__boundDepthTexture !== renderTarget.depthTexture) {\n      // fire the dispose event to get rid of stored state associated with the previously bound depth buffer\n      const depthTexture = renderTarget.depthTexture;\n      if (renderTargetProperties.__depthDisposeCallback) {\n        renderTargetProperties.__depthDisposeCallback();\n      }\n\n      // set up dispose listeners to track when the currently attached buffer is implicitly unbound\n      if (depthTexture) {\n        const disposeEvent = () => {\n          delete renderTargetProperties.__boundDepthTexture;\n          delete renderTargetProperties.__depthDisposeCallback;\n          depthTexture.removeEventListener('dispose', disposeEvent);\n        };\n        depthTexture.addEventListener('dispose', disposeEvent);\n        renderTargetProperties.__depthDisposeCallback = disposeEvent;\n      }\n      renderTargetProperties.__boundDepthTexture = depthTexture;\n    }\n    if (renderTarget.depthTexture && !renderTargetProperties.__autoAllocateDepthBuffer) {\n      if (isCube) throw new Error('target.depthTexture not supported in Cube render targets');\n      setupDepthTexture(renderTargetProperties.__webglFramebuffer, renderTarget);\n    } else {\n      if (isCube) {\n        renderTargetProperties.__webglDepthbuffer = [];\n        for (let i = 0; i < 6; i++) {\n          state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer[i]);\n          if (renderTargetProperties.__webglDepthbuffer[i] === undefined) {\n            renderTargetProperties.__webglDepthbuffer[i] = _gl.createRenderbuffer();\n            setupRenderBufferStorage(renderTargetProperties.__webglDepthbuffer[i], renderTarget, false);\n          } else {\n            // attach buffer if it's been created already\n            const glAttachmentType = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;\n            const renderbuffer = renderTargetProperties.__webglDepthbuffer[i];\n            _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderbuffer);\n            _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, glAttachmentType, _gl.RENDERBUFFER, renderbuffer);\n          }\n        }\n      } else {\n        state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);\n        if (renderTargetProperties.__webglDepthbuffer === undefined) {\n          renderTargetProperties.__webglDepthbuffer = _gl.createRenderbuffer();\n          setupRenderBufferStorage(renderTargetProperties.__webglDepthbuffer, renderTarget, false);\n        } else {\n          // attach buffer if it's been created already\n          const glAttachmentType = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;\n          const renderbuffer = renderTargetProperties.__webglDepthbuffer;\n          _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderbuffer);\n          _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, glAttachmentType, _gl.RENDERBUFFER, renderbuffer);\n        }\n      }\n    }\n    state.bindFramebuffer(_gl.FRAMEBUFFER, null);\n  }\n\n  // rebind framebuffer with external textures\n  function rebindTextures(renderTarget, colorTexture, depthTexture) {\n    const renderTargetProperties = properties.get(renderTarget);\n    if (colorTexture !== undefined) {\n      setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer, renderTarget, renderTarget.texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, 0);\n    }\n    if (depthTexture !== undefined) {\n      setupDepthRenderbuffer(renderTarget);\n    }\n  }\n\n  // Set up GL resources for the render target\n  function setupRenderTarget(renderTarget) {\n    const texture = renderTarget.texture;\n    const renderTargetProperties = properties.get(renderTarget);\n    const textureProperties = properties.get(texture);\n    renderTarget.addEventListener('dispose', onRenderTargetDispose);\n    const textures = renderTarget.textures;\n    const isCube = renderTarget.isWebGLCubeRenderTarget === true;\n    const isMultipleRenderTargets = textures.length > 1;\n    if (!isMultipleRenderTargets) {\n      if (textureProperties.__webglTexture === undefined) {\n        textureProperties.__webglTexture = _gl.createTexture();\n      }\n      textureProperties.__version = texture.version;\n      info.memory.textures++;\n    }\n\n    // Setup framebuffer\n\n    if (isCube) {\n      renderTargetProperties.__webglFramebuffer = [];\n      for (let i = 0; i < 6; i++) {\n        if (texture.mipmaps && texture.mipmaps.length > 0) {\n          renderTargetProperties.__webglFramebuffer[i] = [];\n          for (let level = 0; level < texture.mipmaps.length; level++) {\n            renderTargetProperties.__webglFramebuffer[i][level] = _gl.createFramebuffer();\n          }\n        } else {\n          renderTargetProperties.__webglFramebuffer[i] = _gl.createFramebuffer();\n        }\n      }\n    } else {\n      if (texture.mipmaps && texture.mipmaps.length > 0) {\n        renderTargetProperties.__webglFramebuffer = [];\n        for (let level = 0; level < texture.mipmaps.length; level++) {\n          renderTargetProperties.__webglFramebuffer[level] = _gl.createFramebuffer();\n        }\n      } else {\n        renderTargetProperties.__webglFramebuffer = _gl.createFramebuffer();\n      }\n      if (isMultipleRenderTargets) {\n        for (let i = 0, il = textures.length; i < il; i++) {\n          const attachmentProperties = properties.get(textures[i]);\n          if (attachmentProperties.__webglTexture === undefined) {\n            attachmentProperties.__webglTexture = _gl.createTexture();\n            info.memory.textures++;\n          }\n        }\n      }\n      if (renderTarget.samples > 0 && useMultisampledRTT(renderTarget) === false) {\n        renderTargetProperties.__webglMultisampledFramebuffer = _gl.createFramebuffer();\n        renderTargetProperties.__webglColorRenderbuffer = [];\n        state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);\n        for (let i = 0; i < textures.length; i++) {\n          const texture = textures[i];\n          renderTargetProperties.__webglColorRenderbuffer[i] = _gl.createRenderbuffer();\n          _gl.bindRenderbuffer(_gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);\n          const glFormat = utils.convert(texture.format, texture.colorSpace);\n          const glType = utils.convert(texture.type);\n          const glInternalFormat = getInternalFormat(texture.internalFormat, glFormat, glType, texture.colorSpace, renderTarget.isXRRenderTarget === true);\n          const samples = getRenderTargetSamples(renderTarget);\n          _gl.renderbufferStorageMultisample(_gl.RENDERBUFFER, samples, glInternalFormat, renderTarget.width, renderTarget.height);\n          _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);\n        }\n        _gl.bindRenderbuffer(_gl.RENDERBUFFER, null);\n        if (renderTarget.depthBuffer) {\n          renderTargetProperties.__webglDepthRenderbuffer = _gl.createRenderbuffer();\n          setupRenderBufferStorage(renderTargetProperties.__webglDepthRenderbuffer, renderTarget, true);\n        }\n        state.bindFramebuffer(_gl.FRAMEBUFFER, null);\n      }\n    }\n\n    // Setup color buffer\n\n    if (isCube) {\n      state.bindTexture(_gl.TEXTURE_CUBE_MAP, textureProperties.__webglTexture);\n      setTextureParameters(_gl.TEXTURE_CUBE_MAP, texture);\n      for (let i = 0; i < 6; i++) {\n        if (texture.mipmaps && texture.mipmaps.length > 0) {\n          for (let level = 0; level < texture.mipmaps.length; level++) {\n            setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer[i][level], renderTarget, texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, level);\n          }\n        } else {\n          setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer[i], renderTarget, texture, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + i, 0);\n        }\n      }\n      if (textureNeedsGenerateMipmaps(texture)) {\n        generateMipmap(_gl.TEXTURE_CUBE_MAP);\n      }\n      state.unbindTexture();\n    } else if (isMultipleRenderTargets) {\n      for (let i = 0, il = textures.length; i < il; i++) {\n        const attachment = textures[i];\n        const attachmentProperties = properties.get(attachment);\n        state.bindTexture(_gl.TEXTURE_2D, attachmentProperties.__webglTexture);\n        setTextureParameters(_gl.TEXTURE_2D, attachment);\n        setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer, renderTarget, attachment, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, 0);\n        if (textureNeedsGenerateMipmaps(attachment)) {\n          generateMipmap(_gl.TEXTURE_2D);\n        }\n      }\n      state.unbindTexture();\n    } else {\n      let glTextureType = _gl.TEXTURE_2D;\n      if (renderTarget.isWebGL3DRenderTarget || renderTarget.isWebGLArrayRenderTarget) {\n        glTextureType = renderTarget.isWebGL3DRenderTarget ? _gl.TEXTURE_3D : _gl.TEXTURE_2D_ARRAY;\n      }\n      state.bindTexture(glTextureType, textureProperties.__webglTexture);\n      setTextureParameters(glTextureType, texture);\n      if (texture.mipmaps && texture.mipmaps.length > 0) {\n        for (let level = 0; level < texture.mipmaps.length; level++) {\n          setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer[level], renderTarget, texture, _gl.COLOR_ATTACHMENT0, glTextureType, level);\n        }\n      } else {\n        setupFrameBufferTexture(renderTargetProperties.__webglFramebuffer, renderTarget, texture, _gl.COLOR_ATTACHMENT0, glTextureType, 0);\n      }\n      if (textureNeedsGenerateMipmaps(texture)) {\n        generateMipmap(glTextureType);\n      }\n      state.unbindTexture();\n    }\n\n    // Setup depth and stencil buffers\n\n    if (renderTarget.depthBuffer) {\n      setupDepthRenderbuffer(renderTarget);\n    }\n  }\n  function updateRenderTargetMipmap(renderTarget) {\n    const textures = renderTarget.textures;\n    for (let i = 0, il = textures.length; i < il; i++) {\n      const texture = textures[i];\n      if (textureNeedsGenerateMipmaps(texture)) {\n        const target = renderTarget.isWebGLCubeRenderTarget ? _gl.TEXTURE_CUBE_MAP : _gl.TEXTURE_2D;\n        const webglTexture = properties.get(texture).__webglTexture;\n        state.bindTexture(target, webglTexture);\n        generateMipmap(target);\n        state.unbindTexture();\n      }\n    }\n  }\n  const invalidationArrayRead = [];\n  const invalidationArrayDraw = [];\n  function updateMultisampleRenderTarget(renderTarget) {\n    if (renderTarget.samples > 0) {\n      if (useMultisampledRTT(renderTarget) === false) {\n        const textures = renderTarget.textures;\n        const width = renderTarget.width;\n        const height = renderTarget.height;\n        let mask = _gl.COLOR_BUFFER_BIT;\n        const depthStyle = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;\n        const renderTargetProperties = properties.get(renderTarget);\n        const isMultipleRenderTargets = textures.length > 1;\n\n        // If MRT we need to remove FBO attachments\n        if (isMultipleRenderTargets) {\n          for (let i = 0; i < textures.length; i++) {\n            state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);\n            _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, null);\n            state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);\n            _gl.framebufferTexture2D(_gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, null, 0);\n          }\n        }\n        state.bindFramebuffer(_gl.READ_FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);\n        state.bindFramebuffer(_gl.DRAW_FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);\n        for (let i = 0; i < textures.length; i++) {\n          if (renderTarget.resolveDepthBuffer) {\n            if (renderTarget.depthBuffer) mask |= _gl.DEPTH_BUFFER_BIT;\n\n            // resolving stencil is slow with a D3D backend. disable it for all transmission render targets (see #27799)\n\n            if (renderTarget.stencilBuffer && renderTarget.resolveStencilBuffer) mask |= _gl.STENCIL_BUFFER_BIT;\n          }\n          if (isMultipleRenderTargets) {\n            _gl.framebufferRenderbuffer(_gl.READ_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);\n            const webglTexture = properties.get(textures[i]).__webglTexture;\n            _gl.framebufferTexture2D(_gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_2D, webglTexture, 0);\n          }\n          _gl.blitFramebuffer(0, 0, width, height, 0, 0, width, height, mask, _gl.NEAREST);\n          if (supportsInvalidateFramebuffer === true) {\n            invalidationArrayRead.length = 0;\n            invalidationArrayDraw.length = 0;\n            invalidationArrayRead.push(_gl.COLOR_ATTACHMENT0 + i);\n            if (renderTarget.depthBuffer && renderTarget.resolveDepthBuffer === false) {\n              invalidationArrayRead.push(depthStyle);\n              invalidationArrayDraw.push(depthStyle);\n              _gl.invalidateFramebuffer(_gl.DRAW_FRAMEBUFFER, invalidationArrayDraw);\n            }\n            _gl.invalidateFramebuffer(_gl.READ_FRAMEBUFFER, invalidationArrayRead);\n          }\n        }\n        state.bindFramebuffer(_gl.READ_FRAMEBUFFER, null);\n        state.bindFramebuffer(_gl.DRAW_FRAMEBUFFER, null);\n\n        // If MRT since pre-blit we removed the FBO we need to reconstruct the attachments\n        if (isMultipleRenderTargets) {\n          for (let i = 0; i < textures.length; i++) {\n            state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);\n            _gl.framebufferRenderbuffer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.RENDERBUFFER, renderTargetProperties.__webglColorRenderbuffer[i]);\n            const webglTexture = properties.get(textures[i]).__webglTexture;\n            state.bindFramebuffer(_gl.FRAMEBUFFER, renderTargetProperties.__webglFramebuffer);\n            _gl.framebufferTexture2D(_gl.DRAW_FRAMEBUFFER, _gl.COLOR_ATTACHMENT0 + i, _gl.TEXTURE_2D, webglTexture, 0);\n          }\n        }\n        state.bindFramebuffer(_gl.DRAW_FRAMEBUFFER, renderTargetProperties.__webglMultisampledFramebuffer);\n      } else {\n        if (renderTarget.depthBuffer && renderTarget.resolveDepthBuffer === false && supportsInvalidateFramebuffer) {\n          const depthStyle = renderTarget.stencilBuffer ? _gl.DEPTH_STENCIL_ATTACHMENT : _gl.DEPTH_ATTACHMENT;\n          _gl.invalidateFramebuffer(_gl.DRAW_FRAMEBUFFER, [depthStyle]);\n        }\n      }\n    }\n  }\n  function getRenderTargetSamples(renderTarget) {\n    return Math.min(capabilities.maxSamples, renderTarget.samples);\n  }\n  function useMultisampledRTT(renderTarget) {\n    const renderTargetProperties = properties.get(renderTarget);\n    return renderTarget.samples > 0 && extensions.has('WEBGL_multisampled_render_to_texture') === true && renderTargetProperties.__useRenderToTexture !== false;\n  }\n  function updateVideoTexture(texture) {\n    const frame = info.render.frame;\n\n    // Check the last frame we updated the VideoTexture\n\n    if (_videoTextures.get(texture) !== frame) {\n      _videoTextures.set(texture, frame);\n      texture.update();\n    }\n  }\n  function verifyColorSpace(texture, image) {\n    const colorSpace = texture.colorSpace;\n    const format = texture.format;\n    const type = texture.type;\n    if (texture.isCompressedTexture === true || texture.isVideoTexture === true) return image;\n    if (colorSpace !== LinearSRGBColorSpace && colorSpace !== NoColorSpace) {\n      // sRGB\n\n      if (ColorManagement.getTransfer(colorSpace) === SRGBTransfer) {\n        // in WebGL 2 uncompressed textures can only be sRGB encoded if they have the RGBA8 format\n\n        if (format !== RGBAFormat || type !== UnsignedByteType) {\n          console.warn('THREE.WebGLTextures: sRGB encoded textures have to use RGBAFormat and UnsignedByteType.');\n        }\n      } else {\n        console.error('THREE.WebGLTextures: Unsupported texture color space:', colorSpace);\n      }\n    }\n    return image;\n  }\n  function getDimensions(image) {\n    if (typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement) {\n      // if intrinsic data are not available, fallback to width/height\n\n      _imageDimensions.width = image.naturalWidth || image.width;\n      _imageDimensions.height = image.naturalHeight || image.height;\n    } else if (typeof VideoFrame !== 'undefined' && image instanceof VideoFrame) {\n      _imageDimensions.width = image.displayWidth;\n      _imageDimensions.height = image.displayHeight;\n    } else {\n      _imageDimensions.width = image.width;\n      _imageDimensions.height = image.height;\n    }\n    return _imageDimensions;\n  }\n\n  //\n\n  this.allocateTextureUnit = allocateTextureUnit;\n  this.resetTextureUnits = resetTextureUnits;\n  this.setTexture2D = setTexture2D;\n  this.setTexture2DArray = setTexture2DArray;\n  this.setTexture3D = setTexture3D;\n  this.setTextureCube = setTextureCube;\n  this.rebindTextures = rebindTextures;\n  this.setupRenderTarget = setupRenderTarget;\n  this.updateRenderTargetMipmap = updateRenderTargetMipmap;\n  this.updateMultisampleRenderTarget = updateMultisampleRenderTarget;\n  this.setupDepthRenderbuffer = setupDepthRenderbuffer;\n  this.setupFrameBufferTexture = setupFrameBufferTexture;\n  this.useMultisampledRTT = useMultisampledRTT;\n}\nfunction WebGLUtils(gl, extensions) {\n  function convert(p, colorSpace = NoColorSpace) {\n    let extension;\n    const transfer = ColorManagement.getTransfer(colorSpace);\n    if (p === UnsignedByteType) return gl.UNSIGNED_BYTE;\n    if (p === UnsignedShort4444Type) return gl.UNSIGNED_SHORT_4_4_4_4;\n    if (p === UnsignedShort5551Type) return gl.UNSIGNED_SHORT_5_5_5_1;\n    if (p === UnsignedInt5999Type) return gl.UNSIGNED_INT_5_9_9_9_REV;\n    if (p === ByteType) return gl.BYTE;\n    if (p === ShortType) return gl.SHORT;\n    if (p === UnsignedShortType) return gl.UNSIGNED_SHORT;\n    if (p === IntType) return gl.INT;\n    if (p === UnsignedIntType) return gl.UNSIGNED_INT;\n    if (p === FloatType) return gl.FLOAT;\n    if (p === HalfFloatType) return gl.HALF_FLOAT;\n    if (p === AlphaFormat) return gl.ALPHA;\n    if (p === RGBFormat) return gl.RGB;\n    if (p === RGBAFormat) return gl.RGBA;\n    if (p === LuminanceFormat) return gl.LUMINANCE;\n    if (p === LuminanceAlphaFormat) return gl.LUMINANCE_ALPHA;\n    if (p === DepthFormat) return gl.DEPTH_COMPONENT;\n    if (p === DepthStencilFormat) return gl.DEPTH_STENCIL;\n\n    // WebGL2 formats.\n\n    if (p === RedFormat) return gl.RED;\n    if (p === RedIntegerFormat) return gl.RED_INTEGER;\n    if (p === RGFormat) return gl.RG;\n    if (p === RGIntegerFormat) return gl.RG_INTEGER;\n    if (p === RGBAIntegerFormat) return gl.RGBA_INTEGER;\n\n    // S3TC\n\n    if (p === RGB_S3TC_DXT1_Format || p === RGBA_S3TC_DXT1_Format || p === RGBA_S3TC_DXT3_Format || p === RGBA_S3TC_DXT5_Format) {\n      if (transfer === SRGBTransfer) {\n        extension = extensions.get('WEBGL_compressed_texture_s3tc_srgb');\n        if (extension !== null) {\n          if (p === RGB_S3TC_DXT1_Format) return extension.COMPRESSED_SRGB_S3TC_DXT1_EXT;\n          if (p === RGBA_S3TC_DXT1_Format) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT1_EXT;\n          if (p === RGBA_S3TC_DXT3_Format) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT3_EXT;\n          if (p === RGBA_S3TC_DXT5_Format) return extension.COMPRESSED_SRGB_ALPHA_S3TC_DXT5_EXT;\n        } else {\n          return null;\n        }\n      } else {\n        extension = extensions.get('WEBGL_compressed_texture_s3tc');\n        if (extension !== null) {\n          if (p === RGB_S3TC_DXT1_Format) return extension.COMPRESSED_RGB_S3TC_DXT1_EXT;\n          if (p === RGBA_S3TC_DXT1_Format) return extension.COMPRESSED_RGBA_S3TC_DXT1_EXT;\n          if (p === RGBA_S3TC_DXT3_Format) return extension.COMPRESSED_RGBA_S3TC_DXT3_EXT;\n          if (p === RGBA_S3TC_DXT5_Format) return extension.COMPRESSED_RGBA_S3TC_DXT5_EXT;\n        } else {\n          return null;\n        }\n      }\n    }\n\n    // PVRTC\n\n    if (p === RGB_PVRTC_4BPPV1_Format || p === RGB_PVRTC_2BPPV1_Format || p === RGBA_PVRTC_4BPPV1_Format || p === RGBA_PVRTC_2BPPV1_Format) {\n      extension = extensions.get('WEBGL_compressed_texture_pvrtc');\n      if (extension !== null) {\n        if (p === RGB_PVRTC_4BPPV1_Format) return extension.COMPRESSED_RGB_PVRTC_4BPPV1_IMG;\n        if (p === RGB_PVRTC_2BPPV1_Format) return extension.COMPRESSED_RGB_PVRTC_2BPPV1_IMG;\n        if (p === RGBA_PVRTC_4BPPV1_Format) return extension.COMPRESSED_RGBA_PVRTC_4BPPV1_IMG;\n        if (p === RGBA_PVRTC_2BPPV1_Format) return extension.COMPRESSED_RGBA_PVRTC_2BPPV1_IMG;\n      } else {\n        return null;\n      }\n    }\n\n    // ETC\n\n    if (p === RGB_ETC1_Format || p === RGB_ETC2_Format || p === RGBA_ETC2_EAC_Format) {\n      extension = extensions.get('WEBGL_compressed_texture_etc');\n      if (extension !== null) {\n        if (p === RGB_ETC1_Format || p === RGB_ETC2_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ETC2 : extension.COMPRESSED_RGB8_ETC2;\n        if (p === RGBA_ETC2_EAC_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ETC2_EAC : extension.COMPRESSED_RGBA8_ETC2_EAC;\n      } else {\n        return null;\n      }\n    }\n\n    // ASTC\n\n    if (p === RGBA_ASTC_4x4_Format || p === RGBA_ASTC_5x4_Format || p === RGBA_ASTC_5x5_Format || p === RGBA_ASTC_6x5_Format || p === RGBA_ASTC_6x6_Format || p === RGBA_ASTC_8x5_Format || p === RGBA_ASTC_8x6_Format || p === RGBA_ASTC_8x8_Format || p === RGBA_ASTC_10x5_Format || p === RGBA_ASTC_10x6_Format || p === RGBA_ASTC_10x8_Format || p === RGBA_ASTC_10x10_Format || p === RGBA_ASTC_12x10_Format || p === RGBA_ASTC_12x12_Format) {\n      extension = extensions.get('WEBGL_compressed_texture_astc');\n      if (extension !== null) {\n        if (p === RGBA_ASTC_4x4_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_4x4_KHR : extension.COMPRESSED_RGBA_ASTC_4x4_KHR;\n        if (p === RGBA_ASTC_5x4_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x4_KHR : extension.COMPRESSED_RGBA_ASTC_5x4_KHR;\n        if (p === RGBA_ASTC_5x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_5x5_KHR : extension.COMPRESSED_RGBA_ASTC_5x5_KHR;\n        if (p === RGBA_ASTC_6x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x5_KHR : extension.COMPRESSED_RGBA_ASTC_6x5_KHR;\n        if (p === RGBA_ASTC_6x6_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_6x6_KHR : extension.COMPRESSED_RGBA_ASTC_6x6_KHR;\n        if (p === RGBA_ASTC_8x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x5_KHR : extension.COMPRESSED_RGBA_ASTC_8x5_KHR;\n        if (p === RGBA_ASTC_8x6_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x6_KHR : extension.COMPRESSED_RGBA_ASTC_8x6_KHR;\n        if (p === RGBA_ASTC_8x8_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_8x8_KHR : extension.COMPRESSED_RGBA_ASTC_8x8_KHR;\n        if (p === RGBA_ASTC_10x5_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x5_KHR : extension.COMPRESSED_RGBA_ASTC_10x5_KHR;\n        if (p === RGBA_ASTC_10x6_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x6_KHR : extension.COMPRESSED_RGBA_ASTC_10x6_KHR;\n        if (p === RGBA_ASTC_10x8_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x8_KHR : extension.COMPRESSED_RGBA_ASTC_10x8_KHR;\n        if (p === RGBA_ASTC_10x10_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_10x10_KHR : extension.COMPRESSED_RGBA_ASTC_10x10_KHR;\n        if (p === RGBA_ASTC_12x10_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x10_KHR : extension.COMPRESSED_RGBA_ASTC_12x10_KHR;\n        if (p === RGBA_ASTC_12x12_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB8_ALPHA8_ASTC_12x12_KHR : extension.COMPRESSED_RGBA_ASTC_12x12_KHR;\n      } else {\n        return null;\n      }\n    }\n\n    // BPTC\n\n    if (p === RGBA_BPTC_Format || p === RGB_BPTC_SIGNED_Format || p === RGB_BPTC_UNSIGNED_Format) {\n      extension = extensions.get('EXT_texture_compression_bptc');\n      if (extension !== null) {\n        if (p === RGBA_BPTC_Format) return transfer === SRGBTransfer ? extension.COMPRESSED_SRGB_ALPHA_BPTC_UNORM_EXT : extension.COMPRESSED_RGBA_BPTC_UNORM_EXT;\n        if (p === RGB_BPTC_SIGNED_Format) return extension.COMPRESSED_RGB_BPTC_SIGNED_FLOAT_EXT;\n        if (p === RGB_BPTC_UNSIGNED_Format) return extension.COMPRESSED_RGB_BPTC_UNSIGNED_FLOAT_EXT;\n      } else {\n        return null;\n      }\n    }\n\n    // RGTC\n\n    if (p === RED_RGTC1_Format || p === SIGNED_RED_RGTC1_Format || p === RED_GREEN_RGTC2_Format || p === SIGNED_RED_GREEN_RGTC2_Format) {\n      extension = extensions.get('EXT_texture_compression_rgtc');\n      if (extension !== null) {\n        if (p === RGBA_BPTC_Format) return extension.COMPRESSED_RED_RGTC1_EXT;\n        if (p === SIGNED_RED_RGTC1_Format) return extension.COMPRESSED_SIGNED_RED_RGTC1_EXT;\n        if (p === RED_GREEN_RGTC2_Format) return extension.COMPRESSED_RED_GREEN_RGTC2_EXT;\n        if (p === SIGNED_RED_GREEN_RGTC2_Format) return extension.COMPRESSED_SIGNED_RED_GREEN_RGTC2_EXT;\n      } else {\n        return null;\n      }\n    }\n\n    //\n\n    if (p === UnsignedInt248Type) return gl.UNSIGNED_INT_24_8;\n\n    // if \"p\" can't be resolved, assume the user defines a WebGL constant as a string (fallback/workaround for packed RGB formats)\n\n    return gl[p] !== undefined ? gl[p] : null;\n  }\n  return {\n    convert: convert\n  };\n}\nclass ArrayCamera extends PerspectiveCamera {\n  constructor(array = []) {\n    super();\n    this.isArrayCamera = true;\n    this.cameras = array;\n  }\n}\nclass Group extends Object3D {\n  constructor() {\n    super();\n    this.isGroup = true;\n    this.type = 'Group';\n  }\n}\nconst _moveEvent = {\n  type: 'move'\n};\nclass WebXRController {\n  constructor() {\n    this._targetRay = null;\n    this._grip = null;\n    this._hand = null;\n  }\n  getHandSpace() {\n    if (this._hand === null) {\n      this._hand = new Group();\n      this._hand.matrixAutoUpdate = false;\n      this._hand.visible = false;\n      this._hand.joints = {};\n      this._hand.inputState = {\n        pinching: false\n      };\n    }\n    return this._hand;\n  }\n  getTargetRaySpace() {\n    if (this._targetRay === null) {\n      this._targetRay = new Group();\n      this._targetRay.matrixAutoUpdate = false;\n      this._targetRay.visible = false;\n      this._targetRay.hasLinearVelocity = false;\n      this._targetRay.linearVelocity = new Vector3();\n      this._targetRay.hasAngularVelocity = false;\n      this._targetRay.angularVelocity = new Vector3();\n    }\n    return this._targetRay;\n  }\n  getGripSpace() {\n    if (this._grip === null) {\n      this._grip = new Group();\n      this._grip.matrixAutoUpdate = false;\n      this._grip.visible = false;\n      this._grip.hasLinearVelocity = false;\n      this._grip.linearVelocity = new Vector3();\n      this._grip.hasAngularVelocity = false;\n      this._grip.angularVelocity = new Vector3();\n    }\n    return this._grip;\n  }\n  dispatchEvent(event) {\n    if (this._targetRay !== null) {\n      this._targetRay.dispatchEvent(event);\n    }\n    if (this._grip !== null) {\n      this._grip.dispatchEvent(event);\n    }\n    if (this._hand !== null) {\n      this._hand.dispatchEvent(event);\n    }\n    return this;\n  }\n  connect(inputSource) {\n    if (inputSource && inputSource.hand) {\n      const hand = this._hand;\n      if (hand) {\n        for (const inputjoint of inputSource.hand.values()) {\n          // Initialize hand with joints when connected\n          this._getHandJoint(hand, inputjoint);\n        }\n      }\n    }\n    this.dispatchEvent({\n      type: 'connected',\n      data: inputSource\n    });\n    return this;\n  }\n  disconnect(inputSource) {\n    this.dispatchEvent({\n      type: 'disconnected',\n      data: inputSource\n    });\n    if (this._targetRay !== null) {\n      this._targetRay.visible = false;\n    }\n    if (this._grip !== null) {\n      this._grip.visible = false;\n    }\n    if (this._hand !== null) {\n      this._hand.visible = false;\n    }\n    return this;\n  }\n  update(inputSource, frame, referenceSpace) {\n    let inputPose = null;\n    let gripPose = null;\n    let handPose = null;\n    const targetRay = this._targetRay;\n    const grip = this._grip;\n    const hand = this._hand;\n    if (inputSource && frame.session.visibilityState !== 'visible-blurred') {\n      if (hand && inputSource.hand) {\n        handPose = true;\n        for (const inputjoint of inputSource.hand.values()) {\n          // Update the joints groups with the XRJoint poses\n          const jointPose = frame.getJointPose(inputjoint, referenceSpace);\n\n          // The transform of this joint will be updated with the joint pose on each frame\n          const joint = this._getHandJoint(hand, inputjoint);\n          if (jointPose !== null) {\n            joint.matrix.fromArray(jointPose.transform.matrix);\n            joint.matrix.decompose(joint.position, joint.rotation, joint.scale);\n            joint.matrixWorldNeedsUpdate = true;\n            joint.jointRadius = jointPose.radius;\n          }\n          joint.visible = jointPose !== null;\n        }\n\n        // Custom events\n\n        // Check pinchz\n        const indexTip = hand.joints['index-finger-tip'];\n        const thumbTip = hand.joints['thumb-tip'];\n        const distance = indexTip.position.distanceTo(thumbTip.position);\n        const distanceToPinch = 0.02;\n        const threshold = 0.005;\n        if (hand.inputState.pinching && distance > distanceToPinch + threshold) {\n          hand.inputState.pinching = false;\n          this.dispatchEvent({\n            type: 'pinchend',\n            handedness: inputSource.handedness,\n            target: this\n          });\n        } else if (!hand.inputState.pinching && distance <= distanceToPinch - threshold) {\n          hand.inputState.pinching = true;\n          this.dispatchEvent({\n            type: 'pinchstart',\n            handedness: inputSource.handedness,\n            target: this\n          });\n        }\n      } else {\n        if (grip !== null && inputSource.gripSpace) {\n          gripPose = frame.getPose(inputSource.gripSpace, referenceSpace);\n          if (gripPose !== null) {\n            grip.matrix.fromArray(gripPose.transform.matrix);\n            grip.matrix.decompose(grip.position, grip.rotation, grip.scale);\n            grip.matrixWorldNeedsUpdate = true;\n            if (gripPose.linearVelocity) {\n              grip.hasLinearVelocity = true;\n              grip.linearVelocity.copy(gripPose.linearVelocity);\n            } else {\n              grip.hasLinearVelocity = false;\n            }\n            if (gripPose.angularVelocity) {\n              grip.hasAngularVelocity = true;\n              grip.angularVelocity.copy(gripPose.angularVelocity);\n            } else {\n              grip.hasAngularVelocity = false;\n            }\n          }\n        }\n      }\n      if (targetRay !== null) {\n        inputPose = frame.getPose(inputSource.targetRaySpace, referenceSpace);\n\n        // Some runtimes (namely Vive Cosmos with Vive OpenXR Runtime) have only grip space and ray space is equal to it\n        if (inputPose === null && gripPose !== null) {\n          inputPose = gripPose;\n        }\n        if (inputPose !== null) {\n          targetRay.matrix.fromArray(inputPose.transform.matrix);\n          targetRay.matrix.decompose(targetRay.position, targetRay.rotation, targetRay.scale);\n          targetRay.matrixWorldNeedsUpdate = true;\n          if (inputPose.linearVelocity) {\n            targetRay.hasLinearVelocity = true;\n            targetRay.linearVelocity.copy(inputPose.linearVelocity);\n          } else {\n            targetRay.hasLinearVelocity = false;\n          }\n          if (inputPose.angularVelocity) {\n            targetRay.hasAngularVelocity = true;\n            targetRay.angularVelocity.copy(inputPose.angularVelocity);\n          } else {\n            targetRay.hasAngularVelocity = false;\n          }\n          this.dispatchEvent(_moveEvent);\n        }\n      }\n    }\n    if (targetRay !== null) {\n      targetRay.visible = inputPose !== null;\n    }\n    if (grip !== null) {\n      grip.visible = gripPose !== null;\n    }\n    if (hand !== null) {\n      hand.visible = handPose !== null;\n    }\n    return this;\n  }\n\n  // private method\n\n  _getHandJoint(hand, inputjoint) {\n    if (hand.joints[inputjoint.jointName] === undefined) {\n      const joint = new Group();\n      joint.matrixAutoUpdate = false;\n      joint.visible = false;\n      hand.joints[inputjoint.jointName] = joint;\n      hand.add(joint);\n    }\n    return hand.joints[inputjoint.jointName];\n  }\n}\nconst _occlusion_vertex = `\nvoid main() {\n\n\tgl_Position = vec4( position, 1.0 );\n\n}`;\nconst _occlusion_fragment = `\nuniform sampler2DArray depthColor;\nuniform float depthWidth;\nuniform float depthHeight;\n\nvoid main() {\n\n\tvec2 coord = vec2( gl_FragCoord.x / depthWidth, gl_FragCoord.y / depthHeight );\n\n\tif ( coord.x >= 1.0 ) {\n\n\t\tgl_FragDepth = texture( depthColor, vec3( coord.x - 1.0, coord.y, 1 ) ).r;\n\n\t} else {\n\n\t\tgl_FragDepth = texture( depthColor, vec3( coord.x, coord.y, 0 ) ).r;\n\n\t}\n\n}`;\nclass WebXRDepthSensing {\n  constructor() {\n    this.texture = null;\n    this.mesh = null;\n    this.depthNear = 0;\n    this.depthFar = 0;\n  }\n  init(renderer, depthData, renderState) {\n    if (this.texture === null) {\n      const texture = new Texture$1();\n      const texProps = renderer.properties.get(texture);\n      texProps.__webglTexture = depthData.texture;\n      if (depthData.depthNear != renderState.depthNear || depthData.depthFar != renderState.depthFar) {\n        this.depthNear = depthData.depthNear;\n        this.depthFar = depthData.depthFar;\n      }\n      this.texture = texture;\n    }\n  }\n  getMesh(cameraXR) {\n    if (this.texture !== null) {\n      if (this.mesh === null) {\n        const viewport = cameraXR.cameras[0].viewport;\n        const material = new ShaderMaterial({\n          vertexShader: _occlusion_vertex,\n          fragmentShader: _occlusion_fragment,\n          uniforms: {\n            depthColor: {\n              value: this.texture\n            },\n            depthWidth: {\n              value: viewport.z\n            },\n            depthHeight: {\n              value: viewport.w\n            }\n          }\n        });\n        this.mesh = new Mesh(new PlaneGeometry(20, 20), material);\n      }\n    }\n    return this.mesh;\n  }\n  reset() {\n    this.texture = null;\n    this.mesh = null;\n  }\n  getDepthTexture() {\n    return this.texture;\n  }\n}\nclass WebXRManager extends EventDispatcher {\n  constructor(renderer, gl) {\n    super();\n    const scope = this;\n    let session = null;\n    let framebufferScaleFactor = 1.0;\n    let referenceSpace = null;\n    let referenceSpaceType = 'local-floor';\n    // Set default foveation to maximum.\n    let foveation = 1.0;\n    let customReferenceSpace = null;\n    let pose = null;\n    let glBinding = null;\n    let glProjLayer = null;\n    let glBaseLayer = null;\n    let xrFrame = null;\n    const depthSensing = new WebXRDepthSensing();\n    const attributes = gl.getContextAttributes();\n    let initialRenderTarget = null;\n    let newRenderTarget = null;\n    const controllers = [];\n    const controllerInputSources = [];\n    const currentSize = new Vector2();\n    let currentPixelRatio = null;\n\n    //\n\n    const cameraL = new PerspectiveCamera();\n    cameraL.layers.enable(1);\n    cameraL.viewport = new Vector4();\n    const cameraR = new PerspectiveCamera();\n    cameraR.layers.enable(2);\n    cameraR.viewport = new Vector4();\n    const cameras = [cameraL, cameraR];\n    const cameraXR = new ArrayCamera();\n    cameraXR.layers.enable(1);\n    cameraXR.layers.enable(2);\n    let _currentDepthNear = null;\n    let _currentDepthFar = null;\n\n    //\n\n    this.cameraAutoUpdate = true;\n    this.enabled = false;\n    this.isPresenting = false;\n    this.getController = function (index) {\n      let controller = controllers[index];\n      if (controller === undefined) {\n        controller = new WebXRController();\n        controllers[index] = controller;\n      }\n      return controller.getTargetRaySpace();\n    };\n    this.getControllerGrip = function (index) {\n      let controller = controllers[index];\n      if (controller === undefined) {\n        controller = new WebXRController();\n        controllers[index] = controller;\n      }\n      return controller.getGripSpace();\n    };\n    this.getHand = function (index) {\n      let controller = controllers[index];\n      if (controller === undefined) {\n        controller = new WebXRController();\n        controllers[index] = controller;\n      }\n      return controller.getHandSpace();\n    };\n\n    //\n\n    function onSessionEvent(event) {\n      const controllerIndex = controllerInputSources.indexOf(event.inputSource);\n      if (controllerIndex === -1) {\n        return;\n      }\n      const controller = controllers[controllerIndex];\n      if (controller !== undefined) {\n        controller.update(event.inputSource, event.frame, customReferenceSpace || referenceSpace);\n        controller.dispatchEvent({\n          type: event.type,\n          data: event.inputSource\n        });\n      }\n    }\n    function onSessionEnd() {\n      session.removeEventListener('select', onSessionEvent);\n      session.removeEventListener('selectstart', onSessionEvent);\n      session.removeEventListener('selectend', onSessionEvent);\n      session.removeEventListener('squeeze', onSessionEvent);\n      session.removeEventListener('squeezestart', onSessionEvent);\n      session.removeEventListener('squeezeend', onSessionEvent);\n      session.removeEventListener('end', onSessionEnd);\n      session.removeEventListener('inputsourceschange', onInputSourcesChange);\n      for (let i = 0; i < controllers.length; i++) {\n        const inputSource = controllerInputSources[i];\n        if (inputSource === null) continue;\n        controllerInputSources[i] = null;\n        controllers[i].disconnect(inputSource);\n      }\n      _currentDepthNear = null;\n      _currentDepthFar = null;\n      depthSensing.reset();\n\n      // restore framebuffer/rendering state\n\n      renderer.setRenderTarget(initialRenderTarget);\n      glBaseLayer = null;\n      glProjLayer = null;\n      glBinding = null;\n      session = null;\n      newRenderTarget = null;\n\n      //\n\n      animation.stop();\n      scope.isPresenting = false;\n      renderer.setPixelRatio(currentPixelRatio);\n      renderer.setSize(currentSize.width, currentSize.height, false);\n      scope.dispatchEvent({\n        type: 'sessionend'\n      });\n    }\n    this.setFramebufferScaleFactor = function (value) {\n      framebufferScaleFactor = value;\n      if (scope.isPresenting === true) {\n        console.warn('THREE.WebXRManager: Cannot change framebuffer scale while presenting.');\n      }\n    };\n    this.setReferenceSpaceType = function (value) {\n      referenceSpaceType = value;\n      if (scope.isPresenting === true) {\n        console.warn('THREE.WebXRManager: Cannot change reference space type while presenting.');\n      }\n    };\n    this.getReferenceSpace = function () {\n      return customReferenceSpace || referenceSpace;\n    };\n    this.setReferenceSpace = function (space) {\n      customReferenceSpace = space;\n    };\n    this.getBaseLayer = function () {\n      return glProjLayer !== null ? glProjLayer : glBaseLayer;\n    };\n    this.getBinding = function () {\n      return glBinding;\n    };\n    this.getFrame = function () {\n      return xrFrame;\n    };\n    this.getSession = function () {\n      return session;\n    };\n    this.setSession = async function (value) {\n      session = value;\n      if (session !== null) {\n        initialRenderTarget = renderer.getRenderTarget();\n        session.addEventListener('select', onSessionEvent);\n        session.addEventListener('selectstart', onSessionEvent);\n        session.addEventListener('selectend', onSessionEvent);\n        session.addEventListener('squeeze', onSessionEvent);\n        session.addEventListener('squeezestart', onSessionEvent);\n        session.addEventListener('squeezeend', onSessionEvent);\n        session.addEventListener('end', onSessionEnd);\n        session.addEventListener('inputsourceschange', onInputSourcesChange);\n        if (attributes.xrCompatible !== true) {\n          await gl.makeXRCompatible();\n        }\n        currentPixelRatio = renderer.getPixelRatio();\n        renderer.getSize(currentSize);\n        if (session.renderState.layers === undefined) {\n          const layerInit = {\n            antialias: attributes.antialias,\n            alpha: true,\n            depth: attributes.depth,\n            stencil: attributes.stencil,\n            framebufferScaleFactor: framebufferScaleFactor\n          };\n          glBaseLayer = new XRWebGLLayer(session, gl, layerInit);\n          session.updateRenderState({\n            baseLayer: glBaseLayer\n          });\n          renderer.setPixelRatio(1);\n          renderer.setSize(glBaseLayer.framebufferWidth, glBaseLayer.framebufferHeight, false);\n          newRenderTarget = new WebGLRenderTarget(glBaseLayer.framebufferWidth, glBaseLayer.framebufferHeight, {\n            format: RGBAFormat,\n            type: UnsignedByteType,\n            colorSpace: renderer.outputColorSpace,\n            stencilBuffer: attributes.stencil\n          });\n        } else {\n          let depthFormat = null;\n          let depthType = null;\n          let glDepthFormat = null;\n          if (attributes.depth) {\n            glDepthFormat = attributes.stencil ? gl.DEPTH24_STENCIL8 : gl.DEPTH_COMPONENT24;\n            depthFormat = attributes.stencil ? DepthStencilFormat : DepthFormat;\n            depthType = attributes.stencil ? UnsignedInt248Type : UnsignedIntType;\n          }\n          const projectionlayerInit = {\n            colorFormat: gl.RGBA8,\n            depthFormat: glDepthFormat,\n            scaleFactor: framebufferScaleFactor\n          };\n          glBinding = new XRWebGLBinding(session, gl);\n          glProjLayer = glBinding.createProjectionLayer(projectionlayerInit);\n          session.updateRenderState({\n            layers: [glProjLayer]\n          });\n          renderer.setPixelRatio(1);\n          renderer.setSize(glProjLayer.textureWidth, glProjLayer.textureHeight, false);\n          newRenderTarget = new WebGLRenderTarget(glProjLayer.textureWidth, glProjLayer.textureHeight, {\n            format: RGBAFormat,\n            type: UnsignedByteType,\n            depthTexture: new DepthTexture(glProjLayer.textureWidth, glProjLayer.textureHeight, depthType, undefined, undefined, undefined, undefined, undefined, undefined, depthFormat),\n            stencilBuffer: attributes.stencil,\n            colorSpace: renderer.outputColorSpace,\n            samples: attributes.antialias ? 4 : 0,\n            resolveDepthBuffer: glProjLayer.ignoreDepthValues === false\n          });\n        }\n        newRenderTarget.isXRRenderTarget = true; // TODO Remove this when possible, see #23278\n\n        this.setFoveation(foveation);\n        customReferenceSpace = null;\n        referenceSpace = await session.requestReferenceSpace(referenceSpaceType);\n        animation.setContext(session);\n        animation.start();\n        scope.isPresenting = true;\n        scope.dispatchEvent({\n          type: 'sessionstart'\n        });\n      }\n    };\n    this.getEnvironmentBlendMode = function () {\n      if (session !== null) {\n        return session.environmentBlendMode;\n      }\n    };\n    this.getDepthTexture = function () {\n      return depthSensing.getDepthTexture();\n    };\n    function onInputSourcesChange(event) {\n      // Notify disconnected\n\n      for (let i = 0; i < event.removed.length; i++) {\n        const inputSource = event.removed[i];\n        const index = controllerInputSources.indexOf(inputSource);\n        if (index >= 0) {\n          controllerInputSources[index] = null;\n          controllers[index].disconnect(inputSource);\n        }\n      }\n\n      // Notify connected\n\n      for (let i = 0; i < event.added.length; i++) {\n        const inputSource = event.added[i];\n        let controllerIndex = controllerInputSources.indexOf(inputSource);\n        if (controllerIndex === -1) {\n          // Assign input source a controller that currently has no input source\n\n          for (let i = 0; i < controllers.length; i++) {\n            if (i >= controllerInputSources.length) {\n              controllerInputSources.push(inputSource);\n              controllerIndex = i;\n              break;\n            } else if (controllerInputSources[i] === null) {\n              controllerInputSources[i] = inputSource;\n              controllerIndex = i;\n              break;\n            }\n          }\n\n          // If all controllers do currently receive input we ignore new ones\n\n          if (controllerIndex === -1) break;\n        }\n        const controller = controllers[controllerIndex];\n        if (controller) {\n          controller.connect(inputSource);\n        }\n      }\n    }\n\n    //\n\n    const cameraLPos = new Vector3();\n    const cameraRPos = new Vector3();\n\n    /**\n     * Assumes 2 cameras that are parallel and share an X-axis, and that\n     * the cameras' projection and world matrices have already been set.\n     * And that near and far planes are identical for both cameras.\n     * Visualization of this technique: https://computergraphics.stackexchange.com/a/4765\n     */\n    function setProjectionFromUnion(camera, cameraL, cameraR) {\n      cameraLPos.setFromMatrixPosition(cameraL.matrixWorld);\n      cameraRPos.setFromMatrixPosition(cameraR.matrixWorld);\n      const ipd = cameraLPos.distanceTo(cameraRPos);\n      const projL = cameraL.projectionMatrix.elements;\n      const projR = cameraR.projectionMatrix.elements;\n\n      // VR systems will have identical far and near planes, and\n      // most likely identical top and bottom frustum extents.\n      // Use the left camera for these values.\n      const near = projL[14] / (projL[10] - 1);\n      const far = projL[14] / (projL[10] + 1);\n      const topFov = (projL[9] + 1) / projL[5];\n      const bottomFov = (projL[9] - 1) / projL[5];\n      const leftFov = (projL[8] - 1) / projL[0];\n      const rightFov = (projR[8] + 1) / projR[0];\n      const left = near * leftFov;\n      const right = near * rightFov;\n\n      // Calculate the new camera's position offset from the\n      // left camera. xOffset should be roughly half `ipd`.\n      const zOffset = ipd / (-leftFov + rightFov);\n      const xOffset = zOffset * -leftFov;\n\n      // TODO: Better way to apply this offset?\n      cameraL.matrixWorld.decompose(camera.position, camera.quaternion, camera.scale);\n      camera.translateX(xOffset);\n      camera.translateZ(zOffset);\n      camera.matrixWorld.compose(camera.position, camera.quaternion, camera.scale);\n      camera.matrixWorldInverse.copy(camera.matrixWorld).invert();\n\n      // Check if the projection uses an infinite far plane.\n      if (projL[10] === -1.0) {\n        // Use the projection matrix from the left eye.\n        // The camera offset is sufficient to include the view volumes\n        // of both eyes (assuming symmetric projections).\n        camera.projectionMatrix.copy(cameraL.projectionMatrix);\n        camera.projectionMatrixInverse.copy(cameraL.projectionMatrixInverse);\n      } else {\n        // Find the union of the frustum values of the cameras and scale\n        // the values so that the near plane's position does not change in world space,\n        // although must now be relative to the new union camera.\n        const near2 = near + zOffset;\n        const far2 = far + zOffset;\n        const left2 = left - xOffset;\n        const right2 = right + (ipd - xOffset);\n        const top2 = topFov * far / far2 * near2;\n        const bottom2 = bottomFov * far / far2 * near2;\n        camera.projectionMatrix.makePerspective(left2, right2, top2, bottom2, near2, far2);\n        camera.projectionMatrixInverse.copy(camera.projectionMatrix).invert();\n      }\n    }\n    function updateCamera(camera, parent) {\n      if (parent === null) {\n        camera.matrixWorld.copy(camera.matrix);\n      } else {\n        camera.matrixWorld.multiplyMatrices(parent.matrixWorld, camera.matrix);\n      }\n      camera.matrixWorldInverse.copy(camera.matrixWorld).invert();\n    }\n    this.updateCamera = function (camera) {\n      if (session === null) return;\n      let depthNear = camera.near;\n      let depthFar = camera.far;\n      if (depthSensing.texture !== null) {\n        if (depthSensing.depthNear > 0) depthNear = depthSensing.depthNear;\n        if (depthSensing.depthFar > 0) depthFar = depthSensing.depthFar;\n      }\n      cameraXR.near = cameraR.near = cameraL.near = depthNear;\n      cameraXR.far = cameraR.far = cameraL.far = depthFar;\n      if (_currentDepthNear !== cameraXR.near || _currentDepthFar !== cameraXR.far) {\n        // Note that the new renderState won't apply until the next frame. See #18320\n\n        session.updateRenderState({\n          depthNear: cameraXR.near,\n          depthFar: cameraXR.far\n        });\n        _currentDepthNear = cameraXR.near;\n        _currentDepthFar = cameraXR.far;\n      }\n      const parent = camera.parent;\n      const cameras = cameraXR.cameras;\n      updateCamera(cameraXR, parent);\n      for (let i = 0; i < cameras.length; i++) {\n        updateCamera(cameras[i], parent);\n      }\n\n      // update projection matrix for proper view frustum culling\n\n      if (cameras.length === 2) {\n        setProjectionFromUnion(cameraXR, cameraL, cameraR);\n      } else {\n        // assume single camera setup (AR)\n\n        cameraXR.projectionMatrix.copy(cameraL.projectionMatrix);\n      }\n\n      // update user camera and its children\n\n      updateUserCamera(camera, cameraXR, parent);\n    };\n    function updateUserCamera(camera, cameraXR, parent) {\n      if (parent === null) {\n        camera.matrix.copy(cameraXR.matrixWorld);\n      } else {\n        camera.matrix.copy(parent.matrixWorld);\n        camera.matrix.invert();\n        camera.matrix.multiply(cameraXR.matrixWorld);\n      }\n      camera.matrix.decompose(camera.position, camera.quaternion, camera.scale);\n      camera.updateMatrixWorld(true);\n      camera.projectionMatrix.copy(cameraXR.projectionMatrix);\n      camera.projectionMatrixInverse.copy(cameraXR.projectionMatrixInverse);\n      if (camera.isPerspectiveCamera) {\n        camera.fov = RAD2DEG * 2 * Math.atan(1 / camera.projectionMatrix.elements[5]);\n        camera.zoom = 1;\n      }\n    }\n    this.getCamera = function () {\n      return cameraXR;\n    };\n    this.getFoveation = function () {\n      if (glProjLayer === null && glBaseLayer === null) {\n        return undefined;\n      }\n      return foveation;\n    };\n    this.setFoveation = function (value) {\n      // 0 = no foveation = full resolution\n      // 1 = maximum foveation = the edges render at lower resolution\n\n      foveation = value;\n      if (glProjLayer !== null) {\n        glProjLayer.fixedFoveation = value;\n      }\n      if (glBaseLayer !== null && glBaseLayer.fixedFoveation !== undefined) {\n        glBaseLayer.fixedFoveation = value;\n      }\n    };\n    this.hasDepthSensing = function () {\n      return depthSensing.texture !== null;\n    };\n    this.getDepthSensingMesh = function () {\n      return depthSensing.getMesh(cameraXR);\n    };\n\n    // Animation Loop\n\n    let onAnimationFrameCallback = null;\n    function onAnimationFrame(time, frame) {\n      pose = frame.getViewerPose(customReferenceSpace || referenceSpace);\n      xrFrame = frame;\n      if (pose !== null) {\n        const views = pose.views;\n        if (glBaseLayer !== null) {\n          renderer.setRenderTargetFramebuffer(newRenderTarget, glBaseLayer.framebuffer);\n          renderer.setRenderTarget(newRenderTarget);\n        }\n        let cameraXRNeedsUpdate = false;\n\n        // check if it's necessary to rebuild cameraXR's camera list\n\n        if (views.length !== cameraXR.cameras.length) {\n          cameraXR.cameras.length = 0;\n          cameraXRNeedsUpdate = true;\n        }\n        for (let i = 0; i < views.length; i++) {\n          const view = views[i];\n          let viewport = null;\n          if (glBaseLayer !== null) {\n            viewport = glBaseLayer.getViewport(view);\n          } else {\n            const glSubImage = glBinding.getViewSubImage(glProjLayer, view);\n            viewport = glSubImage.viewport;\n\n            // For side-by-side projection, we only produce a single texture for both eyes.\n            if (i === 0) {\n              renderer.setRenderTargetTextures(newRenderTarget, glSubImage.colorTexture, glProjLayer.ignoreDepthValues ? undefined : glSubImage.depthStencilTexture);\n              renderer.setRenderTarget(newRenderTarget);\n            }\n          }\n          let camera = cameras[i];\n          if (camera === undefined) {\n            camera = new PerspectiveCamera();\n            camera.layers.enable(i);\n            camera.viewport = new Vector4();\n            cameras[i] = camera;\n          }\n          camera.matrix.fromArray(view.transform.matrix);\n          camera.matrix.decompose(camera.position, camera.quaternion, camera.scale);\n          camera.projectionMatrix.fromArray(view.projectionMatrix);\n          camera.projectionMatrixInverse.copy(camera.projectionMatrix).invert();\n          camera.viewport.set(viewport.x, viewport.y, viewport.width, viewport.height);\n          if (i === 0) {\n            cameraXR.matrix.copy(camera.matrix);\n            cameraXR.matrix.decompose(cameraXR.position, cameraXR.quaternion, cameraXR.scale);\n          }\n          if (cameraXRNeedsUpdate === true) {\n            cameraXR.cameras.push(camera);\n          }\n        }\n\n        //\n\n        const enabledFeatures = session.enabledFeatures;\n        if (enabledFeatures && enabledFeatures.includes('depth-sensing')) {\n          const depthData = glBinding.getDepthInformation(views[0]);\n          if (depthData && depthData.isValid && depthData.texture) {\n            depthSensing.init(renderer, depthData, session.renderState);\n          }\n        }\n      }\n\n      //\n\n      for (let i = 0; i < controllers.length; i++) {\n        const inputSource = controllerInputSources[i];\n        const controller = controllers[i];\n        if (inputSource !== null && controller !== undefined) {\n          controller.update(inputSource, frame, customReferenceSpace || referenceSpace);\n        }\n      }\n      if (onAnimationFrameCallback) onAnimationFrameCallback(time, frame);\n      if (frame.detectedPlanes) {\n        scope.dispatchEvent({\n          type: 'planesdetected',\n          data: frame\n        });\n      }\n      xrFrame = null;\n    }\n    const animation = new WebGLAnimation();\n    animation.setAnimationLoop(onAnimationFrame);\n    this.setAnimationLoop = function (callback) {\n      onAnimationFrameCallback = callback;\n    };\n    this.dispose = function () {};\n  }\n}\nconst _e1 = /*@__PURE__*/new Euler();\nconst _m1 = /*@__PURE__*/new Matrix4();\nfunction WebGLMaterials(renderer, properties) {\n  function refreshTransformUniform(map, uniform) {\n    if (map.matrixAutoUpdate === true) {\n      map.updateMatrix();\n    }\n    uniform.value.copy(map.matrix);\n  }\n  function refreshFogUniforms(uniforms, fog) {\n    fog.color.getRGB(uniforms.fogColor.value, getUnlitUniformColorSpace(renderer));\n    if (fog.isFog) {\n      uniforms.fogNear.value = fog.near;\n      uniforms.fogFar.value = fog.far;\n    } else if (fog.isFogExp2) {\n      uniforms.fogDensity.value = fog.density;\n    }\n  }\n  function refreshMaterialUniforms(uniforms, material, pixelRatio, height, transmissionRenderTarget) {\n    if (material.isMeshBasicMaterial) {\n      refreshUniformsCommon(uniforms, material);\n    } else if (material.isMeshLambertMaterial) {\n      refreshUniformsCommon(uniforms, material);\n    } else if (material.isMeshToonMaterial) {\n      refreshUniformsCommon(uniforms, material);\n      refreshUniformsToon(uniforms, material);\n    } else if (material.isMeshPhongMaterial) {\n      refreshUniformsCommon(uniforms, material);\n      refreshUniformsPhong(uniforms, material);\n    } else if (material.isMeshStandardMaterial) {\n      refreshUniformsCommon(uniforms, material);\n      refreshUniformsStandard(uniforms, material);\n      if (material.isMeshPhysicalMaterial) {\n        refreshUniformsPhysical(uniforms, material, transmissionRenderTarget);\n      }\n    } else if (material.isMeshMatcapMaterial) {\n      refreshUniformsCommon(uniforms, material);\n      refreshUniformsMatcap(uniforms, material);\n    } else if (material.isMeshDepthMaterial) {\n      refreshUniformsCommon(uniforms, material);\n    } else if (material.isMeshDistanceMaterial) {\n      refreshUniformsCommon(uniforms, material);\n      refreshUniformsDistance(uniforms, material);\n    } else if (material.isMeshNormalMaterial) {\n      refreshUniformsCommon(uniforms, material);\n    } else if (material.isLineBasicMaterial) {\n      refreshUniformsLine(uniforms, material);\n      if (material.isLineDashedMaterial) {\n        refreshUniformsDash(uniforms, material);\n      }\n    } else if (material.isPointsMaterial) {\n      refreshUniformsPoints(uniforms, material, pixelRatio, height);\n    } else if (material.isSpriteMaterial) {\n      refreshUniformsSprites(uniforms, material);\n    } else if (material.isShadowMaterial) {\n      uniforms.color.value.copy(material.color);\n      uniforms.opacity.value = material.opacity;\n    } else if (material.isShaderMaterial) {\n      material.uniformsNeedUpdate = false; // #15581\n    }\n  }\n  function refreshUniformsCommon(uniforms, material) {\n    uniforms.opacity.value = material.opacity;\n    if (material.color) {\n      uniforms.diffuse.value.copy(material.color);\n    }\n    if (material.emissive) {\n      uniforms.emissive.value.copy(material.emissive).multiplyScalar(material.emissiveIntensity);\n    }\n    if (material.map) {\n      uniforms.map.value = material.map;\n      refreshTransformUniform(material.map, uniforms.mapTransform);\n    }\n    if (material.alphaMap) {\n      uniforms.alphaMap.value = material.alphaMap;\n      refreshTransformUniform(material.alphaMap, uniforms.alphaMapTransform);\n    }\n    if (material.bumpMap) {\n      uniforms.bumpMap.value = material.bumpMap;\n      refreshTransformUniform(material.bumpMap, uniforms.bumpMapTransform);\n      uniforms.bumpScale.value = material.bumpScale;\n      if (material.side === BackSide) {\n        uniforms.bumpScale.value *= -1;\n      }\n    }\n    if (material.normalMap) {\n      uniforms.normalMap.value = material.normalMap;\n      refreshTransformUniform(material.normalMap, uniforms.normalMapTransform);\n      uniforms.normalScale.value.copy(material.normalScale);\n      if (material.side === BackSide) {\n        uniforms.normalScale.value.negate();\n      }\n    }\n    if (material.displacementMap) {\n      uniforms.displacementMap.value = material.displacementMap;\n      refreshTransformUniform(material.displacementMap, uniforms.displacementMapTransform);\n      uniforms.displacementScale.value = material.displacementScale;\n      uniforms.displacementBias.value = material.displacementBias;\n    }\n    if (material.emissiveMap) {\n      uniforms.emissiveMap.value = material.emissiveMap;\n      refreshTransformUniform(material.emissiveMap, uniforms.emissiveMapTransform);\n    }\n    if (material.specularMap) {\n      uniforms.specularMap.value = material.specularMap;\n      refreshTransformUniform(material.specularMap, uniforms.specularMapTransform);\n    }\n    if (material.alphaTest > 0) {\n      uniforms.alphaTest.value = material.alphaTest;\n    }\n    const materialProperties = properties.get(material);\n    const envMap = materialProperties.envMap;\n    const envMapRotation = materialProperties.envMapRotation;\n    if (envMap) {\n      uniforms.envMap.value = envMap;\n      _e1.copy(envMapRotation);\n\n      // accommodate left-handed frame\n      _e1.x *= -1;\n      _e1.y *= -1;\n      _e1.z *= -1;\n      if (envMap.isCubeTexture && envMap.isRenderTargetTexture === false) {\n        // environment maps which are not cube render targets or PMREMs follow a different convention\n        _e1.y *= -1;\n        _e1.z *= -1;\n      }\n      uniforms.envMapRotation.value.setFromMatrix4(_m1.makeRotationFromEuler(_e1));\n      uniforms.flipEnvMap.value = envMap.isCubeTexture && envMap.isRenderTargetTexture === false ? -1 : 1;\n      uniforms.reflectivity.value = material.reflectivity;\n      uniforms.ior.value = material.ior;\n      uniforms.refractionRatio.value = material.refractionRatio;\n    }\n    if (material.lightMap) {\n      uniforms.lightMap.value = material.lightMap;\n      uniforms.lightMapIntensity.value = material.lightMapIntensity;\n      refreshTransformUniform(material.lightMap, uniforms.lightMapTransform);\n    }\n    if (material.aoMap) {\n      uniforms.aoMap.value = material.aoMap;\n      uniforms.aoMapIntensity.value = material.aoMapIntensity;\n      refreshTransformUniform(material.aoMap, uniforms.aoMapTransform);\n    }\n  }\n  function refreshUniformsLine(uniforms, material) {\n    uniforms.diffuse.value.copy(material.color);\n    uniforms.opacity.value = material.opacity;\n    if (material.map) {\n      uniforms.map.value = material.map;\n      refreshTransformUniform(material.map, uniforms.mapTransform);\n    }\n  }\n  function refreshUniformsDash(uniforms, material) {\n    uniforms.dashSize.value = material.dashSize;\n    uniforms.totalSize.value = material.dashSize + material.gapSize;\n    uniforms.scale.value = material.scale;\n  }\n  function refreshUniformsPoints(uniforms, material, pixelRatio, height) {\n    uniforms.diffuse.value.copy(material.color);\n    uniforms.opacity.value = material.opacity;\n    uniforms.size.value = material.size * pixelRatio;\n    uniforms.scale.value = height * 0.5;\n    if (material.map) {\n      uniforms.map.value = material.map;\n      refreshTransformUniform(material.map, uniforms.uvTransform);\n    }\n    if (material.alphaMap) {\n      uniforms.alphaMap.value = material.alphaMap;\n      refreshTransformUniform(material.alphaMap, uniforms.alphaMapTransform);\n    }\n    if (material.alphaTest > 0) {\n      uniforms.alphaTest.value = material.alphaTest;\n    }\n  }\n  function refreshUniformsSprites(uniforms, material) {\n    uniforms.diffuse.value.copy(material.color);\n    uniforms.opacity.value = material.opacity;\n    uniforms.rotation.value = material.rotation;\n    if (material.map) {\n      uniforms.map.value = material.map;\n      refreshTransformUniform(material.map, uniforms.mapTransform);\n    }\n    if (material.alphaMap) {\n      uniforms.alphaMap.value = material.alphaMap;\n      refreshTransformUniform(material.alphaMap, uniforms.alphaMapTransform);\n    }\n    if (material.alphaTest > 0) {\n      uniforms.alphaTest.value = material.alphaTest;\n    }\n  }\n  function refreshUniformsPhong(uniforms, material) {\n    uniforms.specular.value.copy(material.specular);\n    uniforms.shininess.value = Math.max(material.shininess, 1e-4); // to prevent pow( 0.0, 0.0 )\n  }\n  function refreshUniformsToon(uniforms, material) {\n    if (material.gradientMap) {\n      uniforms.gradientMap.value = material.gradientMap;\n    }\n  }\n  function refreshUniformsStandard(uniforms, material) {\n    uniforms.metalness.value = material.metalness;\n    if (material.metalnessMap) {\n      uniforms.metalnessMap.value = material.metalnessMap;\n      refreshTransformUniform(material.metalnessMap, uniforms.metalnessMapTransform);\n    }\n    uniforms.roughness.value = material.roughness;\n    if (material.roughnessMap) {\n      uniforms.roughnessMap.value = material.roughnessMap;\n      refreshTransformUniform(material.roughnessMap, uniforms.roughnessMapTransform);\n    }\n    if (material.envMap) {\n      //uniforms.envMap.value = material.envMap; // part of uniforms common\n\n      uniforms.envMapIntensity.value = material.envMapIntensity;\n    }\n  }\n  function refreshUniformsPhysical(uniforms, material, transmissionRenderTarget) {\n    uniforms.ior.value = material.ior; // also part of uniforms common\n\n    if (material.sheen > 0) {\n      uniforms.sheenColor.value.copy(material.sheenColor).multiplyScalar(material.sheen);\n      uniforms.sheenRoughness.value = material.sheenRoughness;\n      if (material.sheenColorMap) {\n        uniforms.sheenColorMap.value = material.sheenColorMap;\n        refreshTransformUniform(material.sheenColorMap, uniforms.sheenColorMapTransform);\n      }\n      if (material.sheenRoughnessMap) {\n        uniforms.sheenRoughnessMap.value = material.sheenRoughnessMap;\n        refreshTransformUniform(material.sheenRoughnessMap, uniforms.sheenRoughnessMapTransform);\n      }\n    }\n    if (material.clearcoat > 0) {\n      uniforms.clearcoat.value = material.clearcoat;\n      uniforms.clearcoatRoughness.value = material.clearcoatRoughness;\n      if (material.clearcoatMap) {\n        uniforms.clearcoatMap.value = material.clearcoatMap;\n        refreshTransformUniform(material.clearcoatMap, uniforms.clearcoatMapTransform);\n      }\n      if (material.clearcoatRoughnessMap) {\n        uniforms.clearcoatRoughnessMap.value = material.clearcoatRoughnessMap;\n        refreshTransformUniform(material.clearcoatRoughnessMap, uniforms.clearcoatRoughnessMapTransform);\n      }\n      if (material.clearcoatNormalMap) {\n        uniforms.clearcoatNormalMap.value = material.clearcoatNormalMap;\n        refreshTransformUniform(material.clearcoatNormalMap, uniforms.clearcoatNormalMapTransform);\n        uniforms.clearcoatNormalScale.value.copy(material.clearcoatNormalScale);\n        if (material.side === BackSide) {\n          uniforms.clearcoatNormalScale.value.negate();\n        }\n      }\n    }\n    if (material.dispersion > 0) {\n      uniforms.dispersion.value = material.dispersion;\n    }\n    if (material.iridescence > 0) {\n      uniforms.iridescence.value = material.iridescence;\n      uniforms.iridescenceIOR.value = material.iridescenceIOR;\n      uniforms.iridescenceThicknessMinimum.value = material.iridescenceThicknessRange[0];\n      uniforms.iridescenceThicknessMaximum.value = material.iridescenceThicknessRange[1];\n      if (material.iridescenceMap) {\n        uniforms.iridescenceMap.value = material.iridescenceMap;\n        refreshTransformUniform(material.iridescenceMap, uniforms.iridescenceMapTransform);\n      }\n      if (material.iridescenceThicknessMap) {\n        uniforms.iridescenceThicknessMap.value = material.iridescenceThicknessMap;\n        refreshTransformUniform(material.iridescenceThicknessMap, uniforms.iridescenceThicknessMapTransform);\n      }\n    }\n    if (material.transmission > 0) {\n      uniforms.transmission.value = material.transmission;\n      uniforms.transmissionSamplerMap.value = transmissionRenderTarget.texture;\n      uniforms.transmissionSamplerSize.value.set(transmissionRenderTarget.width, transmissionRenderTarget.height);\n      if (material.transmissionMap) {\n        uniforms.transmissionMap.value = material.transmissionMap;\n        refreshTransformUniform(material.transmissionMap, uniforms.transmissionMapTransform);\n      }\n      uniforms.thickness.value = material.thickness;\n      if (material.thicknessMap) {\n        uniforms.thicknessMap.value = material.thicknessMap;\n        refreshTransformUniform(material.thicknessMap, uniforms.thicknessMapTransform);\n      }\n      uniforms.attenuationDistance.value = material.attenuationDistance;\n      uniforms.attenuationColor.value.copy(material.attenuationColor);\n    }\n    if (material.anisotropy > 0) {\n      uniforms.anisotropyVector.value.set(material.anisotropy * Math.cos(material.anisotropyRotation), material.anisotropy * Math.sin(material.anisotropyRotation));\n      if (material.anisotropyMap) {\n        uniforms.anisotropyMap.value = material.anisotropyMap;\n        refreshTransformUniform(material.anisotropyMap, uniforms.anisotropyMapTransform);\n      }\n    }\n    uniforms.specularIntensity.value = material.specularIntensity;\n    uniforms.specularColor.value.copy(material.specularColor);\n    if (material.specularColorMap) {\n      uniforms.specularColorMap.value = material.specularColorMap;\n      refreshTransformUniform(material.specularColorMap, uniforms.specularColorMapTransform);\n    }\n    if (material.specularIntensityMap) {\n      uniforms.specularIntensityMap.value = material.specularIntensityMap;\n      refreshTransformUniform(material.specularIntensityMap, uniforms.specularIntensityMapTransform);\n    }\n  }\n  function refreshUniformsMatcap(uniforms, material) {\n    if (material.matcap) {\n      uniforms.matcap.value = material.matcap;\n    }\n  }\n  function refreshUniformsDistance(uniforms, material) {\n    const light = properties.get(material).light;\n    uniforms.referencePosition.value.setFromMatrixPosition(light.matrixWorld);\n    uniforms.nearDistance.value = light.shadow.camera.near;\n    uniforms.farDistance.value = light.shadow.camera.far;\n  }\n  return {\n    refreshFogUniforms: refreshFogUniforms,\n    refreshMaterialUniforms: refreshMaterialUniforms\n  };\n}\nfunction WebGLUniformsGroups(gl, info, capabilities, state) {\n  let buffers = {};\n  let updateList = {};\n  let allocatedBindingPoints = [];\n  const maxBindingPoints = gl.getParameter(gl.MAX_UNIFORM_BUFFER_BINDINGS); // binding points are global whereas block indices are per shader program\n\n  function bind(uniformsGroup, program) {\n    const webglProgram = program.program;\n    state.uniformBlockBinding(uniformsGroup, webglProgram);\n  }\n  function update(uniformsGroup, program) {\n    let buffer = buffers[uniformsGroup.id];\n    if (buffer === undefined) {\n      prepareUniformsGroup(uniformsGroup);\n      buffer = createBuffer(uniformsGroup);\n      buffers[uniformsGroup.id] = buffer;\n      uniformsGroup.addEventListener('dispose', onUniformsGroupsDispose);\n    }\n\n    // ensure to update the binding points/block indices mapping for this program\n\n    const webglProgram = program.program;\n    state.updateUBOMapping(uniformsGroup, webglProgram);\n\n    // update UBO once per frame\n\n    const frame = info.render.frame;\n    if (updateList[uniformsGroup.id] !== frame) {\n      updateBufferData(uniformsGroup);\n      updateList[uniformsGroup.id] = frame;\n    }\n  }\n  function createBuffer(uniformsGroup) {\n    // the setup of an UBO is independent of a particular shader program but global\n\n    const bindingPointIndex = allocateBindingPointIndex();\n    uniformsGroup.__bindingPointIndex = bindingPointIndex;\n    const buffer = gl.createBuffer();\n    const size = uniformsGroup.__size;\n    const usage = uniformsGroup.usage;\n    gl.bindBuffer(gl.UNIFORM_BUFFER, buffer);\n    gl.bufferData(gl.UNIFORM_BUFFER, size, usage);\n    gl.bindBuffer(gl.UNIFORM_BUFFER, null);\n    gl.bindBufferBase(gl.UNIFORM_BUFFER, bindingPointIndex, buffer);\n    return buffer;\n  }\n  function allocateBindingPointIndex() {\n    for (let i = 0; i < maxBindingPoints; i++) {\n      if (allocatedBindingPoints.indexOf(i) === -1) {\n        allocatedBindingPoints.push(i);\n        return i;\n      }\n    }\n    console.error('THREE.WebGLRenderer: Maximum number of simultaneously usable uniforms groups reached.');\n    return 0;\n  }\n  function updateBufferData(uniformsGroup) {\n    const buffer = buffers[uniformsGroup.id];\n    const uniforms = uniformsGroup.uniforms;\n    const cache = uniformsGroup.__cache;\n    gl.bindBuffer(gl.UNIFORM_BUFFER, buffer);\n    for (let i = 0, il = uniforms.length; i < il; i++) {\n      const uniformArray = Array.isArray(uniforms[i]) ? uniforms[i] : [uniforms[i]];\n      for (let j = 0, jl = uniformArray.length; j < jl; j++) {\n        const uniform = uniformArray[j];\n        if (hasUniformChanged(uniform, i, j, cache) === true) {\n          const offset = uniform.__offset;\n          const values = Array.isArray(uniform.value) ? uniform.value : [uniform.value];\n          let arrayOffset = 0;\n          for (let k = 0; k < values.length; k++) {\n            const value = values[k];\n            const info = getUniformSize(value);\n\n            // TODO add integer and struct support\n            if (typeof value === 'number' || typeof value === 'boolean') {\n              uniform.__data[0] = value;\n              gl.bufferSubData(gl.UNIFORM_BUFFER, offset + arrayOffset, uniform.__data);\n            } else if (value.isMatrix3) {\n              // manually converting 3x3 to 3x4\n\n              uniform.__data[0] = value.elements[0];\n              uniform.__data[1] = value.elements[1];\n              uniform.__data[2] = value.elements[2];\n              uniform.__data[3] = 0;\n              uniform.__data[4] = value.elements[3];\n              uniform.__data[5] = value.elements[4];\n              uniform.__data[6] = value.elements[5];\n              uniform.__data[7] = 0;\n              uniform.__data[8] = value.elements[6];\n              uniform.__data[9] = value.elements[7];\n              uniform.__data[10] = value.elements[8];\n              uniform.__data[11] = 0;\n            } else {\n              value.toArray(uniform.__data, arrayOffset);\n              arrayOffset += info.storage / Float32Array.BYTES_PER_ELEMENT;\n            }\n          }\n          gl.bufferSubData(gl.UNIFORM_BUFFER, offset, uniform.__data);\n        }\n      }\n    }\n    gl.bindBuffer(gl.UNIFORM_BUFFER, null);\n  }\n  function hasUniformChanged(uniform, index, indexArray, cache) {\n    const value = uniform.value;\n    const indexString = index + '_' + indexArray;\n    if (cache[indexString] === undefined) {\n      // cache entry does not exist so far\n\n      if (typeof value === 'number' || typeof value === 'boolean') {\n        cache[indexString] = value;\n      } else {\n        cache[indexString] = value.clone();\n      }\n      return true;\n    } else {\n      const cachedObject = cache[indexString];\n\n      // compare current value with cached entry\n\n      if (typeof value === 'number' || typeof value === 'boolean') {\n        if (cachedObject !== value) {\n          cache[indexString] = value;\n          return true;\n        }\n      } else {\n        if (cachedObject.equals(value) === false) {\n          cachedObject.copy(value);\n          return true;\n        }\n      }\n    }\n    return false;\n  }\n  function prepareUniformsGroup(uniformsGroup) {\n    // determine total buffer size according to the STD140 layout\n    // Hint: STD140 is the only supported layout in WebGL 2\n\n    const uniforms = uniformsGroup.uniforms;\n    let offset = 0; // global buffer offset in bytes\n    const chunkSize = 16; // size of a chunk in bytes\n\n    for (let i = 0, l = uniforms.length; i < l; i++) {\n      const uniformArray = Array.isArray(uniforms[i]) ? uniforms[i] : [uniforms[i]];\n      for (let j = 0, jl = uniformArray.length; j < jl; j++) {\n        const uniform = uniformArray[j];\n        const values = Array.isArray(uniform.value) ? uniform.value : [uniform.value];\n        for (let k = 0, kl = values.length; k < kl; k++) {\n          const value = values[k];\n          const info = getUniformSize(value);\n          const chunkOffset = offset % chunkSize; // offset in the current chunk\n          const chunkPadding = chunkOffset % info.boundary; // required padding to match boundary\n          const chunkStart = chunkOffset + chunkPadding; // the start position in the current chunk for the data\n\n          offset += chunkPadding;\n\n          // Check for chunk overflow\n          if (chunkStart !== 0 && chunkSize - chunkStart < info.storage) {\n            // Add padding and adjust offset\n            offset += chunkSize - chunkStart;\n          }\n\n          // the following two properties will be used for partial buffer updates\n          uniform.__data = new Float32Array(info.storage / Float32Array.BYTES_PER_ELEMENT);\n          uniform.__offset = offset;\n\n          // Update the global offset\n          offset += info.storage;\n        }\n      }\n    }\n\n    // ensure correct final padding\n\n    const chunkOffset = offset % chunkSize;\n    if (chunkOffset > 0) offset += chunkSize - chunkOffset;\n\n    //\n\n    uniformsGroup.__size = offset;\n    uniformsGroup.__cache = {};\n    return this;\n  }\n  function getUniformSize(value) {\n    const info = {\n      boundary: 0,\n      // bytes\n      storage: 0 // bytes\n    };\n\n    // determine sizes according to STD140\n\n    if (typeof value === 'number' || typeof value === 'boolean') {\n      // float/int/bool\n\n      info.boundary = 4;\n      info.storage = 4;\n    } else if (value.isVector2) {\n      // vec2\n\n      info.boundary = 8;\n      info.storage = 8;\n    } else if (value.isVector3 || value.isColor) {\n      // vec3\n\n      info.boundary = 16;\n      info.storage = 12; // evil: vec3 must start on a 16-byte boundary but it only consumes 12 bytes\n    } else if (value.isVector4) {\n      // vec4\n\n      info.boundary = 16;\n      info.storage = 16;\n    } else if (value.isMatrix3) {\n      // mat3 (in STD140 a 3x3 matrix is represented as 3x4)\n\n      info.boundary = 48;\n      info.storage = 48;\n    } else if (value.isMatrix4) {\n      // mat4\n\n      info.boundary = 64;\n      info.storage = 64;\n    } else if (value.isTexture) {\n      console.warn('THREE.WebGLRenderer: Texture samplers can not be part of an uniforms group.');\n    } else {\n      console.warn('THREE.WebGLRenderer: Unsupported uniform value type.', value);\n    }\n    return info;\n  }\n  function onUniformsGroupsDispose(event) {\n    const uniformsGroup = event.target;\n    uniformsGroup.removeEventListener('dispose', onUniformsGroupsDispose);\n    const index = allocatedBindingPoints.indexOf(uniformsGroup.__bindingPointIndex);\n    allocatedBindingPoints.splice(index, 1);\n    gl.deleteBuffer(buffers[uniformsGroup.id]);\n    delete buffers[uniformsGroup.id];\n    delete updateList[uniformsGroup.id];\n  }\n  function dispose() {\n    for (const id in buffers) {\n      gl.deleteBuffer(buffers[id]);\n    }\n    allocatedBindingPoints = [];\n    buffers = {};\n    updateList = {};\n  }\n  return {\n    bind: bind,\n    update: update,\n    dispose: dispose\n  };\n}\nclass WebGLRenderer {\n  constructor(parameters = {}) {\n    const {\n      canvas = createCanvasElement(),\n      context = null,\n      depth = true,\n      stencil = false,\n      alpha = false,\n      antialias = false,\n      premultipliedAlpha = true,\n      preserveDrawingBuffer = false,\n      powerPreference = 'default',\n      failIfMajorPerformanceCaveat = false\n    } = parameters;\n    this.isWebGLRenderer = true;\n    let _alpha;\n    if (context !== null) {\n      if (typeof WebGLRenderingContext !== 'undefined' && context instanceof WebGLRenderingContext) {\n        throw new Error('THREE.WebGLRenderer: WebGL 1 is not supported since r163.');\n      }\n      _alpha = context.getContextAttributes().alpha;\n    } else {\n      _alpha = alpha;\n    }\n    const uintClearColor = new Uint32Array(4);\n    const intClearColor = new Int32Array(4);\n    let currentRenderList = null;\n    let currentRenderState = null;\n\n    // render() can be called from within a callback triggered by another render.\n    // We track this so that the nested render call gets its list and state isolated from the parent render call.\n\n    const renderListStack = [];\n    const renderStateStack = [];\n\n    // public properties\n\n    this.domElement = canvas;\n\n    // Debug configuration container\n    this.debug = {\n      /**\n       * Enables error checking and reporting when shader programs are being compiled\n       * @type {boolean}\n       */\n      checkShaderErrors: true,\n      /**\n       * Callback for custom error reporting.\n       * @type {?Function}\n       */\n      onShaderError: null\n    };\n\n    // clearing\n\n    this.autoClear = true;\n    this.autoClearColor = true;\n    this.autoClearDepth = true;\n    this.autoClearStencil = true;\n\n    // scene graph\n\n    this.sortObjects = true;\n\n    // user-defined clipping\n\n    this.clippingPlanes = [];\n    this.localClippingEnabled = false;\n\n    // physically based shading\n\n    this._outputColorSpace = SRGBColorSpace;\n\n    // tone mapping\n\n    this.toneMapping = NoToneMapping;\n    this.toneMappingExposure = 1.0;\n\n    // internal properties\n\n    const _this = this;\n    let _isContextLost = false;\n\n    // internal state cache\n\n    let _currentActiveCubeFace = 0;\n    let _currentActiveMipmapLevel = 0;\n    let _currentRenderTarget = null;\n    let _currentMaterialId = -1;\n    let _currentCamera = null;\n    const _currentViewport = new Vector4();\n    const _currentScissor = new Vector4();\n    let _currentScissorTest = null;\n    const _currentClearColor = new Color(0x000000);\n    let _currentClearAlpha = 0;\n\n    //\n\n    let _width = canvas.width;\n    let _height = canvas.height;\n    let _pixelRatio = 1;\n    let _opaqueSort = null;\n    let _transparentSort = null;\n    const _viewport = new Vector4(0, 0, _width, _height);\n    const _scissor = new Vector4(0, 0, _width, _height);\n    let _scissorTest = false;\n\n    // frustum\n\n    const _frustum = new Frustum();\n\n    // clipping\n\n    let _clippingEnabled = false;\n    let _localClippingEnabled = false;\n\n    // camera matrices cache\n\n    const _currentProjectionMatrix = new Matrix4();\n    const _projScreenMatrix = new Matrix4();\n    const _vector3 = new Vector3();\n    const _vector4 = new Vector4();\n    const _emptyScene = {\n      background: null,\n      fog: null,\n      environment: null,\n      overrideMaterial: null,\n      isScene: true\n    };\n    let _renderBackground = false;\n    function getTargetPixelRatio() {\n      return _currentRenderTarget === null ? _pixelRatio : 1;\n    }\n\n    // initialize\n\n    let _gl = context;\n    function getContext(contextName, contextAttributes) {\n      return canvas.getContext(contextName, contextAttributes);\n    }\n    try {\n      const contextAttributes = {\n        alpha: true,\n        depth,\n        stencil,\n        antialias,\n        premultipliedAlpha,\n        preserveDrawingBuffer,\n        powerPreference,\n        failIfMajorPerformanceCaveat\n      };\n\n      // OffscreenCanvas does not have setAttribute, see #22811\n      if ('setAttribute' in canvas) canvas.setAttribute('data-engine', `three.js r${REVISION}`);\n\n      // event listeners must be registered before WebGL context is created, see #12753\n      canvas.addEventListener('webglcontextlost', onContextLost, false);\n      canvas.addEventListener('webglcontextrestored', onContextRestore, false);\n      canvas.addEventListener('webglcontextcreationerror', onContextCreationError, false);\n      if (_gl === null) {\n        const contextName = 'webgl2';\n        _gl = getContext(contextName, contextAttributes);\n        if (_gl === null) {\n          if (getContext(contextName)) {\n            throw new Error('Error creating WebGL context with your selected attributes.');\n          } else {\n            throw new Error('Error creating WebGL context.');\n          }\n        }\n      }\n    } catch (error) {\n      console.error('THREE.WebGLRenderer: ' + error.message);\n      throw error;\n    }\n    let extensions, capabilities, state, info;\n    let properties, textures, cubemaps, cubeuvmaps, attributes, geometries, objects;\n    let programCache, materials, renderLists, renderStates, clipping, shadowMap;\n    let background, morphtargets, bufferRenderer, indexedBufferRenderer;\n    let utils, bindingStates, uniformsGroups;\n    function initGLContext() {\n      extensions = new WebGLExtensions(_gl);\n      extensions.init();\n      utils = new WebGLUtils(_gl, extensions);\n      capabilities = new WebGLCapabilities(_gl, extensions, parameters, utils);\n      state = new WebGLState(_gl);\n      if (capabilities.reverseDepthBuffer) state.buffers.depth.setReversed(true);\n      info = new WebGLInfo(_gl);\n      properties = new WebGLProperties();\n      textures = new WebGLTextures(_gl, extensions, state, properties, capabilities, utils, info);\n      cubemaps = new WebGLCubeMaps(_this);\n      cubeuvmaps = new WebGLCubeUVMaps(_this);\n      attributes = new WebGLAttributes(_gl);\n      bindingStates = new WebGLBindingStates(_gl, attributes);\n      geometries = new WebGLGeometries(_gl, attributes, info, bindingStates);\n      objects = new WebGLObjects(_gl, geometries, attributes, info);\n      morphtargets = new WebGLMorphtargets(_gl, capabilities, textures);\n      clipping = new WebGLClipping(properties);\n      programCache = new WebGLPrograms(_this, cubemaps, cubeuvmaps, extensions, capabilities, bindingStates, clipping);\n      materials = new WebGLMaterials(_this, properties);\n      renderLists = new WebGLRenderLists();\n      renderStates = new WebGLRenderStates(extensions);\n      background = new WebGLBackground(_this, cubemaps, cubeuvmaps, state, objects, _alpha, premultipliedAlpha);\n      shadowMap = new WebGLShadowMap(_this, objects, capabilities);\n      uniformsGroups = new WebGLUniformsGroups(_gl, info, capabilities, state);\n      bufferRenderer = new WebGLBufferRenderer(_gl, extensions, info);\n      indexedBufferRenderer = new WebGLIndexedBufferRenderer(_gl, extensions, info);\n      info.programs = programCache.programs;\n      _this.capabilities = capabilities;\n      _this.extensions = extensions;\n      _this.properties = properties;\n      _this.renderLists = renderLists;\n      _this.shadowMap = shadowMap;\n      _this.state = state;\n      _this.info = info;\n    }\n    initGLContext();\n\n    // xr\n\n    const xr = new WebXRManager(_this, _gl);\n    this.xr = xr;\n\n    // API\n\n    this.getContext = function () {\n      return _gl;\n    };\n    this.getContextAttributes = function () {\n      return _gl.getContextAttributes();\n    };\n    this.forceContextLoss = function () {\n      const extension = extensions.get('WEBGL_lose_context');\n      if (extension) extension.loseContext();\n    };\n    this.forceContextRestore = function () {\n      const extension = extensions.get('WEBGL_lose_context');\n      if (extension) extension.restoreContext();\n    };\n    this.getPixelRatio = function () {\n      return _pixelRatio;\n    };\n    this.setPixelRatio = function (value) {\n      if (value === undefined) return;\n      _pixelRatio = value;\n      this.setSize(_width, _height, false);\n    };\n    this.getSize = function (target) {\n      return target.set(_width, _height);\n    };\n    this.setSize = function (width, height, updateStyle = true) {\n      if (xr.isPresenting) {\n        console.warn('THREE.WebGLRenderer: Can\\'t change size while VR device is presenting.');\n        return;\n      }\n      _width = width;\n      _height = height;\n      canvas.width = Math.floor(width * _pixelRatio);\n      canvas.height = Math.floor(height * _pixelRatio);\n      if (updateStyle === true) {\n        canvas.style.width = width + 'px';\n        canvas.style.height = height + 'px';\n      }\n      this.setViewport(0, 0, width, height);\n    };\n    this.getDrawingBufferSize = function (target) {\n      return target.set(_width * _pixelRatio, _height * _pixelRatio).floor();\n    };\n    this.setDrawingBufferSize = function (width, height, pixelRatio) {\n      _width = width;\n      _height = height;\n      _pixelRatio = pixelRatio;\n      canvas.width = Math.floor(width * pixelRatio);\n      canvas.height = Math.floor(height * pixelRatio);\n      this.setViewport(0, 0, width, height);\n    };\n    this.getCurrentViewport = function (target) {\n      return target.copy(_currentViewport);\n    };\n    this.getViewport = function (target) {\n      return target.copy(_viewport);\n    };\n    this.setViewport = function (x, y, width, height) {\n      if (x.isVector4) {\n        _viewport.set(x.x, x.y, x.z, x.w);\n      } else {\n        _viewport.set(x, y, width, height);\n      }\n      state.viewport(_currentViewport.copy(_viewport).multiplyScalar(_pixelRatio).round());\n    };\n    this.getScissor = function (target) {\n      return target.copy(_scissor);\n    };\n    this.setScissor = function (x, y, width, height) {\n      if (x.isVector4) {\n        _scissor.set(x.x, x.y, x.z, x.w);\n      } else {\n        _scissor.set(x, y, width, height);\n      }\n      state.scissor(_currentScissor.copy(_scissor).multiplyScalar(_pixelRatio).round());\n    };\n    this.getScissorTest = function () {\n      return _scissorTest;\n    };\n    this.setScissorTest = function (boolean) {\n      state.setScissorTest(_scissorTest = boolean);\n    };\n    this.setOpaqueSort = function (method) {\n      _opaqueSort = method;\n    };\n    this.setTransparentSort = function (method) {\n      _transparentSort = method;\n    };\n\n    // Clearing\n\n    this.getClearColor = function (target) {\n      return target.copy(background.getClearColor());\n    };\n    this.setClearColor = function () {\n      background.setClearColor.apply(background, arguments);\n    };\n    this.getClearAlpha = function () {\n      return background.getClearAlpha();\n    };\n    this.setClearAlpha = function () {\n      background.setClearAlpha.apply(background, arguments);\n    };\n    this.clear = function (color = true, depth = true, stencil = true) {\n      let bits = 0;\n      if (color) {\n        // check if we're trying to clear an integer target\n        let isIntegerFormat = false;\n        if (_currentRenderTarget !== null) {\n          const targetFormat = _currentRenderTarget.texture.format;\n          isIntegerFormat = targetFormat === RGBAIntegerFormat || targetFormat === RGIntegerFormat || targetFormat === RedIntegerFormat;\n        }\n\n        // use the appropriate clear functions to clear the target if it's a signed\n        // or unsigned integer target\n        if (isIntegerFormat) {\n          const targetType = _currentRenderTarget.texture.type;\n          const isUnsignedType = targetType === UnsignedByteType || targetType === UnsignedIntType || targetType === UnsignedShortType || targetType === UnsignedInt248Type || targetType === UnsignedShort4444Type || targetType === UnsignedShort5551Type;\n          const clearColor = background.getClearColor();\n          const a = background.getClearAlpha();\n          const r = clearColor.r;\n          const g = clearColor.g;\n          const b = clearColor.b;\n          if (isUnsignedType) {\n            uintClearColor[0] = r;\n            uintClearColor[1] = g;\n            uintClearColor[2] = b;\n            uintClearColor[3] = a;\n            _gl.clearBufferuiv(_gl.COLOR, 0, uintClearColor);\n          } else {\n            intClearColor[0] = r;\n            intClearColor[1] = g;\n            intClearColor[2] = b;\n            intClearColor[3] = a;\n            _gl.clearBufferiv(_gl.COLOR, 0, intClearColor);\n          }\n        } else {\n          bits |= _gl.COLOR_BUFFER_BIT;\n        }\n      }\n      if (depth) {\n        bits |= _gl.DEPTH_BUFFER_BIT;\n        _gl.clearDepth(this.capabilities.reverseDepthBuffer ? 0 : 1);\n      }\n      if (stencil) {\n        bits |= _gl.STENCIL_BUFFER_BIT;\n        this.state.buffers.stencil.setMask(0xffffffff);\n      }\n      _gl.clear(bits);\n    };\n    this.clearColor = function () {\n      this.clear(true, false, false);\n    };\n    this.clearDepth = function () {\n      this.clear(false, true, false);\n    };\n    this.clearStencil = function () {\n      this.clear(false, false, true);\n    };\n\n    //\n\n    this.dispose = function () {\n      canvas.removeEventListener('webglcontextlost', onContextLost, false);\n      canvas.removeEventListener('webglcontextrestored', onContextRestore, false);\n      canvas.removeEventListener('webglcontextcreationerror', onContextCreationError, false);\n      renderLists.dispose();\n      renderStates.dispose();\n      properties.dispose();\n      cubemaps.dispose();\n      cubeuvmaps.dispose();\n      objects.dispose();\n      bindingStates.dispose();\n      uniformsGroups.dispose();\n      programCache.dispose();\n      xr.dispose();\n      xr.removeEventListener('sessionstart', onXRSessionStart);\n      xr.removeEventListener('sessionend', onXRSessionEnd);\n      animation.stop();\n    };\n\n    // Events\n\n    function onContextLost(event) {\n      event.preventDefault();\n      console.log('THREE.WebGLRenderer: Context Lost.');\n      _isContextLost = true;\n    }\n    function onContextRestore(/* event */\n    ) {\n      console.log('THREE.WebGLRenderer: Context Restored.');\n      _isContextLost = false;\n      const infoAutoReset = info.autoReset;\n      const shadowMapEnabled = shadowMap.enabled;\n      const shadowMapAutoUpdate = shadowMap.autoUpdate;\n      const shadowMapNeedsUpdate = shadowMap.needsUpdate;\n      const shadowMapType = shadowMap.type;\n      initGLContext();\n      info.autoReset = infoAutoReset;\n      shadowMap.enabled = shadowMapEnabled;\n      shadowMap.autoUpdate = shadowMapAutoUpdate;\n      shadowMap.needsUpdate = shadowMapNeedsUpdate;\n      shadowMap.type = shadowMapType;\n    }\n    function onContextCreationError(event) {\n      console.error('THREE.WebGLRenderer: A WebGL context could not be created. Reason: ', event.statusMessage);\n    }\n    function onMaterialDispose(event) {\n      const material = event.target;\n      material.removeEventListener('dispose', onMaterialDispose);\n      deallocateMaterial(material);\n    }\n\n    // Buffer deallocation\n\n    function deallocateMaterial(material) {\n      releaseMaterialProgramReferences(material);\n      properties.remove(material);\n    }\n    function releaseMaterialProgramReferences(material) {\n      const programs = properties.get(material).programs;\n      if (programs !== undefined) {\n        programs.forEach(function (program) {\n          programCache.releaseProgram(program);\n        });\n        if (material.isShaderMaterial) {\n          programCache.releaseShaderCache(material);\n        }\n      }\n    }\n\n    // Buffer rendering\n\n    this.renderBufferDirect = function (camera, scene, geometry, material, object, group) {\n      if (scene === null) scene = _emptyScene; // renderBufferDirect second parameter used to be fog (could be null)\n\n      const frontFaceCW = object.isMesh && object.matrixWorld.determinant() < 0;\n      const program = setProgram(camera, scene, geometry, material, object);\n      state.setMaterial(material, frontFaceCW);\n\n      //\n\n      let index = geometry.index;\n      let rangeFactor = 1;\n      if (material.wireframe === true) {\n        index = geometries.getWireframeAttribute(geometry);\n        if (index === undefined) return;\n        rangeFactor = 2;\n      }\n\n      //\n\n      const drawRange = geometry.drawRange;\n      const position = geometry.attributes.position;\n      let drawStart = drawRange.start * rangeFactor;\n      let drawEnd = (drawRange.start + drawRange.count) * rangeFactor;\n      if (group !== null) {\n        drawStart = Math.max(drawStart, group.start * rangeFactor);\n        drawEnd = Math.min(drawEnd, (group.start + group.count) * rangeFactor);\n      }\n      if (index !== null) {\n        drawStart = Math.max(drawStart, 0);\n        drawEnd = Math.min(drawEnd, index.count);\n      } else if (position !== undefined && position !== null) {\n        drawStart = Math.max(drawStart, 0);\n        drawEnd = Math.min(drawEnd, position.count);\n      }\n      const drawCount = drawEnd - drawStart;\n      if (drawCount < 0 || drawCount === Infinity) return;\n\n      //\n\n      bindingStates.setup(object, material, program, geometry, index);\n      let attribute;\n      let renderer = bufferRenderer;\n      if (index !== null) {\n        attribute = attributes.get(index);\n        renderer = indexedBufferRenderer;\n        renderer.setIndex(attribute);\n      }\n\n      //\n\n      if (object.isMesh) {\n        if (material.wireframe === true) {\n          state.setLineWidth(material.wireframeLinewidth * getTargetPixelRatio());\n          renderer.setMode(_gl.LINES);\n        } else {\n          renderer.setMode(_gl.TRIANGLES);\n        }\n      } else if (object.isLine) {\n        let lineWidth = material.linewidth;\n        if (lineWidth === undefined) lineWidth = 1; // Not using Line*Material\n\n        state.setLineWidth(lineWidth * getTargetPixelRatio());\n        if (object.isLineSegments) {\n          renderer.setMode(_gl.LINES);\n        } else if (object.isLineLoop) {\n          renderer.setMode(_gl.LINE_LOOP);\n        } else {\n          renderer.setMode(_gl.LINE_STRIP);\n        }\n      } else if (object.isPoints) {\n        renderer.setMode(_gl.POINTS);\n      } else if (object.isSprite) {\n        renderer.setMode(_gl.TRIANGLES);\n      }\n      if (object.isBatchedMesh) {\n        if (object._multiDrawInstances !== null) {\n          renderer.renderMultiDrawInstances(object._multiDrawStarts, object._multiDrawCounts, object._multiDrawCount, object._multiDrawInstances);\n        } else {\n          if (!extensions.get('WEBGL_multi_draw')) {\n            const starts = object._multiDrawStarts;\n            const counts = object._multiDrawCounts;\n            const drawCount = object._multiDrawCount;\n            const bytesPerElement = index ? attributes.get(index).bytesPerElement : 1;\n            const uniforms = properties.get(material).currentProgram.getUniforms();\n            for (let i = 0; i < drawCount; i++) {\n              uniforms.setValue(_gl, '_gl_DrawID', i);\n              renderer.render(starts[i] / bytesPerElement, counts[i]);\n            }\n          } else {\n            renderer.renderMultiDraw(object._multiDrawStarts, object._multiDrawCounts, object._multiDrawCount);\n          }\n        }\n      } else if (object.isInstancedMesh) {\n        renderer.renderInstances(drawStart, drawCount, object.count);\n      } else if (geometry.isInstancedBufferGeometry) {\n        const maxInstanceCount = geometry._maxInstanceCount !== undefined ? geometry._maxInstanceCount : Infinity;\n        const instanceCount = Math.min(geometry.instanceCount, maxInstanceCount);\n        renderer.renderInstances(drawStart, drawCount, instanceCount);\n      } else {\n        renderer.render(drawStart, drawCount);\n      }\n    };\n\n    // Compile\n\n    function prepareMaterial(material, scene, object) {\n      if (material.transparent === true && material.side === DoubleSide && material.forceSinglePass === false) {\n        material.side = BackSide;\n        material.needsUpdate = true;\n        getProgram(material, scene, object);\n        material.side = FrontSide;\n        material.needsUpdate = true;\n        getProgram(material, scene, object);\n        material.side = DoubleSide;\n      } else {\n        getProgram(material, scene, object);\n      }\n    }\n    this.compile = function (scene, camera, targetScene = null) {\n      if (targetScene === null) targetScene = scene;\n      currentRenderState = renderStates.get(targetScene);\n      currentRenderState.init(camera);\n      renderStateStack.push(currentRenderState);\n\n      // gather lights from both the target scene and the new object that will be added to the scene.\n\n      targetScene.traverseVisible(function (object) {\n        if (object.isLight && object.layers.test(camera.layers)) {\n          currentRenderState.pushLight(object);\n          if (object.castShadow) {\n            currentRenderState.pushShadow(object);\n          }\n        }\n      });\n      if (scene !== targetScene) {\n        scene.traverseVisible(function (object) {\n          if (object.isLight && object.layers.test(camera.layers)) {\n            currentRenderState.pushLight(object);\n            if (object.castShadow) {\n              currentRenderState.pushShadow(object);\n            }\n          }\n        });\n      }\n      currentRenderState.setupLights();\n\n      // Only initialize materials in the new scene, not the targetScene.\n\n      const materials = new Set();\n      scene.traverse(function (object) {\n        if (!(object.isMesh || object.isPoints || object.isLine || object.isSprite)) {\n          return;\n        }\n        const material = object.material;\n        if (material) {\n          if (Array.isArray(material)) {\n            for (let i = 0; i < material.length; i++) {\n              const material2 = material[i];\n              prepareMaterial(material2, targetScene, object);\n              materials.add(material2);\n            }\n          } else {\n            prepareMaterial(material, targetScene, object);\n            materials.add(material);\n          }\n        }\n      });\n      renderStateStack.pop();\n      currentRenderState = null;\n      return materials;\n    };\n\n    // compileAsync\n\n    this.compileAsync = function (scene, camera, targetScene = null) {\n      const materials = this.compile(scene, camera, targetScene);\n\n      // Wait for all the materials in the new object to indicate that they're\n      // ready to be used before resolving the promise.\n\n      return new Promise(resolve => {\n        function checkMaterialsReady() {\n          materials.forEach(function (material) {\n            const materialProperties = properties.get(material);\n            const program = materialProperties.currentProgram;\n            if (program.isReady()) {\n              // remove any programs that report they're ready to use from the list\n              materials.delete(material);\n            }\n          });\n\n          // once the list of compiling materials is empty, call the callback\n\n          if (materials.size === 0) {\n            resolve(scene);\n            return;\n          }\n\n          // if some materials are still not ready, wait a bit and check again\n\n          setTimeout(checkMaterialsReady, 10);\n        }\n        if (extensions.get('KHR_parallel_shader_compile') !== null) {\n          // If we can check the compilation status of the materials without\n          // blocking then do so right away.\n\n          checkMaterialsReady();\n        } else {\n          // Otherwise start by waiting a bit to give the materials we just\n          // initialized a chance to finish.\n\n          setTimeout(checkMaterialsReady, 10);\n        }\n      });\n    };\n\n    // Animation Loop\n\n    let onAnimationFrameCallback = null;\n    function onAnimationFrame(time) {\n      if (onAnimationFrameCallback) onAnimationFrameCallback(time);\n    }\n    function onXRSessionStart() {\n      animation.stop();\n    }\n    function onXRSessionEnd() {\n      animation.start();\n    }\n    const animation = new WebGLAnimation();\n    animation.setAnimationLoop(onAnimationFrame);\n    if (typeof self !== 'undefined') animation.setContext(self);\n    this.setAnimationLoop = function (callback) {\n      onAnimationFrameCallback = callback;\n      xr.setAnimationLoop(callback);\n      callback === null ? animation.stop() : animation.start();\n    };\n    xr.addEventListener('sessionstart', onXRSessionStart);\n    xr.addEventListener('sessionend', onXRSessionEnd);\n\n    // Rendering\n\n    this.render = function (scene, camera) {\n      if (camera !== undefined && camera.isCamera !== true) {\n        console.error('THREE.WebGLRenderer.render: camera is not an instance of THREE.Camera.');\n        return;\n      }\n      if (_isContextLost === true) return;\n\n      // update scene graph\n\n      if (scene.matrixWorldAutoUpdate === true) scene.updateMatrixWorld();\n\n      // update camera matrices and frustum\n\n      if (camera.parent === null && camera.matrixWorldAutoUpdate === true) camera.updateMatrixWorld();\n      if (xr.enabled === true && xr.isPresenting === true) {\n        if (xr.cameraAutoUpdate === true) xr.updateCamera(camera);\n        camera = xr.getCamera(); // use XR camera for rendering\n      }\n\n      //\n      if (scene.isScene === true) scene.onBeforeRender(_this, scene, camera, _currentRenderTarget);\n      currentRenderState = renderStates.get(scene, renderStateStack.length);\n      currentRenderState.init(camera);\n      renderStateStack.push(currentRenderState);\n      _projScreenMatrix.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse);\n      _frustum.setFromProjectionMatrix(_projScreenMatrix);\n      _localClippingEnabled = this.localClippingEnabled;\n      _clippingEnabled = clipping.init(this.clippingPlanes, _localClippingEnabled);\n      currentRenderList = renderLists.get(scene, renderListStack.length);\n      currentRenderList.init();\n      renderListStack.push(currentRenderList);\n      if (xr.enabled === true && xr.isPresenting === true) {\n        const depthSensingMesh = _this.xr.getDepthSensingMesh();\n        if (depthSensingMesh !== null) {\n          projectObject(depthSensingMesh, camera, -Infinity, _this.sortObjects);\n        }\n      }\n      projectObject(scene, camera, 0, _this.sortObjects);\n      currentRenderList.finish();\n      if (_this.sortObjects === true) {\n        currentRenderList.sort(_opaqueSort, _transparentSort);\n      }\n      _renderBackground = xr.enabled === false || xr.isPresenting === false || xr.hasDepthSensing() === false;\n      if (_renderBackground) {\n        background.addToRenderList(currentRenderList, scene);\n      }\n\n      //\n\n      this.info.render.frame++;\n      if (_clippingEnabled === true) clipping.beginShadows();\n      const shadowsArray = currentRenderState.state.shadowsArray;\n      shadowMap.render(shadowsArray, scene, camera);\n      if (_clippingEnabled === true) clipping.endShadows();\n\n      //\n\n      if (this.info.autoReset === true) this.info.reset();\n\n      // render scene\n\n      const opaqueObjects = currentRenderList.opaque;\n      const transmissiveObjects = currentRenderList.transmissive;\n      currentRenderState.setupLights();\n      if (camera.isArrayCamera) {\n        const cameras = camera.cameras;\n        if (transmissiveObjects.length > 0) {\n          for (let i = 0, l = cameras.length; i < l; i++) {\n            const camera2 = cameras[i];\n            renderTransmissionPass(opaqueObjects, transmissiveObjects, scene, camera2);\n          }\n        }\n        if (_renderBackground) background.render(scene);\n        for (let i = 0, l = cameras.length; i < l; i++) {\n          const camera2 = cameras[i];\n          renderScene(currentRenderList, scene, camera2, camera2.viewport);\n        }\n      } else {\n        if (transmissiveObjects.length > 0) renderTransmissionPass(opaqueObjects, transmissiveObjects, scene, camera);\n        if (_renderBackground) background.render(scene);\n        renderScene(currentRenderList, scene, camera);\n      }\n\n      //\n\n      if (_currentRenderTarget !== null) {\n        // resolve multisample renderbuffers to a single-sample texture if necessary\n\n        textures.updateMultisampleRenderTarget(_currentRenderTarget);\n\n        // Generate mipmap if we're using any kind of mipmap filtering\n\n        textures.updateRenderTargetMipmap(_currentRenderTarget);\n      }\n\n      //\n\n      if (scene.isScene === true) scene.onAfterRender(_this, scene, camera);\n\n      // _gl.finish();\n\n      bindingStates.resetDefaultState();\n      _currentMaterialId = -1;\n      _currentCamera = null;\n      renderStateStack.pop();\n      if (renderStateStack.length > 0) {\n        currentRenderState = renderStateStack[renderStateStack.length - 1];\n        if (_clippingEnabled === true) clipping.setGlobalState(_this.clippingPlanes, currentRenderState.state.camera);\n      } else {\n        currentRenderState = null;\n      }\n      renderListStack.pop();\n      if (renderListStack.length > 0) {\n        currentRenderList = renderListStack[renderListStack.length - 1];\n      } else {\n        currentRenderList = null;\n      }\n    };\n    function projectObject(object, camera, groupOrder, sortObjects) {\n      if (object.visible === false) return;\n      const visible = object.layers.test(camera.layers);\n      if (visible) {\n        if (object.isGroup) {\n          groupOrder = object.renderOrder;\n        } else if (object.isLOD) {\n          if (object.autoUpdate === true) object.update(camera);\n        } else if (object.isLight) {\n          currentRenderState.pushLight(object);\n          if (object.castShadow) {\n            currentRenderState.pushShadow(object);\n          }\n        } else if (object.isSprite) {\n          if (!object.frustumCulled || _frustum.intersectsSprite(object)) {\n            if (sortObjects) {\n              _vector4.setFromMatrixPosition(object.matrixWorld).applyMatrix4(_projScreenMatrix);\n            }\n            const geometry = objects.update(object);\n            const material = object.material;\n            if (material.visible) {\n              currentRenderList.push(object, geometry, material, groupOrder, _vector4.z, null);\n            }\n          }\n        } else if (object.isMesh || object.isLine || object.isPoints) {\n          if (!object.frustumCulled || _frustum.intersectsObject(object)) {\n            const geometry = objects.update(object);\n            const material = object.material;\n            if (sortObjects) {\n              if (object.boundingSphere !== undefined) {\n                if (object.boundingSphere === null) object.computeBoundingSphere();\n                _vector4.copy(object.boundingSphere.center);\n              } else {\n                if (geometry.boundingSphere === null) geometry.computeBoundingSphere();\n                _vector4.copy(geometry.boundingSphere.center);\n              }\n              _vector4.applyMatrix4(object.matrixWorld).applyMatrix4(_projScreenMatrix);\n            }\n            if (Array.isArray(material)) {\n              const groups = geometry.groups;\n              for (let i = 0, l = groups.length; i < l; i++) {\n                const group = groups[i];\n                const groupMaterial = material[group.materialIndex];\n                if (groupMaterial && groupMaterial.visible) {\n                  currentRenderList.push(object, geometry, groupMaterial, groupOrder, _vector4.z, group);\n                }\n              }\n            } else if (material.visible) {\n              currentRenderList.push(object, geometry, material, groupOrder, _vector4.z, null);\n            }\n          }\n        }\n      }\n      const children = object.children;\n      for (let i = 0, l = children.length; i < l; i++) {\n        projectObject(children[i], camera, groupOrder, sortObjects);\n      }\n    }\n    function renderScene(currentRenderList, scene, camera, viewport) {\n      const opaqueObjects = currentRenderList.opaque;\n      const transmissiveObjects = currentRenderList.transmissive;\n      const transparentObjects = currentRenderList.transparent;\n      currentRenderState.setupLightsView(camera);\n      if (_clippingEnabled === true) clipping.setGlobalState(_this.clippingPlanes, camera);\n      if (viewport) state.viewport(_currentViewport.copy(viewport));\n      if (opaqueObjects.length > 0) renderObjects(opaqueObjects, scene, camera);\n      if (transmissiveObjects.length > 0) renderObjects(transmissiveObjects, scene, camera);\n      if (transparentObjects.length > 0) renderObjects(transparentObjects, scene, camera);\n\n      // Ensure depth buffer writing is enabled so it can be cleared on next render\n\n      state.buffers.depth.setTest(true);\n      state.buffers.depth.setMask(true);\n      state.buffers.color.setMask(true);\n      state.setPolygonOffset(false);\n    }\n    function renderTransmissionPass(opaqueObjects, transmissiveObjects, scene, camera) {\n      const overrideMaterial = scene.isScene === true ? scene.overrideMaterial : null;\n      if (overrideMaterial !== null) {\n        return;\n      }\n      if (currentRenderState.state.transmissionRenderTarget[camera.id] === undefined) {\n        currentRenderState.state.transmissionRenderTarget[camera.id] = new WebGLRenderTarget(1, 1, {\n          generateMipmaps: true,\n          type: extensions.has('EXT_color_buffer_half_float') || extensions.has('EXT_color_buffer_float') ? HalfFloatType : UnsignedByteType,\n          minFilter: LinearMipmapLinearFilter,\n          samples: 4,\n          stencilBuffer: stencil,\n          resolveDepthBuffer: false,\n          resolveStencilBuffer: false,\n          colorSpace: ColorManagement.workingColorSpace\n        });\n\n        // debug\n\n        /*\n        const geometry = new PlaneGeometry();\n        const material = new MeshBasicMaterial( { map: _transmissionRenderTarget.texture } );\n        \tconst mesh = new Mesh( geometry, material );\n        scene.add( mesh );\n        */\n      }\n      const transmissionRenderTarget = currentRenderState.state.transmissionRenderTarget[camera.id];\n      const activeViewport = camera.viewport || _currentViewport;\n      transmissionRenderTarget.setSize(activeViewport.z, activeViewport.w);\n\n      //\n\n      const currentRenderTarget = _this.getRenderTarget();\n      _this.setRenderTarget(transmissionRenderTarget);\n      _this.getClearColor(_currentClearColor);\n      _currentClearAlpha = _this.getClearAlpha();\n      if (_currentClearAlpha < 1) _this.setClearColor(0xffffff, 0.5);\n      _this.clear();\n      if (_renderBackground) background.render(scene);\n\n      // Turn off the features which can affect the frag color for opaque objects pass.\n      // Otherwise they are applied twice in opaque objects pass and transmission objects pass.\n      const currentToneMapping = _this.toneMapping;\n      _this.toneMapping = NoToneMapping;\n\n      // Remove viewport from camera to avoid nested render calls resetting viewport to it (e.g Reflector).\n      // Transmission render pass requires viewport to match the transmissionRenderTarget.\n      const currentCameraViewport = camera.viewport;\n      if (camera.viewport !== undefined) camera.viewport = undefined;\n      currentRenderState.setupLightsView(camera);\n      if (_clippingEnabled === true) clipping.setGlobalState(_this.clippingPlanes, camera);\n      renderObjects(opaqueObjects, scene, camera);\n      textures.updateMultisampleRenderTarget(transmissionRenderTarget);\n      textures.updateRenderTargetMipmap(transmissionRenderTarget);\n      if (extensions.has('WEBGL_multisampled_render_to_texture') === false) {\n        // see #28131\n\n        let renderTargetNeedsUpdate = false;\n        for (let i = 0, l = transmissiveObjects.length; i < l; i++) {\n          const renderItem = transmissiveObjects[i];\n          const object = renderItem.object;\n          const geometry = renderItem.geometry;\n          const material = renderItem.material;\n          const group = renderItem.group;\n          if (material.side === DoubleSide && object.layers.test(camera.layers)) {\n            const currentSide = material.side;\n            material.side = BackSide;\n            material.needsUpdate = true;\n            renderObject(object, scene, camera, geometry, material, group);\n            material.side = currentSide;\n            material.needsUpdate = true;\n            renderTargetNeedsUpdate = true;\n          }\n        }\n        if (renderTargetNeedsUpdate === true) {\n          textures.updateMultisampleRenderTarget(transmissionRenderTarget);\n          textures.updateRenderTargetMipmap(transmissionRenderTarget);\n        }\n      }\n      _this.setRenderTarget(currentRenderTarget);\n      _this.setClearColor(_currentClearColor, _currentClearAlpha);\n      if (currentCameraViewport !== undefined) camera.viewport = currentCameraViewport;\n      _this.toneMapping = currentToneMapping;\n    }\n    function renderObjects(renderList, scene, camera) {\n      const overrideMaterial = scene.isScene === true ? scene.overrideMaterial : null;\n      for (let i = 0, l = renderList.length; i < l; i++) {\n        const renderItem = renderList[i];\n        const object = renderItem.object;\n        const geometry = renderItem.geometry;\n        const material = overrideMaterial === null ? renderItem.material : overrideMaterial;\n        const group = renderItem.group;\n        if (object.layers.test(camera.layers)) {\n          renderObject(object, scene, camera, geometry, material, group);\n        }\n      }\n    }\n    function renderObject(object, scene, camera, geometry, material, group) {\n      object.onBeforeRender(_this, scene, camera, geometry, material, group);\n      object.modelViewMatrix.multiplyMatrices(camera.matrixWorldInverse, object.matrixWorld);\n      object.normalMatrix.getNormalMatrix(object.modelViewMatrix);\n      material.onBeforeRender(_this, scene, camera, geometry, object, group);\n      if (material.transparent === true && material.side === DoubleSide && material.forceSinglePass === false) {\n        material.side = BackSide;\n        material.needsUpdate = true;\n        _this.renderBufferDirect(camera, scene, geometry, material, object, group);\n        material.side = FrontSide;\n        material.needsUpdate = true;\n        _this.renderBufferDirect(camera, scene, geometry, material, object, group);\n        material.side = DoubleSide;\n      } else {\n        _this.renderBufferDirect(camera, scene, geometry, material, object, group);\n      }\n      object.onAfterRender(_this, scene, camera, geometry, material, group);\n    }\n    function getProgram(material, scene, object) {\n      if (scene.isScene !== true) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...\n\n      const materialProperties = properties.get(material);\n      const lights = currentRenderState.state.lights;\n      const shadowsArray = currentRenderState.state.shadowsArray;\n      const lightsStateVersion = lights.state.version;\n      const parameters = programCache.getParameters(material, lights.state, shadowsArray, scene, object);\n      const programCacheKey = programCache.getProgramCacheKey(parameters);\n      let programs = materialProperties.programs;\n\n      // always update environment and fog - changing these trigger an getProgram call, but it's possible that the program doesn't change\n\n      materialProperties.environment = material.isMeshStandardMaterial ? scene.environment : null;\n      materialProperties.fog = scene.fog;\n      materialProperties.envMap = (material.isMeshStandardMaterial ? cubeuvmaps : cubemaps).get(material.envMap || materialProperties.environment);\n      materialProperties.envMapRotation = materialProperties.environment !== null && material.envMap === null ? scene.environmentRotation : material.envMapRotation;\n      if (programs === undefined) {\n        // new material\n\n        material.addEventListener('dispose', onMaterialDispose);\n        programs = new Map();\n        materialProperties.programs = programs;\n      }\n      let program = programs.get(programCacheKey);\n      if (program !== undefined) {\n        // early out if program and light state is identical\n\n        if (materialProperties.currentProgram === program && materialProperties.lightsStateVersion === lightsStateVersion) {\n          updateCommonMaterialProperties(material, parameters);\n          return program;\n        }\n      } else {\n        parameters.uniforms = programCache.getUniforms(material);\n        material.onBeforeCompile(parameters, _this);\n        program = programCache.acquireProgram(parameters, programCacheKey);\n        programs.set(programCacheKey, program);\n        materialProperties.uniforms = parameters.uniforms;\n      }\n      const uniforms = materialProperties.uniforms;\n      if (!material.isShaderMaterial && !material.isRawShaderMaterial || material.clipping === true) {\n        uniforms.clippingPlanes = clipping.uniform;\n      }\n      updateCommonMaterialProperties(material, parameters);\n\n      // store the light setup it was created for\n\n      materialProperties.needsLights = materialNeedsLights(material);\n      materialProperties.lightsStateVersion = lightsStateVersion;\n      if (materialProperties.needsLights) {\n        // wire up the material to this renderer's lighting state\n\n        uniforms.ambientLightColor.value = lights.state.ambient;\n        uniforms.lightProbe.value = lights.state.probe;\n        uniforms.directionalLights.value = lights.state.directional;\n        uniforms.directionalLightShadows.value = lights.state.directionalShadow;\n        uniforms.spotLights.value = lights.state.spot;\n        uniforms.spotLightShadows.value = lights.state.spotShadow;\n        uniforms.rectAreaLights.value = lights.state.rectArea;\n        uniforms.ltc_1.value = lights.state.rectAreaLTC1;\n        uniforms.ltc_2.value = lights.state.rectAreaLTC2;\n        uniforms.pointLights.value = lights.state.point;\n        uniforms.pointLightShadows.value = lights.state.pointShadow;\n        uniforms.hemisphereLights.value = lights.state.hemi;\n        uniforms.directionalShadowMap.value = lights.state.directionalShadowMap;\n        uniforms.directionalShadowMatrix.value = lights.state.directionalShadowMatrix;\n        uniforms.spotShadowMap.value = lights.state.spotShadowMap;\n        uniforms.spotLightMatrix.value = lights.state.spotLightMatrix;\n        uniforms.spotLightMap.value = lights.state.spotLightMap;\n        uniforms.pointShadowMap.value = lights.state.pointShadowMap;\n        uniforms.pointShadowMatrix.value = lights.state.pointShadowMatrix;\n        // TODO (abelnation): add area lights shadow info to uniforms\n      }\n      materialProperties.currentProgram = program;\n      materialProperties.uniformsList = null;\n      return program;\n    }\n    function getUniformList(materialProperties) {\n      if (materialProperties.uniformsList === null) {\n        const progUniforms = materialProperties.currentProgram.getUniforms();\n        materialProperties.uniformsList = WebGLUniforms.seqWithValue(progUniforms.seq, materialProperties.uniforms);\n      }\n      return materialProperties.uniformsList;\n    }\n    function updateCommonMaterialProperties(material, parameters) {\n      const materialProperties = properties.get(material);\n      materialProperties.outputColorSpace = parameters.outputColorSpace;\n      materialProperties.batching = parameters.batching;\n      materialProperties.batchingColor = parameters.batchingColor;\n      materialProperties.instancing = parameters.instancing;\n      materialProperties.instancingColor = parameters.instancingColor;\n      materialProperties.instancingMorph = parameters.instancingMorph;\n      materialProperties.skinning = parameters.skinning;\n      materialProperties.morphTargets = parameters.morphTargets;\n      materialProperties.morphNormals = parameters.morphNormals;\n      materialProperties.morphColors = parameters.morphColors;\n      materialProperties.morphTargetsCount = parameters.morphTargetsCount;\n      materialProperties.numClippingPlanes = parameters.numClippingPlanes;\n      materialProperties.numIntersection = parameters.numClipIntersection;\n      materialProperties.vertexAlphas = parameters.vertexAlphas;\n      materialProperties.vertexTangents = parameters.vertexTangents;\n      materialProperties.toneMapping = parameters.toneMapping;\n    }\n    function setProgram(camera, scene, geometry, material, object) {\n      if (scene.isScene !== true) scene = _emptyScene; // scene could be a Mesh, Line, Points, ...\n\n      textures.resetTextureUnits();\n      const fog = scene.fog;\n      const environment = material.isMeshStandardMaterial ? scene.environment : null;\n      const colorSpace = _currentRenderTarget === null ? _this.outputColorSpace : _currentRenderTarget.isXRRenderTarget === true ? _currentRenderTarget.texture.colorSpace : LinearSRGBColorSpace;\n      const envMap = (material.isMeshStandardMaterial ? cubeuvmaps : cubemaps).get(material.envMap || environment);\n      const vertexAlphas = material.vertexColors === true && !!geometry.attributes.color && geometry.attributes.color.itemSize === 4;\n      const vertexTangents = !!geometry.attributes.tangent && (!!material.normalMap || material.anisotropy > 0);\n      const morphTargets = !!geometry.morphAttributes.position;\n      const morphNormals = !!geometry.morphAttributes.normal;\n      const morphColors = !!geometry.morphAttributes.color;\n      let toneMapping = NoToneMapping;\n      if (material.toneMapped) {\n        if (_currentRenderTarget === null || _currentRenderTarget.isXRRenderTarget === true) {\n          toneMapping = _this.toneMapping;\n        }\n      }\n      const morphAttribute = geometry.morphAttributes.position || geometry.morphAttributes.normal || geometry.morphAttributes.color;\n      const morphTargetsCount = morphAttribute !== undefined ? morphAttribute.length : 0;\n      const materialProperties = properties.get(material);\n      const lights = currentRenderState.state.lights;\n      if (_clippingEnabled === true) {\n        if (_localClippingEnabled === true || camera !== _currentCamera) {\n          const useCache = camera === _currentCamera && material.id === _currentMaterialId;\n\n          // we might want to call this function with some ClippingGroup\n          // object instead of the material, once it becomes feasible\n          // (#8465, #8379)\n          clipping.setState(material, camera, useCache);\n        }\n      }\n\n      //\n\n      let needsProgramChange = false;\n      if (material.version === materialProperties.__version) {\n        if (materialProperties.needsLights && materialProperties.lightsStateVersion !== lights.state.version) {\n          needsProgramChange = true;\n        } else if (materialProperties.outputColorSpace !== colorSpace) {\n          needsProgramChange = true;\n        } else if (object.isBatchedMesh && materialProperties.batching === false) {\n          needsProgramChange = true;\n        } else if (!object.isBatchedMesh && materialProperties.batching === true) {\n          needsProgramChange = true;\n        } else if (object.isBatchedMesh && materialProperties.batchingColor === true && object.colorTexture === null) {\n          needsProgramChange = true;\n        } else if (object.isBatchedMesh && materialProperties.batchingColor === false && object.colorTexture !== null) {\n          needsProgramChange = true;\n        } else if (object.isInstancedMesh && materialProperties.instancing === false) {\n          needsProgramChange = true;\n        } else if (!object.isInstancedMesh && materialProperties.instancing === true) {\n          needsProgramChange = true;\n        } else if (object.isSkinnedMesh && materialProperties.skinning === false) {\n          needsProgramChange = true;\n        } else if (!object.isSkinnedMesh && materialProperties.skinning === true) {\n          needsProgramChange = true;\n        } else if (object.isInstancedMesh && materialProperties.instancingColor === true && object.instanceColor === null) {\n          needsProgramChange = true;\n        } else if (object.isInstancedMesh && materialProperties.instancingColor === false && object.instanceColor !== null) {\n          needsProgramChange = true;\n        } else if (object.isInstancedMesh && materialProperties.instancingMorph === true && object.morphTexture === null) {\n          needsProgramChange = true;\n        } else if (object.isInstancedMesh && materialProperties.instancingMorph === false && object.morphTexture !== null) {\n          needsProgramChange = true;\n        } else if (materialProperties.envMap !== envMap) {\n          needsProgramChange = true;\n        } else if (material.fog === true && materialProperties.fog !== fog) {\n          needsProgramChange = true;\n        } else if (materialProperties.numClippingPlanes !== undefined && (materialProperties.numClippingPlanes !== clipping.numPlanes || materialProperties.numIntersection !== clipping.numIntersection)) {\n          needsProgramChange = true;\n        } else if (materialProperties.vertexAlphas !== vertexAlphas) {\n          needsProgramChange = true;\n        } else if (materialProperties.vertexTangents !== vertexTangents) {\n          needsProgramChange = true;\n        } else if (materialProperties.morphTargets !== morphTargets) {\n          needsProgramChange = true;\n        } else if (materialProperties.morphNormals !== morphNormals) {\n          needsProgramChange = true;\n        } else if (materialProperties.morphColors !== morphColors) {\n          needsProgramChange = true;\n        } else if (materialProperties.toneMapping !== toneMapping) {\n          needsProgramChange = true;\n        } else if (materialProperties.morphTargetsCount !== morphTargetsCount) {\n          needsProgramChange = true;\n        }\n      } else {\n        needsProgramChange = true;\n        materialProperties.__version = material.version;\n      }\n\n      //\n\n      let program = materialProperties.currentProgram;\n      if (needsProgramChange === true) {\n        program = getProgram(material, scene, object);\n      }\n      let refreshProgram = false;\n      let refreshMaterial = false;\n      let refreshLights = false;\n      const p_uniforms = program.getUniforms(),\n        m_uniforms = materialProperties.uniforms;\n      if (state.useProgram(program.program)) {\n        refreshProgram = true;\n        refreshMaterial = true;\n        refreshLights = true;\n      }\n      if (material.id !== _currentMaterialId) {\n        _currentMaterialId = material.id;\n        refreshMaterial = true;\n      }\n      if (refreshProgram || _currentCamera !== camera) {\n        // common camera uniforms\n\n        if (capabilities.reverseDepthBuffer) {\n          _currentProjectionMatrix.copy(camera.projectionMatrix);\n          toNormalizedProjectionMatrix(_currentProjectionMatrix);\n          toReversedProjectionMatrix(_currentProjectionMatrix);\n          p_uniforms.setValue(_gl, 'projectionMatrix', _currentProjectionMatrix);\n        } else {\n          p_uniforms.setValue(_gl, 'projectionMatrix', camera.projectionMatrix);\n        }\n        p_uniforms.setValue(_gl, 'viewMatrix', camera.matrixWorldInverse);\n        const uCamPos = p_uniforms.map.cameraPosition;\n        if (uCamPos !== undefined) {\n          uCamPos.setValue(_gl, _vector3.setFromMatrixPosition(camera.matrixWorld));\n        }\n        if (capabilities.logarithmicDepthBuffer) {\n          p_uniforms.setValue(_gl, 'logDepthBufFC', 2.0 / (Math.log(camera.far + 1.0) / Math.LN2));\n        }\n\n        // consider moving isOrthographic to UniformLib and WebGLMaterials, see https://github.com/mrdoob/three.js/pull/26467#issuecomment-1645185067\n\n        if (material.isMeshPhongMaterial || material.isMeshToonMaterial || material.isMeshLambertMaterial || material.isMeshBasicMaterial || material.isMeshStandardMaterial || material.isShaderMaterial) {\n          p_uniforms.setValue(_gl, 'isOrthographic', camera.isOrthographicCamera === true);\n        }\n        if (_currentCamera !== camera) {\n          _currentCamera = camera;\n\n          // lighting uniforms depend on the camera so enforce an update\n          // now, in case this material supports lights - or later, when\n          // the next material that does gets activated:\n\n          refreshMaterial = true; // set to true on material change\n          refreshLights = true; // remains set until update done\n        }\n      }\n\n      // skinning and morph target uniforms must be set even if material didn't change\n      // auto-setting of texture unit for bone and morph texture must go before other textures\n      // otherwise textures used for skinning and morphing can take over texture units reserved for other material textures\n\n      if (object.isSkinnedMesh) {\n        p_uniforms.setOptional(_gl, object, 'bindMatrix');\n        p_uniforms.setOptional(_gl, object, 'bindMatrixInverse');\n        const skeleton = object.skeleton;\n        if (skeleton) {\n          if (skeleton.boneTexture === null) skeleton.computeBoneTexture();\n          p_uniforms.setValue(_gl, 'boneTexture', skeleton.boneTexture, textures);\n        }\n      }\n      if (object.isBatchedMesh) {\n        p_uniforms.setOptional(_gl, object, 'batchingTexture');\n        p_uniforms.setValue(_gl, 'batchingTexture', object._matricesTexture, textures);\n        p_uniforms.setOptional(_gl, object, 'batchingIdTexture');\n        p_uniforms.setValue(_gl, 'batchingIdTexture', object._indirectTexture, textures);\n        p_uniforms.setOptional(_gl, object, 'batchingColorTexture');\n        if (object._colorsTexture !== null) {\n          p_uniforms.setValue(_gl, 'batchingColorTexture', object._colorsTexture, textures);\n        }\n      }\n      const morphAttributes = geometry.morphAttributes;\n      if (morphAttributes.position !== undefined || morphAttributes.normal !== undefined || morphAttributes.color !== undefined) {\n        morphtargets.update(object, geometry, program);\n      }\n      if (refreshMaterial || materialProperties.receiveShadow !== object.receiveShadow) {\n        materialProperties.receiveShadow = object.receiveShadow;\n        p_uniforms.setValue(_gl, 'receiveShadow', object.receiveShadow);\n      }\n\n      // https://github.com/mrdoob/three.js/pull/24467#issuecomment-1209031512\n\n      if (material.isMeshGouraudMaterial && material.envMap !== null) {\n        m_uniforms.envMap.value = envMap;\n        m_uniforms.flipEnvMap.value = envMap.isCubeTexture && envMap.isRenderTargetTexture === false ? -1 : 1;\n      }\n      if (material.isMeshStandardMaterial && material.envMap === null && scene.environment !== null) {\n        m_uniforms.envMapIntensity.value = scene.environmentIntensity;\n      }\n      if (refreshMaterial) {\n        p_uniforms.setValue(_gl, 'toneMappingExposure', _this.toneMappingExposure);\n        if (materialProperties.needsLights) {\n          // the current material requires lighting info\n\n          // note: all lighting uniforms are always set correctly\n          // they simply reference the renderer's state for their\n          // values\n          //\n          // use the current material's .needsUpdate flags to set\n          // the GL state when required\n\n          markUniformsLightsNeedsUpdate(m_uniforms, refreshLights);\n        }\n\n        // refresh uniforms common to several materials\n\n        if (fog && material.fog === true) {\n          materials.refreshFogUniforms(m_uniforms, fog);\n        }\n        materials.refreshMaterialUniforms(m_uniforms, material, _pixelRatio, _height, currentRenderState.state.transmissionRenderTarget[camera.id]);\n        WebGLUniforms.upload(_gl, getUniformList(materialProperties), m_uniforms, textures);\n      }\n      if (material.isShaderMaterial && material.uniformsNeedUpdate === true) {\n        WebGLUniforms.upload(_gl, getUniformList(materialProperties), m_uniforms, textures);\n        material.uniformsNeedUpdate = false;\n      }\n      if (material.isSpriteMaterial) {\n        p_uniforms.setValue(_gl, 'center', object.center);\n      }\n\n      // common matrices\n\n      p_uniforms.setValue(_gl, 'modelViewMatrix', object.modelViewMatrix);\n      p_uniforms.setValue(_gl, 'normalMatrix', object.normalMatrix);\n      p_uniforms.setValue(_gl, 'modelMatrix', object.matrixWorld);\n\n      // UBOs\n\n      if (material.isShaderMaterial || material.isRawShaderMaterial) {\n        const groups = material.uniformsGroups;\n        for (let i = 0, l = groups.length; i < l; i++) {\n          const group = groups[i];\n          uniformsGroups.update(group, program);\n          uniformsGroups.bind(group, program);\n        }\n      }\n      return program;\n    }\n\n    // If uniforms are marked as clean, they don't need to be loaded to the GPU.\n\n    function markUniformsLightsNeedsUpdate(uniforms, value) {\n      uniforms.ambientLightColor.needsUpdate = value;\n      uniforms.lightProbe.needsUpdate = value;\n      uniforms.directionalLights.needsUpdate = value;\n      uniforms.directionalLightShadows.needsUpdate = value;\n      uniforms.pointLights.needsUpdate = value;\n      uniforms.pointLightShadows.needsUpdate = value;\n      uniforms.spotLights.needsUpdate = value;\n      uniforms.spotLightShadows.needsUpdate = value;\n      uniforms.rectAreaLights.needsUpdate = value;\n      uniforms.hemisphereLights.needsUpdate = value;\n    }\n    function materialNeedsLights(material) {\n      return material.isMeshLambertMaterial || material.isMeshToonMaterial || material.isMeshPhongMaterial || material.isMeshStandardMaterial || material.isShadowMaterial || material.isShaderMaterial && material.lights === true;\n    }\n    this.getActiveCubeFace = function () {\n      return _currentActiveCubeFace;\n    };\n    this.getActiveMipmapLevel = function () {\n      return _currentActiveMipmapLevel;\n    };\n    this.getRenderTarget = function () {\n      return _currentRenderTarget;\n    };\n    this.setRenderTargetTextures = function (renderTarget, colorTexture, depthTexture) {\n      properties.get(renderTarget.texture).__webglTexture = colorTexture;\n      properties.get(renderTarget.depthTexture).__webglTexture = depthTexture;\n      const renderTargetProperties = properties.get(renderTarget);\n      renderTargetProperties.__hasExternalTextures = true;\n      renderTargetProperties.__autoAllocateDepthBuffer = depthTexture === undefined;\n      if (!renderTargetProperties.__autoAllocateDepthBuffer) {\n        // The multisample_render_to_texture extension doesn't work properly if there\n        // are midframe flushes and an external depth buffer. Disable use of the extension.\n        if (extensions.has('WEBGL_multisampled_render_to_texture') === true) {\n          console.warn('THREE.WebGLRenderer: Render-to-texture extension was disabled because an external texture was provided');\n          renderTargetProperties.__useRenderToTexture = false;\n        }\n      }\n    };\n    this.setRenderTargetFramebuffer = function (renderTarget, defaultFramebuffer) {\n      const renderTargetProperties = properties.get(renderTarget);\n      renderTargetProperties.__webglFramebuffer = defaultFramebuffer;\n      renderTargetProperties.__useDefaultFramebuffer = defaultFramebuffer === undefined;\n    };\n    this.setRenderTarget = function (renderTarget, activeCubeFace = 0, activeMipmapLevel = 0) {\n      _currentRenderTarget = renderTarget;\n      _currentActiveCubeFace = activeCubeFace;\n      _currentActiveMipmapLevel = activeMipmapLevel;\n      let useDefaultFramebuffer = true;\n      let framebuffer = null;\n      let isCube = false;\n      let isRenderTarget3D = false;\n      if (renderTarget) {\n        const renderTargetProperties = properties.get(renderTarget);\n        if (renderTargetProperties.__useDefaultFramebuffer !== undefined) {\n          // We need to make sure to rebind the framebuffer.\n          state.bindFramebuffer(_gl.FRAMEBUFFER, null);\n          useDefaultFramebuffer = false;\n        } else if (renderTargetProperties.__webglFramebuffer === undefined) {\n          textures.setupRenderTarget(renderTarget);\n        } else if (renderTargetProperties.__hasExternalTextures) {\n          // Color and depth texture must be rebound in order for the swapchain to update.\n          textures.rebindTextures(renderTarget, properties.get(renderTarget.texture).__webglTexture, properties.get(renderTarget.depthTexture).__webglTexture);\n        } else if (renderTarget.depthBuffer) {\n          // check if the depth texture is already bound to the frame buffer and that it's been initialized\n          const depthTexture = renderTarget.depthTexture;\n          if (renderTargetProperties.__boundDepthTexture !== depthTexture) {\n            // check if the depth texture is compatible\n            if (depthTexture !== null && properties.has(depthTexture) && (renderTarget.width !== depthTexture.image.width || renderTarget.height !== depthTexture.image.height)) {\n              throw new Error('WebGLRenderTarget: Attached DepthTexture is initialized to the incorrect size.');\n            }\n\n            // Swap the depth buffer to the currently attached one\n            textures.setupDepthRenderbuffer(renderTarget);\n          }\n        }\n        const texture = renderTarget.texture;\n        if (texture.isData3DTexture || texture.isDataArrayTexture || texture.isCompressedArrayTexture) {\n          isRenderTarget3D = true;\n        }\n        const __webglFramebuffer = properties.get(renderTarget).__webglFramebuffer;\n        if (renderTarget.isWebGLCubeRenderTarget) {\n          if (Array.isArray(__webglFramebuffer[activeCubeFace])) {\n            framebuffer = __webglFramebuffer[activeCubeFace][activeMipmapLevel];\n          } else {\n            framebuffer = __webglFramebuffer[activeCubeFace];\n          }\n          isCube = true;\n        } else if (renderTarget.samples > 0 && textures.useMultisampledRTT(renderTarget) === false) {\n          framebuffer = properties.get(renderTarget).__webglMultisampledFramebuffer;\n        } else {\n          if (Array.isArray(__webglFramebuffer)) {\n            framebuffer = __webglFramebuffer[activeMipmapLevel];\n          } else {\n            framebuffer = __webglFramebuffer;\n          }\n        }\n        _currentViewport.copy(renderTarget.viewport);\n        _currentScissor.copy(renderTarget.scissor);\n        _currentScissorTest = renderTarget.scissorTest;\n      } else {\n        _currentViewport.copy(_viewport).multiplyScalar(_pixelRatio).floor();\n        _currentScissor.copy(_scissor).multiplyScalar(_pixelRatio).floor();\n        _currentScissorTest = _scissorTest;\n      }\n      const framebufferBound = state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);\n      if (framebufferBound && useDefaultFramebuffer) {\n        state.drawBuffers(renderTarget, framebuffer);\n      }\n      state.viewport(_currentViewport);\n      state.scissor(_currentScissor);\n      state.setScissorTest(_currentScissorTest);\n      if (isCube) {\n        const textureProperties = properties.get(renderTarget.texture);\n        _gl.framebufferTexture2D(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, _gl.TEXTURE_CUBE_MAP_POSITIVE_X + activeCubeFace, textureProperties.__webglTexture, activeMipmapLevel);\n      } else if (isRenderTarget3D) {\n        const textureProperties = properties.get(renderTarget.texture);\n        const layer = activeCubeFace || 0;\n        _gl.framebufferTextureLayer(_gl.FRAMEBUFFER, _gl.COLOR_ATTACHMENT0, textureProperties.__webglTexture, activeMipmapLevel || 0, layer);\n      }\n      _currentMaterialId = -1; // reset current material to ensure correct uniform bindings\n    };\n    this.readRenderTargetPixels = function (renderTarget, x, y, width, height, buffer, activeCubeFaceIndex) {\n      if (!(renderTarget && renderTarget.isWebGLRenderTarget)) {\n        console.error('THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.');\n        return;\n      }\n      let framebuffer = properties.get(renderTarget).__webglFramebuffer;\n      if (renderTarget.isWebGLCubeRenderTarget && activeCubeFaceIndex !== undefined) {\n        framebuffer = framebuffer[activeCubeFaceIndex];\n      }\n      if (framebuffer) {\n        state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);\n        try {\n          const texture = renderTarget.texture;\n          const textureFormat = texture.format;\n          const textureType = texture.type;\n          if (!capabilities.textureFormatReadable(textureFormat)) {\n            console.error('THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in RGBA or implementation defined format.');\n            return;\n          }\n          if (!capabilities.textureTypeReadable(textureType)) {\n            console.error('THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not in UnsignedByteType or implementation defined type.');\n            return;\n          }\n\n          // the following if statement ensures valid read requests (no out-of-bounds pixels, see #8604)\n\n          if (x >= 0 && x <= renderTarget.width - width && y >= 0 && y <= renderTarget.height - height) {\n            _gl.readPixels(x, y, width, height, utils.convert(textureFormat), utils.convert(textureType), buffer);\n          }\n        } finally {\n          // restore framebuffer of current render target if necessary\n\n          const framebuffer = _currentRenderTarget !== null ? properties.get(_currentRenderTarget).__webglFramebuffer : null;\n          state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);\n        }\n      }\n    };\n    this.readRenderTargetPixelsAsync = async function (renderTarget, x, y, width, height, buffer, activeCubeFaceIndex) {\n      if (!(renderTarget && renderTarget.isWebGLRenderTarget)) {\n        throw new Error('THREE.WebGLRenderer.readRenderTargetPixels: renderTarget is not THREE.WebGLRenderTarget.');\n      }\n      let framebuffer = properties.get(renderTarget).__webglFramebuffer;\n      if (renderTarget.isWebGLCubeRenderTarget && activeCubeFaceIndex !== undefined) {\n        framebuffer = framebuffer[activeCubeFaceIndex];\n      }\n      if (framebuffer) {\n        const texture = renderTarget.texture;\n        const textureFormat = texture.format;\n        const textureType = texture.type;\n        if (!capabilities.textureFormatReadable(textureFormat)) {\n          throw new Error('THREE.WebGLRenderer.readRenderTargetPixelsAsync: renderTarget is not in RGBA or implementation defined format.');\n        }\n        if (!capabilities.textureTypeReadable(textureType)) {\n          throw new Error('THREE.WebGLRenderer.readRenderTargetPixelsAsync: renderTarget is not in UnsignedByteType or implementation defined type.');\n        }\n\n        // the following if statement ensures valid read requests (no out-of-bounds pixels, see #8604)\n        if (x >= 0 && x <= renderTarget.width - width && y >= 0 && y <= renderTarget.height - height) {\n          // set the active frame buffer to the one we want to read\n          state.bindFramebuffer(_gl.FRAMEBUFFER, framebuffer);\n          const glBuffer = _gl.createBuffer();\n          _gl.bindBuffer(_gl.PIXEL_PACK_BUFFER, glBuffer);\n          _gl.bufferData(_gl.PIXEL_PACK_BUFFER, buffer.byteLength, _gl.STREAM_READ);\n          _gl.readPixels(x, y, width, height, utils.convert(textureFormat), utils.convert(textureType), 0);\n\n          // reset the frame buffer to the currently set buffer before waiting\n          const currFramebuffer = _currentRenderTarget !== null ? properties.get(_currentRenderTarget).__webglFramebuffer : null;\n          state.bindFramebuffer(_gl.FRAMEBUFFER, currFramebuffer);\n\n          // check if the commands have finished every 8 ms\n          const sync = _gl.fenceSync(_gl.SYNC_GPU_COMMANDS_COMPLETE, 0);\n          _gl.flush();\n          await probeAsync(_gl, sync, 4);\n\n          // read the data and delete the buffer\n          _gl.bindBuffer(_gl.PIXEL_PACK_BUFFER, glBuffer);\n          _gl.getBufferSubData(_gl.PIXEL_PACK_BUFFER, 0, buffer);\n          _gl.deleteBuffer(glBuffer);\n          _gl.deleteSync(sync);\n          return buffer;\n        } else {\n          throw new Error('THREE.WebGLRenderer.readRenderTargetPixelsAsync: requested read bounds are out of range.');\n        }\n      }\n    };\n    this.copyFramebufferToTexture = function (texture, position = null, level = 0) {\n      // support previous signature with position first\n      if (texture.isTexture !== true) {\n        // @deprecated, r165\n        warnOnce('WebGLRenderer: copyFramebufferToTexture function signature has changed.');\n        position = arguments[0] || null;\n        texture = arguments[1];\n      }\n      const levelScale = Math.pow(2, -level);\n      const width = Math.floor(texture.image.width * levelScale);\n      const height = Math.floor(texture.image.height * levelScale);\n      const x = position !== null ? position.x : 0;\n      const y = position !== null ? position.y : 0;\n      textures.setTexture2D(texture, 0);\n      _gl.copyTexSubImage2D(_gl.TEXTURE_2D, level, 0, 0, x, y, width, height);\n      state.unbindTexture();\n    };\n    this.copyTextureToTexture = function (srcTexture, dstTexture, srcRegion = null, dstPosition = null, level = 0) {\n      // support previous signature with dstPosition first\n      if (srcTexture.isTexture !== true) {\n        // @deprecated, r165\n        warnOnce('WebGLRenderer: copyTextureToTexture function signature has changed.');\n        dstPosition = arguments[0] || null;\n        srcTexture = arguments[1];\n        dstTexture = arguments[2];\n        level = arguments[3] || 0;\n        srcRegion = null;\n      }\n      let width, height, minX, minY;\n      let dstX, dstY;\n      if (srcRegion !== null) {\n        width = srcRegion.max.x - srcRegion.min.x;\n        height = srcRegion.max.y - srcRegion.min.y;\n        minX = srcRegion.min.x;\n        minY = srcRegion.min.y;\n      } else {\n        width = srcTexture.image.width;\n        height = srcTexture.image.height;\n        minX = 0;\n        minY = 0;\n      }\n      if (dstPosition !== null) {\n        dstX = dstPosition.x;\n        dstY = dstPosition.y;\n      } else {\n        dstX = 0;\n        dstY = 0;\n      }\n      const glFormat = utils.convert(dstTexture.format);\n      const glType = utils.convert(dstTexture.type);\n      textures.setTexture2D(dstTexture, 0);\n\n      // As another texture upload may have changed pixelStorei\n      // parameters, make sure they are correct for the dstTexture\n      _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, dstTexture.flipY);\n      _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, dstTexture.premultiplyAlpha);\n      _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, dstTexture.unpackAlignment);\n      const currentUnpackRowLen = _gl.getParameter(_gl.UNPACK_ROW_LENGTH);\n      const currentUnpackImageHeight = _gl.getParameter(_gl.UNPACK_IMAGE_HEIGHT);\n      const currentUnpackSkipPixels = _gl.getParameter(_gl.UNPACK_SKIP_PIXELS);\n      const currentUnpackSkipRows = _gl.getParameter(_gl.UNPACK_SKIP_ROWS);\n      const currentUnpackSkipImages = _gl.getParameter(_gl.UNPACK_SKIP_IMAGES);\n      const image = srcTexture.isCompressedTexture ? srcTexture.mipmaps[level] : srcTexture.image;\n      _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, image.width);\n      _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, image.height);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, minX);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, minY);\n      if (srcTexture.isDataTexture) {\n        _gl.texSubImage2D(_gl.TEXTURE_2D, level, dstX, dstY, width, height, glFormat, glType, image.data);\n      } else {\n        if (srcTexture.isCompressedTexture) {\n          _gl.compressedTexSubImage2D(_gl.TEXTURE_2D, level, dstX, dstY, image.width, image.height, glFormat, image.data);\n        } else {\n          _gl.texSubImage2D(_gl.TEXTURE_2D, level, dstX, dstY, width, height, glFormat, glType, image);\n        }\n      }\n      _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, currentUnpackRowLen);\n      _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, currentUnpackImageHeight);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, currentUnpackSkipPixels);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, currentUnpackSkipRows);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_IMAGES, currentUnpackSkipImages);\n\n      // Generate mipmaps only when copying level 0\n      if (level === 0 && dstTexture.generateMipmaps) _gl.generateMipmap(_gl.TEXTURE_2D);\n      state.unbindTexture();\n    };\n    this.copyTextureToTexture3D = function (srcTexture, dstTexture, srcRegion = null, dstPosition = null, level = 0) {\n      // support previous signature with source box first\n      if (srcTexture.isTexture !== true) {\n        // @deprecated, r165\n        warnOnce('WebGLRenderer: copyTextureToTexture3D function signature has changed.');\n        srcRegion = arguments[0] || null;\n        dstPosition = arguments[1] || null;\n        srcTexture = arguments[2];\n        dstTexture = arguments[3];\n        level = arguments[4] || 0;\n      }\n      let width, height, depth, minX, minY, minZ;\n      let dstX, dstY, dstZ;\n      const image = srcTexture.isCompressedTexture ? srcTexture.mipmaps[level] : srcTexture.image;\n      if (srcRegion !== null) {\n        width = srcRegion.max.x - srcRegion.min.x;\n        height = srcRegion.max.y - srcRegion.min.y;\n        depth = srcRegion.max.z - srcRegion.min.z;\n        minX = srcRegion.min.x;\n        minY = srcRegion.min.y;\n        minZ = srcRegion.min.z;\n      } else {\n        width = image.width;\n        height = image.height;\n        depth = image.depth;\n        minX = 0;\n        minY = 0;\n        minZ = 0;\n      }\n      if (dstPosition !== null) {\n        dstX = dstPosition.x;\n        dstY = dstPosition.y;\n        dstZ = dstPosition.z;\n      } else {\n        dstX = 0;\n        dstY = 0;\n        dstZ = 0;\n      }\n      const glFormat = utils.convert(dstTexture.format);\n      const glType = utils.convert(dstTexture.type);\n      let glTarget;\n      if (dstTexture.isData3DTexture) {\n        textures.setTexture3D(dstTexture, 0);\n        glTarget = _gl.TEXTURE_3D;\n      } else if (dstTexture.isDataArrayTexture || dstTexture.isCompressedArrayTexture) {\n        textures.setTexture2DArray(dstTexture, 0);\n        glTarget = _gl.TEXTURE_2D_ARRAY;\n      } else {\n        console.warn('THREE.WebGLRenderer.copyTextureToTexture3D: only supports THREE.DataTexture3D and THREE.DataTexture2DArray.');\n        return;\n      }\n      _gl.pixelStorei(_gl.UNPACK_FLIP_Y_WEBGL, dstTexture.flipY);\n      _gl.pixelStorei(_gl.UNPACK_PREMULTIPLY_ALPHA_WEBGL, dstTexture.premultiplyAlpha);\n      _gl.pixelStorei(_gl.UNPACK_ALIGNMENT, dstTexture.unpackAlignment);\n      const currentUnpackRowLen = _gl.getParameter(_gl.UNPACK_ROW_LENGTH);\n      const currentUnpackImageHeight = _gl.getParameter(_gl.UNPACK_IMAGE_HEIGHT);\n      const currentUnpackSkipPixels = _gl.getParameter(_gl.UNPACK_SKIP_PIXELS);\n      const currentUnpackSkipRows = _gl.getParameter(_gl.UNPACK_SKIP_ROWS);\n      const currentUnpackSkipImages = _gl.getParameter(_gl.UNPACK_SKIP_IMAGES);\n      _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, image.width);\n      _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, image.height);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, minX);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, minY);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_IMAGES, minZ);\n      if (srcTexture.isDataTexture || srcTexture.isData3DTexture) {\n        _gl.texSubImage3D(glTarget, level, dstX, dstY, dstZ, width, height, depth, glFormat, glType, image.data);\n      } else {\n        if (dstTexture.isCompressedArrayTexture) {\n          _gl.compressedTexSubImage3D(glTarget, level, dstX, dstY, dstZ, width, height, depth, glFormat, image.data);\n        } else {\n          _gl.texSubImage3D(glTarget, level, dstX, dstY, dstZ, width, height, depth, glFormat, glType, image);\n        }\n      }\n      _gl.pixelStorei(_gl.UNPACK_ROW_LENGTH, currentUnpackRowLen);\n      _gl.pixelStorei(_gl.UNPACK_IMAGE_HEIGHT, currentUnpackImageHeight);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_PIXELS, currentUnpackSkipPixels);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_ROWS, currentUnpackSkipRows);\n      _gl.pixelStorei(_gl.UNPACK_SKIP_IMAGES, currentUnpackSkipImages);\n\n      // Generate mipmaps only when copying level 0\n      if (level === 0 && dstTexture.generateMipmaps) _gl.generateMipmap(glTarget);\n      state.unbindTexture();\n    };\n    this.initRenderTarget = function (target) {\n      if (properties.get(target).__webglFramebuffer === undefined) {\n        textures.setupRenderTarget(target);\n      }\n    };\n    this.initTexture = function (texture) {\n      if (texture.isCubeTexture) {\n        textures.setTextureCube(texture, 0);\n      } else if (texture.isData3DTexture) {\n        textures.setTexture3D(texture, 0);\n      } else if (texture.isDataArrayTexture || texture.isCompressedArrayTexture) {\n        textures.setTexture2DArray(texture, 0);\n      } else {\n        textures.setTexture2D(texture, 0);\n      }\n      state.unbindTexture();\n    };\n    this.resetState = function () {\n      _currentActiveCubeFace = 0;\n      _currentActiveMipmapLevel = 0;\n      _currentRenderTarget = null;\n      state.reset();\n      bindingStates.reset();\n    };\n    if (typeof __THREE_DEVTOOLS__ !== 'undefined') {\n      __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent('observe', {\n        detail: this\n      }));\n    }\n  }\n  get coordinateSystem() {\n    return WebGLCoordinateSystem;\n  }\n  get outputColorSpace() {\n    return this._outputColorSpace;\n  }\n  set outputColorSpace(colorSpace) {\n    this._outputColorSpace = colorSpace;\n    const gl = this.getContext();\n    gl.drawingBufferColorSpace = colorSpace === DisplayP3ColorSpace ? 'display-p3' : 'srgb';\n    gl.unpackColorSpace = ColorManagement.workingColorSpace === LinearDisplayP3ColorSpace ? 'display-p3' : 'srgb';\n  }\n}\nclass Scene extends Object3D {\n  constructor() {\n    super();\n    this.isScene = true;\n    this.type = 'Scene';\n    this.background = null;\n    this.environment = null;\n    this.fog = null;\n    this.backgroundBlurriness = 0;\n    this.backgroundIntensity = 1;\n    this.backgroundRotation = new Euler();\n    this.environmentIntensity = 1;\n    this.environmentRotation = new Euler();\n    this.overrideMaterial = null;\n    if (typeof __THREE_DEVTOOLS__ !== 'undefined') {\n      __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent('observe', {\n        detail: this\n      }));\n    }\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    if (source.background !== null) this.background = source.background.clone();\n    if (source.environment !== null) this.environment = source.environment.clone();\n    if (source.fog !== null) this.fog = source.fog.clone();\n    this.backgroundBlurriness = source.backgroundBlurriness;\n    this.backgroundIntensity = source.backgroundIntensity;\n    this.backgroundRotation.copy(source.backgroundRotation);\n    this.environmentIntensity = source.environmentIntensity;\n    this.environmentRotation.copy(source.environmentRotation);\n    if (source.overrideMaterial !== null) this.overrideMaterial = source.overrideMaterial.clone();\n    this.matrixAutoUpdate = source.matrixAutoUpdate;\n    return this;\n  }\n  toJSON(meta) {\n    const data = super.toJSON(meta);\n    if (this.fog !== null) data.object.fog = this.fog.toJSON();\n    if (this.backgroundBlurriness > 0) data.object.backgroundBlurriness = this.backgroundBlurriness;\n    if (this.backgroundIntensity !== 1) data.object.backgroundIntensity = this.backgroundIntensity;\n    data.object.backgroundRotation = this.backgroundRotation.toArray();\n    if (this.environmentIntensity !== 1) data.object.environmentIntensity = this.environmentIntensity;\n    data.object.environmentRotation = this.environmentRotation.toArray();\n    return data;\n  }\n}\nclass InterleavedBuffer {\n  constructor(array, stride) {\n    this.isInterleavedBuffer = true;\n    this.array = array;\n    this.stride = stride;\n    this.count = array !== undefined ? array.length / stride : 0;\n    this.usage = StaticDrawUsage;\n    this.updateRanges = [];\n    this.version = 0;\n    this.uuid = generateUUID();\n  }\n  onUploadCallback() {}\n  set needsUpdate(value) {\n    if (value === true) this.version++;\n  }\n  setUsage(value) {\n    this.usage = value;\n    return this;\n  }\n  addUpdateRange(start, count) {\n    this.updateRanges.push({\n      start,\n      count\n    });\n  }\n  clearUpdateRanges() {\n    this.updateRanges.length = 0;\n  }\n  copy(source) {\n    this.array = new source.array.constructor(source.array);\n    this.count = source.count;\n    this.stride = source.stride;\n    this.usage = source.usage;\n    return this;\n  }\n  copyAt(index1, attribute, index2) {\n    index1 *= this.stride;\n    index2 *= attribute.stride;\n    for (let i = 0, l = this.stride; i < l; i++) {\n      this.array[index1 + i] = attribute.array[index2 + i];\n    }\n    return this;\n  }\n  set(value, offset = 0) {\n    this.array.set(value, offset);\n    return this;\n  }\n  clone(data) {\n    if (data.arrayBuffers === undefined) {\n      data.arrayBuffers = {};\n    }\n    if (this.array.buffer._uuid === undefined) {\n      this.array.buffer._uuid = generateUUID();\n    }\n    if (data.arrayBuffers[this.array.buffer._uuid] === undefined) {\n      data.arrayBuffers[this.array.buffer._uuid] = this.array.slice(0).buffer;\n    }\n    const array = new this.array.constructor(data.arrayBuffers[this.array.buffer._uuid]);\n    const ib = new this.constructor(array, this.stride);\n    ib.setUsage(this.usage);\n    return ib;\n  }\n  onUpload(callback) {\n    this.onUploadCallback = callback;\n    return this;\n  }\n  toJSON(data) {\n    if (data.arrayBuffers === undefined) {\n      data.arrayBuffers = {};\n    }\n\n    // generate UUID for array buffer if necessary\n\n    if (this.array.buffer._uuid === undefined) {\n      this.array.buffer._uuid = generateUUID();\n    }\n    if (data.arrayBuffers[this.array.buffer._uuid] === undefined) {\n      data.arrayBuffers[this.array.buffer._uuid] = Array.from(new Uint32Array(this.array.buffer));\n    }\n\n    //\n\n    return {\n      uuid: this.uuid,\n      buffer: this.array.buffer._uuid,\n      type: this.array.constructor.name,\n      stride: this.stride\n    };\n  }\n}\nconst _vector$6 = /*@__PURE__*/new Vector3();\nclass InterleavedBufferAttribute {\n  constructor(interleavedBuffer, itemSize, offset, normalized = false) {\n    this.isInterleavedBufferAttribute = true;\n    this.name = '';\n    this.data = interleavedBuffer;\n    this.itemSize = itemSize;\n    this.offset = offset;\n    this.normalized = normalized;\n  }\n  get count() {\n    return this.data.count;\n  }\n  get array() {\n    return this.data.array;\n  }\n  set needsUpdate(value) {\n    this.data.needsUpdate = value;\n  }\n  applyMatrix4(m) {\n    for (let i = 0, l = this.data.count; i < l; i++) {\n      _vector$6.fromBufferAttribute(this, i);\n      _vector$6.applyMatrix4(m);\n      this.setXYZ(i, _vector$6.x, _vector$6.y, _vector$6.z);\n    }\n    return this;\n  }\n  applyNormalMatrix(m) {\n    for (let i = 0, l = this.count; i < l; i++) {\n      _vector$6.fromBufferAttribute(this, i);\n      _vector$6.applyNormalMatrix(m);\n      this.setXYZ(i, _vector$6.x, _vector$6.y, _vector$6.z);\n    }\n    return this;\n  }\n  transformDirection(m) {\n    for (let i = 0, l = this.count; i < l; i++) {\n      _vector$6.fromBufferAttribute(this, i);\n      _vector$6.transformDirection(m);\n      this.setXYZ(i, _vector$6.x, _vector$6.y, _vector$6.z);\n    }\n    return this;\n  }\n  getComponent(index, component) {\n    let value = this.array[index * this.data.stride + this.offset + component];\n    if (this.normalized) value = denormalize(value, this.array);\n    return value;\n  }\n  setComponent(index, component, value) {\n    if (this.normalized) value = normalize(value, this.array);\n    this.data.array[index * this.data.stride + this.offset + component] = value;\n    return this;\n  }\n  setX(index, x) {\n    if (this.normalized) x = normalize(x, this.array);\n    this.data.array[index * this.data.stride + this.offset] = x;\n    return this;\n  }\n  setY(index, y) {\n    if (this.normalized) y = normalize(y, this.array);\n    this.data.array[index * this.data.stride + this.offset + 1] = y;\n    return this;\n  }\n  setZ(index, z) {\n    if (this.normalized) z = normalize(z, this.array);\n    this.data.array[index * this.data.stride + this.offset + 2] = z;\n    return this;\n  }\n  setW(index, w) {\n    if (this.normalized) w = normalize(w, this.array);\n    this.data.array[index * this.data.stride + this.offset + 3] = w;\n    return this;\n  }\n  getX(index) {\n    let x = this.data.array[index * this.data.stride + this.offset];\n    if (this.normalized) x = denormalize(x, this.array);\n    return x;\n  }\n  getY(index) {\n    let y = this.data.array[index * this.data.stride + this.offset + 1];\n    if (this.normalized) y = denormalize(y, this.array);\n    return y;\n  }\n  getZ(index) {\n    let z = this.data.array[index * this.data.stride + this.offset + 2];\n    if (this.normalized) z = denormalize(z, this.array);\n    return z;\n  }\n  getW(index) {\n    let w = this.data.array[index * this.data.stride + this.offset + 3];\n    if (this.normalized) w = denormalize(w, this.array);\n    return w;\n  }\n  setXY(index, x, y) {\n    index = index * this.data.stride + this.offset;\n    if (this.normalized) {\n      x = normalize(x, this.array);\n      y = normalize(y, this.array);\n    }\n    this.data.array[index + 0] = x;\n    this.data.array[index + 1] = y;\n    return this;\n  }\n  setXYZ(index, x, y, z) {\n    index = index * this.data.stride + this.offset;\n    if (this.normalized) {\n      x = normalize(x, this.array);\n      y = normalize(y, this.array);\n      z = normalize(z, this.array);\n    }\n    this.data.array[index + 0] = x;\n    this.data.array[index + 1] = y;\n    this.data.array[index + 2] = z;\n    return this;\n  }\n  setXYZW(index, x, y, z, w) {\n    index = index * this.data.stride + this.offset;\n    if (this.normalized) {\n      x = normalize(x, this.array);\n      y = normalize(y, this.array);\n      z = normalize(z, this.array);\n      w = normalize(w, this.array);\n    }\n    this.data.array[index + 0] = x;\n    this.data.array[index + 1] = y;\n    this.data.array[index + 2] = z;\n    this.data.array[index + 3] = w;\n    return this;\n  }\n  clone(data) {\n    if (data === undefined) {\n      console.log('THREE.InterleavedBufferAttribute.clone(): Cloning an interleaved buffer attribute will de-interleave buffer data.');\n      const array = [];\n      for (let i = 0; i < this.count; i++) {\n        const index = i * this.data.stride + this.offset;\n        for (let j = 0; j < this.itemSize; j++) {\n          array.push(this.data.array[index + j]);\n        }\n      }\n      return new BufferAttribute(new this.array.constructor(array), this.itemSize, this.normalized);\n    } else {\n      if (data.interleavedBuffers === undefined) {\n        data.interleavedBuffers = {};\n      }\n      if (data.interleavedBuffers[this.data.uuid] === undefined) {\n        data.interleavedBuffers[this.data.uuid] = this.data.clone(data);\n      }\n      return new InterleavedBufferAttribute(data.interleavedBuffers[this.data.uuid], this.itemSize, this.offset, this.normalized);\n    }\n  }\n  toJSON(data) {\n    if (data === undefined) {\n      console.log('THREE.InterleavedBufferAttribute.toJSON(): Serializing an interleaved buffer attribute will de-interleave buffer data.');\n      const array = [];\n      for (let i = 0; i < this.count; i++) {\n        const index = i * this.data.stride + this.offset;\n        for (let j = 0; j < this.itemSize; j++) {\n          array.push(this.data.array[index + j]);\n        }\n      }\n\n      // de-interleave data and save it as an ordinary buffer attribute for now\n\n      return {\n        itemSize: this.itemSize,\n        type: this.array.constructor.name,\n        array: array,\n        normalized: this.normalized\n      };\n    } else {\n      // save as true interleaved attribute\n\n      if (data.interleavedBuffers === undefined) {\n        data.interleavedBuffers = {};\n      }\n      if (data.interleavedBuffers[this.data.uuid] === undefined) {\n        data.interleavedBuffers[this.data.uuid] = this.data.toJSON(data);\n      }\n      return {\n        isInterleavedBufferAttribute: true,\n        itemSize: this.itemSize,\n        data: this.data.uuid,\n        offset: this.offset,\n        normalized: this.normalized\n      };\n    }\n  }\n}\nconst _basePosition = /*@__PURE__*/new Vector3();\nconst _skinIndex = /*@__PURE__*/new Vector4();\nconst _skinWeight = /*@__PURE__*/new Vector4();\nconst _vector3 = /*@__PURE__*/new Vector3();\nconst _matrix4 = /*@__PURE__*/new Matrix4();\nconst _vertex = /*@__PURE__*/new Vector3();\nconst _sphere$4 = /*@__PURE__*/new Sphere();\nconst _inverseMatrix$2 = /*@__PURE__*/new Matrix4();\nconst _ray$2 = /*@__PURE__*/new Ray();\nclass SkinnedMesh extends Mesh {\n  constructor(geometry, material) {\n    super(geometry, material);\n    this.isSkinnedMesh = true;\n    this.type = 'SkinnedMesh';\n    this.bindMode = AttachedBindMode;\n    this.bindMatrix = new Matrix4();\n    this.bindMatrixInverse = new Matrix4();\n    this.boundingBox = null;\n    this.boundingSphere = null;\n  }\n  computeBoundingBox() {\n    const geometry = this.geometry;\n    if (this.boundingBox === null) {\n      this.boundingBox = new Box3();\n    }\n    this.boundingBox.makeEmpty();\n    const positionAttribute = geometry.getAttribute('position');\n    for (let i = 0; i < positionAttribute.count; i++) {\n      this.getVertexPosition(i, _vertex);\n      this.boundingBox.expandByPoint(_vertex);\n    }\n  }\n  computeBoundingSphere() {\n    const geometry = this.geometry;\n    if (this.boundingSphere === null) {\n      this.boundingSphere = new Sphere();\n    }\n    this.boundingSphere.makeEmpty();\n    const positionAttribute = geometry.getAttribute('position');\n    for (let i = 0; i < positionAttribute.count; i++) {\n      this.getVertexPosition(i, _vertex);\n      this.boundingSphere.expandByPoint(_vertex);\n    }\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.bindMode = source.bindMode;\n    this.bindMatrix.copy(source.bindMatrix);\n    this.bindMatrixInverse.copy(source.bindMatrixInverse);\n    this.skeleton = source.skeleton;\n    if (source.boundingBox !== null) this.boundingBox = source.boundingBox.clone();\n    if (source.boundingSphere !== null) this.boundingSphere = source.boundingSphere.clone();\n    return this;\n  }\n  raycast(raycaster, intersects) {\n    const material = this.material;\n    const matrixWorld = this.matrixWorld;\n    if (material === undefined) return;\n\n    // test with bounding sphere in world space\n\n    if (this.boundingSphere === null) this.computeBoundingSphere();\n    _sphere$4.copy(this.boundingSphere);\n    _sphere$4.applyMatrix4(matrixWorld);\n    if (raycaster.ray.intersectsSphere(_sphere$4) === false) return;\n\n    // convert ray to local space of skinned mesh\n\n    _inverseMatrix$2.copy(matrixWorld).invert();\n    _ray$2.copy(raycaster.ray).applyMatrix4(_inverseMatrix$2);\n\n    // test with bounding box in local space\n\n    if (this.boundingBox !== null) {\n      if (_ray$2.intersectsBox(this.boundingBox) === false) return;\n    }\n\n    // test for intersections with geometry\n\n    this._computeIntersections(raycaster, intersects, _ray$2);\n  }\n  getVertexPosition(index, target) {\n    super.getVertexPosition(index, target);\n    this.applyBoneTransform(index, target);\n    return target;\n  }\n  bind(skeleton, bindMatrix) {\n    this.skeleton = skeleton;\n    if (bindMatrix === undefined) {\n      this.updateMatrixWorld(true);\n      this.skeleton.calculateInverses();\n      bindMatrix = this.matrixWorld;\n    }\n    this.bindMatrix.copy(bindMatrix);\n    this.bindMatrixInverse.copy(bindMatrix).invert();\n  }\n  pose() {\n    this.skeleton.pose();\n  }\n  normalizeSkinWeights() {\n    const vector = new Vector4();\n    const skinWeight = this.geometry.attributes.skinWeight;\n    for (let i = 0, l = skinWeight.count; i < l; i++) {\n      vector.fromBufferAttribute(skinWeight, i);\n      const scale = 1.0 / vector.manhattanLength();\n      if (scale !== Infinity) {\n        vector.multiplyScalar(scale);\n      } else {\n        vector.set(1, 0, 0, 0); // do something reasonable\n      }\n      skinWeight.setXYZW(i, vector.x, vector.y, vector.z, vector.w);\n    }\n  }\n  updateMatrixWorld(force) {\n    super.updateMatrixWorld(force);\n    if (this.bindMode === AttachedBindMode) {\n      this.bindMatrixInverse.copy(this.matrixWorld).invert();\n    } else if (this.bindMode === DetachedBindMode) {\n      this.bindMatrixInverse.copy(this.bindMatrix).invert();\n    } else {\n      console.warn('THREE.SkinnedMesh: Unrecognized bindMode: ' + this.bindMode);\n    }\n  }\n  applyBoneTransform(index, vector) {\n    const skeleton = this.skeleton;\n    const geometry = this.geometry;\n    _skinIndex.fromBufferAttribute(geometry.attributes.skinIndex, index);\n    _skinWeight.fromBufferAttribute(geometry.attributes.skinWeight, index);\n    _basePosition.copy(vector).applyMatrix4(this.bindMatrix);\n    vector.set(0, 0, 0);\n    for (let i = 0; i < 4; i++) {\n      const weight = _skinWeight.getComponent(i);\n      if (weight !== 0) {\n        const boneIndex = _skinIndex.getComponent(i);\n        _matrix4.multiplyMatrices(skeleton.bones[boneIndex].matrixWorld, skeleton.boneInverses[boneIndex]);\n        vector.addScaledVector(_vector3.copy(_basePosition).applyMatrix4(_matrix4), weight);\n      }\n    }\n    return vector.applyMatrix4(this.bindMatrixInverse);\n  }\n}\nclass Bone extends Object3D {\n  constructor() {\n    super();\n    this.isBone = true;\n    this.type = 'Bone';\n  }\n}\nclass DataTexture extends Texture$1 {\n  constructor(data = null, width = 1, height = 1, format, type, mapping, wrapS, wrapT, magFilter = NearestFilter, minFilter = NearestFilter, anisotropy, colorSpace) {\n    super(null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace);\n    this.isDataTexture = true;\n    this.image = {\n      data: data,\n      width: width,\n      height: height\n    };\n    this.generateMipmaps = false;\n    this.flipY = false;\n    this.unpackAlignment = 1;\n  }\n}\nconst _offsetMatrix = /*@__PURE__*/new Matrix4();\nconst _identityMatrix$1 = /*@__PURE__*/new Matrix4();\nclass Skeleton {\n  constructor(bones = [], boneInverses = []) {\n    this.uuid = generateUUID();\n    this.bones = bones.slice(0);\n    this.boneInverses = boneInverses;\n    this.boneMatrices = null;\n    this.boneTexture = null;\n    this.init();\n  }\n  init() {\n    const bones = this.bones;\n    const boneInverses = this.boneInverses;\n    this.boneMatrices = new Float32Array(bones.length * 16);\n\n    // calculate inverse bone matrices if necessary\n\n    if (boneInverses.length === 0) {\n      this.calculateInverses();\n    } else {\n      // handle special case\n\n      if (bones.length !== boneInverses.length) {\n        console.warn('THREE.Skeleton: Number of inverse bone matrices does not match amount of bones.');\n        this.boneInverses = [];\n        for (let i = 0, il = this.bones.length; i < il; i++) {\n          this.boneInverses.push(new Matrix4());\n        }\n      }\n    }\n  }\n  calculateInverses() {\n    this.boneInverses.length = 0;\n    for (let i = 0, il = this.bones.length; i < il; i++) {\n      const inverse = new Matrix4();\n      if (this.bones[i]) {\n        inverse.copy(this.bones[i].matrixWorld).invert();\n      }\n      this.boneInverses.push(inverse);\n    }\n  }\n  pose() {\n    // recover the bind-time world matrices\n\n    for (let i = 0, il = this.bones.length; i < il; i++) {\n      const bone = this.bones[i];\n      if (bone) {\n        bone.matrixWorld.copy(this.boneInverses[i]).invert();\n      }\n    }\n\n    // compute the local matrices, positions, rotations and scales\n\n    for (let i = 0, il = this.bones.length; i < il; i++) {\n      const bone = this.bones[i];\n      if (bone) {\n        if (bone.parent && bone.parent.isBone) {\n          bone.matrix.copy(bone.parent.matrixWorld).invert();\n          bone.matrix.multiply(bone.matrixWorld);\n        } else {\n          bone.matrix.copy(bone.matrixWorld);\n        }\n        bone.matrix.decompose(bone.position, bone.quaternion, bone.scale);\n      }\n    }\n  }\n  update() {\n    const bones = this.bones;\n    const boneInverses = this.boneInverses;\n    const boneMatrices = this.boneMatrices;\n    const boneTexture = this.boneTexture;\n\n    // flatten bone matrices to array\n\n    for (let i = 0, il = bones.length; i < il; i++) {\n      // compute the offset between the current and the original transform\n\n      const matrix = bones[i] ? bones[i].matrixWorld : _identityMatrix$1;\n      _offsetMatrix.multiplyMatrices(matrix, boneInverses[i]);\n      _offsetMatrix.toArray(boneMatrices, i * 16);\n    }\n    if (boneTexture !== null) {\n      boneTexture.needsUpdate = true;\n    }\n  }\n  clone() {\n    return new Skeleton(this.bones, this.boneInverses);\n  }\n  computeBoneTexture() {\n    // layout (1 matrix = 4 pixels)\n    //      RGBA RGBA RGBA RGBA (=> column1, column2, column3, column4)\n    //  with  8x8  pixel texture max   16 bones * 4 pixels =  (8 * 8)\n    //       16x16 pixel texture max   64 bones * 4 pixels = (16 * 16)\n    //       32x32 pixel texture max  256 bones * 4 pixels = (32 * 32)\n    //       64x64 pixel texture max 1024 bones * 4 pixels = (64 * 64)\n\n    let size = Math.sqrt(this.bones.length * 4); // 4 pixels needed for 1 matrix\n    size = Math.ceil(size / 4) * 4;\n    size = Math.max(size, 4);\n    const boneMatrices = new Float32Array(size * size * 4); // 4 floats per RGBA pixel\n    boneMatrices.set(this.boneMatrices); // copy current values\n\n    const boneTexture = new DataTexture(boneMatrices, size, size, RGBAFormat, FloatType);\n    boneTexture.needsUpdate = true;\n    this.boneMatrices = boneMatrices;\n    this.boneTexture = boneTexture;\n    return this;\n  }\n  getBoneByName(name) {\n    for (let i = 0, il = this.bones.length; i < il; i++) {\n      const bone = this.bones[i];\n      if (bone.name === name) {\n        return bone;\n      }\n    }\n    return undefined;\n  }\n  dispose() {\n    if (this.boneTexture !== null) {\n      this.boneTexture.dispose();\n      this.boneTexture = null;\n    }\n  }\n  fromJSON(json, bones) {\n    this.uuid = json.uuid;\n    for (let i = 0, l = json.bones.length; i < l; i++) {\n      const uuid = json.bones[i];\n      let bone = bones[uuid];\n      if (bone === undefined) {\n        console.warn('THREE.Skeleton: No bone found with UUID:', uuid);\n        bone = new Bone();\n      }\n      this.bones.push(bone);\n      this.boneInverses.push(new Matrix4().fromArray(json.boneInverses[i]));\n    }\n    this.init();\n    return this;\n  }\n  toJSON() {\n    const data = {\n      metadata: {\n        version: 4.6,\n        type: 'Skeleton',\n        generator: 'Skeleton.toJSON'\n      },\n      bones: [],\n      boneInverses: []\n    };\n    data.uuid = this.uuid;\n    const bones = this.bones;\n    const boneInverses = this.boneInverses;\n    for (let i = 0, l = bones.length; i < l; i++) {\n      const bone = bones[i];\n      data.bones.push(bone.uuid);\n      const boneInverse = boneInverses[i];\n      data.boneInverses.push(boneInverse.toArray());\n    }\n    return data;\n  }\n}\nclass InstancedBufferAttribute extends BufferAttribute {\n  constructor(array, itemSize, normalized, meshPerAttribute = 1) {\n    super(array, itemSize, normalized);\n    this.isInstancedBufferAttribute = true;\n    this.meshPerAttribute = meshPerAttribute;\n  }\n  copy(source) {\n    super.copy(source);\n    this.meshPerAttribute = source.meshPerAttribute;\n    return this;\n  }\n  toJSON() {\n    const data = super.toJSON();\n    data.meshPerAttribute = this.meshPerAttribute;\n    data.isInstancedBufferAttribute = true;\n    return data;\n  }\n}\nconst _instanceLocalMatrix = /*@__PURE__*/new Matrix4();\nconst _instanceWorldMatrix = /*@__PURE__*/new Matrix4();\nconst _instanceIntersects = [];\nconst _box3 = /*@__PURE__*/new Box3();\nconst _identity = /*@__PURE__*/new Matrix4();\nconst _mesh$1 = /*@__PURE__*/new Mesh();\nconst _sphere$3 = /*@__PURE__*/new Sphere();\nclass InstancedMesh extends Mesh {\n  constructor(geometry, material, count) {\n    super(geometry, material);\n    this.isInstancedMesh = true;\n    this.instanceMatrix = new InstancedBufferAttribute(new Float32Array(count * 16), 16);\n    this.instanceColor = null;\n    this.morphTexture = null;\n    this.count = count;\n    this.boundingBox = null;\n    this.boundingSphere = null;\n    for (let i = 0; i < count; i++) {\n      this.setMatrixAt(i, _identity);\n    }\n  }\n  computeBoundingBox() {\n    const geometry = this.geometry;\n    const count = this.count;\n    if (this.boundingBox === null) {\n      this.boundingBox = new Box3();\n    }\n    if (geometry.boundingBox === null) {\n      geometry.computeBoundingBox();\n    }\n    this.boundingBox.makeEmpty();\n    for (let i = 0; i < count; i++) {\n      this.getMatrixAt(i, _instanceLocalMatrix);\n      _box3.copy(geometry.boundingBox).applyMatrix4(_instanceLocalMatrix);\n      this.boundingBox.union(_box3);\n    }\n  }\n  computeBoundingSphere() {\n    const geometry = this.geometry;\n    const count = this.count;\n    if (this.boundingSphere === null) {\n      this.boundingSphere = new Sphere();\n    }\n    if (geometry.boundingSphere === null) {\n      geometry.computeBoundingSphere();\n    }\n    this.boundingSphere.makeEmpty();\n    for (let i = 0; i < count; i++) {\n      this.getMatrixAt(i, _instanceLocalMatrix);\n      _sphere$3.copy(geometry.boundingSphere).applyMatrix4(_instanceLocalMatrix);\n      this.boundingSphere.union(_sphere$3);\n    }\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.instanceMatrix.copy(source.instanceMatrix);\n    if (source.morphTexture !== null) this.morphTexture = source.morphTexture.clone();\n    if (source.instanceColor !== null) this.instanceColor = source.instanceColor.clone();\n    this.count = source.count;\n    if (source.boundingBox !== null) this.boundingBox = source.boundingBox.clone();\n    if (source.boundingSphere !== null) this.boundingSphere = source.boundingSphere.clone();\n    return this;\n  }\n  getColorAt(index, color) {\n    color.fromArray(this.instanceColor.array, index * 3);\n  }\n  getMatrixAt(index, matrix) {\n    matrix.fromArray(this.instanceMatrix.array, index * 16);\n  }\n  getMorphAt(index, object) {\n    const objectInfluences = object.morphTargetInfluences;\n    const array = this.morphTexture.source.data.data;\n    const len = objectInfluences.length + 1; // All influences + the baseInfluenceSum\n\n    const dataIndex = index * len + 1; // Skip the baseInfluenceSum at the beginning\n\n    for (let i = 0; i < objectInfluences.length; i++) {\n      objectInfluences[i] = array[dataIndex + i];\n    }\n  }\n  raycast(raycaster, intersects) {\n    const matrixWorld = this.matrixWorld;\n    const raycastTimes = this.count;\n    _mesh$1.geometry = this.geometry;\n    _mesh$1.material = this.material;\n    if (_mesh$1.material === undefined) return;\n\n    // test with bounding sphere first\n\n    if (this.boundingSphere === null) this.computeBoundingSphere();\n    _sphere$3.copy(this.boundingSphere);\n    _sphere$3.applyMatrix4(matrixWorld);\n    if (raycaster.ray.intersectsSphere(_sphere$3) === false) return;\n\n    // now test each instance\n\n    for (let instanceId = 0; instanceId < raycastTimes; instanceId++) {\n      // calculate the world matrix for each instance\n\n      this.getMatrixAt(instanceId, _instanceLocalMatrix);\n      _instanceWorldMatrix.multiplyMatrices(matrixWorld, _instanceLocalMatrix);\n\n      // the mesh represents this single instance\n\n      _mesh$1.matrixWorld = _instanceWorldMatrix;\n      _mesh$1.raycast(raycaster, _instanceIntersects);\n\n      // process the result of raycast\n\n      for (let i = 0, l = _instanceIntersects.length; i < l; i++) {\n        const intersect = _instanceIntersects[i];\n        intersect.instanceId = instanceId;\n        intersect.object = this;\n        intersects.push(intersect);\n      }\n      _instanceIntersects.length = 0;\n    }\n  }\n  setColorAt(index, color) {\n    if (this.instanceColor === null) {\n      this.instanceColor = new InstancedBufferAttribute(new Float32Array(this.instanceMatrix.count * 3).fill(1), 3);\n    }\n    color.toArray(this.instanceColor.array, index * 3);\n  }\n  setMatrixAt(index, matrix) {\n    matrix.toArray(this.instanceMatrix.array, index * 16);\n  }\n  setMorphAt(index, object) {\n    const objectInfluences = object.morphTargetInfluences;\n    const len = objectInfluences.length + 1; // morphBaseInfluence + all influences\n\n    if (this.morphTexture === null) {\n      this.morphTexture = new DataTexture(new Float32Array(len * this.count), len, this.count, RedFormat, FloatType);\n    }\n    const array = this.morphTexture.source.data.data;\n    let morphInfluencesSum = 0;\n    for (let i = 0; i < objectInfluences.length; i++) {\n      morphInfluencesSum += objectInfluences[i];\n    }\n    const morphBaseInfluence = this.geometry.morphTargetsRelative ? 1 : 1 - morphInfluencesSum;\n    const dataIndex = len * index;\n    array[dataIndex] = morphBaseInfluence;\n    array.set(objectInfluences, dataIndex + 1);\n  }\n  updateMorphTargets() {}\n  dispose() {\n    this.dispatchEvent({\n      type: 'dispose'\n    });\n    if (this.morphTexture !== null) {\n      this.morphTexture.dispose();\n      this.morphTexture = null;\n    }\n    return this;\n  }\n}\nclass LineBasicMaterial extends Material$1 {\n  constructor(parameters) {\n    super();\n    this.isLineBasicMaterial = true;\n    this.type = 'LineBasicMaterial';\n    this.color = new Color(0xffffff);\n    this.map = null;\n    this.linewidth = 1;\n    this.linecap = 'round';\n    this.linejoin = 'round';\n    this.fog = true;\n    this.setValues(parameters);\n  }\n  copy(source) {\n    super.copy(source);\n    this.color.copy(source.color);\n    this.map = source.map;\n    this.linewidth = source.linewidth;\n    this.linecap = source.linecap;\n    this.linejoin = source.linejoin;\n    this.fog = source.fog;\n    return this;\n  }\n}\nconst _vStart = /*@__PURE__*/new Vector3();\nconst _vEnd = /*@__PURE__*/new Vector3();\nconst _inverseMatrix$1 = /*@__PURE__*/new Matrix4();\nconst _ray$1 = /*@__PURE__*/new Ray();\nconst _sphere$1 = /*@__PURE__*/new Sphere();\nconst _intersectPointOnRay = /*@__PURE__*/new Vector3();\nconst _intersectPointOnSegment = /*@__PURE__*/new Vector3();\nclass Line extends Object3D {\n  constructor(geometry = new BufferGeometry(), material = new LineBasicMaterial()) {\n    super();\n    this.isLine = true;\n    this.type = 'Line';\n    this.geometry = geometry;\n    this.material = material;\n    this.updateMorphTargets();\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.material = Array.isArray(source.material) ? source.material.slice() : source.material;\n    this.geometry = source.geometry;\n    return this;\n  }\n  computeLineDistances() {\n    const geometry = this.geometry;\n\n    // we assume non-indexed geometry\n\n    if (geometry.index === null) {\n      const positionAttribute = geometry.attributes.position;\n      const lineDistances = [0];\n      for (let i = 1, l = positionAttribute.count; i < l; i++) {\n        _vStart.fromBufferAttribute(positionAttribute, i - 1);\n        _vEnd.fromBufferAttribute(positionAttribute, i);\n        lineDistances[i] = lineDistances[i - 1];\n        lineDistances[i] += _vStart.distanceTo(_vEnd);\n      }\n      geometry.setAttribute('lineDistance', new Float32BufferAttribute(lineDistances, 1));\n    } else {\n      console.warn('THREE.Line.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.');\n    }\n    return this;\n  }\n  raycast(raycaster, intersects) {\n    const geometry = this.geometry;\n    const matrixWorld = this.matrixWorld;\n    const threshold = raycaster.params.Line.threshold;\n    const drawRange = geometry.drawRange;\n\n    // Checking boundingSphere distance to ray\n\n    if (geometry.boundingSphere === null) geometry.computeBoundingSphere();\n    _sphere$1.copy(geometry.boundingSphere);\n    _sphere$1.applyMatrix4(matrixWorld);\n    _sphere$1.radius += threshold;\n    if (raycaster.ray.intersectsSphere(_sphere$1) === false) return;\n\n    //\n\n    _inverseMatrix$1.copy(matrixWorld).invert();\n    _ray$1.copy(raycaster.ray).applyMatrix4(_inverseMatrix$1);\n    const localThreshold = threshold / ((this.scale.x + this.scale.y + this.scale.z) / 3);\n    const localThresholdSq = localThreshold * localThreshold;\n    const step = this.isLineSegments ? 2 : 1;\n    const index = geometry.index;\n    const attributes = geometry.attributes;\n    const positionAttribute = attributes.position;\n    if (index !== null) {\n      const start = Math.max(0, drawRange.start);\n      const end = Math.min(index.count, drawRange.start + drawRange.count);\n      for (let i = start, l = end - 1; i < l; i += step) {\n        const a = index.getX(i);\n        const b = index.getX(i + 1);\n        const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, a, b);\n        if (intersect) {\n          intersects.push(intersect);\n        }\n      }\n      if (this.isLineLoop) {\n        const a = index.getX(end - 1);\n        const b = index.getX(start);\n        const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, a, b);\n        if (intersect) {\n          intersects.push(intersect);\n        }\n      }\n    } else {\n      const start = Math.max(0, drawRange.start);\n      const end = Math.min(positionAttribute.count, drawRange.start + drawRange.count);\n      for (let i = start, l = end - 1; i < l; i += step) {\n        const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, i, i + 1);\n        if (intersect) {\n          intersects.push(intersect);\n        }\n      }\n      if (this.isLineLoop) {\n        const intersect = checkIntersection(this, raycaster, _ray$1, localThresholdSq, end - 1, start);\n        if (intersect) {\n          intersects.push(intersect);\n        }\n      }\n    }\n  }\n  updateMorphTargets() {\n    const geometry = this.geometry;\n    const morphAttributes = geometry.morphAttributes;\n    const keys = Object.keys(morphAttributes);\n    if (keys.length > 0) {\n      const morphAttribute = morphAttributes[keys[0]];\n      if (morphAttribute !== undefined) {\n        this.morphTargetInfluences = [];\n        this.morphTargetDictionary = {};\n        for (let m = 0, ml = morphAttribute.length; m < ml; m++) {\n          const name = morphAttribute[m].name || String(m);\n          this.morphTargetInfluences.push(0);\n          this.morphTargetDictionary[name] = m;\n        }\n      }\n    }\n  }\n}\nfunction checkIntersection(object, raycaster, ray, thresholdSq, a, b) {\n  const positionAttribute = object.geometry.attributes.position;\n  _vStart.fromBufferAttribute(positionAttribute, a);\n  _vEnd.fromBufferAttribute(positionAttribute, b);\n  const distSq = ray.distanceSqToSegment(_vStart, _vEnd, _intersectPointOnRay, _intersectPointOnSegment);\n  if (distSq > thresholdSq) return;\n  _intersectPointOnRay.applyMatrix4(object.matrixWorld); // Move back to world space for distance calculation\n\n  const distance = raycaster.ray.origin.distanceTo(_intersectPointOnRay);\n  if (distance < raycaster.near || distance > raycaster.far) return;\n  return {\n    distance: distance,\n    // What do we want? intersection point on the ray or on the segment??\n    // point: raycaster.ray.at( distance ),\n    point: _intersectPointOnSegment.clone().applyMatrix4(object.matrixWorld),\n    index: a,\n    face: null,\n    faceIndex: null,\n    barycoord: null,\n    object: object\n  };\n}\nconst _start = /*@__PURE__*/new Vector3();\nconst _end = /*@__PURE__*/new Vector3();\nclass LineSegments extends Line {\n  constructor(geometry, material) {\n    super(geometry, material);\n    this.isLineSegments = true;\n    this.type = 'LineSegments';\n  }\n  computeLineDistances() {\n    const geometry = this.geometry;\n\n    // we assume non-indexed geometry\n\n    if (geometry.index === null) {\n      const positionAttribute = geometry.attributes.position;\n      const lineDistances = [];\n      for (let i = 0, l = positionAttribute.count; i < l; i += 2) {\n        _start.fromBufferAttribute(positionAttribute, i);\n        _end.fromBufferAttribute(positionAttribute, i + 1);\n        lineDistances[i] = i === 0 ? 0 : lineDistances[i - 1];\n        lineDistances[i + 1] = lineDistances[i] + _start.distanceTo(_end);\n      }\n      geometry.setAttribute('lineDistance', new Float32BufferAttribute(lineDistances, 1));\n    } else {\n      console.warn('THREE.LineSegments.computeLineDistances(): Computation only possible with non-indexed BufferGeometry.');\n    }\n    return this;\n  }\n}\nclass LineLoop extends Line {\n  constructor(geometry, material) {\n    super(geometry, material);\n    this.isLineLoop = true;\n    this.type = 'LineLoop';\n  }\n}\nclass PointsMaterial extends Material$1 {\n  constructor(parameters) {\n    super();\n    this.isPointsMaterial = true;\n    this.type = 'PointsMaterial';\n    this.color = new Color(0xffffff);\n    this.map = null;\n    this.alphaMap = null;\n    this.size = 1;\n    this.sizeAttenuation = true;\n    this.fog = true;\n    this.setValues(parameters);\n  }\n  copy(source) {\n    super.copy(source);\n    this.color.copy(source.color);\n    this.map = source.map;\n    this.alphaMap = source.alphaMap;\n    this.size = source.size;\n    this.sizeAttenuation = source.sizeAttenuation;\n    this.fog = source.fog;\n    return this;\n  }\n}\nconst _inverseMatrix = /*@__PURE__*/new Matrix4();\nconst _ray = /*@__PURE__*/new Ray();\nconst _sphere = /*@__PURE__*/new Sphere();\nconst _position$2 = /*@__PURE__*/new Vector3();\nclass Points extends Object3D {\n  constructor(geometry = new BufferGeometry(), material = new PointsMaterial()) {\n    super();\n    this.isPoints = true;\n    this.type = 'Points';\n    this.geometry = geometry;\n    this.material = material;\n    this.updateMorphTargets();\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.material = Array.isArray(source.material) ? source.material.slice() : source.material;\n    this.geometry = source.geometry;\n    return this;\n  }\n  raycast(raycaster, intersects) {\n    const geometry = this.geometry;\n    const matrixWorld = this.matrixWorld;\n    const threshold = raycaster.params.Points.threshold;\n    const drawRange = geometry.drawRange;\n\n    // Checking boundingSphere distance to ray\n\n    if (geometry.boundingSphere === null) geometry.computeBoundingSphere();\n    _sphere.copy(geometry.boundingSphere);\n    _sphere.applyMatrix4(matrixWorld);\n    _sphere.radius += threshold;\n    if (raycaster.ray.intersectsSphere(_sphere) === false) return;\n\n    //\n\n    _inverseMatrix.copy(matrixWorld).invert();\n    _ray.copy(raycaster.ray).applyMatrix4(_inverseMatrix);\n    const localThreshold = threshold / ((this.scale.x + this.scale.y + this.scale.z) / 3);\n    const localThresholdSq = localThreshold * localThreshold;\n    const index = geometry.index;\n    const attributes = geometry.attributes;\n    const positionAttribute = attributes.position;\n    if (index !== null) {\n      const start = Math.max(0, drawRange.start);\n      const end = Math.min(index.count, drawRange.start + drawRange.count);\n      for (let i = start, il = end; i < il; i++) {\n        const a = index.getX(i);\n        _position$2.fromBufferAttribute(positionAttribute, a);\n        testPoint(_position$2, a, localThresholdSq, matrixWorld, raycaster, intersects, this);\n      }\n    } else {\n      const start = Math.max(0, drawRange.start);\n      const end = Math.min(positionAttribute.count, drawRange.start + drawRange.count);\n      for (let i = start, l = end; i < l; i++) {\n        _position$2.fromBufferAttribute(positionAttribute, i);\n        testPoint(_position$2, i, localThresholdSq, matrixWorld, raycaster, intersects, this);\n      }\n    }\n  }\n  updateMorphTargets() {\n    const geometry = this.geometry;\n    const morphAttributes = geometry.morphAttributes;\n    const keys = Object.keys(morphAttributes);\n    if (keys.length > 0) {\n      const morphAttribute = morphAttributes[keys[0]];\n      if (morphAttribute !== undefined) {\n        this.morphTargetInfluences = [];\n        this.morphTargetDictionary = {};\n        for (let m = 0, ml = morphAttribute.length; m < ml; m++) {\n          const name = morphAttribute[m].name || String(m);\n          this.morphTargetInfluences.push(0);\n          this.morphTargetDictionary[name] = m;\n        }\n      }\n    }\n  }\n}\nfunction testPoint(point, index, localThresholdSq, matrixWorld, raycaster, intersects, object) {\n  const rayPointDistanceSq = _ray.distanceSqToPoint(point);\n  if (rayPointDistanceSq < localThresholdSq) {\n    const intersectPoint = new Vector3();\n    _ray.closestPointToPoint(point, intersectPoint);\n    intersectPoint.applyMatrix4(matrixWorld);\n    const distance = raycaster.ray.origin.distanceTo(intersectPoint);\n    if (distance < raycaster.near || distance > raycaster.far) return;\n    intersects.push({\n      distance: distance,\n      distanceToRay: Math.sqrt(rayPointDistanceSq),\n      point: intersectPoint,\n      index: index,\n      face: null,\n      faceIndex: null,\n      barycoord: null,\n      object: object\n    });\n  }\n}\nclass VideoTexture extends Texture$1 {\n  constructor(video, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy) {\n    super(video, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy);\n    this.isVideoTexture = true;\n    this.minFilter = minFilter !== undefined ? minFilter : LinearFilter;\n    this.magFilter = magFilter !== undefined ? magFilter : LinearFilter;\n    this.generateMipmaps = false;\n    const scope = this;\n    function updateVideo() {\n      scope.needsUpdate = true;\n      video.requestVideoFrameCallback(updateVideo);\n    }\n    if ('requestVideoFrameCallback' in video) {\n      video.requestVideoFrameCallback(updateVideo);\n    }\n  }\n  clone() {\n    return new this.constructor(this.image).copy(this);\n  }\n  update() {\n    const video = this.image;\n    const hasVideoFrameCallback = 'requestVideoFrameCallback' in video;\n    if (hasVideoFrameCallback === false && video.readyState >= video.HAVE_CURRENT_DATA) {\n      this.needsUpdate = true;\n    }\n  }\n}\nclass CompressedTexture extends Texture$1 {\n  constructor(mipmaps, width, height, format, type, mapping, wrapS, wrapT, magFilter, minFilter, anisotropy, colorSpace) {\n    super(null, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy, colorSpace);\n    this.isCompressedTexture = true;\n    this.image = {\n      width: width,\n      height: height\n    };\n    this.mipmaps = mipmaps;\n\n    // no flipping for cube textures\n    // (also flipping doesn't work for compressed textures )\n\n    this.flipY = false;\n\n    // can't generate mipmaps for compressed textures\n    // mips must be embedded in DDS files\n\n    this.generateMipmaps = false;\n  }\n}\nclass CompressedArrayTexture extends CompressedTexture {\n  constructor(mipmaps, width, height, depth, format, type) {\n    super(mipmaps, width, height, format, type);\n    this.isCompressedArrayTexture = true;\n    this.image.depth = depth;\n    this.wrapR = ClampToEdgeWrapping;\n    this.layerUpdates = new Set();\n  }\n  addLayerUpdate(layerIndex) {\n    this.layerUpdates.add(layerIndex);\n  }\n  clearLayerUpdates() {\n    this.layerUpdates.clear();\n  }\n}\nclass CompressedCubeTexture extends CompressedTexture {\n  constructor(images, format, type) {\n    super(undefined, images[0].width, images[0].height, format, type, CubeReflectionMapping);\n    this.isCompressedCubeTexture = true;\n    this.isCubeTexture = true;\n    this.image = images;\n  }\n}\nclass CanvasTexture extends Texture$1 {\n  constructor(canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy) {\n    super(canvas, mapping, wrapS, wrapT, magFilter, minFilter, format, type, anisotropy);\n    this.isCanvasTexture = true;\n    this.needsUpdate = true;\n  }\n}\nclass SphereGeometry extends BufferGeometry {\n  constructor(radius = 1, widthSegments = 32, heightSegments = 16, phiStart = 0, phiLength = Math.PI * 2, thetaStart = 0, thetaLength = Math.PI) {\n    super();\n    this.type = 'SphereGeometry';\n    this.parameters = {\n      radius: radius,\n      widthSegments: widthSegments,\n      heightSegments: heightSegments,\n      phiStart: phiStart,\n      phiLength: phiLength,\n      thetaStart: thetaStart,\n      thetaLength: thetaLength\n    };\n    widthSegments = Math.max(3, Math.floor(widthSegments));\n    heightSegments = Math.max(2, Math.floor(heightSegments));\n    const thetaEnd = Math.min(thetaStart + thetaLength, Math.PI);\n    let index = 0;\n    const grid = [];\n    const vertex = new Vector3();\n    const normal = new Vector3();\n\n    // buffers\n\n    const indices = [];\n    const vertices = [];\n    const normals = [];\n    const uvs = [];\n\n    // generate vertices, normals and uvs\n\n    for (let iy = 0; iy <= heightSegments; iy++) {\n      const verticesRow = [];\n      const v = iy / heightSegments;\n\n      // special case for the poles\n\n      let uOffset = 0;\n      if (iy === 0 && thetaStart === 0) {\n        uOffset = 0.5 / widthSegments;\n      } else if (iy === heightSegments && thetaEnd === Math.PI) {\n        uOffset = -0.5 / widthSegments;\n      }\n      for (let ix = 0; ix <= widthSegments; ix++) {\n        const u = ix / widthSegments;\n\n        // vertex\n\n        vertex.x = -radius * Math.cos(phiStart + u * phiLength) * Math.sin(thetaStart + v * thetaLength);\n        vertex.y = radius * Math.cos(thetaStart + v * thetaLength);\n        vertex.z = radius * Math.sin(phiStart + u * phiLength) * Math.sin(thetaStart + v * thetaLength);\n        vertices.push(vertex.x, vertex.y, vertex.z);\n\n        // normal\n\n        normal.copy(vertex).normalize();\n        normals.push(normal.x, normal.y, normal.z);\n\n        // uv\n\n        uvs.push(u + uOffset, 1 - v);\n        verticesRow.push(index++);\n      }\n      grid.push(verticesRow);\n    }\n\n    // indices\n\n    for (let iy = 0; iy < heightSegments; iy++) {\n      for (let ix = 0; ix < widthSegments; ix++) {\n        const a = grid[iy][ix + 1];\n        const b = grid[iy][ix];\n        const c = grid[iy + 1][ix];\n        const d = grid[iy + 1][ix + 1];\n        if (iy !== 0 || thetaStart > 0) indices.push(a, b, d);\n        if (iy !== heightSegments - 1 || thetaEnd < Math.PI) indices.push(b, c, d);\n      }\n    }\n\n    // build geometry\n\n    this.setIndex(indices);\n    this.setAttribute('position', new Float32BufferAttribute(vertices, 3));\n    this.setAttribute('normal', new Float32BufferAttribute(normals, 3));\n    this.setAttribute('uv', new Float32BufferAttribute(uvs, 2));\n  }\n  copy(source) {\n    super.copy(source);\n    this.parameters = Object.assign({}, source.parameters);\n    return this;\n  }\n  static fromJSON(data) {\n    return new SphereGeometry(data.radius, data.widthSegments, data.heightSegments, data.phiStart, data.phiLength, data.thetaStart, data.thetaLength);\n  }\n}\nclass MeshStandardMaterial extends Material$1 {\n  constructor(parameters) {\n    super();\n    this.isMeshStandardMaterial = true;\n    this.defines = {\n      'STANDARD': ''\n    };\n    this.type = 'MeshStandardMaterial';\n    this.color = new Color(0xffffff); // diffuse\n    this.roughness = 1.0;\n    this.metalness = 0.0;\n    this.map = null;\n    this.lightMap = null;\n    this.lightMapIntensity = 1.0;\n    this.aoMap = null;\n    this.aoMapIntensity = 1.0;\n    this.emissive = new Color(0x000000);\n    this.emissiveIntensity = 1.0;\n    this.emissiveMap = null;\n    this.bumpMap = null;\n    this.bumpScale = 1;\n    this.normalMap = null;\n    this.normalMapType = TangentSpaceNormalMap;\n    this.normalScale = new Vector2(1, 1);\n    this.displacementMap = null;\n    this.displacementScale = 1;\n    this.displacementBias = 0;\n    this.roughnessMap = null;\n    this.metalnessMap = null;\n    this.alphaMap = null;\n    this.envMap = null;\n    this.envMapRotation = new Euler();\n    this.envMapIntensity = 1.0;\n    this.wireframe = false;\n    this.wireframeLinewidth = 1;\n    this.wireframeLinecap = 'round';\n    this.wireframeLinejoin = 'round';\n    this.flatShading = false;\n    this.fog = true;\n    this.setValues(parameters);\n  }\n  copy(source) {\n    super.copy(source);\n    this.defines = {\n      'STANDARD': ''\n    };\n    this.color.copy(source.color);\n    this.roughness = source.roughness;\n    this.metalness = source.metalness;\n    this.map = source.map;\n    this.lightMap = source.lightMap;\n    this.lightMapIntensity = source.lightMapIntensity;\n    this.aoMap = source.aoMap;\n    this.aoMapIntensity = source.aoMapIntensity;\n    this.emissive.copy(source.emissive);\n    this.emissiveMap = source.emissiveMap;\n    this.emissiveIntensity = source.emissiveIntensity;\n    this.bumpMap = source.bumpMap;\n    this.bumpScale = source.bumpScale;\n    this.normalMap = source.normalMap;\n    this.normalMapType = source.normalMapType;\n    this.normalScale.copy(source.normalScale);\n    this.displacementMap = source.displacementMap;\n    this.displacementScale = source.displacementScale;\n    this.displacementBias = source.displacementBias;\n    this.roughnessMap = source.roughnessMap;\n    this.metalnessMap = source.metalnessMap;\n    this.alphaMap = source.alphaMap;\n    this.envMap = source.envMap;\n    this.envMapRotation.copy(source.envMapRotation);\n    this.envMapIntensity = source.envMapIntensity;\n    this.wireframe = source.wireframe;\n    this.wireframeLinewidth = source.wireframeLinewidth;\n    this.wireframeLinecap = source.wireframeLinecap;\n    this.wireframeLinejoin = source.wireframeLinejoin;\n    this.flatShading = source.flatShading;\n    this.fog = source.fog;\n    return this;\n  }\n}\nclass MeshPhysicalMaterial extends MeshStandardMaterial {\n  constructor(parameters) {\n    super();\n    this.isMeshPhysicalMaterial = true;\n    this.defines = {\n      'STANDARD': '',\n      'PHYSICAL': ''\n    };\n    this.type = 'MeshPhysicalMaterial';\n    this.anisotropyRotation = 0;\n    this.anisotropyMap = null;\n    this.clearcoatMap = null;\n    this.clearcoatRoughness = 0.0;\n    this.clearcoatRoughnessMap = null;\n    this.clearcoatNormalScale = new Vector2(1, 1);\n    this.clearcoatNormalMap = null;\n    this.ior = 1.5;\n    Object.defineProperty(this, 'reflectivity', {\n      get: function () {\n        return clamp$1(2.5 * (this.ior - 1) / (this.ior + 1), 0, 1);\n      },\n      set: function (reflectivity) {\n        this.ior = (1 + 0.4 * reflectivity) / (1 - 0.4 * reflectivity);\n      }\n    });\n    this.iridescenceMap = null;\n    this.iridescenceIOR = 1.3;\n    this.iridescenceThicknessRange = [100, 400];\n    this.iridescenceThicknessMap = null;\n    this.sheenColor = new Color(0x000000);\n    this.sheenColorMap = null;\n    this.sheenRoughness = 1.0;\n    this.sheenRoughnessMap = null;\n    this.transmissionMap = null;\n    this.thickness = 0;\n    this.thicknessMap = null;\n    this.attenuationDistance = Infinity;\n    this.attenuationColor = new Color(1, 1, 1);\n    this.specularIntensity = 1.0;\n    this.specularIntensityMap = null;\n    this.specularColor = new Color(1, 1, 1);\n    this.specularColorMap = null;\n    this._anisotropy = 0;\n    this._clearcoat = 0;\n    this._dispersion = 0;\n    this._iridescence = 0;\n    this._sheen = 0.0;\n    this._transmission = 0;\n    this.setValues(parameters);\n  }\n  get anisotropy() {\n    return this._anisotropy;\n  }\n  set anisotropy(value) {\n    if (this._anisotropy > 0 !== value > 0) {\n      this.version++;\n    }\n    this._anisotropy = value;\n  }\n  get clearcoat() {\n    return this._clearcoat;\n  }\n  set clearcoat(value) {\n    if (this._clearcoat > 0 !== value > 0) {\n      this.version++;\n    }\n    this._clearcoat = value;\n  }\n  get iridescence() {\n    return this._iridescence;\n  }\n  set iridescence(value) {\n    if (this._iridescence > 0 !== value > 0) {\n      this.version++;\n    }\n    this._iridescence = value;\n  }\n  get dispersion() {\n    return this._dispersion;\n  }\n  set dispersion(value) {\n    if (this._dispersion > 0 !== value > 0) {\n      this.version++;\n    }\n    this._dispersion = value;\n  }\n  get sheen() {\n    return this._sheen;\n  }\n  set sheen(value) {\n    if (this._sheen > 0 !== value > 0) {\n      this.version++;\n    }\n    this._sheen = value;\n  }\n  get transmission() {\n    return this._transmission;\n  }\n  set transmission(value) {\n    if (this._transmission > 0 !== value > 0) {\n      this.version++;\n    }\n    this._transmission = value;\n  }\n  copy(source) {\n    super.copy(source);\n    this.defines = {\n      'STANDARD': '',\n      'PHYSICAL': ''\n    };\n    this.anisotropy = source.anisotropy;\n    this.anisotropyRotation = source.anisotropyRotation;\n    this.anisotropyMap = source.anisotropyMap;\n    this.clearcoat = source.clearcoat;\n    this.clearcoatMap = source.clearcoatMap;\n    this.clearcoatRoughness = source.clearcoatRoughness;\n    this.clearcoatRoughnessMap = source.clearcoatRoughnessMap;\n    this.clearcoatNormalMap = source.clearcoatNormalMap;\n    this.clearcoatNormalScale.copy(source.clearcoatNormalScale);\n    this.dispersion = source.dispersion;\n    this.ior = source.ior;\n    this.iridescence = source.iridescence;\n    this.iridescenceMap = source.iridescenceMap;\n    this.iridescenceIOR = source.iridescenceIOR;\n    this.iridescenceThicknessRange = [...source.iridescenceThicknessRange];\n    this.iridescenceThicknessMap = source.iridescenceThicknessMap;\n    this.sheen = source.sheen;\n    this.sheenColor.copy(source.sheenColor);\n    this.sheenColorMap = source.sheenColorMap;\n    this.sheenRoughness = source.sheenRoughness;\n    this.sheenRoughnessMap = source.sheenRoughnessMap;\n    this.transmission = source.transmission;\n    this.transmissionMap = source.transmissionMap;\n    this.thickness = source.thickness;\n    this.thicknessMap = source.thicknessMap;\n    this.attenuationDistance = source.attenuationDistance;\n    this.attenuationColor.copy(source.attenuationColor);\n    this.specularIntensity = source.specularIntensity;\n    this.specularIntensityMap = source.specularIntensityMap;\n    this.specularColor.copy(source.specularColor);\n    this.specularColorMap = source.specularColorMap;\n    return this;\n  }\n}\n\n// converts an array to a specific type\nfunction convertArray(array, type, forceClone) {\n  if (!array ||\n  // let 'undefined' and 'null' pass\n  !forceClone && array.constructor === type) return array;\n  if (typeof type.BYTES_PER_ELEMENT === 'number') {\n    return new type(array); // create typed array\n  }\n  return Array.prototype.slice.call(array); // create Array\n}\nfunction isTypedArray(object) {\n  return ArrayBuffer.isView(object) && !(object instanceof DataView);\n}\n\n// returns an array by which times and values can be sorted\nfunction getKeyframeOrder(times) {\n  function compareTime(i, j) {\n    return times[i] - times[j];\n  }\n  const n = times.length;\n  const result = new Array(n);\n  for (let i = 0; i !== n; ++i) result[i] = i;\n  result.sort(compareTime);\n  return result;\n}\n\n// uses the array previously returned by 'getKeyframeOrder' to sort data\nfunction sortedArray(values, stride, order) {\n  const nValues = values.length;\n  const result = new values.constructor(nValues);\n  for (let i = 0, dstOffset = 0; dstOffset !== nValues; ++i) {\n    const srcOffset = order[i] * stride;\n    for (let j = 0; j !== stride; ++j) {\n      result[dstOffset++] = values[srcOffset + j];\n    }\n  }\n  return result;\n}\n\n// function for parsing AOS keyframe formats\nfunction flattenJSON(jsonKeys, times, values, valuePropertyName) {\n  let i = 1,\n    key = jsonKeys[0];\n  while (key !== undefined && key[valuePropertyName] === undefined) {\n    key = jsonKeys[i++];\n  }\n  if (key === undefined) return; // no data\n\n  let value = key[valuePropertyName];\n  if (value === undefined) return; // no data\n\n  if (Array.isArray(value)) {\n    do {\n      value = key[valuePropertyName];\n      if (value !== undefined) {\n        times.push(key.time);\n        values.push.apply(values, value); // push all elements\n      }\n      key = jsonKeys[i++];\n    } while (key !== undefined);\n  } else if (value.toArray !== undefined) {\n    // ...assume THREE.Math-ish\n\n    do {\n      value = key[valuePropertyName];\n      if (value !== undefined) {\n        times.push(key.time);\n        value.toArray(values, values.length);\n      }\n      key = jsonKeys[i++];\n    } while (key !== undefined);\n  } else {\n    // otherwise push as-is\n\n    do {\n      value = key[valuePropertyName];\n      if (value !== undefined) {\n        times.push(key.time);\n        values.push(value);\n      }\n      key = jsonKeys[i++];\n    } while (key !== undefined);\n  }\n}\n\n/**\n * Abstract base class of interpolants over parametric samples.\n *\n * The parameter domain is one dimensional, typically the time or a path\n * along a curve defined by the data.\n *\n * The sample values can have any dimensionality and derived classes may\n * apply special interpretations to the data.\n *\n * This class provides the interval seek in a Template Method, deferring\n * the actual interpolation to derived classes.\n *\n * Time complexity is O(1) for linear access crossing at most two points\n * and O(log N) for random access, where N is the number of positions.\n *\n * References:\n *\n * \t\thttp://www.oodesign.com/template-method-pattern.html\n *\n */\n\nclass Interpolant {\n  constructor(parameterPositions, sampleValues, sampleSize, resultBuffer) {\n    this.parameterPositions = parameterPositions;\n    this._cachedIndex = 0;\n    this.resultBuffer = resultBuffer !== undefined ? resultBuffer : new sampleValues.constructor(sampleSize);\n    this.sampleValues = sampleValues;\n    this.valueSize = sampleSize;\n    this.settings = null;\n    this.DefaultSettings_ = {};\n  }\n  evaluate(t) {\n    const pp = this.parameterPositions;\n    let i1 = this._cachedIndex,\n      t1 = pp[i1],\n      t0 = pp[i1 - 1];\n    validate_interval: {\n      seek: {\n        let right;\n        linear_scan: {\n          //- See http://jsperf.com/comparison-to-undefined/3\n          //- slower code:\n          //-\n          //- \t\t\t\tif ( t >= t1 || t1 === undefined ) {\n          forward_scan: if (!(t < t1)) {\n            for (let giveUpAt = i1 + 2;;) {\n              if (t1 === undefined) {\n                if (t < t0) break forward_scan;\n\n                // after end\n\n                i1 = pp.length;\n                this._cachedIndex = i1;\n                return this.copySampleValue_(i1 - 1);\n              }\n              if (i1 === giveUpAt) break; // this loop\n\n              t0 = t1;\n              t1 = pp[++i1];\n              if (t < t1) {\n                // we have arrived at the sought interval\n                break seek;\n              }\n            }\n\n            // prepare binary search on the right side of the index\n            right = pp.length;\n            break linear_scan;\n          }\n\n          //- slower code:\n          //-\t\t\t\t\tif ( t < t0 || t0 === undefined ) {\n          if (!(t >= t0)) {\n            // looping?\n\n            const t1global = pp[1];\n            if (t < t1global) {\n              i1 = 2; // + 1, using the scan for the details\n              t0 = t1global;\n            }\n\n            // linear reverse scan\n\n            for (let giveUpAt = i1 - 2;;) {\n              if (t0 === undefined) {\n                // before start\n\n                this._cachedIndex = 0;\n                return this.copySampleValue_(0);\n              }\n              if (i1 === giveUpAt) break; // this loop\n\n              t1 = t0;\n              t0 = pp[--i1 - 1];\n              if (t >= t0) {\n                // we have arrived at the sought interval\n                break seek;\n              }\n            }\n\n            // prepare binary search on the left side of the index\n            right = i1;\n            i1 = 0;\n            break linear_scan;\n          }\n\n          // the interval is valid\n\n          break validate_interval;\n        } // linear scan\n\n        // binary search\n\n        while (i1 < right) {\n          const mid = i1 + right >>> 1;\n          if (t < pp[mid]) {\n            right = mid;\n          } else {\n            i1 = mid + 1;\n          }\n        }\n        t1 = pp[i1];\n        t0 = pp[i1 - 1];\n\n        // check boundary cases, again\n\n        if (t0 === undefined) {\n          this._cachedIndex = 0;\n          return this.copySampleValue_(0);\n        }\n        if (t1 === undefined) {\n          i1 = pp.length;\n          this._cachedIndex = i1;\n          return this.copySampleValue_(i1 - 1);\n        }\n      } // seek\n\n      this._cachedIndex = i1;\n      this.intervalChanged_(i1, t0, t1);\n    } // validate_interval\n\n    return this.interpolate_(i1, t0, t, t1);\n  }\n  getSettings_() {\n    return this.settings || this.DefaultSettings_;\n  }\n  copySampleValue_(index) {\n    // copies a sample value to the result buffer\n\n    const result = this.resultBuffer,\n      values = this.sampleValues,\n      stride = this.valueSize,\n      offset = index * stride;\n    for (let i = 0; i !== stride; ++i) {\n      result[i] = values[offset + i];\n    }\n    return result;\n  }\n\n  // Template methods for derived classes:\n\n  interpolate_(/* i1, t0, t, t1 */\n  ) {\n    throw new Error('call to abstract method');\n    // implementations shall return this.resultBuffer\n  }\n  intervalChanged_(/* i1, t0, t1 */\n  ) {\n\n    // empty\n  }\n}\n\n/**\n * Fast and simple cubic spline interpolant.\n *\n * It was derived from a Hermitian construction setting the first derivative\n * at each sample position to the linear slope between neighboring positions\n * over their parameter interval.\n */\n\nclass CubicInterpolant extends Interpolant {\n  constructor(parameterPositions, sampleValues, sampleSize, resultBuffer) {\n    super(parameterPositions, sampleValues, sampleSize, resultBuffer);\n    this._weightPrev = -0;\n    this._offsetPrev = -0;\n    this._weightNext = -0;\n    this._offsetNext = -0;\n    this.DefaultSettings_ = {\n      endingStart: ZeroCurvatureEnding,\n      endingEnd: ZeroCurvatureEnding\n    };\n  }\n  intervalChanged_(i1, t0, t1) {\n    const pp = this.parameterPositions;\n    let iPrev = i1 - 2,\n      iNext = i1 + 1,\n      tPrev = pp[iPrev],\n      tNext = pp[iNext];\n    if (tPrev === undefined) {\n      switch (this.getSettings_().endingStart) {\n        case ZeroSlopeEnding:\n          // f'(t0) = 0\n          iPrev = i1;\n          tPrev = 2 * t0 - t1;\n          break;\n        case WrapAroundEnding:\n          // use the other end of the curve\n          iPrev = pp.length - 2;\n          tPrev = t0 + pp[iPrev] - pp[iPrev + 1];\n          break;\n        default:\n          // ZeroCurvatureEnding\n\n          // f''(t0) = 0 a.k.a. Natural Spline\n          iPrev = i1;\n          tPrev = t1;\n      }\n    }\n    if (tNext === undefined) {\n      switch (this.getSettings_().endingEnd) {\n        case ZeroSlopeEnding:\n          // f'(tN) = 0\n          iNext = i1;\n          tNext = 2 * t1 - t0;\n          break;\n        case WrapAroundEnding:\n          // use the other end of the curve\n          iNext = 1;\n          tNext = t1 + pp[1] - pp[0];\n          break;\n        default:\n          // ZeroCurvatureEnding\n\n          // f''(tN) = 0, a.k.a. Natural Spline\n          iNext = i1 - 1;\n          tNext = t0;\n      }\n    }\n    const halfDt = (t1 - t0) * 0.5,\n      stride = this.valueSize;\n    this._weightPrev = halfDt / (t0 - tPrev);\n    this._weightNext = halfDt / (tNext - t1);\n    this._offsetPrev = iPrev * stride;\n    this._offsetNext = iNext * stride;\n  }\n  interpolate_(i1, t0, t, t1) {\n    const result = this.resultBuffer,\n      values = this.sampleValues,\n      stride = this.valueSize,\n      o1 = i1 * stride,\n      o0 = o1 - stride,\n      oP = this._offsetPrev,\n      oN = this._offsetNext,\n      wP = this._weightPrev,\n      wN = this._weightNext,\n      p = (t - t0) / (t1 - t0),\n      pp = p * p,\n      ppp = pp * p;\n\n    // evaluate polynomials\n\n    const sP = -wP * ppp + 2 * wP * pp - wP * p;\n    const s0 = (1 + wP) * ppp + (-1.5 - 2 * wP) * pp + (-0.5 + wP) * p + 1;\n    const s1 = (-1 - wN) * ppp + (1.5 + wN) * pp + 0.5 * p;\n    const sN = wN * ppp - wN * pp;\n\n    // combine data linearly\n\n    for (let i = 0; i !== stride; ++i) {\n      result[i] = sP * values[oP + i] + s0 * values[o0 + i] + s1 * values[o1 + i] + sN * values[oN + i];\n    }\n    return result;\n  }\n}\nclass LinearInterpolant extends Interpolant {\n  constructor(parameterPositions, sampleValues, sampleSize, resultBuffer) {\n    super(parameterPositions, sampleValues, sampleSize, resultBuffer);\n  }\n  interpolate_(i1, t0, t, t1) {\n    const result = this.resultBuffer,\n      values = this.sampleValues,\n      stride = this.valueSize,\n      offset1 = i1 * stride,\n      offset0 = offset1 - stride,\n      weight1 = (t - t0) / (t1 - t0),\n      weight0 = 1 - weight1;\n    for (let i = 0; i !== stride; ++i) {\n      result[i] = values[offset0 + i] * weight0 + values[offset1 + i] * weight1;\n    }\n    return result;\n  }\n}\n\n/**\n *\n * Interpolant that evaluates to the sample value at the position preceding\n * the parameter.\n */\n\nclass DiscreteInterpolant extends Interpolant {\n  constructor(parameterPositions, sampleValues, sampleSize, resultBuffer) {\n    super(parameterPositions, sampleValues, sampleSize, resultBuffer);\n  }\n  interpolate_(i1 /*, t0, t, t1 */) {\n    return this.copySampleValue_(i1 - 1);\n  }\n}\nclass KeyframeTrack {\n  constructor(name, times, values, interpolation) {\n    if (name === undefined) throw new Error('THREE.KeyframeTrack: track name is undefined');\n    if (times === undefined || times.length === 0) throw new Error('THREE.KeyframeTrack: no keyframes in track named ' + name);\n    this.name = name;\n    this.times = convertArray(times, this.TimeBufferType);\n    this.values = convertArray(values, this.ValueBufferType);\n    this.setInterpolation(interpolation || this.DefaultInterpolation);\n  }\n\n  // Serialization (in static context, because of constructor invocation\n  // and automatic invocation of .toJSON):\n\n  static toJSON(track) {\n    const trackType = track.constructor;\n    let json;\n\n    // derived classes can define a static toJSON method\n    if (trackType.toJSON !== this.toJSON) {\n      json = trackType.toJSON(track);\n    } else {\n      // by default, we assume the data can be serialized as-is\n      json = {\n        'name': track.name,\n        'times': convertArray(track.times, Array),\n        'values': convertArray(track.values, Array)\n      };\n      const interpolation = track.getInterpolation();\n      if (interpolation !== track.DefaultInterpolation) {\n        json.interpolation = interpolation;\n      }\n    }\n    json.type = track.ValueTypeName; // mandatory\n\n    return json;\n  }\n  InterpolantFactoryMethodDiscrete(result) {\n    return new DiscreteInterpolant(this.times, this.values, this.getValueSize(), result);\n  }\n  InterpolantFactoryMethodLinear(result) {\n    return new LinearInterpolant(this.times, this.values, this.getValueSize(), result);\n  }\n  InterpolantFactoryMethodSmooth(result) {\n    return new CubicInterpolant(this.times, this.values, this.getValueSize(), result);\n  }\n  setInterpolation(interpolation) {\n    let factoryMethod;\n    switch (interpolation) {\n      case InterpolateDiscrete:\n        factoryMethod = this.InterpolantFactoryMethodDiscrete;\n        break;\n      case InterpolateLinear:\n        factoryMethod = this.InterpolantFactoryMethodLinear;\n        break;\n      case InterpolateSmooth:\n        factoryMethod = this.InterpolantFactoryMethodSmooth;\n        break;\n    }\n    if (factoryMethod === undefined) {\n      const message = 'unsupported interpolation for ' + this.ValueTypeName + ' keyframe track named ' + this.name;\n      if (this.createInterpolant === undefined) {\n        // fall back to default, unless the default itself is messed up\n        if (interpolation !== this.DefaultInterpolation) {\n          this.setInterpolation(this.DefaultInterpolation);\n        } else {\n          throw new Error(message); // fatal, in this case\n        }\n      }\n      console.warn('THREE.KeyframeTrack:', message);\n      return this;\n    }\n    this.createInterpolant = factoryMethod;\n    return this;\n  }\n  getInterpolation() {\n    switch (this.createInterpolant) {\n      case this.InterpolantFactoryMethodDiscrete:\n        return InterpolateDiscrete;\n      case this.InterpolantFactoryMethodLinear:\n        return InterpolateLinear;\n      case this.InterpolantFactoryMethodSmooth:\n        return InterpolateSmooth;\n    }\n  }\n  getValueSize() {\n    return this.values.length / this.times.length;\n  }\n\n  // move all keyframes either forwards or backwards in time\n  shift(timeOffset) {\n    if (timeOffset !== 0.0) {\n      const times = this.times;\n      for (let i = 0, n = times.length; i !== n; ++i) {\n        times[i] += timeOffset;\n      }\n    }\n    return this;\n  }\n\n  // scale all keyframe times by a factor (useful for frame <-> seconds conversions)\n  scale(timeScale) {\n    if (timeScale !== 1.0) {\n      const times = this.times;\n      for (let i = 0, n = times.length; i !== n; ++i) {\n        times[i] *= timeScale;\n      }\n    }\n    return this;\n  }\n\n  // removes keyframes before and after animation without changing any values within the range [startTime, endTime].\n  // IMPORTANT: We do not shift around keys to the start of the track time, because for interpolated keys this will change their values\n  trim(startTime, endTime) {\n    const times = this.times,\n      nKeys = times.length;\n    let from = 0,\n      to = nKeys - 1;\n    while (from !== nKeys && times[from] < startTime) {\n      ++from;\n    }\n    while (to !== -1 && times[to] > endTime) {\n      --to;\n    }\n    ++to; // inclusive -> exclusive bound\n\n    if (from !== 0 || to !== nKeys) {\n      // empty tracks are forbidden, so keep at least one keyframe\n      if (from >= to) {\n        to = Math.max(to, 1);\n        from = to - 1;\n      }\n      const stride = this.getValueSize();\n      this.times = times.slice(from, to);\n      this.values = this.values.slice(from * stride, to * stride);\n    }\n    return this;\n  }\n\n  // ensure we do not get a GarbageInGarbageOut situation, make sure tracks are at least minimally viable\n  validate() {\n    let valid = true;\n    const valueSize = this.getValueSize();\n    if (valueSize - Math.floor(valueSize) !== 0) {\n      console.error('THREE.KeyframeTrack: Invalid value size in track.', this);\n      valid = false;\n    }\n    const times = this.times,\n      values = this.values,\n      nKeys = times.length;\n    if (nKeys === 0) {\n      console.error('THREE.KeyframeTrack: Track is empty.', this);\n      valid = false;\n    }\n    let prevTime = null;\n    for (let i = 0; i !== nKeys; i++) {\n      const currTime = times[i];\n      if (typeof currTime === 'number' && isNaN(currTime)) {\n        console.error('THREE.KeyframeTrack: Time is not a valid number.', this, i, currTime);\n        valid = false;\n        break;\n      }\n      if (prevTime !== null && prevTime > currTime) {\n        console.error('THREE.KeyframeTrack: Out of order keys.', this, i, currTime, prevTime);\n        valid = false;\n        break;\n      }\n      prevTime = currTime;\n    }\n    if (values !== undefined) {\n      if (isTypedArray(values)) {\n        for (let i = 0, n = values.length; i !== n; ++i) {\n          const value = values[i];\n          if (isNaN(value)) {\n            console.error('THREE.KeyframeTrack: Value is not a valid number.', this, i, value);\n            valid = false;\n            break;\n          }\n        }\n      }\n    }\n    return valid;\n  }\n\n  // removes equivalent sequential keys as common in morph target sequences\n  // (0,0,0,0,1,1,1,0,0,0,0,0,0,0) --> (0,0,1,1,0,0)\n  optimize() {\n    // times or values may be shared with other tracks, so overwriting is unsafe\n    const times = this.times.slice(),\n      values = this.values.slice(),\n      stride = this.getValueSize(),\n      smoothInterpolation = this.getInterpolation() === InterpolateSmooth,\n      lastIndex = times.length - 1;\n    let writeIndex = 1;\n    for (let i = 1; i < lastIndex; ++i) {\n      let keep = false;\n      const time = times[i];\n      const timeNext = times[i + 1];\n\n      // remove adjacent keyframes scheduled at the same time\n\n      if (time !== timeNext && (i !== 1 || time !== times[0])) {\n        if (!smoothInterpolation) {\n          // remove unnecessary keyframes same as their neighbors\n\n          const offset = i * stride,\n            offsetP = offset - stride,\n            offsetN = offset + stride;\n          for (let j = 0; j !== stride; ++j) {\n            const value = values[offset + j];\n            if (value !== values[offsetP + j] || value !== values[offsetN + j]) {\n              keep = true;\n              break;\n            }\n          }\n        } else {\n          keep = true;\n        }\n      }\n\n      // in-place compaction\n\n      if (keep) {\n        if (i !== writeIndex) {\n          times[writeIndex] = times[i];\n          const readOffset = i * stride,\n            writeOffset = writeIndex * stride;\n          for (let j = 0; j !== stride; ++j) {\n            values[writeOffset + j] = values[readOffset + j];\n          }\n        }\n        ++writeIndex;\n      }\n    }\n\n    // flush last keyframe (compaction looks ahead)\n\n    if (lastIndex > 0) {\n      times[writeIndex] = times[lastIndex];\n      for (let readOffset = lastIndex * stride, writeOffset = writeIndex * stride, j = 0; j !== stride; ++j) {\n        values[writeOffset + j] = values[readOffset + j];\n      }\n      ++writeIndex;\n    }\n    if (writeIndex !== times.length) {\n      this.times = times.slice(0, writeIndex);\n      this.values = values.slice(0, writeIndex * stride);\n    } else {\n      this.times = times;\n      this.values = values;\n    }\n    return this;\n  }\n  clone() {\n    const times = this.times.slice();\n    const values = this.values.slice();\n    const TypedKeyframeTrack = this.constructor;\n    const track = new TypedKeyframeTrack(this.name, times, values);\n\n    // Interpolant argument to constructor is not saved, so copy the factory method directly.\n    track.createInterpolant = this.createInterpolant;\n    return track;\n  }\n}\nKeyframeTrack.prototype.TimeBufferType = Float32Array;\nKeyframeTrack.prototype.ValueBufferType = Float32Array;\nKeyframeTrack.prototype.DefaultInterpolation = InterpolateLinear;\n\n/**\n * A Track of Boolean keyframe values.\n */\nclass BooleanKeyframeTrack extends KeyframeTrack {\n  // No interpolation parameter because only InterpolateDiscrete is valid.\n  constructor(name, times, values) {\n    super(name, times, values);\n  }\n}\nBooleanKeyframeTrack.prototype.ValueTypeName = 'bool';\nBooleanKeyframeTrack.prototype.ValueBufferType = Array;\nBooleanKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;\nBooleanKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;\nBooleanKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;\n\n/**\n * A Track of keyframe values that represent color.\n */\nclass ColorKeyframeTrack extends KeyframeTrack {}\nColorKeyframeTrack.prototype.ValueTypeName = 'color';\n\n/**\n * A Track of numeric keyframe values.\n */\nclass NumberKeyframeTrack extends KeyframeTrack {}\nNumberKeyframeTrack.prototype.ValueTypeName = 'number';\n\n/**\n * Spherical linear unit quaternion interpolant.\n */\n\nclass QuaternionLinearInterpolant extends Interpolant {\n  constructor(parameterPositions, sampleValues, sampleSize, resultBuffer) {\n    super(parameterPositions, sampleValues, sampleSize, resultBuffer);\n  }\n  interpolate_(i1, t0, t, t1) {\n    const result = this.resultBuffer,\n      values = this.sampleValues,\n      stride = this.valueSize,\n      alpha = (t - t0) / (t1 - t0);\n    let offset = i1 * stride;\n    for (let end = offset + stride; offset !== end; offset += 4) {\n      Quaternion.slerpFlat(result, 0, values, offset - stride, values, offset, alpha);\n    }\n    return result;\n  }\n}\n\n/**\n * A Track of quaternion keyframe values.\n */\nclass QuaternionKeyframeTrack extends KeyframeTrack {\n  InterpolantFactoryMethodLinear(result) {\n    return new QuaternionLinearInterpolant(this.times, this.values, this.getValueSize(), result);\n  }\n}\nQuaternionKeyframeTrack.prototype.ValueTypeName = 'quaternion';\n// ValueBufferType is inherited\n// DefaultInterpolation is inherited;\nQuaternionKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;\n\n/**\n * A Track that interpolates Strings\n */\nclass StringKeyframeTrack extends KeyframeTrack {\n  // No interpolation parameter because only InterpolateDiscrete is valid.\n  constructor(name, times, values) {\n    super(name, times, values);\n  }\n}\nStringKeyframeTrack.prototype.ValueTypeName = 'string';\nStringKeyframeTrack.prototype.ValueBufferType = Array;\nStringKeyframeTrack.prototype.DefaultInterpolation = InterpolateDiscrete;\nStringKeyframeTrack.prototype.InterpolantFactoryMethodLinear = undefined;\nStringKeyframeTrack.prototype.InterpolantFactoryMethodSmooth = undefined;\n\n/**\n * A Track of vectored keyframe values.\n */\nclass VectorKeyframeTrack extends KeyframeTrack {}\nVectorKeyframeTrack.prototype.ValueTypeName = 'vector';\nclass AnimationClip {\n  constructor(name = '', duration = -1, tracks = [], blendMode = NormalAnimationBlendMode) {\n    this.name = name;\n    this.tracks = tracks;\n    this.duration = duration;\n    this.blendMode = blendMode;\n    this.uuid = generateUUID();\n\n    // this means it should figure out its duration by scanning the tracks\n    if (this.duration < 0) {\n      this.resetDuration();\n    }\n  }\n  static parse(json) {\n    const tracks = [],\n      jsonTracks = json.tracks,\n      frameTime = 1.0 / (json.fps || 1.0);\n    for (let i = 0, n = jsonTracks.length; i !== n; ++i) {\n      tracks.push(parseKeyframeTrack(jsonTracks[i]).scale(frameTime));\n    }\n    const clip = new this(json.name, json.duration, tracks, json.blendMode);\n    clip.uuid = json.uuid;\n    return clip;\n  }\n  static toJSON(clip) {\n    const tracks = [],\n      clipTracks = clip.tracks;\n    const json = {\n      'name': clip.name,\n      'duration': clip.duration,\n      'tracks': tracks,\n      'uuid': clip.uuid,\n      'blendMode': clip.blendMode\n    };\n    for (let i = 0, n = clipTracks.length; i !== n; ++i) {\n      tracks.push(KeyframeTrack.toJSON(clipTracks[i]));\n    }\n    return json;\n  }\n  static CreateFromMorphTargetSequence(name, morphTargetSequence, fps, noLoop) {\n    const numMorphTargets = morphTargetSequence.length;\n    const tracks = [];\n    for (let i = 0; i < numMorphTargets; i++) {\n      let times = [];\n      let values = [];\n      times.push((i + numMorphTargets - 1) % numMorphTargets, i, (i + 1) % numMorphTargets);\n      values.push(0, 1, 0);\n      const order = getKeyframeOrder(times);\n      times = sortedArray(times, 1, order);\n      values = sortedArray(values, 1, order);\n\n      // if there is a key at the first frame, duplicate it as the\n      // last frame as well for perfect loop.\n      if (!noLoop && times[0] === 0) {\n        times.push(numMorphTargets);\n        values.push(values[0]);\n      }\n      tracks.push(new NumberKeyframeTrack('.morphTargetInfluences[' + morphTargetSequence[i].name + ']', times, values).scale(1.0 / fps));\n    }\n    return new this(name, -1, tracks);\n  }\n  static findByName(objectOrClipArray, name) {\n    let clipArray = objectOrClipArray;\n    if (!Array.isArray(objectOrClipArray)) {\n      const o = objectOrClipArray;\n      clipArray = o.geometry && o.geometry.animations || o.animations;\n    }\n    for (let i = 0; i < clipArray.length; i++) {\n      if (clipArray[i].name === name) {\n        return clipArray[i];\n      }\n    }\n    return null;\n  }\n  static CreateClipsFromMorphTargetSequences(morphTargets, fps, noLoop) {\n    const animationToMorphTargets = {};\n\n    // tested with https://regex101.com/ on trick sequences\n    // such flamingo_flyA_003, flamingo_run1_003, crdeath0059\n    const pattern = /^([\\w-]*?)([\\d]+)$/;\n\n    // sort morph target names into animation groups based\n    // patterns like Walk_001, Walk_002, Run_001, Run_002\n    for (let i = 0, il = morphTargets.length; i < il; i++) {\n      const morphTarget = morphTargets[i];\n      const parts = morphTarget.name.match(pattern);\n      if (parts && parts.length > 1) {\n        const name = parts[1];\n        let animationMorphTargets = animationToMorphTargets[name];\n        if (!animationMorphTargets) {\n          animationToMorphTargets[name] = animationMorphTargets = [];\n        }\n        animationMorphTargets.push(morphTarget);\n      }\n    }\n    const clips = [];\n    for (const name in animationToMorphTargets) {\n      clips.push(this.CreateFromMorphTargetSequence(name, animationToMorphTargets[name], fps, noLoop));\n    }\n    return clips;\n  }\n\n  // parse the animation.hierarchy format\n  static parseAnimation(animation, bones) {\n    if (!animation) {\n      console.error('THREE.AnimationClip: No animation in JSONLoader data.');\n      return null;\n    }\n    const addNonemptyTrack = function (trackType, trackName, animationKeys, propertyName, destTracks) {\n      // only return track if there are actually keys.\n      if (animationKeys.length !== 0) {\n        const times = [];\n        const values = [];\n        flattenJSON(animationKeys, times, values, propertyName);\n\n        // empty keys are filtered out, so check again\n        if (times.length !== 0) {\n          destTracks.push(new trackType(trackName, times, values));\n        }\n      }\n    };\n    const tracks = [];\n    const clipName = animation.name || 'default';\n    const fps = animation.fps || 30;\n    const blendMode = animation.blendMode;\n\n    // automatic length determination in AnimationClip.\n    let duration = animation.length || -1;\n    const hierarchyTracks = animation.hierarchy || [];\n    for (let h = 0; h < hierarchyTracks.length; h++) {\n      const animationKeys = hierarchyTracks[h].keys;\n\n      // skip empty tracks\n      if (!animationKeys || animationKeys.length === 0) continue;\n\n      // process morph targets\n      if (animationKeys[0].morphTargets) {\n        // figure out all morph targets used in this track\n        const morphTargetNames = {};\n        let k;\n        for (k = 0; k < animationKeys.length; k++) {\n          if (animationKeys[k].morphTargets) {\n            for (let m = 0; m < animationKeys[k].morphTargets.length; m++) {\n              morphTargetNames[animationKeys[k].morphTargets[m]] = -1;\n            }\n          }\n        }\n\n        // create a track for each morph target with all zero\n        // morphTargetInfluences except for the keys in which\n        // the morphTarget is named.\n        for (const morphTargetName in morphTargetNames) {\n          const times = [];\n          const values = [];\n          for (let m = 0; m !== animationKeys[k].morphTargets.length; ++m) {\n            const animationKey = animationKeys[k];\n            times.push(animationKey.time);\n            values.push(animationKey.morphTarget === morphTargetName ? 1 : 0);\n          }\n          tracks.push(new NumberKeyframeTrack('.morphTargetInfluence[' + morphTargetName + ']', times, values));\n        }\n        duration = morphTargetNames.length * fps;\n      } else {\n        // ...assume skeletal animation\n\n        const boneName = '.bones[' + bones[h].name + ']';\n        addNonemptyTrack(VectorKeyframeTrack, boneName + '.position', animationKeys, 'pos', tracks);\n        addNonemptyTrack(QuaternionKeyframeTrack, boneName + '.quaternion', animationKeys, 'rot', tracks);\n        addNonemptyTrack(VectorKeyframeTrack, boneName + '.scale', animationKeys, 'scl', tracks);\n      }\n    }\n    if (tracks.length === 0) {\n      return null;\n    }\n    const clip = new this(clipName, duration, tracks, blendMode);\n    return clip;\n  }\n  resetDuration() {\n    const tracks = this.tracks;\n    let duration = 0;\n    for (let i = 0, n = tracks.length; i !== n; ++i) {\n      const track = this.tracks[i];\n      duration = Math.max(duration, track.times[track.times.length - 1]);\n    }\n    this.duration = duration;\n    return this;\n  }\n  trim() {\n    for (let i = 0; i < this.tracks.length; i++) {\n      this.tracks[i].trim(0, this.duration);\n    }\n    return this;\n  }\n  validate() {\n    let valid = true;\n    for (let i = 0; i < this.tracks.length; i++) {\n      valid = valid && this.tracks[i].validate();\n    }\n    return valid;\n  }\n  optimize() {\n    for (let i = 0; i < this.tracks.length; i++) {\n      this.tracks[i].optimize();\n    }\n    return this;\n  }\n  clone() {\n    const tracks = [];\n    for (let i = 0; i < this.tracks.length; i++) {\n      tracks.push(this.tracks[i].clone());\n    }\n    return new this.constructor(this.name, this.duration, tracks, this.blendMode);\n  }\n  toJSON() {\n    return this.constructor.toJSON(this);\n  }\n}\nfunction getTrackTypeForValueTypeName(typeName) {\n  switch (typeName.toLowerCase()) {\n    case 'scalar':\n    case 'double':\n    case 'float':\n    case 'number':\n    case 'integer':\n      return NumberKeyframeTrack;\n    case 'vector':\n    case 'vector2':\n    case 'vector3':\n    case 'vector4':\n      return VectorKeyframeTrack;\n    case 'color':\n      return ColorKeyframeTrack;\n    case 'quaternion':\n      return QuaternionKeyframeTrack;\n    case 'bool':\n    case 'boolean':\n      return BooleanKeyframeTrack;\n    case 'string':\n      return StringKeyframeTrack;\n  }\n  throw new Error('THREE.KeyframeTrack: Unsupported typeName: ' + typeName);\n}\nfunction parseKeyframeTrack(json) {\n  if (json.type === undefined) {\n    throw new Error('THREE.KeyframeTrack: track type undefined, can not parse');\n  }\n  const trackType = getTrackTypeForValueTypeName(json.type);\n  if (json.times === undefined) {\n    const times = [],\n      values = [];\n    flattenJSON(json.keys, times, values, 'value');\n    json.times = times;\n    json.values = values;\n  }\n\n  // derived classes can define a static parse method\n  if (trackType.parse !== undefined) {\n    return trackType.parse(json);\n  } else {\n    // by default, we assume a constructor compatible with the base\n    return new trackType(json.name, json.times, json.values, json.interpolation);\n  }\n}\nconst Cache = {\n  enabled: false,\n  files: {},\n  add: function (key, file) {\n    if (this.enabled === false) return;\n\n    // console.log( 'THREE.Cache', 'Adding key:', key );\n\n    this.files[key] = file;\n  },\n  get: function (key) {\n    if (this.enabled === false) return;\n\n    // console.log( 'THREE.Cache', 'Checking key:', key );\n\n    return this.files[key];\n  },\n  remove: function (key) {\n    delete this.files[key];\n  },\n  clear: function () {\n    this.files = {};\n  }\n};\nclass LoadingManager {\n  constructor(onLoad, onProgress, onError) {\n    const scope = this;\n    let isLoading = false;\n    let itemsLoaded = 0;\n    let itemsTotal = 0;\n    let urlModifier = undefined;\n    const handlers = [];\n\n    // Refer to #5689 for the reason why we don't set .onStart\n    // in the constructor\n\n    this.onStart = undefined;\n    this.onLoad = onLoad;\n    this.onProgress = onProgress;\n    this.onError = onError;\n    this.itemStart = function (url) {\n      itemsTotal++;\n      if (isLoading === false) {\n        if (scope.onStart !== undefined) {\n          scope.onStart(url, itemsLoaded, itemsTotal);\n        }\n      }\n      isLoading = true;\n    };\n    this.itemEnd = function (url) {\n      itemsLoaded++;\n      if (scope.onProgress !== undefined) {\n        scope.onProgress(url, itemsLoaded, itemsTotal);\n      }\n      if (itemsLoaded === itemsTotal) {\n        isLoading = false;\n        if (scope.onLoad !== undefined) {\n          scope.onLoad();\n        }\n      }\n    };\n    this.itemError = function (url) {\n      if (scope.onError !== undefined) {\n        scope.onError(url);\n      }\n    };\n    this.resolveURL = function (url) {\n      if (urlModifier) {\n        return urlModifier(url);\n      }\n      return url;\n    };\n    this.setURLModifier = function (transform) {\n      urlModifier = transform;\n      return this;\n    };\n    this.addHandler = function (regex, loader) {\n      handlers.push(regex, loader);\n      return this;\n    };\n    this.removeHandler = function (regex) {\n      const index = handlers.indexOf(regex);\n      if (index !== -1) {\n        handlers.splice(index, 2);\n      }\n      return this;\n    };\n    this.getHandler = function (file) {\n      for (let i = 0, l = handlers.length; i < l; i += 2) {\n        const regex = handlers[i];\n        const loader = handlers[i + 1];\n        if (regex.global) regex.lastIndex = 0; // see #17920\n\n        if (regex.test(file)) {\n          return loader;\n        }\n      }\n      return null;\n    };\n  }\n}\nconst DefaultLoadingManager = /*@__PURE__*/new LoadingManager();\nclass Loader {\n  constructor(manager) {\n    this.manager = manager !== undefined ? manager : DefaultLoadingManager;\n    this.crossOrigin = 'anonymous';\n    this.withCredentials = false;\n    this.path = '';\n    this.resourcePath = '';\n    this.requestHeader = {};\n  }\n  load(/* url, onLoad, onProgress, onError */) {}\n  loadAsync(url, onProgress) {\n    const scope = this;\n    return new Promise(function (resolve, reject) {\n      scope.load(url, resolve, onProgress, reject);\n    });\n  }\n  parse(/* data */) {}\n  setCrossOrigin(crossOrigin) {\n    this.crossOrigin = crossOrigin;\n    return this;\n  }\n  setWithCredentials(value) {\n    this.withCredentials = value;\n    return this;\n  }\n  setPath(path) {\n    this.path = path;\n    return this;\n  }\n  setResourcePath(resourcePath) {\n    this.resourcePath = resourcePath;\n    return this;\n  }\n  setRequestHeader(requestHeader) {\n    this.requestHeader = requestHeader;\n    return this;\n  }\n}\nLoader.DEFAULT_MATERIAL_NAME = '__DEFAULT';\nconst loading = {};\nclass HttpError extends Error {\n  constructor(message, response) {\n    super(message);\n    this.response = response;\n  }\n}\nclass FileLoader extends Loader {\n  constructor(manager) {\n    super(manager);\n  }\n  load(url, onLoad, onProgress, onError) {\n    if (url === undefined) url = '';\n    if (this.path !== undefined) url = this.path + url;\n    url = this.manager.resolveURL(url);\n    const cached = Cache.get(url);\n    if (cached !== undefined) {\n      this.manager.itemStart(url);\n      setTimeout(() => {\n        if (onLoad) onLoad(cached);\n        this.manager.itemEnd(url);\n      }, 0);\n      return cached;\n    }\n\n    // Check if request is duplicate\n\n    if (loading[url] !== undefined) {\n      loading[url].push({\n        onLoad: onLoad,\n        onProgress: onProgress,\n        onError: onError\n      });\n      return;\n    }\n\n    // Initialise array for duplicate requests\n    loading[url] = [];\n    loading[url].push({\n      onLoad: onLoad,\n      onProgress: onProgress,\n      onError: onError\n    });\n\n    // create request\n    const req = new Request(url, {\n      headers: new Headers(this.requestHeader),\n      credentials: this.withCredentials ? 'include' : 'same-origin'\n      // An abort controller could be added within a future PR\n    });\n\n    // record states ( avoid data race )\n    const mimeType = this.mimeType;\n    const responseType = this.responseType;\n\n    // start the fetch\n    fetch(req).then(response => {\n      if (response.status === 200 || response.status === 0) {\n        // Some browsers return HTTP Status 0 when using non-http protocol\n        // e.g. 'file://' or 'data://'. Handle as success.\n\n        if (response.status === 0) {\n          console.warn('THREE.FileLoader: HTTP Status 0 received.');\n        }\n\n        // Workaround: Checking if response.body === undefined for Alipay browser #23548\n\n        if (typeof ReadableStream === 'undefined' || response.body === undefined || response.body.getReader === undefined) {\n          return response;\n        }\n        const callbacks = loading[url];\n        const reader = response.body.getReader();\n\n        // Nginx needs X-File-Size check\n        // https://serverfault.com/questions/482875/why-does-nginx-remove-content-length-header-for-chunked-content\n        const contentLength = response.headers.get('X-File-Size') || response.headers.get('Content-Length');\n        const total = contentLength ? parseInt(contentLength) : 0;\n        const lengthComputable = total !== 0;\n        let loaded = 0;\n\n        // periodically read data into the new stream tracking while download progress\n        const stream = new ReadableStream({\n          start(controller) {\n            readData();\n            function readData() {\n              reader.read().then(({\n                done,\n                value\n              }) => {\n                if (done) {\n                  controller.close();\n                } else {\n                  loaded += value.byteLength;\n                  const event = new ProgressEvent('progress', {\n                    lengthComputable,\n                    loaded,\n                    total\n                  });\n                  for (let i = 0, il = callbacks.length; i < il; i++) {\n                    const callback = callbacks[i];\n                    if (callback.onProgress) callback.onProgress(event);\n                  }\n                  controller.enqueue(value);\n                  readData();\n                }\n              }, e => {\n                controller.error(e);\n              });\n            }\n          }\n        });\n        return new Response(stream);\n      } else {\n        throw new HttpError(`fetch for \"${response.url}\" responded with ${response.status}: ${response.statusText}`, response);\n      }\n    }).then(response => {\n      switch (responseType) {\n        case 'arraybuffer':\n          return response.arrayBuffer();\n        case 'blob':\n          return response.blob();\n        case 'document':\n          return response.text().then(text => {\n            const parser = new DOMParser();\n            return parser.parseFromString(text, mimeType);\n          });\n        case 'json':\n          return response.json();\n        default:\n          if (mimeType === undefined) {\n            return response.text();\n          } else {\n            // sniff encoding\n            const re = /charset=\"?([^;\"\\s]*)\"?/i;\n            const exec = re.exec(mimeType);\n            const label = exec && exec[1] ? exec[1].toLowerCase() : undefined;\n            const decoder = new TextDecoder(label);\n            return response.arrayBuffer().then(ab => decoder.decode(ab));\n          }\n      }\n    }).then(data => {\n      // Add to cache only on HTTP success, so that we do not cache\n      // error response bodies as proper responses to requests.\n      Cache.add(url, data);\n      const callbacks = loading[url];\n      delete loading[url];\n      for (let i = 0, il = callbacks.length; i < il; i++) {\n        const callback = callbacks[i];\n        if (callback.onLoad) callback.onLoad(data);\n      }\n    }).catch(err => {\n      // Abort errors and other errors are handled the same\n\n      const callbacks = loading[url];\n      if (callbacks === undefined) {\n        // When onLoad was called and url was deleted in `loading`\n        this.manager.itemError(url);\n        throw err;\n      }\n      delete loading[url];\n      for (let i = 0, il = callbacks.length; i < il; i++) {\n        const callback = callbacks[i];\n        if (callback.onError) callback.onError(err);\n      }\n      this.manager.itemError(url);\n    }).finally(() => {\n      this.manager.itemEnd(url);\n    });\n    this.manager.itemStart(url);\n  }\n  setResponseType(value) {\n    this.responseType = value;\n    return this;\n  }\n  setMimeType(value) {\n    this.mimeType = value;\n    return this;\n  }\n}\nclass ImageLoader extends Loader {\n  constructor(manager) {\n    super(manager);\n  }\n  load(url, onLoad, onProgress, onError) {\n    if (this.path !== undefined) url = this.path + url;\n    url = this.manager.resolveURL(url);\n    const scope = this;\n    const cached = Cache.get(url);\n    if (cached !== undefined) {\n      scope.manager.itemStart(url);\n      setTimeout(function () {\n        if (onLoad) onLoad(cached);\n        scope.manager.itemEnd(url);\n      }, 0);\n      return cached;\n    }\n    const image = createElementNS('img');\n    function onImageLoad() {\n      removeEventListeners();\n      Cache.add(url, this);\n      if (onLoad) onLoad(this);\n      scope.manager.itemEnd(url);\n    }\n    function onImageError(event) {\n      removeEventListeners();\n      if (onError) onError(event);\n      scope.manager.itemError(url);\n      scope.manager.itemEnd(url);\n    }\n    function removeEventListeners() {\n      image.removeEventListener('load', onImageLoad, false);\n      image.removeEventListener('error', onImageError, false);\n    }\n    image.addEventListener('load', onImageLoad, false);\n    image.addEventListener('error', onImageError, false);\n    if (url.slice(0, 5) !== 'data:') {\n      if (this.crossOrigin !== undefined) image.crossOrigin = this.crossOrigin;\n    }\n    scope.manager.itemStart(url);\n    image.src = url;\n    return image;\n  }\n}\n\n/**\n * Abstract Base class to load generic binary textures formats (rgbe, hdr, ...)\n *\n * Sub classes have to implement the parse() method which will be used in load().\n */\n\nclass DataTextureLoader extends Loader {\n  constructor(manager) {\n    super(manager);\n  }\n  load(url, onLoad, onProgress, onError) {\n    const scope = this;\n    const texture = new DataTexture();\n    const loader = new FileLoader(this.manager);\n    loader.setResponseType('arraybuffer');\n    loader.setRequestHeader(this.requestHeader);\n    loader.setPath(this.path);\n    loader.setWithCredentials(scope.withCredentials);\n    loader.load(url, function (buffer) {\n      let texData;\n      try {\n        texData = scope.parse(buffer);\n      } catch (error) {\n        if (onError !== undefined) {\n          onError(error);\n        } else {\n          console.error(error);\n          return;\n        }\n      }\n      if (texData.image !== undefined) {\n        texture.image = texData.image;\n      } else if (texData.data !== undefined) {\n        texture.image.width = texData.width;\n        texture.image.height = texData.height;\n        texture.image.data = texData.data;\n      }\n      texture.wrapS = texData.wrapS !== undefined ? texData.wrapS : ClampToEdgeWrapping;\n      texture.wrapT = texData.wrapT !== undefined ? texData.wrapT : ClampToEdgeWrapping;\n      texture.magFilter = texData.magFilter !== undefined ? texData.magFilter : LinearFilter;\n      texture.minFilter = texData.minFilter !== undefined ? texData.minFilter : LinearFilter;\n      texture.anisotropy = texData.anisotropy !== undefined ? texData.anisotropy : 1;\n      if (texData.colorSpace !== undefined) {\n        texture.colorSpace = texData.colorSpace;\n      }\n      if (texData.flipY !== undefined) {\n        texture.flipY = texData.flipY;\n      }\n      if (texData.format !== undefined) {\n        texture.format = texData.format;\n      }\n      if (texData.type !== undefined) {\n        texture.type = texData.type;\n      }\n      if (texData.mipmaps !== undefined) {\n        texture.mipmaps = texData.mipmaps;\n        texture.minFilter = LinearMipmapLinearFilter; // presumably...\n      }\n      if (texData.mipmapCount === 1) {\n        texture.minFilter = LinearFilter;\n      }\n      if (texData.generateMipmaps !== undefined) {\n        texture.generateMipmaps = texData.generateMipmaps;\n      }\n      texture.needsUpdate = true;\n      if (onLoad) onLoad(texture, texData);\n    }, onProgress, onError);\n    return texture;\n  }\n}\nclass TextureLoader extends Loader {\n  constructor(manager) {\n    super(manager);\n  }\n  load(url, onLoad, onProgress, onError) {\n    const texture = new Texture$1();\n    const loader = new ImageLoader(this.manager);\n    loader.setCrossOrigin(this.crossOrigin);\n    loader.setPath(this.path);\n    loader.load(url, function (image) {\n      texture.image = image;\n      texture.needsUpdate = true;\n      if (onLoad !== undefined) {\n        onLoad(texture);\n      }\n    }, onProgress, onError);\n    return texture;\n  }\n}\nclass Light extends Object3D {\n  constructor(color, intensity = 1) {\n    super();\n    this.isLight = true;\n    this.type = 'Light';\n    this.color = new Color(color);\n    this.intensity = intensity;\n  }\n  dispose() {\n\n    // Empty here in base class; some subclasses override.\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.color.copy(source.color);\n    this.intensity = source.intensity;\n    return this;\n  }\n  toJSON(meta) {\n    const data = super.toJSON(meta);\n    data.object.color = this.color.getHex();\n    data.object.intensity = this.intensity;\n    if (this.groundColor !== undefined) data.object.groundColor = this.groundColor.getHex();\n    if (this.distance !== undefined) data.object.distance = this.distance;\n    if (this.angle !== undefined) data.object.angle = this.angle;\n    if (this.decay !== undefined) data.object.decay = this.decay;\n    if (this.penumbra !== undefined) data.object.penumbra = this.penumbra;\n    if (this.shadow !== undefined) data.object.shadow = this.shadow.toJSON();\n    if (this.target !== undefined) data.object.target = this.target.uuid;\n    return data;\n  }\n}\nconst _projScreenMatrix$1 = /*@__PURE__*/new Matrix4();\nconst _lightPositionWorld$1 = /*@__PURE__*/new Vector3();\nconst _lookTarget$1 = /*@__PURE__*/new Vector3();\nclass LightShadow {\n  constructor(camera) {\n    this.camera = camera;\n    this.intensity = 1;\n    this.bias = 0;\n    this.normalBias = 0;\n    this.radius = 1;\n    this.blurSamples = 8;\n    this.mapSize = new Vector2(512, 512);\n    this.map = null;\n    this.mapPass = null;\n    this.matrix = new Matrix4();\n    this.autoUpdate = true;\n    this.needsUpdate = false;\n    this._frustum = new Frustum();\n    this._frameExtents = new Vector2(1, 1);\n    this._viewportCount = 1;\n    this._viewports = [new Vector4(0, 0, 1, 1)];\n  }\n  getViewportCount() {\n    return this._viewportCount;\n  }\n  getFrustum() {\n    return this._frustum;\n  }\n  updateMatrices(light) {\n    const shadowCamera = this.camera;\n    const shadowMatrix = this.matrix;\n    _lightPositionWorld$1.setFromMatrixPosition(light.matrixWorld);\n    shadowCamera.position.copy(_lightPositionWorld$1);\n    _lookTarget$1.setFromMatrixPosition(light.target.matrixWorld);\n    shadowCamera.lookAt(_lookTarget$1);\n    shadowCamera.updateMatrixWorld();\n    _projScreenMatrix$1.multiplyMatrices(shadowCamera.projectionMatrix, shadowCamera.matrixWorldInverse);\n    this._frustum.setFromProjectionMatrix(_projScreenMatrix$1);\n    shadowMatrix.set(0.5, 0.0, 0.0, 0.5, 0.0, 0.5, 0.0, 0.5, 0.0, 0.0, 0.5, 0.5, 0.0, 0.0, 0.0, 1.0);\n    shadowMatrix.multiply(_projScreenMatrix$1);\n  }\n  getViewport(viewportIndex) {\n    return this._viewports[viewportIndex];\n  }\n  getFrameExtents() {\n    return this._frameExtents;\n  }\n  dispose() {\n    if (this.map) {\n      this.map.dispose();\n    }\n    if (this.mapPass) {\n      this.mapPass.dispose();\n    }\n  }\n  copy(source) {\n    this.camera = source.camera.clone();\n    this.intensity = source.intensity;\n    this.bias = source.bias;\n    this.radius = source.radius;\n    this.mapSize.copy(source.mapSize);\n    return this;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  toJSON() {\n    const object = {};\n    if (this.intensity !== 1) object.intensity = this.intensity;\n    if (this.bias !== 0) object.bias = this.bias;\n    if (this.normalBias !== 0) object.normalBias = this.normalBias;\n    if (this.radius !== 1) object.radius = this.radius;\n    if (this.mapSize.x !== 512 || this.mapSize.y !== 512) object.mapSize = this.mapSize.toArray();\n    object.camera = this.camera.toJSON(false).object;\n    delete object.camera.matrix;\n    return object;\n  }\n}\nclass SpotLightShadow extends LightShadow {\n  constructor() {\n    super(new PerspectiveCamera(50, 1, 0.5, 500));\n    this.isSpotLightShadow = true;\n    this.focus = 1;\n  }\n  updateMatrices(light) {\n    const camera = this.camera;\n    const fov = RAD2DEG * 2 * light.angle * this.focus;\n    const aspect = this.mapSize.width / this.mapSize.height;\n    const far = light.distance || camera.far;\n    if (fov !== camera.fov || aspect !== camera.aspect || far !== camera.far) {\n      camera.fov = fov;\n      camera.aspect = aspect;\n      camera.far = far;\n      camera.updateProjectionMatrix();\n    }\n    super.updateMatrices(light);\n  }\n  copy(source) {\n    super.copy(source);\n    this.focus = source.focus;\n    return this;\n  }\n}\nclass SpotLight extends Light {\n  constructor(color, intensity, distance = 0, angle = Math.PI / 3, penumbra = 0, decay = 2) {\n    super(color, intensity);\n    this.isSpotLight = true;\n    this.type = 'SpotLight';\n    this.position.copy(Object3D.DEFAULT_UP);\n    this.updateMatrix();\n    this.target = new Object3D();\n    this.distance = distance;\n    this.angle = angle;\n    this.penumbra = penumbra;\n    this.decay = decay;\n    this.map = null;\n    this.shadow = new SpotLightShadow();\n  }\n  get power() {\n    // compute the light's luminous power (in lumens) from its intensity (in candela)\n    // by convention for a spotlight, luminous power (lm) =  * luminous intensity (cd)\n    return this.intensity * Math.PI;\n  }\n  set power(power) {\n    // set the light's intensity (in candela) from the desired luminous power (in lumens)\n    this.intensity = power / Math.PI;\n  }\n  dispose() {\n    this.shadow.dispose();\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.distance = source.distance;\n    this.angle = source.angle;\n    this.penumbra = source.penumbra;\n    this.decay = source.decay;\n    this.target = source.target.clone();\n    this.shadow = source.shadow.clone();\n    return this;\n  }\n}\nconst _projScreenMatrix = /*@__PURE__*/new Matrix4();\nconst _lightPositionWorld = /*@__PURE__*/new Vector3();\nconst _lookTarget = /*@__PURE__*/new Vector3();\nclass PointLightShadow extends LightShadow {\n  constructor() {\n    super(new PerspectiveCamera(90, 1, 0.5, 500));\n    this.isPointLightShadow = true;\n    this._frameExtents = new Vector2(4, 2);\n    this._viewportCount = 6;\n    this._viewports = [\n    // These viewports map a cube-map onto a 2D texture with the\n    // following orientation:\n    //\n    //  xzXZ\n    //   y Y\n    //\n    // X - Positive x direction\n    // x - Negative x direction\n    // Y - Positive y direction\n    // y - Negative y direction\n    // Z - Positive z direction\n    // z - Negative z direction\n\n    // positive X\n    new Vector4(2, 1, 1, 1),\n    // negative X\n    new Vector4(0, 1, 1, 1),\n    // positive Z\n    new Vector4(3, 1, 1, 1),\n    // negative Z\n    new Vector4(1, 1, 1, 1),\n    // positive Y\n    new Vector4(3, 0, 1, 1),\n    // negative Y\n    new Vector4(1, 0, 1, 1)];\n    this._cubeDirections = [new Vector3(1, 0, 0), new Vector3(-1, 0, 0), new Vector3(0, 0, 1), new Vector3(0, 0, -1), new Vector3(0, 1, 0), new Vector3(0, -1, 0)];\n    this._cubeUps = [new Vector3(0, 1, 0), new Vector3(0, 1, 0), new Vector3(0, 1, 0), new Vector3(0, 1, 0), new Vector3(0, 0, 1), new Vector3(0, 0, -1)];\n  }\n  updateMatrices(light, viewportIndex = 0) {\n    const camera = this.camera;\n    const shadowMatrix = this.matrix;\n    const far = light.distance || camera.far;\n    if (far !== camera.far) {\n      camera.far = far;\n      camera.updateProjectionMatrix();\n    }\n    _lightPositionWorld.setFromMatrixPosition(light.matrixWorld);\n    camera.position.copy(_lightPositionWorld);\n    _lookTarget.copy(camera.position);\n    _lookTarget.add(this._cubeDirections[viewportIndex]);\n    camera.up.copy(this._cubeUps[viewportIndex]);\n    camera.lookAt(_lookTarget);\n    camera.updateMatrixWorld();\n    shadowMatrix.makeTranslation(-_lightPositionWorld.x, -_lightPositionWorld.y, -_lightPositionWorld.z);\n    _projScreenMatrix.multiplyMatrices(camera.projectionMatrix, camera.matrixWorldInverse);\n    this._frustum.setFromProjectionMatrix(_projScreenMatrix);\n  }\n}\nclass PointLight extends Light {\n  constructor(color, intensity, distance = 0, decay = 2) {\n    super(color, intensity);\n    this.isPointLight = true;\n    this.type = 'PointLight';\n    this.distance = distance;\n    this.decay = decay;\n    this.shadow = new PointLightShadow();\n  }\n  get power() {\n    // compute the light's luminous power (in lumens) from its intensity (in candela)\n    // for an isotropic light source, luminous power (lm) = 4  luminous intensity (cd)\n    return this.intensity * 4 * Math.PI;\n  }\n  set power(power) {\n    // set the light's intensity (in candela) from the desired luminous power (in lumens)\n    this.intensity = power / (4 * Math.PI);\n  }\n  dispose() {\n    this.shadow.dispose();\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.distance = source.distance;\n    this.decay = source.decay;\n    this.shadow = source.shadow.clone();\n    return this;\n  }\n}\nclass DirectionalLightShadow extends LightShadow {\n  constructor() {\n    super(new OrthographicCamera(-5, 5, 5, -5, 0.5, 500));\n    this.isDirectionalLightShadow = true;\n  }\n}\nclass DirectionalLight extends Light {\n  constructor(color, intensity) {\n    super(color, intensity);\n    this.isDirectionalLight = true;\n    this.type = 'DirectionalLight';\n    this.position.copy(Object3D.DEFAULT_UP);\n    this.updateMatrix();\n    this.target = new Object3D();\n    this.shadow = new DirectionalLightShadow();\n  }\n  dispose() {\n    this.shadow.dispose();\n  }\n  copy(source) {\n    super.copy(source);\n    this.target = source.target.clone();\n    this.shadow = source.shadow.clone();\n    return this;\n  }\n}\n\n/**\n * Primary reference:\n *   https://graphics.stanford.edu/papers/envmap/envmap.pdf\n *\n * Secondary reference:\n *   https://www.ppsloan.org/publications/StupidSH36.pdf\n */\n\n// 3-band SH defined by 9 coefficients\n\nclass SphericalHarmonics3 {\n  constructor() {\n    this.isSphericalHarmonics3 = true;\n    this.coefficients = [];\n    for (let i = 0; i < 9; i++) {\n      this.coefficients.push(new Vector3());\n    }\n  }\n  set(coefficients) {\n    for (let i = 0; i < 9; i++) {\n      this.coefficients[i].copy(coefficients[i]);\n    }\n    return this;\n  }\n  zero() {\n    for (let i = 0; i < 9; i++) {\n      this.coefficients[i].set(0, 0, 0);\n    }\n    return this;\n  }\n\n  // get the radiance in the direction of the normal\n  // target is a Vector3\n  getAt(normal, target) {\n    // normal is assumed to be unit length\n\n    const x = normal.x,\n      y = normal.y,\n      z = normal.z;\n    const coeff = this.coefficients;\n\n    // band 0\n    target.copy(coeff[0]).multiplyScalar(0.282095);\n\n    // band 1\n    target.addScaledVector(coeff[1], 0.488603 * y);\n    target.addScaledVector(coeff[2], 0.488603 * z);\n    target.addScaledVector(coeff[3], 0.488603 * x);\n\n    // band 2\n    target.addScaledVector(coeff[4], 1.092548 * (x * y));\n    target.addScaledVector(coeff[5], 1.092548 * (y * z));\n    target.addScaledVector(coeff[6], 0.315392 * (3.0 * z * z - 1.0));\n    target.addScaledVector(coeff[7], 1.092548 * (x * z));\n    target.addScaledVector(coeff[8], 0.546274 * (x * x - y * y));\n    return target;\n  }\n\n  // get the irradiance (radiance convolved with cosine lobe) in the direction of the normal\n  // target is a Vector3\n  // https://graphics.stanford.edu/papers/envmap/envmap.pdf\n  getIrradianceAt(normal, target) {\n    // normal is assumed to be unit length\n\n    const x = normal.x,\n      y = normal.y,\n      z = normal.z;\n    const coeff = this.coefficients;\n\n    // band 0\n    target.copy(coeff[0]).multiplyScalar(0.886227); //  * 0.282095\n\n    // band 1\n    target.addScaledVector(coeff[1], 2.0 * 0.511664 * y); // ( 2 *  / 3 ) * 0.488603\n    target.addScaledVector(coeff[2], 2.0 * 0.511664 * z);\n    target.addScaledVector(coeff[3], 2.0 * 0.511664 * x);\n\n    // band 2\n    target.addScaledVector(coeff[4], 2.0 * 0.429043 * x * y); // (  / 4 ) * 1.092548\n    target.addScaledVector(coeff[5], 2.0 * 0.429043 * y * z);\n    target.addScaledVector(coeff[6], 0.743125 * z * z - 0.247708); // (  / 4 ) * 0.315392 * 3\n    target.addScaledVector(coeff[7], 2.0 * 0.429043 * x * z);\n    target.addScaledVector(coeff[8], 0.429043 * (x * x - y * y)); // (  / 4 ) * 0.546274\n\n    return target;\n  }\n  add(sh) {\n    for (let i = 0; i < 9; i++) {\n      this.coefficients[i].add(sh.coefficients[i]);\n    }\n    return this;\n  }\n  addScaledSH(sh, s) {\n    for (let i = 0; i < 9; i++) {\n      this.coefficients[i].addScaledVector(sh.coefficients[i], s);\n    }\n    return this;\n  }\n  scale(s) {\n    for (let i = 0; i < 9; i++) {\n      this.coefficients[i].multiplyScalar(s);\n    }\n    return this;\n  }\n  lerp(sh, alpha) {\n    for (let i = 0; i < 9; i++) {\n      this.coefficients[i].lerp(sh.coefficients[i], alpha);\n    }\n    return this;\n  }\n  equals(sh) {\n    for (let i = 0; i < 9; i++) {\n      if (!this.coefficients[i].equals(sh.coefficients[i])) {\n        return false;\n      }\n    }\n    return true;\n  }\n  copy(sh) {\n    return this.set(sh.coefficients);\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n  fromArray(array, offset = 0) {\n    const coefficients = this.coefficients;\n    for (let i = 0; i < 9; i++) {\n      coefficients[i].fromArray(array, offset + i * 3);\n    }\n    return this;\n  }\n  toArray(array = [], offset = 0) {\n    const coefficients = this.coefficients;\n    for (let i = 0; i < 9; i++) {\n      coefficients[i].toArray(array, offset + i * 3);\n    }\n    return array;\n  }\n\n  // evaluate the basis functions\n  // shBasis is an Array[ 9 ]\n  static getBasisAt(normal, shBasis) {\n    // normal is assumed to be unit length\n\n    const x = normal.x,\n      y = normal.y,\n      z = normal.z;\n\n    // band 0\n    shBasis[0] = 0.282095;\n\n    // band 1\n    shBasis[1] = 0.488603 * y;\n    shBasis[2] = 0.488603 * z;\n    shBasis[3] = 0.488603 * x;\n\n    // band 2\n    shBasis[4] = 1.092548 * x * y;\n    shBasis[5] = 1.092548 * y * z;\n    shBasis[6] = 0.315392 * (3 * z * z - 1);\n    shBasis[7] = 1.092548 * x * z;\n    shBasis[8] = 0.546274 * (x * x - y * y);\n  }\n}\nclass LightProbe extends Light {\n  constructor(sh = new SphericalHarmonics3(), intensity = 1) {\n    super(undefined, intensity);\n    this.isLightProbe = true;\n    this.sh = sh;\n  }\n  copy(source) {\n    super.copy(source);\n    this.sh.copy(source.sh);\n    return this;\n  }\n  fromJSON(json) {\n    this.intensity = json.intensity; // TODO: Move this bit to Light.fromJSON();\n    this.sh.fromArray(json.sh);\n    return this;\n  }\n  toJSON(meta) {\n    const data = super.toJSON(meta);\n    data.object.sh = this.sh.toArray();\n    return data;\n  }\n}\nclass LoaderUtils {\n  static decodeText(array) {\n    // @deprecated, r165\n\n    console.warn('THREE.LoaderUtils: decodeText() has been deprecated with r165 and will be removed with r175. Use TextDecoder instead.');\n    if (typeof TextDecoder !== 'undefined') {\n      return new TextDecoder().decode(array);\n    }\n\n    // Avoid the String.fromCharCode.apply(null, array) shortcut, which\n    // throws a \"maximum call stack size exceeded\" error for large arrays.\n\n    let s = '';\n    for (let i = 0, il = array.length; i < il; i++) {\n      // Implicitly assumes little-endian.\n      s += String.fromCharCode(array[i]);\n    }\n    try {\n      // merges multi-byte utf-8 characters.\n\n      return decodeURIComponent(escape(s));\n    } catch (e) {\n      // see #16358\n\n      return s;\n    }\n  }\n  static extractUrlBase(url) {\n    const index = url.lastIndexOf('/');\n    if (index === -1) return './';\n    return url.slice(0, index + 1);\n  }\n  static resolveURL(url, path) {\n    // Invalid URL\n    if (typeof url !== 'string' || url === '') return '';\n\n    // Host Relative URL\n    if (/^https?:\\/\\//i.test(path) && /^\\//.test(url)) {\n      path = path.replace(/(^https?:\\/\\/[^\\/]+).*/i, '$1');\n    }\n\n    // Absolute URL http://,https://,//\n    if (/^(https?:)?\\/\\//i.test(url)) return url;\n\n    // Data URI\n    if (/^data:.*,.*$/i.test(url)) return url;\n\n    // Blob URL\n    if (/^blob:.*$/i.test(url)) return url;\n\n    // Relative URL\n    return path + url;\n  }\n}\nclass ImageBitmapLoader extends Loader {\n  constructor(manager) {\n    super(manager);\n    this.isImageBitmapLoader = true;\n    if (typeof createImageBitmap === 'undefined') {\n      console.warn('THREE.ImageBitmapLoader: createImageBitmap() not supported.');\n    }\n    if (typeof fetch === 'undefined') {\n      console.warn('THREE.ImageBitmapLoader: fetch() not supported.');\n    }\n    this.options = {\n      premultiplyAlpha: 'none'\n    };\n  }\n  setOptions(options) {\n    this.options = options;\n    return this;\n  }\n  load(url, onLoad, onProgress, onError) {\n    if (url === undefined) url = '';\n    if (this.path !== undefined) url = this.path + url;\n    url = this.manager.resolveURL(url);\n    const scope = this;\n    const cached = Cache.get(url);\n    if (cached !== undefined) {\n      scope.manager.itemStart(url);\n\n      // If cached is a promise, wait for it to resolve\n      if (cached.then) {\n        cached.then(imageBitmap => {\n          if (onLoad) onLoad(imageBitmap);\n          scope.manager.itemEnd(url);\n        }).catch(e => {\n          if (onError) onError(e);\n        });\n        return;\n      }\n\n      // If cached is not a promise (i.e., it's already an imageBitmap)\n      setTimeout(function () {\n        if (onLoad) onLoad(cached);\n        scope.manager.itemEnd(url);\n      }, 0);\n      return cached;\n    }\n    const fetchOptions = {};\n    fetchOptions.credentials = this.crossOrigin === 'anonymous' ? 'same-origin' : 'include';\n    fetchOptions.headers = this.requestHeader;\n    const promise = fetch(url, fetchOptions).then(function (res) {\n      return res.blob();\n    }).then(function (blob) {\n      return createImageBitmap(blob, Object.assign(scope.options, {\n        colorSpaceConversion: 'none'\n      }));\n    }).then(function (imageBitmap) {\n      Cache.add(url, imageBitmap);\n      if (onLoad) onLoad(imageBitmap);\n      scope.manager.itemEnd(url);\n      return imageBitmap;\n    }).catch(function (e) {\n      if (onError) onError(e);\n      Cache.remove(url);\n      scope.manager.itemError(url);\n      scope.manager.itemEnd(url);\n    });\n    Cache.add(url, promise);\n    scope.manager.itemStart(url);\n  }\n}\nclass PropertyMixer {\n  constructor(binding, typeName, valueSize) {\n    this.binding = binding;\n    this.valueSize = valueSize;\n    let mixFunction, mixFunctionAdditive, setIdentity;\n\n    // buffer layout: [ incoming | accu0 | accu1 | orig | addAccu | (optional work) ]\n    //\n    // interpolators can use .buffer as their .result\n    // the data then goes to 'incoming'\n    //\n    // 'accu0' and 'accu1' are used frame-interleaved for\n    // the cumulative result and are compared to detect\n    // changes\n    //\n    // 'orig' stores the original state of the property\n    //\n    // 'add' is used for additive cumulative results\n    //\n    // 'work' is optional and is only present for quaternion types. It is used\n    // to store intermediate quaternion multiplication results\n\n    switch (typeName) {\n      case 'quaternion':\n        mixFunction = this._slerp;\n        mixFunctionAdditive = this._slerpAdditive;\n        setIdentity = this._setAdditiveIdentityQuaternion;\n        this.buffer = new Float64Array(valueSize * 6);\n        this._workIndex = 5;\n        break;\n      case 'string':\n      case 'bool':\n        mixFunction = this._select;\n\n        // Use the regular mix function and for additive on these types,\n        // additive is not relevant for non-numeric types\n        mixFunctionAdditive = this._select;\n        setIdentity = this._setAdditiveIdentityOther;\n        this.buffer = new Array(valueSize * 5);\n        break;\n      default:\n        mixFunction = this._lerp;\n        mixFunctionAdditive = this._lerpAdditive;\n        setIdentity = this._setAdditiveIdentityNumeric;\n        this.buffer = new Float64Array(valueSize * 5);\n    }\n    this._mixBufferRegion = mixFunction;\n    this._mixBufferRegionAdditive = mixFunctionAdditive;\n    this._setIdentity = setIdentity;\n    this._origIndex = 3;\n    this._addIndex = 4;\n    this.cumulativeWeight = 0;\n    this.cumulativeWeightAdditive = 0;\n    this.useCount = 0;\n    this.referenceCount = 0;\n  }\n\n  // accumulate data in the 'incoming' region into 'accu<i>'\n  accumulate(accuIndex, weight) {\n    // note: happily accumulating nothing when weight = 0, the caller knows\n    // the weight and shouldn't have made the call in the first place\n\n    const buffer = this.buffer,\n      stride = this.valueSize,\n      offset = accuIndex * stride + stride;\n    let currentWeight = this.cumulativeWeight;\n    if (currentWeight === 0) {\n      // accuN := incoming * weight\n\n      for (let i = 0; i !== stride; ++i) {\n        buffer[offset + i] = buffer[i];\n      }\n      currentWeight = weight;\n    } else {\n      // accuN := accuN + incoming * weight\n\n      currentWeight += weight;\n      const mix = weight / currentWeight;\n      this._mixBufferRegion(buffer, offset, 0, mix, stride);\n    }\n    this.cumulativeWeight = currentWeight;\n  }\n\n  // accumulate data in the 'incoming' region into 'add'\n  accumulateAdditive(weight) {\n    const buffer = this.buffer,\n      stride = this.valueSize,\n      offset = stride * this._addIndex;\n    if (this.cumulativeWeightAdditive === 0) {\n      // add = identity\n\n      this._setIdentity();\n    }\n\n    // add := add + incoming * weight\n\n    this._mixBufferRegionAdditive(buffer, offset, 0, weight, stride);\n    this.cumulativeWeightAdditive += weight;\n  }\n\n  // apply the state of 'accu<i>' to the binding when accus differ\n  apply(accuIndex) {\n    const stride = this.valueSize,\n      buffer = this.buffer,\n      offset = accuIndex * stride + stride,\n      weight = this.cumulativeWeight,\n      weightAdditive = this.cumulativeWeightAdditive,\n      binding = this.binding;\n    this.cumulativeWeight = 0;\n    this.cumulativeWeightAdditive = 0;\n    if (weight < 1) {\n      // accuN := accuN + original * ( 1 - cumulativeWeight )\n\n      const originalValueOffset = stride * this._origIndex;\n      this._mixBufferRegion(buffer, offset, originalValueOffset, 1 - weight, stride);\n    }\n    if (weightAdditive > 0) {\n      // accuN := accuN + additive accuN\n\n      this._mixBufferRegionAdditive(buffer, offset, this._addIndex * stride, 1, stride);\n    }\n    for (let i = stride, e = stride + stride; i !== e; ++i) {\n      if (buffer[i] !== buffer[i + stride]) {\n        // value has changed -> update scene graph\n\n        binding.setValue(buffer, offset);\n        break;\n      }\n    }\n  }\n\n  // remember the state of the bound property and copy it to both accus\n  saveOriginalState() {\n    const binding = this.binding;\n    const buffer = this.buffer,\n      stride = this.valueSize,\n      originalValueOffset = stride * this._origIndex;\n    binding.getValue(buffer, originalValueOffset);\n\n    // accu[0..1] := orig -- initially detect changes against the original\n    for (let i = stride, e = originalValueOffset; i !== e; ++i) {\n      buffer[i] = buffer[originalValueOffset + i % stride];\n    }\n\n    // Add to identity for additive\n    this._setIdentity();\n    this.cumulativeWeight = 0;\n    this.cumulativeWeightAdditive = 0;\n  }\n\n  // apply the state previously taken via 'saveOriginalState' to the binding\n  restoreOriginalState() {\n    const originalValueOffset = this.valueSize * 3;\n    this.binding.setValue(this.buffer, originalValueOffset);\n  }\n  _setAdditiveIdentityNumeric() {\n    const startIndex = this._addIndex * this.valueSize;\n    const endIndex = startIndex + this.valueSize;\n    for (let i = startIndex; i < endIndex; i++) {\n      this.buffer[i] = 0;\n    }\n  }\n  _setAdditiveIdentityQuaternion() {\n    this._setAdditiveIdentityNumeric();\n    this.buffer[this._addIndex * this.valueSize + 3] = 1;\n  }\n  _setAdditiveIdentityOther() {\n    const startIndex = this._origIndex * this.valueSize;\n    const targetIndex = this._addIndex * this.valueSize;\n    for (let i = 0; i < this.valueSize; i++) {\n      this.buffer[targetIndex + i] = this.buffer[startIndex + i];\n    }\n  }\n\n  // mix functions\n\n  _select(buffer, dstOffset, srcOffset, t, stride) {\n    if (t >= 0.5) {\n      for (let i = 0; i !== stride; ++i) {\n        buffer[dstOffset + i] = buffer[srcOffset + i];\n      }\n    }\n  }\n  _slerp(buffer, dstOffset, srcOffset, t) {\n    Quaternion.slerpFlat(buffer, dstOffset, buffer, dstOffset, buffer, srcOffset, t);\n  }\n  _slerpAdditive(buffer, dstOffset, srcOffset, t, stride) {\n    const workOffset = this._workIndex * stride;\n\n    // Store result in intermediate buffer offset\n    Quaternion.multiplyQuaternionsFlat(buffer, workOffset, buffer, dstOffset, buffer, srcOffset);\n\n    // Slerp to the intermediate result\n    Quaternion.slerpFlat(buffer, dstOffset, buffer, dstOffset, buffer, workOffset, t);\n  }\n  _lerp(buffer, dstOffset, srcOffset, t, stride) {\n    const s = 1 - t;\n    for (let i = 0; i !== stride; ++i) {\n      const j = dstOffset + i;\n      buffer[j] = buffer[j] * s + buffer[srcOffset + i] * t;\n    }\n  }\n  _lerpAdditive(buffer, dstOffset, srcOffset, t, stride) {\n    for (let i = 0; i !== stride; ++i) {\n      const j = dstOffset + i;\n      buffer[j] = buffer[j] + buffer[srcOffset + i] * t;\n    }\n  }\n}\n\n// Characters [].:/ are reserved for track binding syntax.\nconst _RESERVED_CHARS_RE = '\\\\[\\\\]\\\\.:\\\\/';\nconst _reservedRe = new RegExp('[' + _RESERVED_CHARS_RE + ']', 'g');\n\n// Attempts to allow node names from any language. ES5's `\\w` regexp matches\n// only latin characters, and the unicode \\p{L} is not yet supported. So\n// instead, we exclude reserved characters and match everything else.\nconst _wordChar = '[^' + _RESERVED_CHARS_RE + ']';\nconst _wordCharOrDot = '[^' + _RESERVED_CHARS_RE.replace('\\\\.', '') + ']';\n\n// Parent directories, delimited by '/' or ':'. Currently unused, but must\n// be matched to parse the rest of the track name.\nconst _directoryRe = /*@__PURE__*//((?:WC+[\\/:])*)/.source.replace('WC', _wordChar);\n\n// Target node. May contain word characters (a-zA-Z0-9_) and '.' or '-'.\nconst _nodeRe = /*@__PURE__*//(WCOD+)?/.source.replace('WCOD', _wordCharOrDot);\n\n// Object on target node, and accessor. May not contain reserved\n// characters. Accessor may contain any character except closing bracket.\nconst _objectRe = /*@__PURE__*//(?:\\.(WC+)(?:\\[(.+)\\])?)?/.source.replace('WC', _wordChar);\n\n// Property and accessor. May not contain reserved characters. Accessor may\n// contain any non-bracket characters.\nconst _propertyRe = /*@__PURE__*//\\.(WC+)(?:\\[(.+)\\])?/.source.replace('WC', _wordChar);\nconst _trackRe = new RegExp('' + '^' + _directoryRe + _nodeRe + _objectRe + _propertyRe + '$');\nconst _supportedObjectNames = ['material', 'materials', 'bones', 'map'];\nclass Composite {\n  constructor(targetGroup, path, optionalParsedPath) {\n    const parsedPath = optionalParsedPath || PropertyBinding.parseTrackName(path);\n    this._targetGroup = targetGroup;\n    this._bindings = targetGroup.subscribe_(path, parsedPath);\n  }\n  getValue(array, offset) {\n    this.bind(); // bind all binding\n\n    const firstValidIndex = this._targetGroup.nCachedObjects_,\n      binding = this._bindings[firstValidIndex];\n\n    // and only call .getValue on the first\n    if (binding !== undefined) binding.getValue(array, offset);\n  }\n  setValue(array, offset) {\n    const bindings = this._bindings;\n    for (let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++i) {\n      bindings[i].setValue(array, offset);\n    }\n  }\n  bind() {\n    const bindings = this._bindings;\n    for (let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++i) {\n      bindings[i].bind();\n    }\n  }\n  unbind() {\n    const bindings = this._bindings;\n    for (let i = this._targetGroup.nCachedObjects_, n = bindings.length; i !== n; ++i) {\n      bindings[i].unbind();\n    }\n  }\n}\n\n// Note: This class uses a State pattern on a per-method basis:\n// 'bind' sets 'this.getValue' / 'setValue' and shadows the\n// prototype version of these methods with one that represents\n// the bound state. When the property is not found, the methods\n// become no-ops.\nclass PropertyBinding {\n  constructor(rootNode, path, parsedPath) {\n    this.path = path;\n    this.parsedPath = parsedPath || PropertyBinding.parseTrackName(path);\n    this.node = PropertyBinding.findNode(rootNode, this.parsedPath.nodeName);\n    this.rootNode = rootNode;\n\n    // initial state of these methods that calls 'bind'\n    this.getValue = this._getValue_unbound;\n    this.setValue = this._setValue_unbound;\n  }\n  static create(root, path, parsedPath) {\n    if (!(root && root.isAnimationObjectGroup)) {\n      return new PropertyBinding(root, path, parsedPath);\n    } else {\n      return new PropertyBinding.Composite(root, path, parsedPath);\n    }\n  }\n\n  /**\n   * Replaces spaces with underscores and removes unsupported characters from\n   * node names, to ensure compatibility with parseTrackName().\n   *\n   * @param {string} name Node name to be sanitized.\n   * @return {string}\n   */\n  static sanitizeNodeName(name) {\n    return name.replace(/\\s/g, '_').replace(_reservedRe, '');\n  }\n  static parseTrackName(trackName) {\n    const matches = _trackRe.exec(trackName);\n    if (matches === null) {\n      throw new Error('PropertyBinding: Cannot parse trackName: ' + trackName);\n    }\n    const results = {\n      // directoryName: matches[ 1 ], // (tschw) currently unused\n      nodeName: matches[2],\n      objectName: matches[3],\n      objectIndex: matches[4],\n      propertyName: matches[5],\n      // required\n      propertyIndex: matches[6]\n    };\n    const lastDot = results.nodeName && results.nodeName.lastIndexOf('.');\n    if (lastDot !== undefined && lastDot !== -1) {\n      const objectName = results.nodeName.substring(lastDot + 1);\n\n      // Object names must be checked against an allowlist. Otherwise, there\n      // is no way to parse 'foo.bar.baz': 'baz' must be a property, but\n      // 'bar' could be the objectName, or part of a nodeName (which can\n      // include '.' characters).\n      if (_supportedObjectNames.indexOf(objectName) !== -1) {\n        results.nodeName = results.nodeName.substring(0, lastDot);\n        results.objectName = objectName;\n      }\n    }\n    if (results.propertyName === null || results.propertyName.length === 0) {\n      throw new Error('PropertyBinding: can not parse propertyName from trackName: ' + trackName);\n    }\n    return results;\n  }\n  static findNode(root, nodeName) {\n    if (nodeName === undefined || nodeName === '' || nodeName === '.' || nodeName === -1 || nodeName === root.name || nodeName === root.uuid) {\n      return root;\n    }\n\n    // search into skeleton bones.\n    if (root.skeleton) {\n      const bone = root.skeleton.getBoneByName(nodeName);\n      if (bone !== undefined) {\n        return bone;\n      }\n    }\n\n    // search into node subtree.\n    if (root.children) {\n      const searchNodeSubtree = function (children) {\n        for (let i = 0; i < children.length; i++) {\n          const childNode = children[i];\n          if (childNode.name === nodeName || childNode.uuid === nodeName) {\n            return childNode;\n          }\n          const result = searchNodeSubtree(childNode.children);\n          if (result) return result;\n        }\n        return null;\n      };\n      const subTreeNode = searchNodeSubtree(root.children);\n      if (subTreeNode) {\n        return subTreeNode;\n      }\n    }\n    return null;\n  }\n\n  // these are used to \"bind\" a nonexistent property\n  _getValue_unavailable() {}\n  _setValue_unavailable() {}\n\n  // Getters\n\n  _getValue_direct(buffer, offset) {\n    buffer[offset] = this.targetObject[this.propertyName];\n  }\n  _getValue_array(buffer, offset) {\n    const source = this.resolvedProperty;\n    for (let i = 0, n = source.length; i !== n; ++i) {\n      buffer[offset++] = source[i];\n    }\n  }\n  _getValue_arrayElement(buffer, offset) {\n    buffer[offset] = this.resolvedProperty[this.propertyIndex];\n  }\n  _getValue_toArray(buffer, offset) {\n    this.resolvedProperty.toArray(buffer, offset);\n  }\n\n  // Direct\n\n  _setValue_direct(buffer, offset) {\n    this.targetObject[this.propertyName] = buffer[offset];\n  }\n  _setValue_direct_setNeedsUpdate(buffer, offset) {\n    this.targetObject[this.propertyName] = buffer[offset];\n    this.targetObject.needsUpdate = true;\n  }\n  _setValue_direct_setMatrixWorldNeedsUpdate(buffer, offset) {\n    this.targetObject[this.propertyName] = buffer[offset];\n    this.targetObject.matrixWorldNeedsUpdate = true;\n  }\n\n  // EntireArray\n\n  _setValue_array(buffer, offset) {\n    const dest = this.resolvedProperty;\n    for (let i = 0, n = dest.length; i !== n; ++i) {\n      dest[i] = buffer[offset++];\n    }\n  }\n  _setValue_array_setNeedsUpdate(buffer, offset) {\n    const dest = this.resolvedProperty;\n    for (let i = 0, n = dest.length; i !== n; ++i) {\n      dest[i] = buffer[offset++];\n    }\n    this.targetObject.needsUpdate = true;\n  }\n  _setValue_array_setMatrixWorldNeedsUpdate(buffer, offset) {\n    const dest = this.resolvedProperty;\n    for (let i = 0, n = dest.length; i !== n; ++i) {\n      dest[i] = buffer[offset++];\n    }\n    this.targetObject.matrixWorldNeedsUpdate = true;\n  }\n\n  // ArrayElement\n\n  _setValue_arrayElement(buffer, offset) {\n    this.resolvedProperty[this.propertyIndex] = buffer[offset];\n  }\n  _setValue_arrayElement_setNeedsUpdate(buffer, offset) {\n    this.resolvedProperty[this.propertyIndex] = buffer[offset];\n    this.targetObject.needsUpdate = true;\n  }\n  _setValue_arrayElement_setMatrixWorldNeedsUpdate(buffer, offset) {\n    this.resolvedProperty[this.propertyIndex] = buffer[offset];\n    this.targetObject.matrixWorldNeedsUpdate = true;\n  }\n\n  // HasToFromArray\n\n  _setValue_fromArray(buffer, offset) {\n    this.resolvedProperty.fromArray(buffer, offset);\n  }\n  _setValue_fromArray_setNeedsUpdate(buffer, offset) {\n    this.resolvedProperty.fromArray(buffer, offset);\n    this.targetObject.needsUpdate = true;\n  }\n  _setValue_fromArray_setMatrixWorldNeedsUpdate(buffer, offset) {\n    this.resolvedProperty.fromArray(buffer, offset);\n    this.targetObject.matrixWorldNeedsUpdate = true;\n  }\n  _getValue_unbound(targetArray, offset) {\n    this.bind();\n    this.getValue(targetArray, offset);\n  }\n  _setValue_unbound(sourceArray, offset) {\n    this.bind();\n    this.setValue(sourceArray, offset);\n  }\n\n  // create getter / setter pair for a property in the scene graph\n  bind() {\n    let targetObject = this.node;\n    const parsedPath = this.parsedPath;\n    const objectName = parsedPath.objectName;\n    const propertyName = parsedPath.propertyName;\n    let propertyIndex = parsedPath.propertyIndex;\n    if (!targetObject) {\n      targetObject = PropertyBinding.findNode(this.rootNode, parsedPath.nodeName);\n      this.node = targetObject;\n    }\n\n    // set fail state so we can just 'return' on error\n    this.getValue = this._getValue_unavailable;\n    this.setValue = this._setValue_unavailable;\n\n    // ensure there is a value node\n    if (!targetObject) {\n      console.warn('THREE.PropertyBinding: No target node found for track: ' + this.path + '.');\n      return;\n    }\n    if (objectName) {\n      let objectIndex = parsedPath.objectIndex;\n\n      // special cases were we need to reach deeper into the hierarchy to get the face materials....\n      switch (objectName) {\n        case 'materials':\n          if (!targetObject.material) {\n            console.error('THREE.PropertyBinding: Can not bind to material as node does not have a material.', this);\n            return;\n          }\n          if (!targetObject.material.materials) {\n            console.error('THREE.PropertyBinding: Can not bind to material.materials as node.material does not have a materials array.', this);\n            return;\n          }\n          targetObject = targetObject.material.materials;\n          break;\n        case 'bones':\n          if (!targetObject.skeleton) {\n            console.error('THREE.PropertyBinding: Can not bind to bones as node does not have a skeleton.', this);\n            return;\n          }\n\n          // potential future optimization: skip this if propertyIndex is already an integer\n          // and convert the integer string to a true integer.\n\n          targetObject = targetObject.skeleton.bones;\n\n          // support resolving morphTarget names into indices.\n          for (let i = 0; i < targetObject.length; i++) {\n            if (targetObject[i].name === objectIndex) {\n              objectIndex = i;\n              break;\n            }\n          }\n          break;\n        case 'map':\n          if ('map' in targetObject) {\n            targetObject = targetObject.map;\n            break;\n          }\n          if (!targetObject.material) {\n            console.error('THREE.PropertyBinding: Can not bind to material as node does not have a material.', this);\n            return;\n          }\n          if (!targetObject.material.map) {\n            console.error('THREE.PropertyBinding: Can not bind to material.map as node.material does not have a map.', this);\n            return;\n          }\n          targetObject = targetObject.material.map;\n          break;\n        default:\n          if (targetObject[objectName] === undefined) {\n            console.error('THREE.PropertyBinding: Can not bind to objectName of node undefined.', this);\n            return;\n          }\n          targetObject = targetObject[objectName];\n      }\n      if (objectIndex !== undefined) {\n        if (targetObject[objectIndex] === undefined) {\n          console.error('THREE.PropertyBinding: Trying to bind to objectIndex of objectName, but is undefined.', this, targetObject);\n          return;\n        }\n        targetObject = targetObject[objectIndex];\n      }\n    }\n\n    // resolve property\n    const nodeProperty = targetObject[propertyName];\n    if (nodeProperty === undefined) {\n      const nodeName = parsedPath.nodeName;\n      console.error('THREE.PropertyBinding: Trying to update property for track: ' + nodeName + '.' + propertyName + ' but it wasn\\'t found.', targetObject);\n      return;\n    }\n\n    // determine versioning scheme\n    let versioning = this.Versioning.None;\n    this.targetObject = targetObject;\n    if (targetObject.needsUpdate !== undefined) {\n      // material\n\n      versioning = this.Versioning.NeedsUpdate;\n    } else if (targetObject.matrixWorldNeedsUpdate !== undefined) {\n      // node transform\n\n      versioning = this.Versioning.MatrixWorldNeedsUpdate;\n    }\n\n    // determine how the property gets bound\n    let bindingType = this.BindingType.Direct;\n    if (propertyIndex !== undefined) {\n      // access a sub element of the property array (only primitives are supported right now)\n\n      if (propertyName === 'morphTargetInfluences') {\n        // potential optimization, skip this if propertyIndex is already an integer, and convert the integer string to a true integer.\n\n        // support resolving morphTarget names into indices.\n        if (!targetObject.geometry) {\n          console.error('THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.', this);\n          return;\n        }\n        if (!targetObject.geometry.morphAttributes) {\n          console.error('THREE.PropertyBinding: Can not bind to morphTargetInfluences because node does not have a geometry.morphAttributes.', this);\n          return;\n        }\n        if (targetObject.morphTargetDictionary[propertyIndex] !== undefined) {\n          propertyIndex = targetObject.morphTargetDictionary[propertyIndex];\n        }\n      }\n      bindingType = this.BindingType.ArrayElement;\n      this.resolvedProperty = nodeProperty;\n      this.propertyIndex = propertyIndex;\n    } else if (nodeProperty.fromArray !== undefined && nodeProperty.toArray !== undefined) {\n      // must use copy for Object3D.Euler/Quaternion\n\n      bindingType = this.BindingType.HasFromToArray;\n      this.resolvedProperty = nodeProperty;\n    } else if (Array.isArray(nodeProperty)) {\n      bindingType = this.BindingType.EntireArray;\n      this.resolvedProperty = nodeProperty;\n    } else {\n      this.propertyName = propertyName;\n    }\n\n    // select getter / setter\n    this.getValue = this.GetterByBindingType[bindingType];\n    this.setValue = this.SetterByBindingTypeAndVersioning[bindingType][versioning];\n  }\n  unbind() {\n    this.node = null;\n\n    // back to the prototype version of getValue / setValue\n    // note: avoiding to mutate the shape of 'this' via 'delete'\n    this.getValue = this._getValue_unbound;\n    this.setValue = this._setValue_unbound;\n  }\n}\nPropertyBinding.Composite = Composite;\nPropertyBinding.prototype.BindingType = {\n  Direct: 0,\n  EntireArray: 1,\n  ArrayElement: 2,\n  HasFromToArray: 3\n};\nPropertyBinding.prototype.Versioning = {\n  None: 0,\n  NeedsUpdate: 1,\n  MatrixWorldNeedsUpdate: 2\n};\nPropertyBinding.prototype.GetterByBindingType = [PropertyBinding.prototype._getValue_direct, PropertyBinding.prototype._getValue_array, PropertyBinding.prototype._getValue_arrayElement, PropertyBinding.prototype._getValue_toArray];\nPropertyBinding.prototype.SetterByBindingTypeAndVersioning = [[\n// Direct\nPropertyBinding.prototype._setValue_direct, PropertyBinding.prototype._setValue_direct_setNeedsUpdate, PropertyBinding.prototype._setValue_direct_setMatrixWorldNeedsUpdate], [\n// EntireArray\n\nPropertyBinding.prototype._setValue_array, PropertyBinding.prototype._setValue_array_setNeedsUpdate, PropertyBinding.prototype._setValue_array_setMatrixWorldNeedsUpdate], [\n// ArrayElement\nPropertyBinding.prototype._setValue_arrayElement, PropertyBinding.prototype._setValue_arrayElement_setNeedsUpdate, PropertyBinding.prototype._setValue_arrayElement_setMatrixWorldNeedsUpdate], [\n// HasToFromArray\nPropertyBinding.prototype._setValue_fromArray, PropertyBinding.prototype._setValue_fromArray_setNeedsUpdate, PropertyBinding.prototype._setValue_fromArray_setMatrixWorldNeedsUpdate]];\nclass AnimationAction {\n  constructor(mixer, clip, localRoot = null, blendMode = clip.blendMode) {\n    this._mixer = mixer;\n    this._clip = clip;\n    this._localRoot = localRoot;\n    this.blendMode = blendMode;\n    const tracks = clip.tracks,\n      nTracks = tracks.length,\n      interpolants = new Array(nTracks);\n    const interpolantSettings = {\n      endingStart: ZeroCurvatureEnding,\n      endingEnd: ZeroCurvatureEnding\n    };\n    for (let i = 0; i !== nTracks; ++i) {\n      const interpolant = tracks[i].createInterpolant(null);\n      interpolants[i] = interpolant;\n      interpolant.settings = interpolantSettings;\n    }\n    this._interpolantSettings = interpolantSettings;\n    this._interpolants = interpolants; // bound by the mixer\n\n    // inside: PropertyMixer (managed by the mixer)\n    this._propertyBindings = new Array(nTracks);\n    this._cacheIndex = null; // for the memory manager\n    this._byClipCacheIndex = null; // for the memory manager\n\n    this._timeScaleInterpolant = null;\n    this._weightInterpolant = null;\n    this.loop = LoopRepeat;\n    this._loopCount = -1;\n\n    // global mixer time when the action is to be started\n    // it's set back to 'null' upon start of the action\n    this._startTime = null;\n\n    // scaled local time of the action\n    // gets clamped or wrapped to 0..clip.duration according to loop\n    this.time = 0;\n    this.timeScale = 1;\n    this._effectiveTimeScale = 1;\n    this.weight = 1;\n    this._effectiveWeight = 1;\n    this.repetitions = Infinity; // no. of repetitions when looping\n\n    this.paused = false; // true -> zero effective time scale\n    this.enabled = true; // false -> zero effective weight\n\n    this.clampWhenFinished = false; // keep feeding the last frame?\n\n    this.zeroSlopeAtStart = true; // for smooth interpolation w/o separate\n    this.zeroSlopeAtEnd = true; // clips for start, loop and end\n  }\n\n  // State & Scheduling\n\n  play() {\n    this._mixer._activateAction(this);\n    return this;\n  }\n  stop() {\n    this._mixer._deactivateAction(this);\n    return this.reset();\n  }\n  reset() {\n    this.paused = false;\n    this.enabled = true;\n    this.time = 0; // restart clip\n    this._loopCount = -1; // forget previous loops\n    this._startTime = null; // forget scheduling\n\n    return this.stopFading().stopWarping();\n  }\n  isRunning() {\n    return this.enabled && !this.paused && this.timeScale !== 0 && this._startTime === null && this._mixer._isActiveAction(this);\n  }\n\n  // return true when play has been called\n  isScheduled() {\n    return this._mixer._isActiveAction(this);\n  }\n  startAt(time) {\n    this._startTime = time;\n    return this;\n  }\n  setLoop(mode, repetitions) {\n    this.loop = mode;\n    this.repetitions = repetitions;\n    return this;\n  }\n\n  // Weight\n\n  // set the weight stopping any scheduled fading\n  // although .enabled = false yields an effective weight of zero, this\n  // method does *not* change .enabled, because it would be confusing\n  setEffectiveWeight(weight) {\n    this.weight = weight;\n\n    // note: same logic as when updated at runtime\n    this._effectiveWeight = this.enabled ? weight : 0;\n    return this.stopFading();\n  }\n\n  // return the weight considering fading and .enabled\n  getEffectiveWeight() {\n    return this._effectiveWeight;\n  }\n  fadeIn(duration) {\n    return this._scheduleFading(duration, 0, 1);\n  }\n  fadeOut(duration) {\n    return this._scheduleFading(duration, 1, 0);\n  }\n  crossFadeFrom(fadeOutAction, duration, warp) {\n    fadeOutAction.fadeOut(duration);\n    this.fadeIn(duration);\n    if (warp) {\n      const fadeInDuration = this._clip.duration,\n        fadeOutDuration = fadeOutAction._clip.duration,\n        startEndRatio = fadeOutDuration / fadeInDuration,\n        endStartRatio = fadeInDuration / fadeOutDuration;\n      fadeOutAction.warp(1.0, startEndRatio, duration);\n      this.warp(endStartRatio, 1.0, duration);\n    }\n    return this;\n  }\n  crossFadeTo(fadeInAction, duration, warp) {\n    return fadeInAction.crossFadeFrom(this, duration, warp);\n  }\n  stopFading() {\n    const weightInterpolant = this._weightInterpolant;\n    if (weightInterpolant !== null) {\n      this._weightInterpolant = null;\n      this._mixer._takeBackControlInterpolant(weightInterpolant);\n    }\n    return this;\n  }\n\n  // Time Scale Control\n\n  // set the time scale stopping any scheduled warping\n  // although .paused = true yields an effective time scale of zero, this\n  // method does *not* change .paused, because it would be confusing\n  setEffectiveTimeScale(timeScale) {\n    this.timeScale = timeScale;\n    this._effectiveTimeScale = this.paused ? 0 : timeScale;\n    return this.stopWarping();\n  }\n\n  // return the time scale considering warping and .paused\n  getEffectiveTimeScale() {\n    return this._effectiveTimeScale;\n  }\n  setDuration(duration) {\n    this.timeScale = this._clip.duration / duration;\n    return this.stopWarping();\n  }\n  syncWith(action) {\n    this.time = action.time;\n    this.timeScale = action.timeScale;\n    return this.stopWarping();\n  }\n  halt(duration) {\n    return this.warp(this._effectiveTimeScale, 0, duration);\n  }\n  warp(startTimeScale, endTimeScale, duration) {\n    const mixer = this._mixer,\n      now = mixer.time,\n      timeScale = this.timeScale;\n    let interpolant = this._timeScaleInterpolant;\n    if (interpolant === null) {\n      interpolant = mixer._lendControlInterpolant();\n      this._timeScaleInterpolant = interpolant;\n    }\n    const times = interpolant.parameterPositions,\n      values = interpolant.sampleValues;\n    times[0] = now;\n    times[1] = now + duration;\n    values[0] = startTimeScale / timeScale;\n    values[1] = endTimeScale / timeScale;\n    return this;\n  }\n  stopWarping() {\n    const timeScaleInterpolant = this._timeScaleInterpolant;\n    if (timeScaleInterpolant !== null) {\n      this._timeScaleInterpolant = null;\n      this._mixer._takeBackControlInterpolant(timeScaleInterpolant);\n    }\n    return this;\n  }\n\n  // Object Accessors\n\n  getMixer() {\n    return this._mixer;\n  }\n  getClip() {\n    return this._clip;\n  }\n  getRoot() {\n    return this._localRoot || this._mixer._root;\n  }\n\n  // Interna\n\n  _update(time, deltaTime, timeDirection, accuIndex) {\n    // called by the mixer\n\n    if (!this.enabled) {\n      // call ._updateWeight() to update ._effectiveWeight\n\n      this._updateWeight(time);\n      return;\n    }\n    const startTime = this._startTime;\n    if (startTime !== null) {\n      // check for scheduled start of action\n\n      const timeRunning = (time - startTime) * timeDirection;\n      if (timeRunning < 0 || timeDirection === 0) {\n        deltaTime = 0;\n      } else {\n        this._startTime = null; // unschedule\n        deltaTime = timeDirection * timeRunning;\n      }\n    }\n\n    // apply time scale and advance time\n\n    deltaTime *= this._updateTimeScale(time);\n    const clipTime = this._updateTime(deltaTime);\n\n    // note: _updateTime may disable the action resulting in\n    // an effective weight of 0\n\n    const weight = this._updateWeight(time);\n    if (weight > 0) {\n      const interpolants = this._interpolants;\n      const propertyMixers = this._propertyBindings;\n      switch (this.blendMode) {\n        case AdditiveAnimationBlendMode:\n          for (let j = 0, m = interpolants.length; j !== m; ++j) {\n            interpolants[j].evaluate(clipTime);\n            propertyMixers[j].accumulateAdditive(weight);\n          }\n          break;\n        case NormalAnimationBlendMode:\n        default:\n          for (let j = 0, m = interpolants.length; j !== m; ++j) {\n            interpolants[j].evaluate(clipTime);\n            propertyMixers[j].accumulate(accuIndex, weight);\n          }\n      }\n    }\n  }\n  _updateWeight(time) {\n    let weight = 0;\n    if (this.enabled) {\n      weight = this.weight;\n      const interpolant = this._weightInterpolant;\n      if (interpolant !== null) {\n        const interpolantValue = interpolant.evaluate(time)[0];\n        weight *= interpolantValue;\n        if (time > interpolant.parameterPositions[1]) {\n          this.stopFading();\n          if (interpolantValue === 0) {\n            // faded out, disable\n            this.enabled = false;\n          }\n        }\n      }\n    }\n    this._effectiveWeight = weight;\n    return weight;\n  }\n  _updateTimeScale(time) {\n    let timeScale = 0;\n    if (!this.paused) {\n      timeScale = this.timeScale;\n      const interpolant = this._timeScaleInterpolant;\n      if (interpolant !== null) {\n        const interpolantValue = interpolant.evaluate(time)[0];\n        timeScale *= interpolantValue;\n        if (time > interpolant.parameterPositions[1]) {\n          this.stopWarping();\n          if (timeScale === 0) {\n            // motion has halted, pause\n            this.paused = true;\n          } else {\n            // warp done - apply final time scale\n            this.timeScale = timeScale;\n          }\n        }\n      }\n    }\n    this._effectiveTimeScale = timeScale;\n    return timeScale;\n  }\n  _updateTime(deltaTime) {\n    const duration = this._clip.duration;\n    const loop = this.loop;\n    let time = this.time + deltaTime;\n    let loopCount = this._loopCount;\n    const pingPong = loop === LoopPingPong;\n    if (deltaTime === 0) {\n      if (loopCount === -1) return time;\n      return pingPong && (loopCount & 1) === 1 ? duration - time : time;\n    }\n    if (loop === LoopOnce) {\n      if (loopCount === -1) {\n        // just started\n\n        this._loopCount = 0;\n        this._setEndings(true, true, false);\n      }\n      handle_stop: {\n        if (time >= duration) {\n          time = duration;\n        } else if (time < 0) {\n          time = 0;\n        } else {\n          this.time = time;\n          break handle_stop;\n        }\n        if (this.clampWhenFinished) this.paused = true;else this.enabled = false;\n        this.time = time;\n        this._mixer.dispatchEvent({\n          type: 'finished',\n          action: this,\n          direction: deltaTime < 0 ? -1 : 1\n        });\n      }\n    } else {\n      // repetitive Repeat or PingPong\n\n      if (loopCount === -1) {\n        // just started\n\n        if (deltaTime >= 0) {\n          loopCount = 0;\n          this._setEndings(true, this.repetitions === 0, pingPong);\n        } else {\n          // when looping in reverse direction, the initial\n          // transition through zero counts as a repetition,\n          // so leave loopCount at -1\n\n          this._setEndings(this.repetitions === 0, true, pingPong);\n        }\n      }\n      if (time >= duration || time < 0) {\n        // wrap around\n\n        const loopDelta = Math.floor(time / duration); // signed\n        time -= duration * loopDelta;\n        loopCount += Math.abs(loopDelta);\n        const pending = this.repetitions - loopCount;\n        if (pending <= 0) {\n          // have to stop (switch state, clamp time, fire event)\n\n          if (this.clampWhenFinished) this.paused = true;else this.enabled = false;\n          time = deltaTime > 0 ? duration : 0;\n          this.time = time;\n          this._mixer.dispatchEvent({\n            type: 'finished',\n            action: this,\n            direction: deltaTime > 0 ? 1 : -1\n          });\n        } else {\n          // keep running\n\n          if (pending === 1) {\n            // entering the last round\n\n            const atStart = deltaTime < 0;\n            this._setEndings(atStart, !atStart, pingPong);\n          } else {\n            this._setEndings(false, false, pingPong);\n          }\n          this._loopCount = loopCount;\n          this.time = time;\n          this._mixer.dispatchEvent({\n            type: 'loop',\n            action: this,\n            loopDelta: loopDelta\n          });\n        }\n      } else {\n        this.time = time;\n      }\n      if (pingPong && (loopCount & 1) === 1) {\n        // invert time for the \"pong round\"\n\n        return duration - time;\n      }\n    }\n    return time;\n  }\n  _setEndings(atStart, atEnd, pingPong) {\n    const settings = this._interpolantSettings;\n    if (pingPong) {\n      settings.endingStart = ZeroSlopeEnding;\n      settings.endingEnd = ZeroSlopeEnding;\n    } else {\n      // assuming for LoopOnce atStart == atEnd == true\n\n      if (atStart) {\n        settings.endingStart = this.zeroSlopeAtStart ? ZeroSlopeEnding : ZeroCurvatureEnding;\n      } else {\n        settings.endingStart = WrapAroundEnding;\n      }\n      if (atEnd) {\n        settings.endingEnd = this.zeroSlopeAtEnd ? ZeroSlopeEnding : ZeroCurvatureEnding;\n      } else {\n        settings.endingEnd = WrapAroundEnding;\n      }\n    }\n  }\n  _scheduleFading(duration, weightNow, weightThen) {\n    const mixer = this._mixer,\n      now = mixer.time;\n    let interpolant = this._weightInterpolant;\n    if (interpolant === null) {\n      interpolant = mixer._lendControlInterpolant();\n      this._weightInterpolant = interpolant;\n    }\n    const times = interpolant.parameterPositions,\n      values = interpolant.sampleValues;\n    times[0] = now;\n    values[0] = weightNow;\n    times[1] = now + duration;\n    values[1] = weightThen;\n    return this;\n  }\n}\nconst _controlInterpolantsResultBuffer = new Float32Array(1);\nclass AnimationMixer extends EventDispatcher {\n  constructor(root) {\n    super();\n    this._root = root;\n    this._initMemoryManager();\n    this._accuIndex = 0;\n    this.time = 0;\n    this.timeScale = 1.0;\n  }\n  _bindAction(action, prototypeAction) {\n    const root = action._localRoot || this._root,\n      tracks = action._clip.tracks,\n      nTracks = tracks.length,\n      bindings = action._propertyBindings,\n      interpolants = action._interpolants,\n      rootUuid = root.uuid,\n      bindingsByRoot = this._bindingsByRootAndName;\n    let bindingsByName = bindingsByRoot[rootUuid];\n    if (bindingsByName === undefined) {\n      bindingsByName = {};\n      bindingsByRoot[rootUuid] = bindingsByName;\n    }\n    for (let i = 0; i !== nTracks; ++i) {\n      const track = tracks[i],\n        trackName = track.name;\n      let binding = bindingsByName[trackName];\n      if (binding !== undefined) {\n        ++binding.referenceCount;\n        bindings[i] = binding;\n      } else {\n        binding = bindings[i];\n        if (binding !== undefined) {\n          // existing binding, make sure the cache knows\n\n          if (binding._cacheIndex === null) {\n            ++binding.referenceCount;\n            this._addInactiveBinding(binding, rootUuid, trackName);\n          }\n          continue;\n        }\n        const path = prototypeAction && prototypeAction._propertyBindings[i].binding.parsedPath;\n        binding = new PropertyMixer(PropertyBinding.create(root, trackName, path), track.ValueTypeName, track.getValueSize());\n        ++binding.referenceCount;\n        this._addInactiveBinding(binding, rootUuid, trackName);\n        bindings[i] = binding;\n      }\n      interpolants[i].resultBuffer = binding.buffer;\n    }\n  }\n  _activateAction(action) {\n    if (!this._isActiveAction(action)) {\n      if (action._cacheIndex === null) {\n        // this action has been forgotten by the cache, but the user\n        // appears to be still using it -> rebind\n\n        const rootUuid = (action._localRoot || this._root).uuid,\n          clipUuid = action._clip.uuid,\n          actionsForClip = this._actionsByClip[clipUuid];\n        this._bindAction(action, actionsForClip && actionsForClip.knownActions[0]);\n        this._addInactiveAction(action, clipUuid, rootUuid);\n      }\n      const bindings = action._propertyBindings;\n\n      // increment reference counts / sort out state\n      for (let i = 0, n = bindings.length; i !== n; ++i) {\n        const binding = bindings[i];\n        if (binding.useCount++ === 0) {\n          this._lendBinding(binding);\n          binding.saveOriginalState();\n        }\n      }\n      this._lendAction(action);\n    }\n  }\n  _deactivateAction(action) {\n    if (this._isActiveAction(action)) {\n      const bindings = action._propertyBindings;\n\n      // decrement reference counts / sort out state\n      for (let i = 0, n = bindings.length; i !== n; ++i) {\n        const binding = bindings[i];\n        if (--binding.useCount === 0) {\n          binding.restoreOriginalState();\n          this._takeBackBinding(binding);\n        }\n      }\n      this._takeBackAction(action);\n    }\n  }\n\n  // Memory manager\n\n  _initMemoryManager() {\n    this._actions = []; // 'nActiveActions' followed by inactive ones\n    this._nActiveActions = 0;\n    this._actionsByClip = {};\n    // inside:\n    // {\n    // \tknownActions: Array< AnimationAction > - used as prototypes\n    // \tactionByRoot: AnimationAction - lookup\n    // }\n\n    this._bindings = []; // 'nActiveBindings' followed by inactive ones\n    this._nActiveBindings = 0;\n    this._bindingsByRootAndName = {}; // inside: Map< name, PropertyMixer >\n\n    this._controlInterpolants = []; // same game as above\n    this._nActiveControlInterpolants = 0;\n    const scope = this;\n    this.stats = {\n      actions: {\n        get total() {\n          return scope._actions.length;\n        },\n        get inUse() {\n          return scope._nActiveActions;\n        }\n      },\n      bindings: {\n        get total() {\n          return scope._bindings.length;\n        },\n        get inUse() {\n          return scope._nActiveBindings;\n        }\n      },\n      controlInterpolants: {\n        get total() {\n          return scope._controlInterpolants.length;\n        },\n        get inUse() {\n          return scope._nActiveControlInterpolants;\n        }\n      }\n    };\n  }\n\n  // Memory management for AnimationAction objects\n\n  _isActiveAction(action) {\n    const index = action._cacheIndex;\n    return index !== null && index < this._nActiveActions;\n  }\n  _addInactiveAction(action, clipUuid, rootUuid) {\n    const actions = this._actions,\n      actionsByClip = this._actionsByClip;\n    let actionsForClip = actionsByClip[clipUuid];\n    if (actionsForClip === undefined) {\n      actionsForClip = {\n        knownActions: [action],\n        actionByRoot: {}\n      };\n      action._byClipCacheIndex = 0;\n      actionsByClip[clipUuid] = actionsForClip;\n    } else {\n      const knownActions = actionsForClip.knownActions;\n      action._byClipCacheIndex = knownActions.length;\n      knownActions.push(action);\n    }\n    action._cacheIndex = actions.length;\n    actions.push(action);\n    actionsForClip.actionByRoot[rootUuid] = action;\n  }\n  _removeInactiveAction(action) {\n    const actions = this._actions,\n      lastInactiveAction = actions[actions.length - 1],\n      cacheIndex = action._cacheIndex;\n    lastInactiveAction._cacheIndex = cacheIndex;\n    actions[cacheIndex] = lastInactiveAction;\n    actions.pop();\n    action._cacheIndex = null;\n    const clipUuid = action._clip.uuid,\n      actionsByClip = this._actionsByClip,\n      actionsForClip = actionsByClip[clipUuid],\n      knownActionsForClip = actionsForClip.knownActions,\n      lastKnownAction = knownActionsForClip[knownActionsForClip.length - 1],\n      byClipCacheIndex = action._byClipCacheIndex;\n    lastKnownAction._byClipCacheIndex = byClipCacheIndex;\n    knownActionsForClip[byClipCacheIndex] = lastKnownAction;\n    knownActionsForClip.pop();\n    action._byClipCacheIndex = null;\n    const actionByRoot = actionsForClip.actionByRoot,\n      rootUuid = (action._localRoot || this._root).uuid;\n    delete actionByRoot[rootUuid];\n    if (knownActionsForClip.length === 0) {\n      delete actionsByClip[clipUuid];\n    }\n    this._removeInactiveBindingsForAction(action);\n  }\n  _removeInactiveBindingsForAction(action) {\n    const bindings = action._propertyBindings;\n    for (let i = 0, n = bindings.length; i !== n; ++i) {\n      const binding = bindings[i];\n      if (--binding.referenceCount === 0) {\n        this._removeInactiveBinding(binding);\n      }\n    }\n  }\n  _lendAction(action) {\n    // [ active actions |  inactive actions  ]\n    // [  active actions >| inactive actions ]\n    //                 s        a\n    //                  <-swap->\n    //                 a        s\n\n    const actions = this._actions,\n      prevIndex = action._cacheIndex,\n      lastActiveIndex = this._nActiveActions++,\n      firstInactiveAction = actions[lastActiveIndex];\n    action._cacheIndex = lastActiveIndex;\n    actions[lastActiveIndex] = action;\n    firstInactiveAction._cacheIndex = prevIndex;\n    actions[prevIndex] = firstInactiveAction;\n  }\n  _takeBackAction(action) {\n    // [  active actions  | inactive actions ]\n    // [ active actions |< inactive actions  ]\n    //        a        s\n    //         <-swap->\n    //        s        a\n\n    const actions = this._actions,\n      prevIndex = action._cacheIndex,\n      firstInactiveIndex = --this._nActiveActions,\n      lastActiveAction = actions[firstInactiveIndex];\n    action._cacheIndex = firstInactiveIndex;\n    actions[firstInactiveIndex] = action;\n    lastActiveAction._cacheIndex = prevIndex;\n    actions[prevIndex] = lastActiveAction;\n  }\n\n  // Memory management for PropertyMixer objects\n\n  _addInactiveBinding(binding, rootUuid, trackName) {\n    const bindingsByRoot = this._bindingsByRootAndName,\n      bindings = this._bindings;\n    let bindingByName = bindingsByRoot[rootUuid];\n    if (bindingByName === undefined) {\n      bindingByName = {};\n      bindingsByRoot[rootUuid] = bindingByName;\n    }\n    bindingByName[trackName] = binding;\n    binding._cacheIndex = bindings.length;\n    bindings.push(binding);\n  }\n  _removeInactiveBinding(binding) {\n    const bindings = this._bindings,\n      propBinding = binding.binding,\n      rootUuid = propBinding.rootNode.uuid,\n      trackName = propBinding.path,\n      bindingsByRoot = this._bindingsByRootAndName,\n      bindingByName = bindingsByRoot[rootUuid],\n      lastInactiveBinding = bindings[bindings.length - 1],\n      cacheIndex = binding._cacheIndex;\n    lastInactiveBinding._cacheIndex = cacheIndex;\n    bindings[cacheIndex] = lastInactiveBinding;\n    bindings.pop();\n    delete bindingByName[trackName];\n    if (Object.keys(bindingByName).length === 0) {\n      delete bindingsByRoot[rootUuid];\n    }\n  }\n  _lendBinding(binding) {\n    const bindings = this._bindings,\n      prevIndex = binding._cacheIndex,\n      lastActiveIndex = this._nActiveBindings++,\n      firstInactiveBinding = bindings[lastActiveIndex];\n    binding._cacheIndex = lastActiveIndex;\n    bindings[lastActiveIndex] = binding;\n    firstInactiveBinding._cacheIndex = prevIndex;\n    bindings[prevIndex] = firstInactiveBinding;\n  }\n  _takeBackBinding(binding) {\n    const bindings = this._bindings,\n      prevIndex = binding._cacheIndex,\n      firstInactiveIndex = --this._nActiveBindings,\n      lastActiveBinding = bindings[firstInactiveIndex];\n    binding._cacheIndex = firstInactiveIndex;\n    bindings[firstInactiveIndex] = binding;\n    lastActiveBinding._cacheIndex = prevIndex;\n    bindings[prevIndex] = lastActiveBinding;\n  }\n\n  // Memory management of Interpolants for weight and time scale\n\n  _lendControlInterpolant() {\n    const interpolants = this._controlInterpolants,\n      lastActiveIndex = this._nActiveControlInterpolants++;\n    let interpolant = interpolants[lastActiveIndex];\n    if (interpolant === undefined) {\n      interpolant = new LinearInterpolant(new Float32Array(2), new Float32Array(2), 1, _controlInterpolantsResultBuffer);\n      interpolant.__cacheIndex = lastActiveIndex;\n      interpolants[lastActiveIndex] = interpolant;\n    }\n    return interpolant;\n  }\n  _takeBackControlInterpolant(interpolant) {\n    const interpolants = this._controlInterpolants,\n      prevIndex = interpolant.__cacheIndex,\n      firstInactiveIndex = --this._nActiveControlInterpolants,\n      lastActiveInterpolant = interpolants[firstInactiveIndex];\n    interpolant.__cacheIndex = firstInactiveIndex;\n    interpolants[firstInactiveIndex] = interpolant;\n    lastActiveInterpolant.__cacheIndex = prevIndex;\n    interpolants[prevIndex] = lastActiveInterpolant;\n  }\n\n  // return an action for a clip optionally using a custom root target\n  // object (this method allocates a lot of dynamic memory in case a\n  // previously unknown clip/root combination is specified)\n  clipAction(clip, optionalRoot, blendMode) {\n    const root = optionalRoot || this._root,\n      rootUuid = root.uuid;\n    let clipObject = typeof clip === 'string' ? AnimationClip.findByName(root, clip) : clip;\n    const clipUuid = clipObject !== null ? clipObject.uuid : clip;\n    const actionsForClip = this._actionsByClip[clipUuid];\n    let prototypeAction = null;\n    if (blendMode === undefined) {\n      if (clipObject !== null) {\n        blendMode = clipObject.blendMode;\n      } else {\n        blendMode = NormalAnimationBlendMode;\n      }\n    }\n    if (actionsForClip !== undefined) {\n      const existingAction = actionsForClip.actionByRoot[rootUuid];\n      if (existingAction !== undefined && existingAction.blendMode === blendMode) {\n        return existingAction;\n      }\n\n      // we know the clip, so we don't have to parse all\n      // the bindings again but can just copy\n      prototypeAction = actionsForClip.knownActions[0];\n\n      // also, take the clip from the prototype action\n      if (clipObject === null) clipObject = prototypeAction._clip;\n    }\n\n    // clip must be known when specified via string\n    if (clipObject === null) return null;\n\n    // allocate all resources required to run it\n    const newAction = new AnimationAction(this, clipObject, optionalRoot, blendMode);\n    this._bindAction(newAction, prototypeAction);\n\n    // and make the action known to the memory manager\n    this._addInactiveAction(newAction, clipUuid, rootUuid);\n    return newAction;\n  }\n\n  // get an existing action\n  existingAction(clip, optionalRoot) {\n    const root = optionalRoot || this._root,\n      rootUuid = root.uuid,\n      clipObject = typeof clip === 'string' ? AnimationClip.findByName(root, clip) : clip,\n      clipUuid = clipObject ? clipObject.uuid : clip,\n      actionsForClip = this._actionsByClip[clipUuid];\n    if (actionsForClip !== undefined) {\n      return actionsForClip.actionByRoot[rootUuid] || null;\n    }\n    return null;\n  }\n\n  // deactivates all previously scheduled actions\n  stopAllAction() {\n    const actions = this._actions,\n      nActions = this._nActiveActions;\n    for (let i = nActions - 1; i >= 0; --i) {\n      actions[i].stop();\n    }\n    return this;\n  }\n\n  // advance the time and update apply the animation\n  update(deltaTime) {\n    deltaTime *= this.timeScale;\n    const actions = this._actions,\n      nActions = this._nActiveActions,\n      time = this.time += deltaTime,\n      timeDirection = Math.sign(deltaTime),\n      accuIndex = this._accuIndex ^= 1;\n\n    // run active actions\n\n    for (let i = 0; i !== nActions; ++i) {\n      const action = actions[i];\n      action._update(time, deltaTime, timeDirection, accuIndex);\n    }\n\n    // update scene graph\n\n    const bindings = this._bindings,\n      nBindings = this._nActiveBindings;\n    for (let i = 0; i !== nBindings; ++i) {\n      bindings[i].apply(accuIndex);\n    }\n    return this;\n  }\n\n  // Allows you to seek to a specific time in an animation.\n  setTime(timeInSeconds) {\n    this.time = 0; // Zero out time attribute for AnimationMixer object;\n    for (let i = 0; i < this._actions.length; i++) {\n      this._actions[i].time = 0; // Zero out time attribute for all associated AnimationAction objects.\n    }\n    return this.update(timeInSeconds); // Update used to set exact time. Returns \"this\" AnimationMixer object.\n  }\n\n  // return this mixer's root target object\n  getRoot() {\n    return this._root;\n  }\n\n  // free all resources specific to a particular clip\n  uncacheClip(clip) {\n    const actions = this._actions,\n      clipUuid = clip.uuid,\n      actionsByClip = this._actionsByClip,\n      actionsForClip = actionsByClip[clipUuid];\n    if (actionsForClip !== undefined) {\n      // note: just calling _removeInactiveAction would mess up the\n      // iteration state and also require updating the state we can\n      // just throw away\n\n      const actionsToRemove = actionsForClip.knownActions;\n      for (let i = 0, n = actionsToRemove.length; i !== n; ++i) {\n        const action = actionsToRemove[i];\n        this._deactivateAction(action);\n        const cacheIndex = action._cacheIndex,\n          lastInactiveAction = actions[actions.length - 1];\n        action._cacheIndex = null;\n        action._byClipCacheIndex = null;\n        lastInactiveAction._cacheIndex = cacheIndex;\n        actions[cacheIndex] = lastInactiveAction;\n        actions.pop();\n        this._removeInactiveBindingsForAction(action);\n      }\n      delete actionsByClip[clipUuid];\n    }\n  }\n\n  // free all resources specific to a particular root target object\n  uncacheRoot(root) {\n    const rootUuid = root.uuid,\n      actionsByClip = this._actionsByClip;\n    for (const clipUuid in actionsByClip) {\n      const actionByRoot = actionsByClip[clipUuid].actionByRoot,\n        action = actionByRoot[rootUuid];\n      if (action !== undefined) {\n        this._deactivateAction(action);\n        this._removeInactiveAction(action);\n      }\n    }\n    const bindingsByRoot = this._bindingsByRootAndName,\n      bindingByName = bindingsByRoot[rootUuid];\n    if (bindingByName !== undefined) {\n      for (const trackName in bindingByName) {\n        const binding = bindingByName[trackName];\n        binding.restoreOriginalState();\n        this._removeInactiveBinding(binding);\n      }\n    }\n  }\n\n  // remove a targeted clip from the cache\n  uncacheAction(clip, optionalRoot) {\n    const action = this.existingAction(clip, optionalRoot);\n    if (action !== null) {\n      this._deactivateAction(action);\n      this._removeInactiveAction(action);\n    }\n  }\n}\nclass Uniform {\n  constructor(value) {\n    this.value = value;\n  }\n  clone() {\n    return new Uniform(this.value.clone === undefined ? this.value : this.value.clone());\n  }\n}\nconst _matrix = /*@__PURE__*/new Matrix4();\nclass Raycaster {\n  constructor(origin, direction, near = 0, far = Infinity) {\n    this.ray = new Ray(origin, direction);\n    // direction is assumed to be normalized (for accurate distance calculations)\n\n    this.near = near;\n    this.far = far;\n    this.camera = null;\n    this.layers = new Layers();\n    this.params = {\n      Mesh: {},\n      Line: {\n        threshold: 1\n      },\n      LOD: {},\n      Points: {\n        threshold: 1\n      },\n      Sprite: {}\n    };\n  }\n  set(origin, direction) {\n    // direction is assumed to be normalized (for accurate distance calculations)\n\n    this.ray.set(origin, direction);\n  }\n  setFromCamera(coords, camera) {\n    if (camera.isPerspectiveCamera) {\n      this.ray.origin.setFromMatrixPosition(camera.matrixWorld);\n      this.ray.direction.set(coords.x, coords.y, 0.5).unproject(camera).sub(this.ray.origin).normalize();\n      this.camera = camera;\n    } else if (camera.isOrthographicCamera) {\n      this.ray.origin.set(coords.x, coords.y, (camera.near + camera.far) / (camera.near - camera.far)).unproject(camera); // set origin in plane of camera\n      this.ray.direction.set(0, 0, -1).transformDirection(camera.matrixWorld);\n      this.camera = camera;\n    } else {\n      console.error('THREE.Raycaster: Unsupported camera type: ' + camera.type);\n    }\n  }\n  setFromXRController(controller) {\n    _matrix.identity().extractRotation(controller.matrixWorld);\n    this.ray.origin.setFromMatrixPosition(controller.matrixWorld);\n    this.ray.direction.set(0, 0, -1).applyMatrix4(_matrix);\n    return this;\n  }\n  intersectObject(object, recursive = true, intersects = []) {\n    intersect(object, this, intersects, recursive);\n    intersects.sort(ascSort);\n    return intersects;\n  }\n  intersectObjects(objects, recursive = true, intersects = []) {\n    for (let i = 0, l = objects.length; i < l; i++) {\n      intersect(objects[i], this, intersects, recursive);\n    }\n    intersects.sort(ascSort);\n    return intersects;\n  }\n}\nfunction ascSort(a, b) {\n  return a.distance - b.distance;\n}\nfunction intersect(object, raycaster, intersects, recursive) {\n  let propagate = true;\n  if (object.layers.test(raycaster.layers)) {\n    const result = object.raycast(raycaster, intersects);\n    if (result === false) propagate = false;\n  }\n  if (propagate === true && recursive === true) {\n    const children = object.children;\n    for (let i = 0, l = children.length; i < l; i++) {\n      intersect(children[i], raycaster, intersects, true);\n    }\n  }\n}\n\n/**\n * Ref: https://en.wikipedia.org/wiki/Spherical_coordinate_system\n *\n * phi (the polar angle) is measured from the positive y-axis. The positive y-axis is up.\n * theta (the azimuthal angle) is measured from the positive z-axis.\n */\nclass Spherical {\n  constructor(radius = 1, phi = 0, theta = 0) {\n    this.radius = radius;\n    this.phi = phi; // polar angle\n    this.theta = theta; // azimuthal angle\n\n    return this;\n  }\n  set(radius, phi, theta) {\n    this.radius = radius;\n    this.phi = phi;\n    this.theta = theta;\n    return this;\n  }\n  copy(other) {\n    this.radius = other.radius;\n    this.phi = other.phi;\n    this.theta = other.theta;\n    return this;\n  }\n\n  // restrict phi to be between EPS and PI-EPS\n  makeSafe() {\n    const EPS = 0.000001;\n    this.phi = Math.max(EPS, Math.min(Math.PI - EPS, this.phi));\n    return this;\n  }\n  setFromVector3(v) {\n    return this.setFromCartesianCoords(v.x, v.y, v.z);\n  }\n  setFromCartesianCoords(x, y, z) {\n    this.radius = Math.sqrt(x * x + y * y + z * z);\n    if (this.radius === 0) {\n      this.theta = 0;\n      this.phi = 0;\n    } else {\n      this.theta = Math.atan2(x, z);\n      this.phi = Math.acos(clamp$1(y / this.radius, -1, 1));\n    }\n    return this;\n  }\n  clone() {\n    return new this.constructor().copy(this);\n  }\n}\nif (typeof __THREE_DEVTOOLS__ !== 'undefined') {\n  __THREE_DEVTOOLS__.dispatchEvent(new CustomEvent('register', {\n    detail: {\n      revision: REVISION\n    }\n  }));\n}\nif (typeof window !== 'undefined') {\n  if (window.__THREE__) {\n    console.warn('WARNING: Multiple instances of Three.js being imported.');\n  } else {\n    window.__THREE__ = REVISION;\n  }\n}\n\n/**\n * @license\n * Copyright 2019 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nconst t$3 = window,\n  e$4 = t$3.ShadowRoot && (void 0 === t$3.ShadyCSS || t$3.ShadyCSS.nativeShadow) && \"adoptedStyleSheets\" in Document.prototype && \"replace\" in CSSStyleSheet.prototype,\n  s$5 = Symbol(),\n  n$6 = new WeakMap();\nclass o$5 {\n  constructor(t, e, n) {\n    if (this._$cssResult$ = !0, n !== s$5) throw Error(\"CSSResult is not constructable. Use `unsafeCSS` or `css` instead.\");\n    this.cssText = t, this.t = e;\n  }\n  get styleSheet() {\n    let t = this.o;\n    const s = this.t;\n    if (e$4 && void 0 === t) {\n      const e = void 0 !== s && 1 === s.length;\n      e && (t = n$6.get(s)), void 0 === t && ((this.o = t = new CSSStyleSheet()).replaceSync(this.cssText), e && n$6.set(s, t));\n    }\n    return t;\n  }\n  toString() {\n    return this.cssText;\n  }\n}\nconst r$4 = t => new o$5(\"string\" == typeof t ? t : t + \"\", void 0, s$5),\n  S$2 = (s, n) => {\n    e$4 ? s.adoptedStyleSheets = n.map(t => t instanceof CSSStyleSheet ? t : t.styleSheet) : n.forEach(e => {\n      const n = document.createElement(\"style\"),\n        o = t$3.litNonce;\n      void 0 !== o && n.setAttribute(\"nonce\", o), n.textContent = e.cssText, s.appendChild(n);\n    });\n  },\n  c$3 = e$4 ? t => t : t => t instanceof CSSStyleSheet ? (t => {\n    let e = \"\";\n    for (const s of t.cssRules) e += s.cssText;\n    return r$4(e);\n  })(t) : t;\n\n/**\n * @license\n * Copyright 2017 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nvar s$4;\nconst e$3 = window,\n  r$3 = e$3.trustedTypes,\n  h$2 = r$3 ? r$3.emptyScript : \"\",\n  o$4 = e$3.reactiveElementPolyfillSupport,\n  n$5 = {\n    toAttribute(t, i) {\n      switch (i) {\n        case Boolean:\n          t = t ? h$2 : null;\n          break;\n        case Object:\n        case Array:\n          t = null == t ? t : JSON.stringify(t);\n      }\n      return t;\n    },\n    fromAttribute(t, i) {\n      let s = t;\n      switch (i) {\n        case Boolean:\n          s = null !== t;\n          break;\n        case Number:\n          s = null === t ? null : Number(t);\n          break;\n        case Object:\n        case Array:\n          try {\n            s = JSON.parse(t);\n          } catch (t) {\n            s = null;\n          }\n      }\n      return s;\n    }\n  },\n  a$3 = (t, i) => i !== t && (i == i || t == t),\n  l$3 = {\n    attribute: !0,\n    type: String,\n    converter: n$5,\n    reflect: !1,\n    hasChanged: a$3\n  },\n  d$2 = \"finalized\";\nclass u$3 extends HTMLElement {\n  constructor() {\n    super(), this._$Ei = new Map(), this.isUpdatePending = !1, this.hasUpdated = !1, this._$El = null, this._$Eu();\n  }\n  static addInitializer(t) {\n    var i;\n    this.finalize(), (null !== (i = this.h) && void 0 !== i ? i : this.h = []).push(t);\n  }\n  static get observedAttributes() {\n    this.finalize();\n    const t = [];\n    return this.elementProperties.forEach((i, s) => {\n      const e = this._$Ep(s, i);\n      void 0 !== e && (this._$Ev.set(e, s), t.push(e));\n    }), t;\n  }\n  static createProperty(t, i = l$3) {\n    if (i.state && (i.attribute = !1), this.finalize(), this.elementProperties.set(t, i), !i.noAccessor && !this.prototype.hasOwnProperty(t)) {\n      const s = \"symbol\" == typeof t ? Symbol() : \"__\" + t,\n        e = this.getPropertyDescriptor(t, s, i);\n      void 0 !== e && Object.defineProperty(this.prototype, t, e);\n    }\n  }\n  static getPropertyDescriptor(t, i, s) {\n    return {\n      get() {\n        return this[i];\n      },\n      set(e) {\n        const r = this[t];\n        this[i] = e, this.requestUpdate(t, r, s);\n      },\n      configurable: !0,\n      enumerable: !0\n    };\n  }\n  static getPropertyOptions(t) {\n    return this.elementProperties.get(t) || l$3;\n  }\n  static finalize() {\n    if (this.hasOwnProperty(d$2)) return !1;\n    this[d$2] = !0;\n    const t = Object.getPrototypeOf(this);\n    if (t.finalize(), void 0 !== t.h && (this.h = [...t.h]), this.elementProperties = new Map(t.elementProperties), this._$Ev = new Map(), this.hasOwnProperty(\"properties\")) {\n      const t = this.properties,\n        i = [...Object.getOwnPropertyNames(t), ...Object.getOwnPropertySymbols(t)];\n      for (const s of i) this.createProperty(s, t[s]);\n    }\n    return this.elementStyles = this.finalizeStyles(this.styles), !0;\n  }\n  static finalizeStyles(i) {\n    const s = [];\n    if (Array.isArray(i)) {\n      const e = new Set(i.flat(1 / 0).reverse());\n      for (const i of e) s.unshift(c$3(i));\n    } else void 0 !== i && s.push(c$3(i));\n    return s;\n  }\n  static _$Ep(t, i) {\n    const s = i.attribute;\n    return !1 === s ? void 0 : \"string\" == typeof s ? s : \"string\" == typeof t ? t.toLowerCase() : void 0;\n  }\n  _$Eu() {\n    var t;\n    this._$E_ = new Promise(t => this.enableUpdating = t), this._$AL = new Map(), this._$Eg(), this.requestUpdate(), null === (t = this.constructor.h) || void 0 === t || t.forEach(t => t(this));\n  }\n  addController(t) {\n    var i, s;\n    (null !== (i = this._$ES) && void 0 !== i ? i : this._$ES = []).push(t), void 0 !== this.renderRoot && this.isConnected && (null === (s = t.hostConnected) || void 0 === s || s.call(t));\n  }\n  removeController(t) {\n    var i;\n    null === (i = this._$ES) || void 0 === i || i.splice(this._$ES.indexOf(t) >>> 0, 1);\n  }\n  _$Eg() {\n    this.constructor.elementProperties.forEach((t, i) => {\n      this.hasOwnProperty(i) && (this._$Ei.set(i, this[i]), delete this[i]);\n    });\n  }\n  createRenderRoot() {\n    var t;\n    const s = null !== (t = this.shadowRoot) && void 0 !== t ? t : this.attachShadow(this.constructor.shadowRootOptions);\n    return S$2(s, this.constructor.elementStyles), s;\n  }\n  connectedCallback() {\n    var t;\n    void 0 === this.renderRoot && (this.renderRoot = this.createRenderRoot()), this.enableUpdating(!0), null === (t = this._$ES) || void 0 === t || t.forEach(t => {\n      var i;\n      return null === (i = t.hostConnected) || void 0 === i ? void 0 : i.call(t);\n    });\n  }\n  enableUpdating(t) {}\n  disconnectedCallback() {\n    var t;\n    null === (t = this._$ES) || void 0 === t || t.forEach(t => {\n      var i;\n      return null === (i = t.hostDisconnected) || void 0 === i ? void 0 : i.call(t);\n    });\n  }\n  attributeChangedCallback(t, i, s) {\n    this._$AK(t, s);\n  }\n  _$EO(t, i, s = l$3) {\n    var e;\n    const r = this.constructor._$Ep(t, s);\n    if (void 0 !== r && !0 === s.reflect) {\n      const h = (void 0 !== (null === (e = s.converter) || void 0 === e ? void 0 : e.toAttribute) ? s.converter : n$5).toAttribute(i, s.type);\n      this._$El = t, null == h ? this.removeAttribute(r) : this.setAttribute(r, h), this._$El = null;\n    }\n  }\n  _$AK(t, i) {\n    var s;\n    const e = this.constructor,\n      r = e._$Ev.get(t);\n    if (void 0 !== r && this._$El !== r) {\n      const t = e.getPropertyOptions(r),\n        h = \"function\" == typeof t.converter ? {\n          fromAttribute: t.converter\n        } : void 0 !== (null === (s = t.converter) || void 0 === s ? void 0 : s.fromAttribute) ? t.converter : n$5;\n      this._$El = r, this[r] = h.fromAttribute(i, t.type), this._$El = null;\n    }\n  }\n  requestUpdate(t, i, s) {\n    let e = !0;\n    void 0 !== t && (((s = s || this.constructor.getPropertyOptions(t)).hasChanged || a$3)(this[t], i) ? (this._$AL.has(t) || this._$AL.set(t, i), !0 === s.reflect && this._$El !== t && (void 0 === this._$EC && (this._$EC = new Map()), this._$EC.set(t, s))) : e = !1), !this.isUpdatePending && e && (this._$E_ = this._$Ej());\n  }\n  async _$Ej() {\n    this.isUpdatePending = !0;\n    try {\n      await this._$E_;\n    } catch (t) {\n      Promise.reject(t);\n    }\n    const t = this.scheduleUpdate();\n    return null != t && (await t), !this.isUpdatePending;\n  }\n  scheduleUpdate() {\n    return this.performUpdate();\n  }\n  performUpdate() {\n    var t;\n    if (!this.isUpdatePending) return;\n    this.hasUpdated, this._$Ei && (this._$Ei.forEach((t, i) => this[i] = t), this._$Ei = void 0);\n    let i = !1;\n    const s = this._$AL;\n    try {\n      i = this.shouldUpdate(s), i ? (this.willUpdate(s), null === (t = this._$ES) || void 0 === t || t.forEach(t => {\n        var i;\n        return null === (i = t.hostUpdate) || void 0 === i ? void 0 : i.call(t);\n      }), this.update(s)) : this._$Ek();\n    } catch (t) {\n      throw i = !1, this._$Ek(), t;\n    }\n    i && this._$AE(s);\n  }\n  willUpdate(t) {}\n  _$AE(t) {\n    var i;\n    null === (i = this._$ES) || void 0 === i || i.forEach(t => {\n      var i;\n      return null === (i = t.hostUpdated) || void 0 === i ? void 0 : i.call(t);\n    }), this.hasUpdated || (this.hasUpdated = !0, this.firstUpdated(t)), this.updated(t);\n  }\n  _$Ek() {\n    this._$AL = new Map(), this.isUpdatePending = !1;\n  }\n  get updateComplete() {\n    return this.getUpdateComplete();\n  }\n  getUpdateComplete() {\n    return this._$E_;\n  }\n  shouldUpdate(t) {\n    return !0;\n  }\n  update(t) {\n    void 0 !== this._$EC && (this._$EC.forEach((t, i) => this._$EO(i, this[i], t)), this._$EC = void 0), this._$Ek();\n  }\n  updated(t) {}\n  firstUpdated(t) {}\n}\nu$3[d$2] = !0, u$3.elementProperties = new Map(), u$3.elementStyles = [], u$3.shadowRootOptions = {\n  mode: \"open\"\n}, null == o$4 || o$4({\n  ReactiveElement: u$3\n}), (null !== (s$4 = e$3.reactiveElementVersions) && void 0 !== s$4 ? s$4 : e$3.reactiveElementVersions = []).push(\"1.6.3\");\n\n/**\n * @license\n * Copyright 2017 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nvar t$2;\nconst i$1 = window,\n  s$3 = i$1.trustedTypes,\n  e$2 = s$3 ? s$3.createPolicy(\"lit-html\", {\n    createHTML: t => t\n  }) : void 0,\n  o$3 = \"$lit$\",\n  n$4 = `lit$${(Math.random() + \"\").slice(9)}$`,\n  l$2 = \"?\" + n$4,\n  h$1 = `<${l$2}>`,\n  r$2 = document,\n  u$2 = () => r$2.createComment(\"\"),\n  d$1 = t => null === t || \"object\" != typeof t && \"function\" != typeof t,\n  c$2 = Array.isArray,\n  v = t => c$2(t) || \"function\" == typeof (null == t ? void 0 : t[Symbol.iterator]),\n  a$2 = \"[ \\t\\n\\f\\r]\",\n  f = /<(?:(!--|\\/[^a-zA-Z])|(\\/?[a-zA-Z][^>\\s]*)|(\\/?$))/g,\n  _ = /-->/g,\n  m = />/g,\n  p = RegExp(`>|${a$2}(?:([^\\\\s\"'>=/]+)(${a$2}*=${a$2}*(?:[^ \\t\\n\\f\\r\"'\\`<>=]|(\"|')|))|$)`, \"g\"),\n  g$2 = /'/g,\n  $ = /\"/g,\n  y = /^(?:script|style|textarea|title)$/i,\n  w = t => (i, ...s) => ({\n    _$litType$: t,\n    strings: i,\n    values: s\n  }),\n  x$1 = w(1),\n  T$1 = Symbol.for(\"lit-noChange\"),\n  A$1 = Symbol.for(\"lit-nothing\"),\n  E = new WeakMap(),\n  C$2 = r$2.createTreeWalker(r$2, 129, null, !1);\nfunction P(t, i) {\n  if (!Array.isArray(t) || !t.hasOwnProperty(\"raw\")) throw Error(\"invalid template strings array\");\n  return void 0 !== e$2 ? e$2.createHTML(i) : i;\n}\nconst V = (t, i) => {\n  const s = t.length - 1,\n    e = [];\n  let l,\n    r = 2 === i ? \"<svg>\" : \"\",\n    u = f;\n  for (let i = 0; i < s; i++) {\n    const s = t[i];\n    let d,\n      c,\n      v = -1,\n      a = 0;\n    for (; a < s.length && (u.lastIndex = a, c = u.exec(s), null !== c);) a = u.lastIndex, u === f ? \"!--\" === c[1] ? u = _ : void 0 !== c[1] ? u = m : void 0 !== c[2] ? (y.test(c[2]) && (l = RegExp(\"</\" + c[2], \"g\")), u = p) : void 0 !== c[3] && (u = p) : u === p ? \">\" === c[0] ? (u = null != l ? l : f, v = -1) : void 0 === c[1] ? v = -2 : (v = u.lastIndex - c[2].length, d = c[1], u = void 0 === c[3] ? p : '\"' === c[3] ? $ : g$2) : u === $ || u === g$2 ? u = p : u === _ || u === m ? u = f : (u = p, l = void 0);\n    const w = u === p && t[i + 1].startsWith(\"/>\") ? \" \" : \"\";\n    r += u === f ? s + h$1 : v >= 0 ? (e.push(d), s.slice(0, v) + o$3 + s.slice(v) + n$4 + w) : s + n$4 + (-2 === v ? (e.push(void 0), i) : w);\n  }\n  return [P(t, r + (t[s] || \"<?>\") + (2 === i ? \"</svg>\" : \"\")), e];\n};\nclass N {\n  constructor({\n    strings: t,\n    _$litType$: i\n  }, e) {\n    let h;\n    this.parts = [];\n    let r = 0,\n      d = 0;\n    const c = t.length - 1,\n      v = this.parts,\n      [a, f] = V(t, i);\n    if (this.el = N.createElement(a, e), C$2.currentNode = this.el.content, 2 === i) {\n      const t = this.el.content,\n        i = t.firstChild;\n      i.remove(), t.append(...i.childNodes);\n    }\n    for (; null !== (h = C$2.nextNode()) && v.length < c;) {\n      if (1 === h.nodeType) {\n        if (h.hasAttributes()) {\n          const t = [];\n          for (const i of h.getAttributeNames()) if (i.endsWith(o$3) || i.startsWith(n$4)) {\n            const s = f[d++];\n            if (t.push(i), void 0 !== s) {\n              const t = h.getAttribute(s.toLowerCase() + o$3).split(n$4),\n                i = /([.?@])?(.*)/.exec(s);\n              v.push({\n                type: 1,\n                index: r,\n                name: i[2],\n                strings: t,\n                ctor: \".\" === i[1] ? H : \"?\" === i[1] ? L : \"@\" === i[1] ? z : k\n              });\n            } else v.push({\n              type: 6,\n              index: r\n            });\n          }\n          for (const i of t) h.removeAttribute(i);\n        }\n        if (y.test(h.tagName)) {\n          const t = h.textContent.split(n$4),\n            i = t.length - 1;\n          if (i > 0) {\n            h.textContent = s$3 ? s$3.emptyScript : \"\";\n            for (let s = 0; s < i; s++) h.append(t[s], u$2()), C$2.nextNode(), v.push({\n              type: 2,\n              index: ++r\n            });\n            h.append(t[i], u$2());\n          }\n        }\n      } else if (8 === h.nodeType) if (h.data === l$2) v.push({\n        type: 2,\n        index: r\n      });else {\n        let t = -1;\n        for (; -1 !== (t = h.data.indexOf(n$4, t + 1));) v.push({\n          type: 7,\n          index: r\n        }), t += n$4.length - 1;\n      }\n      r++;\n    }\n  }\n  static createElement(t, i) {\n    const s = r$2.createElement(\"template\");\n    return s.innerHTML = t, s;\n  }\n}\nfunction S$1(t, i, s = t, e) {\n  var o, n, l, h;\n  if (i === T$1) return i;\n  let r = void 0 !== e ? null === (o = s._$Co) || void 0 === o ? void 0 : o[e] : s._$Cl;\n  const u = d$1(i) ? void 0 : i._$litDirective$;\n  return (null == r ? void 0 : r.constructor) !== u && (null === (n = null == r ? void 0 : r._$AO) || void 0 === n || n.call(r, !1), void 0 === u ? r = void 0 : (r = new u(t), r._$AT(t, s, e)), void 0 !== e ? (null !== (l = (h = s)._$Co) && void 0 !== l ? l : h._$Co = [])[e] = r : s._$Cl = r), void 0 !== r && (i = S$1(t, r._$AS(t, i.values), r, e)), i;\n}\nclass M {\n  constructor(t, i) {\n    this._$AV = [], this._$AN = void 0, this._$AD = t, this._$AM = i;\n  }\n  get parentNode() {\n    return this._$AM.parentNode;\n  }\n  get _$AU() {\n    return this._$AM._$AU;\n  }\n  u(t) {\n    var i;\n    const {\n        el: {\n          content: s\n        },\n        parts: e\n      } = this._$AD,\n      o = (null !== (i = null == t ? void 0 : t.creationScope) && void 0 !== i ? i : r$2).importNode(s, !0);\n    C$2.currentNode = o;\n    let n = C$2.nextNode(),\n      l = 0,\n      h = 0,\n      u = e[0];\n    for (; void 0 !== u;) {\n      if (l === u.index) {\n        let i;\n        2 === u.type ? i = new R$1(n, n.nextSibling, this, t) : 1 === u.type ? i = new u.ctor(n, u.name, u.strings, this, t) : 6 === u.type && (i = new Z(n, this, t)), this._$AV.push(i), u = e[++h];\n      }\n      l !== (null == u ? void 0 : u.index) && (n = C$2.nextNode(), l++);\n    }\n    return C$2.currentNode = r$2, o;\n  }\n  v(t) {\n    let i = 0;\n    for (const s of this._$AV) void 0 !== s && (void 0 !== s.strings ? (s._$AI(t, s, i), i += s.strings.length - 2) : s._$AI(t[i])), i++;\n  }\n}\nclass R$1 {\n  constructor(t, i, s, e) {\n    var o;\n    this.type = 2, this._$AH = A$1, this._$AN = void 0, this._$AA = t, this._$AB = i, this._$AM = s, this.options = e, this._$Cp = null === (o = null == e ? void 0 : e.isConnected) || void 0 === o || o;\n  }\n  get _$AU() {\n    var t, i;\n    return null !== (i = null === (t = this._$AM) || void 0 === t ? void 0 : t._$AU) && void 0 !== i ? i : this._$Cp;\n  }\n  get parentNode() {\n    let t = this._$AA.parentNode;\n    const i = this._$AM;\n    return void 0 !== i && 11 === (null == t ? void 0 : t.nodeType) && (t = i.parentNode), t;\n  }\n  get startNode() {\n    return this._$AA;\n  }\n  get endNode() {\n    return this._$AB;\n  }\n  _$AI(t, i = this) {\n    t = S$1(this, t, i), d$1(t) ? t === A$1 || null == t || \"\" === t ? (this._$AH !== A$1 && this._$AR(), this._$AH = A$1) : t !== this._$AH && t !== T$1 && this._(t) : void 0 !== t._$litType$ ? this.g(t) : void 0 !== t.nodeType ? this.$(t) : v(t) ? this.T(t) : this._(t);\n  }\n  k(t) {\n    return this._$AA.parentNode.insertBefore(t, this._$AB);\n  }\n  $(t) {\n    this._$AH !== t && (this._$AR(), this._$AH = this.k(t));\n  }\n  _(t) {\n    this._$AH !== A$1 && d$1(this._$AH) ? this._$AA.nextSibling.data = t : this.$(r$2.createTextNode(t)), this._$AH = t;\n  }\n  g(t) {\n    var i;\n    const {\n        values: s,\n        _$litType$: e\n      } = t,\n      o = \"number\" == typeof e ? this._$AC(t) : (void 0 === e.el && (e.el = N.createElement(P(e.h, e.h[0]), this.options)), e);\n    if ((null === (i = this._$AH) || void 0 === i ? void 0 : i._$AD) === o) this._$AH.v(s);else {\n      const t = new M(o, this),\n        i = t.u(this.options);\n      t.v(s), this.$(i), this._$AH = t;\n    }\n  }\n  _$AC(t) {\n    let i = E.get(t.strings);\n    return void 0 === i && E.set(t.strings, i = new N(t)), i;\n  }\n  T(t) {\n    c$2(this._$AH) || (this._$AH = [], this._$AR());\n    const i = this._$AH;\n    let s,\n      e = 0;\n    for (const o of t) e === i.length ? i.push(s = new R$1(this.k(u$2()), this.k(u$2()), this, this.options)) : s = i[e], s._$AI(o), e++;\n    e < i.length && (this._$AR(s && s._$AB.nextSibling, e), i.length = e);\n  }\n  _$AR(t = this._$AA.nextSibling, i) {\n    var s;\n    for (null === (s = this._$AP) || void 0 === s || s.call(this, !1, !0, i); t && t !== this._$AB;) {\n      const i = t.nextSibling;\n      t.remove(), t = i;\n    }\n  }\n  setConnected(t) {\n    var i;\n    void 0 === this._$AM && (this._$Cp = t, null === (i = this._$AP) || void 0 === i || i.call(this, t));\n  }\n}\nclass k {\n  constructor(t, i, s, e, o) {\n    this.type = 1, this._$AH = A$1, this._$AN = void 0, this.element = t, this.name = i, this._$AM = e, this.options = o, s.length > 2 || \"\" !== s[0] || \"\" !== s[1] ? (this._$AH = Array(s.length - 1).fill(new String()), this.strings = s) : this._$AH = A$1;\n  }\n  get tagName() {\n    return this.element.tagName;\n  }\n  get _$AU() {\n    return this._$AM._$AU;\n  }\n  _$AI(t, i = this, s, e) {\n    const o = this.strings;\n    let n = !1;\n    if (void 0 === o) t = S$1(this, t, i, 0), n = !d$1(t) || t !== this._$AH && t !== T$1, n && (this._$AH = t);else {\n      const e = t;\n      let l, h;\n      for (t = o[0], l = 0; l < o.length - 1; l++) h = S$1(this, e[s + l], i, l), h === T$1 && (h = this._$AH[l]), n || (n = !d$1(h) || h !== this._$AH[l]), h === A$1 ? t = A$1 : t !== A$1 && (t += (null != h ? h : \"\") + o[l + 1]), this._$AH[l] = h;\n    }\n    n && !e && this.j(t);\n  }\n  j(t) {\n    t === A$1 ? this.element.removeAttribute(this.name) : this.element.setAttribute(this.name, null != t ? t : \"\");\n  }\n}\nclass H extends k {\n  constructor() {\n    super(...arguments), this.type = 3;\n  }\n  j(t) {\n    this.element[this.name] = t === A$1 ? void 0 : t;\n  }\n}\nconst I$1 = s$3 ? s$3.emptyScript : \"\";\nclass L extends k {\n  constructor() {\n    super(...arguments), this.type = 4;\n  }\n  j(t) {\n    t && t !== A$1 ? this.element.setAttribute(this.name, I$1) : this.element.removeAttribute(this.name);\n  }\n}\nclass z extends k {\n  constructor(t, i, s, e, o) {\n    super(t, i, s, e, o), this.type = 5;\n  }\n  _$AI(t, i = this) {\n    var s;\n    if ((t = null !== (s = S$1(this, t, i, 0)) && void 0 !== s ? s : A$1) === T$1) return;\n    const e = this._$AH,\n      o = t === A$1 && e !== A$1 || t.capture !== e.capture || t.once !== e.once || t.passive !== e.passive,\n      n = t !== A$1 && (e === A$1 || o);\n    o && this.element.removeEventListener(this.name, this, e), n && this.element.addEventListener(this.name, this, t), this._$AH = t;\n  }\n  handleEvent(t) {\n    var i, s;\n    \"function\" == typeof this._$AH ? this._$AH.call(null !== (s = null === (i = this.options) || void 0 === i ? void 0 : i.host) && void 0 !== s ? s : this.element, t) : this._$AH.handleEvent(t);\n  }\n}\nclass Z {\n  constructor(t, i, s) {\n    this.element = t, this.type = 6, this._$AN = void 0, this._$AM = i, this.options = s;\n  }\n  get _$AU() {\n    return this._$AM._$AU;\n  }\n  _$AI(t) {\n    S$1(this, t);\n  }\n}\nconst B$1 = i$1.litHtmlPolyfillSupport;\nnull == B$1 || B$1(N, R$1), (null !== (t$2 = i$1.litHtmlVersions) && void 0 !== t$2 ? t$2 : i$1.litHtmlVersions = []).push(\"2.8.0\");\nconst D = (t, i, s) => {\n  var e, o;\n  const n = null !== (e = null == s ? void 0 : s.renderBefore) && void 0 !== e ? e : i;\n  let l = n._$litPart$;\n  if (void 0 === l) {\n    const t = null !== (o = null == s ? void 0 : s.renderBefore) && void 0 !== o ? o : null;\n    n._$litPart$ = l = new R$1(i.insertBefore(u$2(), t), t, void 0, null != s ? s : {});\n  }\n  return l._$AI(t), l;\n};\n\n/**\n * @license\n * Copyright 2019 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nconst t$1 = window,\n  e$1 = t$1.ShadowRoot && (void 0 === t$1.ShadyCSS || t$1.ShadyCSS.nativeShadow) && \"adoptedStyleSheets\" in Document.prototype && \"replace\" in CSSStyleSheet.prototype,\n  s$2 = Symbol(),\n  n$3 = new WeakMap();\nclass o$2 {\n  constructor(t, e, n) {\n    if (this._$cssResult$ = !0, n !== s$2) throw Error(\"CSSResult is not constructable. Use `unsafeCSS` or `css` instead.\");\n    this.cssText = t, this.t = e;\n  }\n  get styleSheet() {\n    let t = this.o;\n    const s = this.t;\n    if (e$1 && void 0 === t) {\n      const e = void 0 !== s && 1 === s.length;\n      e && (t = n$3.get(s)), void 0 === t && ((this.o = t = new CSSStyleSheet()).replaceSync(this.cssText), e && n$3.set(s, t));\n    }\n    return t;\n  }\n  toString() {\n    return this.cssText;\n  }\n}\nconst r$1 = t => new o$2(\"string\" == typeof t ? t : t + \"\", void 0, s$2),\n  S = (s, n) => {\n    e$1 ? s.adoptedStyleSheets = n.map(t => t instanceof CSSStyleSheet ? t : t.styleSheet) : n.forEach(e => {\n      const n = document.createElement(\"style\"),\n        o = t$1.litNonce;\n      void 0 !== o && n.setAttribute(\"nonce\", o), n.textContent = e.cssText, s.appendChild(n);\n    });\n  },\n  c$1 = e$1 ? t => t : t => t instanceof CSSStyleSheet ? (t => {\n    let e = \"\";\n    for (const s of t.cssRules) e += s.cssText;\n    return r$1(e);\n  })(t) : t;\n\n/**\n * @license\n * Copyright 2017 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nvar s$1;\nconst e = window,\n  r = e.trustedTypes,\n  h = r ? r.emptyScript : \"\",\n  o$1 = e.reactiveElementPolyfillSupport,\n  n$2 = {\n    toAttribute(t, i) {\n      switch (i) {\n        case Boolean:\n          t = t ? h : null;\n          break;\n        case Object:\n        case Array:\n          t = null == t ? t : JSON.stringify(t);\n      }\n      return t;\n    },\n    fromAttribute(t, i) {\n      let s = t;\n      switch (i) {\n        case Boolean:\n          s = null !== t;\n          break;\n        case Number:\n          s = null === t ? null : Number(t);\n          break;\n        case Object:\n        case Array:\n          try {\n            s = JSON.parse(t);\n          } catch (t) {\n            s = null;\n          }\n      }\n      return s;\n    }\n  },\n  a$1 = (t, i) => i !== t && (i == i || t == t),\n  l$1 = {\n    attribute: !0,\n    type: String,\n    converter: n$2,\n    reflect: !1,\n    hasChanged: a$1\n  },\n  d = \"finalized\";\nclass u$1 extends HTMLElement {\n  constructor() {\n    super(), this._$Ei = new Map(), this.isUpdatePending = !1, this.hasUpdated = !1, this._$El = null, this._$Eu();\n  }\n  static addInitializer(t) {\n    var i;\n    this.finalize(), (null !== (i = this.h) && void 0 !== i ? i : this.h = []).push(t);\n  }\n  static get observedAttributes() {\n    this.finalize();\n    const t = [];\n    return this.elementProperties.forEach((i, s) => {\n      const e = this._$Ep(s, i);\n      void 0 !== e && (this._$Ev.set(e, s), t.push(e));\n    }), t;\n  }\n  static createProperty(t, i = l$1) {\n    if (i.state && (i.attribute = !1), this.finalize(), this.elementProperties.set(t, i), !i.noAccessor && !this.prototype.hasOwnProperty(t)) {\n      const s = \"symbol\" == typeof t ? Symbol() : \"__\" + t,\n        e = this.getPropertyDescriptor(t, s, i);\n      void 0 !== e && Object.defineProperty(this.prototype, t, e);\n    }\n  }\n  static getPropertyDescriptor(t, i, s) {\n    return {\n      get() {\n        return this[i];\n      },\n      set(e) {\n        const r = this[t];\n        this[i] = e, this.requestUpdate(t, r, s);\n      },\n      configurable: !0,\n      enumerable: !0\n    };\n  }\n  static getPropertyOptions(t) {\n    return this.elementProperties.get(t) || l$1;\n  }\n  static finalize() {\n    if (this.hasOwnProperty(d)) return !1;\n    this[d] = !0;\n    const t = Object.getPrototypeOf(this);\n    if (t.finalize(), void 0 !== t.h && (this.h = [...t.h]), this.elementProperties = new Map(t.elementProperties), this._$Ev = new Map(), this.hasOwnProperty(\"properties\")) {\n      const t = this.properties,\n        i = [...Object.getOwnPropertyNames(t), ...Object.getOwnPropertySymbols(t)];\n      for (const s of i) this.createProperty(s, t[s]);\n    }\n    return this.elementStyles = this.finalizeStyles(this.styles), !0;\n  }\n  static finalizeStyles(i) {\n    const s = [];\n    if (Array.isArray(i)) {\n      const e = new Set(i.flat(1 / 0).reverse());\n      for (const i of e) s.unshift(c$1(i));\n    } else void 0 !== i && s.push(c$1(i));\n    return s;\n  }\n  static _$Ep(t, i) {\n    const s = i.attribute;\n    return !1 === s ? void 0 : \"string\" == typeof s ? s : \"string\" == typeof t ? t.toLowerCase() : void 0;\n  }\n  _$Eu() {\n    var t;\n    this._$E_ = new Promise(t => this.enableUpdating = t), this._$AL = new Map(), this._$Eg(), this.requestUpdate(), null === (t = this.constructor.h) || void 0 === t || t.forEach(t => t(this));\n  }\n  addController(t) {\n    var i, s;\n    (null !== (i = this._$ES) && void 0 !== i ? i : this._$ES = []).push(t), void 0 !== this.renderRoot && this.isConnected && (null === (s = t.hostConnected) || void 0 === s || s.call(t));\n  }\n  removeController(t) {\n    var i;\n    null === (i = this._$ES) || void 0 === i || i.splice(this._$ES.indexOf(t) >>> 0, 1);\n  }\n  _$Eg() {\n    this.constructor.elementProperties.forEach((t, i) => {\n      this.hasOwnProperty(i) && (this._$Ei.set(i, this[i]), delete this[i]);\n    });\n  }\n  createRenderRoot() {\n    var t;\n    const s = null !== (t = this.shadowRoot) && void 0 !== t ? t : this.attachShadow(this.constructor.shadowRootOptions);\n    return S(s, this.constructor.elementStyles), s;\n  }\n  connectedCallback() {\n    var t;\n    void 0 === this.renderRoot && (this.renderRoot = this.createRenderRoot()), this.enableUpdating(!0), null === (t = this._$ES) || void 0 === t || t.forEach(t => {\n      var i;\n      return null === (i = t.hostConnected) || void 0 === i ? void 0 : i.call(t);\n    });\n  }\n  enableUpdating(t) {}\n  disconnectedCallback() {\n    var t;\n    null === (t = this._$ES) || void 0 === t || t.forEach(t => {\n      var i;\n      return null === (i = t.hostDisconnected) || void 0 === i ? void 0 : i.call(t);\n    });\n  }\n  attributeChangedCallback(t, i, s) {\n    this._$AK(t, s);\n  }\n  _$EO(t, i, s = l$1) {\n    var e;\n    const r = this.constructor._$Ep(t, s);\n    if (void 0 !== r && !0 === s.reflect) {\n      const h = (void 0 !== (null === (e = s.converter) || void 0 === e ? void 0 : e.toAttribute) ? s.converter : n$2).toAttribute(i, s.type);\n      this._$El = t, null == h ? this.removeAttribute(r) : this.setAttribute(r, h), this._$El = null;\n    }\n  }\n  _$AK(t, i) {\n    var s;\n    const e = this.constructor,\n      r = e._$Ev.get(t);\n    if (void 0 !== r && this._$El !== r) {\n      const t = e.getPropertyOptions(r),\n        h = \"function\" == typeof t.converter ? {\n          fromAttribute: t.converter\n        } : void 0 !== (null === (s = t.converter) || void 0 === s ? void 0 : s.fromAttribute) ? t.converter : n$2;\n      this._$El = r, this[r] = h.fromAttribute(i, t.type), this._$El = null;\n    }\n  }\n  requestUpdate(t, i, s) {\n    let e = !0;\n    void 0 !== t && (((s = s || this.constructor.getPropertyOptions(t)).hasChanged || a$1)(this[t], i) ? (this._$AL.has(t) || this._$AL.set(t, i), !0 === s.reflect && this._$El !== t && (void 0 === this._$EC && (this._$EC = new Map()), this._$EC.set(t, s))) : e = !1), !this.isUpdatePending && e && (this._$E_ = this._$Ej());\n  }\n  async _$Ej() {\n    this.isUpdatePending = !0;\n    try {\n      await this._$E_;\n    } catch (t) {\n      Promise.reject(t);\n    }\n    const t = this.scheduleUpdate();\n    return null != t && (await t), !this.isUpdatePending;\n  }\n  scheduleUpdate() {\n    return this.performUpdate();\n  }\n  performUpdate() {\n    var t;\n    if (!this.isUpdatePending) return;\n    this.hasUpdated, this._$Ei && (this._$Ei.forEach((t, i) => this[i] = t), this._$Ei = void 0);\n    let i = !1;\n    const s = this._$AL;\n    try {\n      i = this.shouldUpdate(s), i ? (this.willUpdate(s), null === (t = this._$ES) || void 0 === t || t.forEach(t => {\n        var i;\n        return null === (i = t.hostUpdate) || void 0 === i ? void 0 : i.call(t);\n      }), this.update(s)) : this._$Ek();\n    } catch (t) {\n      throw i = !1, this._$Ek(), t;\n    }\n    i && this._$AE(s);\n  }\n  willUpdate(t) {}\n  _$AE(t) {\n    var i;\n    null === (i = this._$ES) || void 0 === i || i.forEach(t => {\n      var i;\n      return null === (i = t.hostUpdated) || void 0 === i ? void 0 : i.call(t);\n    }), this.hasUpdated || (this.hasUpdated = !0, this.firstUpdated(t)), this.updated(t);\n  }\n  _$Ek() {\n    this._$AL = new Map(), this.isUpdatePending = !1;\n  }\n  get updateComplete() {\n    return this.getUpdateComplete();\n  }\n  getUpdateComplete() {\n    return this._$E_;\n  }\n  shouldUpdate(t) {\n    return !0;\n  }\n  update(t) {\n    void 0 !== this._$EC && (this._$EC.forEach((t, i) => this._$EO(i, this[i], t)), this._$EC = void 0), this._$Ek();\n  }\n  updated(t) {}\n  firstUpdated(t) {}\n}\nu$1[d] = !0, u$1.elementProperties = new Map(), u$1.elementStyles = [], u$1.shadowRootOptions = {\n  mode: \"open\"\n}, null == o$1 || o$1({\n  ReactiveElement: u$1\n}), (null !== (s$1 = e.reactiveElementVersions) && void 0 !== s$1 ? s$1 : e.reactiveElementVersions = []).push(\"1.6.3\");\n\n/**\n * @license\n * Copyright 2017 Google LLC\n * SPDX-License-Identifier: BSD-3-Clause\n */\nvar l, o;\nclass s extends u$1 {\n  constructor() {\n    super(...arguments), this.renderOptions = {\n      host: this\n    }, this._$Do = void 0;\n  }\n  createRenderRoot() {\n    var t, e;\n    const i = super.createRenderRoot();\n    return null !== (t = (e = this.renderOptions).renderBefore) && void 0 !== t || (e.renderBefore = i.firstChild), i;\n  }\n  update(t) {\n    const i = this.render();\n    this.hasUpdated || (this.renderOptions.isConnected = this.isConnected), super.update(t), this._$Do = D(i, this.renderRoot, this.renderOptions);\n  }\n  connectedCallback() {\n    var t;\n    super.connectedCallback(), null === (t = this._$Do) || void 0 === t || t.setConnected(!0);\n  }\n  disconnectedCallback() {\n    var t;\n    super.disconnectedCallback(), null === (t = this._$Do) || void 0 === t || t.setConnected(!1);\n  }\n  render() {\n    return T$1;\n  }\n}\ns.finalized = !0, s._$litElement$ = !0, null === (l = globalThis.litElementHydrateSupport) || void 0 === l || l.call(globalThis, {\n  LitElement: s\n});\nconst n$1 = globalThis.litElementPolyfillSupport;\nnull == n$1 || n$1({\n  LitElement: s\n});\n(null !== (o = globalThis.litElementVersions) && void 0 !== o ? o : globalThis.litElementVersions = []).push(\"3.3.3\");\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// NOTE(cdata): The HAS_WEBXR_* constants can be enabled in Chrome by turning on\n// the appropriate flags. However, just because we have the API does not\n// guarantee that AR will work.\nconst HAS_WEBXR_DEVICE_API = navigator.xr != null && self.XRSession != null && navigator.xr.isSessionSupported != null;\nconst HAS_WEBXR_HIT_TEST_API = HAS_WEBXR_DEVICE_API && self.XRSession.prototype.requestHitTestSource != null;\nconst HAS_RESIZE_OBSERVER = self.ResizeObserver != null;\nconst HAS_INTERSECTION_OBSERVER = self.IntersectionObserver != null;\nconst IS_WEBXR_AR_CANDIDATE = HAS_WEBXR_HIT_TEST_API;\n(() => {\n  const userAgent = navigator.userAgent || navigator.vendor || self.opera;\n  let check = false;\n  // eslint-disable-next-line\n  if (/(android|bb\\d+|meego).+mobile|avantgo|bada\\/|blackberry|blazer|compal|elaine|fennec|hiptop|iemobile|ip(hone|od)|iris|kindle|lge |maemo|midp|mmp|mobile.+firefox|netfront|opera m(ob|in)i|palm( os)?|phone|p(ixi|re)\\/|plucker|pocket|psp|series(4|6)0|symbian|treo|up\\.(browser|link)|vodafone|wap|windows ce|xda|xiino/i.test(userAgent) || /1207|6310|6590|3gso|4thp|50[1-6]i|770s|802s|a wa|abac|ac(er|oo|s\\-)|ai(ko|rn)|al(av|ca|co)|amoi|an(ex|ny|yw)|aptu|ar(ch|go)|as(te|us)|attw|au(di|\\-m|r |s )|avan|be(ck|ll|nq)|bi(lb|rd)|bl(ac|az)|br(e|v)w|bumb|bw\\-(n|u)|c55\\/|capi|ccwa|cdm\\-|cell|chtm|cldc|cmd\\-|co(mp|nd)|craw|da(it|ll|ng)|dbte|dc\\-s|devi|dica|dmob|do(c|p)o|ds(12|\\-d)|el(49|ai)|em(l2|ul)|er(ic|k0)|esl8|ez([4-7]0|os|wa|ze)|fetc|fly(\\-|_)|g1 u|g560|gene|gf\\-5|g\\-mo|go(\\.w|od)|gr(ad|un)|haie|hcit|hd\\-(m|p|t)|hei\\-|hi(pt|ta)|hp( i|ip)|hs\\-c|ht(c(\\-| |_|a|g|p|s|t)|tp)|hu(aw|tc)|i\\-(20|go|ma)|i230|iac( |\\-|\\/)|ibro|idea|ig01|ikom|im1k|inno|ipaq|iris|ja(t|v)a|jbro|jemu|jigs|kddi|keji|kgt( |\\/)|klon|kpt |kwc\\-|kyo(c|k)|le(no|xi)|lg( g|\\/(k|l|u)|50|54|\\-[a-w])|libw|lynx|m1\\-w|m3ga|m50\\/|ma(te|ui|xo)|mc(01|21|ca)|m\\-cr|me(rc|ri)|mi(o8|oa|ts)|mmef|mo(01|02|bi|de|do|t(\\-| |o|v)|zz)|mt(50|p1|v )|mwbp|mywa|n10[0-2]|n20[2-3]|n30(0|2)|n50(0|2|5)|n7(0(0|1)|10)|ne((c|m)\\-|on|tf|wf|wg|wt)|nok(6|i)|nzph|o2im|op(ti|wv)|oran|owg1|p800|pan(a|d|t)|pdxg|pg(13|\\-([1-8]|c))|phil|pire|pl(ay|uc)|pn\\-2|po(ck|rt|se)|prox|psio|pt\\-g|qa\\-a|qc(07|12|21|32|60|\\-[2-7]|i\\-)|qtek|r380|r600|raks|rim9|ro(ve|zo)|s55\\/|sa(ge|ma|mm|ms|ny|va)|sc(01|h\\-|oo|p\\-)|sdk\\/|se(c(\\-|0|1)|47|mc|nd|ri)|sgh\\-|shar|sie(\\-|m)|sk\\-0|sl(45|id)|sm(al|ar|b3|it|t5)|so(ft|ny)|sp(01|h\\-|v\\-|v )|sy(01|mb)|t2(18|50)|t6(00|10|18)|ta(gt|lk)|tcl\\-|tdg\\-|tel(i|m)|tim\\-|t\\-mo|to(pl|sh)|ts(70|m\\-|m3|m5)|tx\\-9|up(\\.b|g1|si)|utst|v400|v750|veri|vi(rg|te)|vk(40|5[0-3]|\\-v)|vm40|voda|vulc|vx(52|53|60|61|70|80|81|83|85|98)|w3c(\\-| )|webc|whit|wi(g |nc|nw)|wmlb|wonu|x700|yas\\-|your|zeto|zte\\-/i.test(userAgent.substr(0, 4))) {\n    check = true;\n  }\n  return check;\n})();\n/\\bCrOS\\b/.test(navigator.userAgent);\nconst IS_ANDROID = /android/i.test(navigator.userAgent);\n// Prior to iOS 13, detecting iOS Safari was relatively straight-forward.\n// As of iOS 13, Safari on iPad (in its default configuration) reports the same\n// user-agent string as Safari on desktop MacOS. Strictly speaking, we only care\n// about iOS for the purposes if selecting for cases where Quick Look is known\n// to be supported. However, for API correctness purposes, we must rely on\n// known, detectable signals to distinguish iOS Safari from MacOS Safari. At the\n// time of this writing, there are no non-iOS/iPadOS Apple devices with\n// multi-touch displays.\n// @see https://stackoverflow.com/questions/57765958/how-to-detect-ipad-and-ipad-os-version-in-ios-13-and-up\n// @see https://forums.developer.apple.com/thread/119186\n// @see https://github.com/google/model-viewer/issues/758\nconst IS_IOS = /iPad|iPhone|iPod/.test(navigator.userAgent) && !self.MSStream || navigator.platform === 'MacIntel' && navigator.maxTouchPoints > 1;\n// @see https://developer.chrome.com/multidevice/user-agent\n/Safari\\//.test(navigator.userAgent);\nconst IS_FIREFOX = /firefox/i.test(navigator.userAgent);\nconst IS_OCULUS = /OculusBrowser/.test(navigator.userAgent);\nIS_IOS && /CriOS\\//.test(navigator.userAgent);\nconst IS_SCENEVIEWER_CANDIDATE = IS_ANDROID && !IS_FIREFOX && !IS_OCULUS;\nconst IS_WKWEBVIEW = Boolean(window.webkit && window.webkit.messageHandlers);\n// If running in iOS Safari proper, and not within a WKWebView component\n// instance, check for ARQL feature support. Otherwise, if running in a\n// WKWebView instance, check for known ARQL compatible iOS browsers, including:\n// Chrome (CriOS), Edge (EdgiOS), Firefox (FxiOS), Google App (GSA), DuckDuckGo\n// (DuckDuckGo). All other iOS browsers / apps will fail by default.\nconst IS_AR_QUICKLOOK_CANDIDATE = (() => {\n  if (IS_IOS) {\n    if (!IS_WKWEBVIEW) {\n      const tempAnchor = document.createElement('a');\n      return Boolean(tempAnchor.relList && tempAnchor.relList.supports && tempAnchor.relList.supports('ar'));\n    } else {\n      return Boolean(/CriOS\\/|EdgiOS\\/|FxiOS\\/|GSA\\/|DuckDuckGo\\//.test(navigator.userAgent));\n    }\n  } else {\n    return false;\n  }\n})();\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst deserializeUrl = url => !!url && url !== 'null' ? toFullUrl(url) : null;\nconst assertIsArCandidate = () => {\n  if (IS_WEBXR_AR_CANDIDATE) {\n    return;\n  }\n  const missingApis = [];\n  if (!HAS_WEBXR_DEVICE_API) {\n    missingApis.push('WebXR Device API');\n  }\n  if (!HAS_WEBXR_HIT_TEST_API) {\n    missingApis.push('WebXR Hit Test API');\n  }\n  throw new Error(`The following APIs are required for AR, but are missing in this browser: ${missingApis.join(', ')}`);\n};\n/**\n * Converts a partial URL string to a fully qualified URL string.\n *\n * @param {String} url\n * @return {String}\n */\nconst toFullUrl = partialUrl => {\n  const url = new URL(partialUrl, window.location.toString());\n  return url.toString();\n};\n/**\n * Returns a throttled version of a given function that is only invoked at most\n * once within a given threshold of time in milliseconds.\n *\n * The throttled version of the function has a \"flush\" property that resets the\n * threshold for cases when immediate invocation is desired.\n */\nconst throttle = (fn, ms) => {\n  let timer = null;\n  const throttled = (...args) => {\n    if (timer != null) {\n      return;\n    }\n    fn(...args);\n    timer = self.setTimeout(() => timer = null, ms);\n  };\n  throttled.flush = () => {\n    if (timer != null) {\n      self.clearTimeout(timer);\n      timer = null;\n    }\n  };\n  return throttled;\n};\nconst debounce = (fn, ms) => {\n  let timer = null;\n  return (...args) => {\n    if (timer != null) {\n      self.clearTimeout(timer);\n    }\n    timer = self.setTimeout(() => {\n      timer = null;\n      fn(...args);\n    }, ms);\n  };\n};\n/**\n * @param {Number} value\n * @param {Number} lowerLimit\n * @param {Number} upperLimit\n * @return {Number} value clamped within lowerLimit..upperLimit\n */\nconst clamp = (value, lowerLimit, upperLimit) => Math.max(lowerLimit, Math.min(upperLimit, value));\n/**\n * Debug mode is enabled when one of the two following conditions is true:\n *\n *  1. A 'model-viewer-debug-mode' query parameter is present in the current\n *     search string\n *  2. There is a global object ModelViewerElement with a debugMode property set\n *     to true\n */\nconst isDebugMode = (() => {\n  const debugQueryParameterName = 'model-viewer-debug-mode';\n  const debugQueryParameter = new RegExp(`[?&]${debugQueryParameterName}(&|$)`);\n  return () => self.ModelViewerElement && self.ModelViewerElement.debugMode || self.location && self.location.search && self.location.search.match(debugQueryParameter);\n})();\nconst timePasses = (ms = 0) => new Promise(resolve => setTimeout(resolve, ms));\n/**\n * @param {EventTarget|EventDispatcher} target\n * @param {string} eventName\n * @param {?Function} predicate\n */\nconst waitForEvent = (target, eventName, predicate = null) => new Promise(resolve => {\n  function handler(event) {\n    if (!predicate || predicate(event)) {\n      resolve(event);\n      target.removeEventListener(eventName, handler);\n    }\n  }\n  target.addEventListener(eventName, handler);\n});\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate$7 = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nconst BASE_OPACITY = 0.5;\nconst DEFAULT_SHADOW_INTENSITY = 0.0;\nconst DEFAULT_SHADOW_SOFTNESS = 1.0;\nconst DEFAULT_EXPOSURE = 1.0;\nconst $currentEnvironmentMap = Symbol('currentEnvironmentMap');\nconst $currentBackground = Symbol('currentBackground');\nconst $updateEnvironment = Symbol('updateEnvironment');\nconst $cancelEnvironmentUpdate = Symbol('cancelEnvironmentUpdate');\nconst EnvironmentMixin = ModelViewerElement => {\n  var _a, _b, _c;\n  class EnvironmentModelViewerElement extends ModelViewerElement {\n    constructor() {\n      super(...arguments);\n      this.environmentImage = null;\n      this.skyboxImage = null;\n      this.shadowIntensity = DEFAULT_SHADOW_INTENSITY;\n      this.shadowSoftness = DEFAULT_SHADOW_SOFTNESS;\n      this.exposure = DEFAULT_EXPOSURE;\n      this.toneMapping = 'auto';\n      this.skyboxHeight = '0';\n      this[_a] = null;\n      this[_b] = null;\n      this[_c] = null;\n    }\n    updated(changedProperties) {\n      super.updated(changedProperties);\n      if (changedProperties.has('shadowIntensity')) {\n        this[$scene].setShadowIntensity(this.shadowIntensity * BASE_OPACITY);\n        this[$needsRender]();\n      }\n      if (changedProperties.has('shadowSoftness')) {\n        this[$scene].setShadowSoftness(this.shadowSoftness);\n        this[$needsRender]();\n      }\n      if (changedProperties.has('exposure')) {\n        this[$scene].exposure = this.exposure;\n        this[$needsRender]();\n      }\n      if (changedProperties.has('toneMapping')) {\n        this[$scene].toneMapping = this.toneMapping === 'aces' ? ACESFilmicToneMapping : this.toneMapping === 'agx' ? AgXToneMapping : NeutralToneMapping;\n        this[$needsRender]();\n      }\n      if ((changedProperties.has('environmentImage') || changedProperties.has('skyboxImage')) && this[$shouldAttemptPreload]()) {\n        this[$updateEnvironment]();\n      }\n      if (changedProperties.has('skyboxHeight')) {\n        this[$scene].setGroundedSkybox();\n        this[$needsRender]();\n      }\n    }\n    hasBakedShadow() {\n      return this[$scene].bakedShadows.size > 0;\n    }\n    async [(_a = $currentEnvironmentMap, _b = $currentBackground, _c = $cancelEnvironmentUpdate, $updateEnvironment)]() {\n      const {\n        skyboxImage,\n        environmentImage\n      } = this;\n      if (this[$cancelEnvironmentUpdate] != null) {\n        this[$cancelEnvironmentUpdate]();\n        this[$cancelEnvironmentUpdate] = null;\n      }\n      const {\n        textureUtils\n      } = this[$renderer];\n      if (textureUtils == null) {\n        return;\n      }\n      const updateEnvProgress = this[$progressTracker].beginActivity('environment-update');\n      try {\n        const {\n          environmentMap,\n          skybox\n        } = await textureUtils.generateEnvironmentMapAndSkybox(deserializeUrl(skyboxImage), environmentImage, progress => updateEnvProgress(clamp(progress, 0, 1)), this.withCredentials);\n        if (this[$currentEnvironmentMap] !== environmentMap) {\n          this[$currentEnvironmentMap] = environmentMap;\n          this.dispatchEvent(new CustomEvent('environment-change'));\n        }\n        if (skybox != null) {\n          // When using the same environment and skybox, use the environment as\n          // it gives HDR filtering.\n          this[$currentBackground] = skybox.name === environmentMap.name ? environmentMap : skybox;\n        } else {\n          this[$currentBackground] = null;\n        }\n        this[$scene].setEnvironmentAndSkybox(this[$currentEnvironmentMap], this[$currentBackground]);\n      } catch (errorOrPromise) {\n        if (errorOrPromise instanceof Error) {\n          this[$scene].setEnvironmentAndSkybox(null, null);\n          throw errorOrPromise;\n        }\n      } finally {\n        updateEnvProgress(1.0);\n      }\n    }\n  }\n  __decorate$7([n$8({\n    type: String,\n    attribute: 'environment-image'\n  })], EnvironmentModelViewerElement.prototype, \"environmentImage\", void 0);\n  __decorate$7([n$8({\n    type: String,\n    attribute: 'skybox-image'\n  })], EnvironmentModelViewerElement.prototype, \"skyboxImage\", void 0);\n  __decorate$7([n$8({\n    type: Number,\n    attribute: 'shadow-intensity'\n  })], EnvironmentModelViewerElement.prototype, \"shadowIntensity\", void 0);\n  __decorate$7([n$8({\n    type: Number,\n    attribute: 'shadow-softness'\n  })], EnvironmentModelViewerElement.prototype, \"shadowSoftness\", void 0);\n  __decorate$7([n$8({\n    type: Number\n  })], EnvironmentModelViewerElement.prototype, \"exposure\", void 0);\n  __decorate$7([n$8({\n    type: String,\n    attribute: 'tone-mapping'\n  })], EnvironmentModelViewerElement.prototype, \"toneMapping\", void 0);\n  __decorate$7([n$8({\n    type: String,\n    attribute: 'skybox-height'\n  })], EnvironmentModelViewerElement.prototype, \"skyboxHeight\", void 0);\n  return EnvironmentModelViewerElement;\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar CloseIcon = x$1`\n<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24px\" height=\"24px\" viewBox=\"0 0 24 24\" fill=\"#000000\">\n    <!-- NOTE(cdata): This SVG filter is a stop-gap until we can implement\n         support for dynamic re-coloring of UI components -->\n    <defs>\n      <filter id=\"drop-shadow\" x=\"-100%\" y=\"-100%\" width=\"300%\" height=\"300%\">\n        <feGaussianBlur in=\"SourceAlpha\" stdDeviation=\"1\"/>\n        <feOffset dx=\"0\" dy=\"0\" result=\"offsetblur\"/>\n        <feFlood flood-color=\"#000000\"/>\n        <feComposite in2=\"offsetblur\" operator=\"in\"/>\n        <feMerge>\n          <feMergeNode/>\n          <feMergeNode in=\"SourceGraphic\"/>\n        </feMerge>\n      </filter>\n    </defs>\n    <path filter=\"url(#drop-shadow)\" d=\"M19 6.41L17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z\"/>\n    <path d=\"M0 0h24v24H0z\" fill=\"none\"/>\n</svg>`;\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar ControlsPrompt = x$1`\n<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"25\" height=\"36\">\n    <defs>\n        <path id=\"A\" d=\"M.001.232h24.997V36H.001z\" />\n    </defs>\n    <g transform=\"translate(-11 -4)\" fill=\"none\" fill-rule=\"evenodd\">\n        <path fill-opacity=\"0\" fill=\"#fff\" d=\"M0 0h44v44H0z\" />\n        <g transform=\"translate(11 3)\">\n            <path d=\"M8.733 11.165c.04-1.108.766-2.027 1.743-2.307a2.54 2.54 0 0 1 .628-.089c.16 0 .314.017.463.044 1.088.2 1.9 1.092 1.9 2.16v8.88h1.26c2.943-1.39 5-4.45 5-8.025a9.01 9.01 0 0 0-1.9-5.56l-.43-.5c-.765-.838-1.683-1.522-2.712-2-1.057-.49-2.226-.77-3.46-.77s-2.4.278-3.46.77c-1.03.478-1.947 1.162-2.71 2l-.43.5a9.01 9.01 0 0 0-1.9 5.56 9.04 9.04 0 0 0 .094 1.305c.03.21.088.41.13.617l.136.624c.083.286.196.56.305.832l.124.333a8.78 8.78 0 0 0 .509.953l.065.122a8.69 8.69 0 0 0 3.521 3.191l1.11.537v-9.178z\" fill-opacity=\".5\" fill=\"#e4e4e4\" />\n            <path d=\"M22.94 26.218l-2.76 7.74c-.172.485-.676.8-1.253.8H12.24c-1.606 0-3.092-.68-3.98-1.82-1.592-2.048-3.647-3.822-6.11-5.27-.095-.055-.15-.137-.152-.23-.004-.1.046-.196.193-.297.56-.393 1.234-.6 1.926-.6a3.43 3.43 0 0 1 .691.069l4.922.994V10.972c0-.663.615-1.203 1.37-1.203s1.373.54 1.373 1.203v9.882h2.953c.273 0 .533.073.757.21l6.257 3.874c.027.017.045.042.07.06.41.296.586.77.426 1.22M4.1 16.614c-.024-.04-.042-.083-.065-.122a8.69 8.69 0 0 1-.509-.953c-.048-.107-.08-.223-.124-.333l-.305-.832c-.058-.202-.09-.416-.136-.624l-.13-.617a9.03 9.03 0 0 1-.094-1.305c0-2.107.714-4.04 1.9-5.56l.43-.5c.764-.84 1.682-1.523 2.71-2 1.058-.49 2.226-.77 3.46-.77s2.402.28 3.46.77c1.03.477 1.947 1.16 2.712 2l.428.5a9 9 0 0 1 1.901 5.559c0 3.577-2.056 6.636-5 8.026h-1.26v-8.882c0-1.067-.822-1.96-1.9-2.16-.15-.028-.304-.044-.463-.044-.22 0-.427.037-.628.09-.977.28-1.703 1.198-1.743 2.306v9.178l-1.11-.537C6.18 19.098 4.96 18 4.1 16.614M22.97 24.09l-6.256-3.874c-.102-.063-.218-.098-.33-.144 2.683-1.8 4.354-4.855 4.354-8.243 0-.486-.037-.964-.104-1.43a9.97 9.97 0 0 0-1.57-4.128l-.295-.408-.066-.092a10.05 10.05 0 0 0-.949-1.078c-.342-.334-.708-.643-1.094-.922-1.155-.834-2.492-1.412-3.94-1.65l-.732-.088-.748-.03a9.29 9.29 0 0 0-1.482.119c-1.447.238-2.786.816-3.94 1.65a9.33 9.33 0 0 0-.813.686 9.59 9.59 0 0 0-.845.877l-.385.437-.36.5-.288.468-.418.778-.04.09c-.593 1.28-.93 2.71-.93 4.222 0 3.832 2.182 7.342 5.56 8.938l1.437.68v4.946L5 25.64a4.44 4.44 0 0 0-.888-.086c-.017 0-.034.003-.05.003-.252.004-.503.033-.75.08a5.08 5.08 0 0 0-.237.056c-.193.046-.382.107-.568.18-.075.03-.15.057-.225.1-.25.114-.494.244-.723.405a1.31 1.31 0 0 0-.566 1.122 1.28 1.28 0 0 0 .645 1.051C4 29.925 5.96 31.614 7.473 33.563a5.06 5.06 0 0 0 .434.491c1.086 1.082 2.656 1.713 4.326 1.715h6.697c.748-.001 1.43-.333 1.858-.872.142-.18.256-.38.336-.602l2.757-7.74c.094-.26.13-.53.112-.794s-.088-.52-.203-.76a2.19 2.19 0 0 0-.821-.91\" fill-opacity=\".6\" fill=\"#000\" />\n            <path d=\"M22.444 24.94l-6.257-3.874a1.45 1.45 0 0 0-.757-.211h-2.953v-9.88c0-.663-.616-1.203-1.373-1.203s-1.37.54-1.37 1.203v16.643l-4.922-.994a3.44 3.44 0 0 0-.692-.069 3.35 3.35 0 0 0-1.925.598c-.147.102-.198.198-.194.298.004.094.058.176.153.23 2.462 1.448 4.517 3.22 6.11 5.27.887 1.14 2.373 1.82 3.98 1.82h6.686c.577 0 1.08-.326 1.253-.8l2.76-7.74c.16-.448-.017-.923-.426-1.22-.025-.02-.043-.043-.07-.06z\" fill=\"#fff\" />\n            <g transform=\"translate(0 .769)\">\n                <mask id=\"B\" fill=\"#fff\">\n                    <use xlink:href=\"#A\" />\n                </mask>\n                <path d=\"M23.993 24.992a1.96 1.96 0 0 1-.111.794l-2.758 7.74c-.08.22-.194.423-.336.602-.427.54-1.11.87-1.857.872h-6.698c-1.67-.002-3.24-.633-4.326-1.715-.154-.154-.3-.318-.434-.49C5.96 30.846 4 29.157 1.646 27.773c-.385-.225-.626-.618-.645-1.05a1.31 1.31 0 0 1 .566-1.122 4.56 4.56 0 0 1 .723-.405l.225-.1a4.3 4.3 0 0 1 .568-.18l.237-.056c.248-.046.5-.075.75-.08.018 0 .034-.003.05-.003.303-.001.597.027.89.086l3.722.752V20.68l-1.436-.68c-3.377-1.596-5.56-5.106-5.56-8.938 0-1.51.336-2.94.93-4.222.015-.03.025-.06.04-.09.127-.267.268-.525.418-.778.093-.16.186-.316.288-.468.063-.095.133-.186.2-.277L3.773 5c.118-.155.26-.29.385-.437.266-.3.544-.604.845-.877a9.33 9.33 0 0 1 .813-.686C6.97 2.167 8.31 1.59 9.757 1.35a9.27 9.27 0 0 1 1.481-.119 8.82 8.82 0 0 1 .748.031c.247.02.49.05.733.088 1.448.238 2.786.816 3.94 1.65.387.28.752.588 1.094.922a9.94 9.94 0 0 1 .949 1.078l.066.092c.102.133.203.268.295.408a9.97 9.97 0 0 1 1.571 4.128c.066.467.103.945.103 1.43 0 3.388-1.67 6.453-4.353 8.243.11.046.227.08.33.144l6.256 3.874c.37.23.645.55.82.9.115.24.185.498.203.76m.697-1.195c-.265-.55-.677-1.007-1.194-1.326l-5.323-3.297c2.255-2.037 3.564-4.97 3.564-8.114 0-2.19-.637-4.304-1.84-6.114-.126-.188-.26-.37-.4-.552-.645-.848-1.402-1.6-2.252-2.204C15.472.91 13.393.232 11.238.232A10.21 10.21 0 0 0 5.23 2.19c-.848.614-1.606 1.356-2.253 2.205-.136.18-.272.363-.398.55C1.374 6.756.737 8.87.737 11.06c0 4.218 2.407 8.08 6.133 9.842l.863.41v3.092l-2.525-.51c-.356-.07-.717-.106-1.076-.106a5.45 5.45 0 0 0-3.14.996c-.653.46-1.022 1.202-.99 1.983a2.28 2.28 0 0 0 1.138 1.872c2.24 1.318 4.106 2.923 5.543 4.772 1.26 1.62 3.333 2.59 5.55 2.592h6.698c1.42-.001 2.68-.86 3.134-2.138l2.76-7.74c.272-.757.224-1.584-.134-2.325\" fill-opacity=\".05\" fill=\"#000\" mask=\"url(#B)\" />\n            </g>\n        </g>\n    </g>\n</svg>`;\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar ARGlyph = x$1`\n<svg version=\"1.1\" id=\"view_x5F_in_x5F_AR_x5F_icon\"\n\t xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" x=\"0px\" y=\"0px\" width=\"24px\" height=\"24px\"\n\t viewBox=\"0 0 24 24\" enable-background=\"new 0 0 24 24\" xml:space=\"preserve\">\n<rect id=\"Bounding_Box\" x=\"0\" y=\"0\" fill=\"none\" width=\"24\" height=\"24\"/>\n<g id=\"Art_layer\">\n\t<path d=\"M3,4c0-0.55,0.45-1,1-1h2V1H4C2.35,1,1,2.35,1,4v2h2V4z\"/>\n\t<path d=\"M20,3c0.55,0,1,0.45,1,1v2h2V4c0-1.65-1.35-3-3-3h-2v2H20z\"/>\n\t<path d=\"M4,21c-0.55,0-1-0.45-1-1v-2H1v2c0,1.65,1.35,3,3,3h2v-2H4z\"/>\n\t<path d=\"M20,21c0.55,0,1-0.45,1-1v-2h2v2c0,1.65-1.35,3-3,3h-2v-2H20z\"/>\n\t<g>\n\t\t<path d=\"M18.25,7.6l-5.5-3.18c-0.46-0.27-1.04-0.27-1.5,0L5.75,7.6C5.29,7.87,5,8.36,5,8.9v6.35c0,0.54,0.29,1.03,0.75,1.3\n\t\t\tl5.5,3.18c0.46,0.27,1.04,0.27,1.5,0l5.5-3.18c0.46-0.27,0.75-0.76,0.75-1.3V8.9C19,8.36,18.71,7.87,18.25,7.6z M7,14.96v-4.62\n\t\t\tl4,2.32v4.61L7,14.96z M12,10.93L8,8.61l4-2.31l4,2.31L12,10.93z M13,17.27v-4.61l4-2.32v4.62L13,17.27z\"/>\n\t</g>\n</g>\n</svg>`;\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst templateResult = x$1`\n<style>\n:host {\n  display: block;\n  position: relative;\n  contain: strict;\n  width: 300px;\n  height: 150px;\n}\n\n.container {\n  position: relative;\n  overflow: hidden;\n}\n\n.userInput {\n  width: 100%;\n  height: 100%;\n  display: none;\n  position: relative;\n  outline-offset: -1px;\n  outline-width: 1px;\n}\n\ncanvas {\n  position: absolute;\n  display: none;\n  pointer-events: none;\n  /* NOTE(cdata): Chrome 76 and below apparently have a bug\n   * that causes our canvas not to display pixels unless it is\n   * on its own render layer\n   * @see https://github.com/google/model-viewer/pull/755#issuecomment-536597893\n   */\n  transform: translateZ(0);\n}\n\n.show {\n  display: block;\n}\n\n/* Adapted from HTML5 Boilerplate\n *\n * @see https://github.com/h5bp/html5-boilerplate/blob/ceb4620c78fc82e13534fc44202a3f168754873f/dist/css/main.css#L122-L133 */\n.screen-reader-only {\n  border: 0;\n  left: 0;\n  top: 0;\n  clip: rect(0, 0, 0, 0);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  white-space: nowrap;\n  width: 1px;\n  pointer-events: none;\n}\n\n.slot {\n  position: absolute;\n  pointer-events: none;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n}\n\n.slot > * {\n  pointer-events: initial;\n}\n\n.annotation-wrapper ::slotted(*) {\n  opacity: var(--max-hotspot-opacity, 1);\n  transition: opacity 0.3s;\n}\n\n.pointer-tumbling .annotation-wrapper ::slotted(*) {\n  pointer-events: none;\n}\n\n.annotation-wrapper ::slotted(*) {\n  pointer-events: initial;\n}\n\n.annotation-wrapper.hide ::slotted(*) {\n  opacity: var(--min-hotspot-opacity, 0.25);\n}\n\n.slot.poster {\n  display: none;\n  background-color: inherit;\n}\n\n.slot.poster.show {\n  display: inherit;\n}\n\n.slot.poster > * {\n  pointer-events: initial;\n}\n\n.slot.poster:not(.show) > * {\n  pointer-events: none;\n}\n\n#default-poster {\n  width: 100%;\n  height: 100%;\n  /* The default poster is a <button> so we need to set display\n   * to prevent it from being affected by text-align: */\n  display: block;\n  position: absolute;\n  border: none;\n  padding: 0;\n  background-size: contain;\n  background-repeat: no-repeat;\n  background-position: center;\n  background-color: #fff0;\n}\n\n#default-progress-bar {\n  display: block;\n  position: relative;\n  width: 100%;\n  height: 100%;\n  pointer-events: none;\n  overflow: hidden;\n}\n\n#default-progress-bar > .bar {\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: var(--progress-bar-height, 5px);\n  background-color: var(--progress-bar-color, rgba(0, 0, 0, 0.4));\n  transition: transform 0.09s;\n  transform-origin: top left;\n  transform: scaleX(0);\n  overflow: hidden;\n}\n\n#default-progress-bar > .bar.hide {\n  transition: opacity 0.3s 1s;\n  opacity: 0;\n}\n\n.centered {\n  align-items: center;\n  justify-content: center;\n}\n\n.cover {\n  position: absolute;\n  top: 0;\n  left: 0;\n  width: 100%;\n  height: 100%;\n  pointer-events: none;\n}\n\n.slot.interaction-prompt {\n  display: var(--interaction-prompt-display, flex);\n  overflow: hidden;\n  opacity: 0;\n  will-change: opacity;\n  transition: opacity 0.3s;\n}\n\n.slot.interaction-prompt.visible {\n  opacity: 1;\n}\n\n.animated-container {\n  will-change: transform, opacity;\n  opacity: 0;\n  transition: opacity 0.3s;\n}\n\n.slot.interaction-prompt > * {\n  pointer-events: none;\n}\n\n.slot.ar-button {\n  -moz-user-select: none;\n  -webkit-tap-highlight-color: transparent;\n  user-select: none;\n\n  display: var(--ar-button-display, block);\n}\n\n.slot.ar-button:not(.enabled) {\n  display: none;\n}\n\n.fab {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  box-sizing: border-box;\n  width: 40px;\n  height: 40px;\n  cursor: pointer;\n  background-color: #fff;\n  box-shadow: 0px 0px 4px rgba(0, 0, 0, 0.15);\n  border-radius: 100px;\n}\n\n.fab > * {\n  opacity: 0.87;\n}\n\n#default-ar-button {\n  position: absolute;\n  bottom: 16px;\n  right: 16px;\n  transform: scale(var(--ar-button-scale, 1));\n  transform-origin: bottom right;\n}\n\n.slot.pan-target {\n  display: block;\n  position: absolute;\n  width: 0;\n  height: 0;\n  left: 50%;\n  top: 50%;\n  transform: translate3d(-50%, -50%, 0);\n  background-color: transparent;\n  opacity: 0;\n  transition: opacity 0.3s;\n}\n\n#default-pan-target {\n  width: 6px;\n  height: 6px;\n  border-radius: 6px;\n  border: 1px solid white;\n  box-shadow: 0px 0px 2px 1px rgba(0, 0, 0, 0.8);\n}\n\n.slot.default {\n  pointer-events: none;\n}\n\n.slot.progress-bar {\n  pointer-events: none;\n}\n\n.slot.exit-webxr-ar-button {\n  pointer-events: none;\n}\n\n.slot.exit-webxr-ar-button:not(.enabled) {\n  display: none;\n}\n\n#default-exit-webxr-ar-button {\n  display: flex;\n  align-items: center;\n  justify-content: center;\n  position: absolute;\n  top: env(safe-area-inset-top, 16px);\n  right: 16px;\n  width: 40px;\n  height: 40px;\n  box-sizing: border-box;\n}\n\n#default-exit-webxr-ar-button > svg {\n  fill: #fff;\n}\n</style>\n<div class=\"container\">\n  <div class=\"userInput\" tabindex=\"0\" role=\"img\"\n      aria-label=\"3D model\">\n      <div class=\"slot canvas\">\n        <slot name=\"canvas\">\n          <canvas></canvas>\n        </slot>\n      </div>\n\n  </div>\n\n  <!-- NOTE(cdata): We need to wrap slots because browsers without ShadowDOM\n        will have their <slot> elements removed by ShadyCSS -->\n  <div class=\"slot poster\">\n    <slot name=\"poster\">\n      <button type=\"button\" id=\"default-poster\" aria-hidden=\"true\" aria-label=\"Loading 3D model\"></button>\n    </slot>\n  </div>\n\n  <div class=\"slot ar-button\">\n    <slot name=\"ar-button\">\n      <a id=\"default-ar-button\" part=\"default-ar-button\" class=\"fab\"\n          tabindex=\"2\"\n          role=\"button\"\n          href=\"javascript:void(0);\"\n          aria-label=\"View in your space\">\n        ${ARGlyph}\n      </a>\n    </slot>\n  </div>\n\n  <div class=\"slot pan-target\">\n    <slot name=\"pan-target\">\n      <div id=\"default-pan-target\">\n      </div>\n    </slot>\n  </div>\n\n  <div class=\"slot interaction-prompt cover centered\">\n    <div id=\"prompt\" class=\"animated-container\">\n      <slot name=\"interaction-prompt\" aria-hidden=\"true\">\n        ${ControlsPrompt}\n      </slot>\n    </div>\n  </div>\n\n  <div id=\"finger0\" class=\"animated-container cover\">\n    <slot name=\"finger0\" aria-hidden=\"true\">\n    </slot>\n  </div>\n  <div id=\"finger1\" class=\"animated-container cover\">\n    <slot name=\"finger1\" aria-hidden=\"true\">\n    </slot>\n  </div>\n\n  <div class=\"slot default\">\n    <slot></slot>\n\n    <div class=\"slot progress-bar\">\n      <slot name=\"progress-bar\">\n        <div id=\"default-progress-bar\" aria-hidden=\"true\">\n          <div class=\"bar\" part=\"default-progress-bar\"></div>\n        </div>\n      </slot>\n    </div>\n\n    <div class=\"slot exit-webxr-ar-button\">\n      <slot name=\"exit-webxr-ar-button\">\n        <a id=\"default-exit-webxr-ar-button\" part=\"default-exit-webxr-ar-button\"\n            tabindex=\"3\"\n            aria-label=\"Exit AR\"\n            aria-hidden=\"true\">\n          ${CloseIcon}\n        </a>\n      </slot>\n    </div>\n  </div>\n</div>\n<div class=\"screen-reader-only\" role=\"region\" aria-label=\"Live announcements\">\n  <span id=\"status\" role=\"status\"></span>\n</div>`;\nconst makeTemplate = shadowRoot => {\n  D(templateResult, shadowRoot);\n};\nconst _taskCache$1 = new WeakMap();\nclass DRACOLoader extends Loader {\n  constructor(manager) {\n    super(manager);\n    this.decoderPath = '';\n    this.decoderConfig = {};\n    this.decoderBinary = null;\n    this.decoderPending = null;\n    this.workerLimit = 4;\n    this.workerPool = [];\n    this.workerNextTaskID = 1;\n    this.workerSourceURL = '';\n    this.defaultAttributeIDs = {\n      position: 'POSITION',\n      normal: 'NORMAL',\n      color: 'COLOR',\n      uv: 'TEX_COORD'\n    };\n    this.defaultAttributeTypes = {\n      position: 'Float32Array',\n      normal: 'Float32Array',\n      color: 'Float32Array',\n      uv: 'Float32Array'\n    };\n  }\n  setDecoderPath(path) {\n    this.decoderPath = path;\n    return this;\n  }\n  setDecoderConfig(config) {\n    this.decoderConfig = config;\n    return this;\n  }\n  setWorkerLimit(workerLimit) {\n    this.workerLimit = workerLimit;\n    return this;\n  }\n  load(url, onLoad, onProgress, onError) {\n    const loader = new FileLoader(this.manager);\n    loader.setPath(this.path);\n    loader.setResponseType('arraybuffer');\n    loader.setRequestHeader(this.requestHeader);\n    loader.setWithCredentials(this.withCredentials);\n    loader.load(url, buffer => {\n      this.parse(buffer, onLoad, onError);\n    }, onProgress, onError);\n  }\n  parse(buffer, onLoad, onError = () => {}) {\n    this.decodeDracoFile(buffer, onLoad, null, null, SRGBColorSpace, onError).catch(onError);\n  }\n  decodeDracoFile(buffer, callback, attributeIDs, attributeTypes, vertexColorSpace = LinearSRGBColorSpace, onError = () => {}) {\n    const taskConfig = {\n      attributeIDs: attributeIDs || this.defaultAttributeIDs,\n      attributeTypes: attributeTypes || this.defaultAttributeTypes,\n      useUniqueIDs: !!attributeIDs,\n      vertexColorSpace: vertexColorSpace\n    };\n    return this.decodeGeometry(buffer, taskConfig).then(callback).catch(onError);\n  }\n  decodeGeometry(buffer, taskConfig) {\n    const taskKey = JSON.stringify(taskConfig);\n\n    // Check for an existing task using this buffer. A transferred buffer cannot be transferred\n    // again from this thread.\n    if (_taskCache$1.has(buffer)) {\n      const cachedTask = _taskCache$1.get(buffer);\n      if (cachedTask.key === taskKey) {\n        return cachedTask.promise;\n      } else if (buffer.byteLength === 0) {\n        // Technically, it would be possible to wait for the previous task to complete,\n        // transfer the buffer back, and decode again with the second configuration. That\n        // is complex, and I don't know of any reason to decode a Draco buffer twice in\n        // different ways, so this is left unimplemented.\n        throw new Error('THREE.DRACOLoader: Unable to re-decode a buffer with different ' + 'settings. Buffer has already been transferred.');\n      }\n    }\n\n    //\n\n    let worker;\n    const taskID = this.workerNextTaskID++;\n    const taskCost = buffer.byteLength;\n\n    // Obtain a worker and assign a task, and construct a geometry instance\n    // when the task completes.\n    const geometryPending = this._getWorker(taskID, taskCost).then(_worker => {\n      worker = _worker;\n      return new Promise((resolve, reject) => {\n        worker._callbacks[taskID] = {\n          resolve,\n          reject\n        };\n        worker.postMessage({\n          type: 'decode',\n          id: taskID,\n          taskConfig,\n          buffer\n        }, [buffer]);\n\n        // this.debug();\n      });\n    }).then(message => this._createGeometry(message.geometry));\n\n    // Remove task from the task list.\n    // Note: replaced '.finally()' with '.catch().then()' block - iOS 11 support (#19416)\n    geometryPending.catch(() => true).then(() => {\n      if (worker && taskID) {\n        this._releaseTask(worker, taskID);\n\n        // this.debug();\n      }\n    });\n\n    // Cache the task result.\n    _taskCache$1.set(buffer, {\n      key: taskKey,\n      promise: geometryPending\n    });\n    return geometryPending;\n  }\n  _createGeometry(geometryData) {\n    const geometry = new BufferGeometry();\n    if (geometryData.index) {\n      geometry.setIndex(new BufferAttribute(geometryData.index.array, 1));\n    }\n    for (let i = 0; i < geometryData.attributes.length; i++) {\n      const result = geometryData.attributes[i];\n      const name = result.name;\n      const array = result.array;\n      const itemSize = result.itemSize;\n      const attribute = new BufferAttribute(array, itemSize);\n      if (name === 'color') {\n        this._assignVertexColorSpace(attribute, result.vertexColorSpace);\n        attribute.normalized = array instanceof Float32Array === false;\n      }\n      geometry.setAttribute(name, attribute);\n    }\n    return geometry;\n  }\n  _assignVertexColorSpace(attribute, inputColorSpace) {\n    // While .drc files do not specify colorspace, the only 'official' tooling\n    // is PLY and OBJ converters, which use sRGB. We'll assume sRGB when a .drc\n    // file is passed into .load() or .parse(). GLTFLoader uses internal APIs\n    // to decode geometry, and vertex colors are already Linear-sRGB in there.\n\n    if (inputColorSpace !== SRGBColorSpace) return;\n    const _color = new Color();\n    for (let i = 0, il = attribute.count; i < il; i++) {\n      _color.fromBufferAttribute(attribute, i);\n      ColorManagement.toWorkingColorSpace(_color, SRGBColorSpace);\n      attribute.setXYZ(i, _color.r, _color.g, _color.b);\n    }\n  }\n  _loadLibrary(url, responseType) {\n    const loader = new FileLoader(this.manager);\n    loader.setPath(this.decoderPath);\n    loader.setResponseType(responseType);\n    loader.setWithCredentials(this.withCredentials);\n    return new Promise((resolve, reject) => {\n      loader.load(url, resolve, undefined, reject);\n    });\n  }\n  preload() {\n    this._initDecoder();\n    return this;\n  }\n  _initDecoder() {\n    if (this.decoderPending) return this.decoderPending;\n    const useJS = typeof WebAssembly !== 'object' || this.decoderConfig.type === 'js';\n    const librariesPending = [];\n    if (useJS) {\n      librariesPending.push(this._loadLibrary('draco_decoder.js', 'text'));\n    } else {\n      librariesPending.push(this._loadLibrary('draco_wasm_wrapper.js', 'text'));\n      librariesPending.push(this._loadLibrary('draco_decoder.wasm', 'arraybuffer'));\n    }\n    this.decoderPending = Promise.all(librariesPending).then(libraries => {\n      const jsContent = libraries[0];\n      if (!useJS) {\n        this.decoderConfig.wasmBinary = libraries[1];\n      }\n      const fn = DRACOWorker.toString();\n      const body = ['/* draco decoder */', jsContent, '', '/* worker */', fn.substring(fn.indexOf('{') + 1, fn.lastIndexOf('}'))].join('\\n');\n      this.workerSourceURL = URL.createObjectURL(new Blob([body]));\n    });\n    return this.decoderPending;\n  }\n  _getWorker(taskID, taskCost) {\n    return this._initDecoder().then(() => {\n      if (this.workerPool.length < this.workerLimit) {\n        const worker = new Worker(this.workerSourceURL);\n        worker._callbacks = {};\n        worker._taskCosts = {};\n        worker._taskLoad = 0;\n        worker.postMessage({\n          type: 'init',\n          decoderConfig: this.decoderConfig\n        });\n        worker.onmessage = function (e) {\n          const message = e.data;\n          switch (message.type) {\n            case 'decode':\n              worker._callbacks[message.id].resolve(message);\n              break;\n            case 'error':\n              worker._callbacks[message.id].reject(message);\n              break;\n            default:\n              console.error('THREE.DRACOLoader: Unexpected message, \"' + message.type + '\"');\n          }\n        };\n        this.workerPool.push(worker);\n      } else {\n        this.workerPool.sort(function (a, b) {\n          return a._taskLoad > b._taskLoad ? -1 : 1;\n        });\n      }\n      const worker = this.workerPool[this.workerPool.length - 1];\n      worker._taskCosts[taskID] = taskCost;\n      worker._taskLoad += taskCost;\n      return worker;\n    });\n  }\n  _releaseTask(worker, taskID) {\n    worker._taskLoad -= worker._taskCosts[taskID];\n    delete worker._callbacks[taskID];\n    delete worker._taskCosts[taskID];\n  }\n  debug() {\n    console.log('Task load: ', this.workerPool.map(worker => worker._taskLoad));\n  }\n  dispose() {\n    for (let i = 0; i < this.workerPool.length; ++i) {\n      this.workerPool[i].terminate();\n    }\n    this.workerPool.length = 0;\n    if (this.workerSourceURL !== '') {\n      URL.revokeObjectURL(this.workerSourceURL);\n    }\n    return this;\n  }\n}\n\n/* WEB WORKER */\n\nfunction DRACOWorker() {\n  let decoderConfig;\n  let decoderPending;\n  onmessage = function (e) {\n    const message = e.data;\n    switch (message.type) {\n      case 'init':\n        decoderConfig = message.decoderConfig;\n        decoderPending = new Promise(function (resolve /*, reject*/) {\n          decoderConfig.onModuleLoaded = function (draco) {\n            // Module is Promise-like. Wrap before resolving to avoid loop.\n            resolve({\n              draco: draco\n            });\n          };\n          DracoDecoderModule(decoderConfig); // eslint-disable-line no-undef\n        });\n        break;\n      case 'decode':\n        const buffer = message.buffer;\n        const taskConfig = message.taskConfig;\n        decoderPending.then(module => {\n          const draco = module.draco;\n          const decoder = new draco.Decoder();\n          try {\n            const geometry = decodeGeometry(draco, decoder, new Int8Array(buffer), taskConfig);\n            const buffers = geometry.attributes.map(attr => attr.array.buffer);\n            if (geometry.index) buffers.push(geometry.index.array.buffer);\n            self.postMessage({\n              type: 'decode',\n              id: message.id,\n              geometry\n            }, buffers);\n          } catch (error) {\n            console.error(error);\n            self.postMessage({\n              type: 'error',\n              id: message.id,\n              error: error.message\n            });\n          } finally {\n            draco.destroy(decoder);\n          }\n        });\n        break;\n    }\n  };\n  function decodeGeometry(draco, decoder, array, taskConfig) {\n    const attributeIDs = taskConfig.attributeIDs;\n    const attributeTypes = taskConfig.attributeTypes;\n    let dracoGeometry;\n    let decodingStatus;\n    const geometryType = decoder.GetEncodedGeometryType(array);\n    if (geometryType === draco.TRIANGULAR_MESH) {\n      dracoGeometry = new draco.Mesh();\n      decodingStatus = decoder.DecodeArrayToMesh(array, array.byteLength, dracoGeometry);\n    } else if (geometryType === draco.POINT_CLOUD) {\n      dracoGeometry = new draco.PointCloud();\n      decodingStatus = decoder.DecodeArrayToPointCloud(array, array.byteLength, dracoGeometry);\n    } else {\n      throw new Error('THREE.DRACOLoader: Unexpected geometry type.');\n    }\n    if (!decodingStatus.ok() || dracoGeometry.ptr === 0) {\n      throw new Error('THREE.DRACOLoader: Decoding failed: ' + decodingStatus.error_msg());\n    }\n    const geometry = {\n      index: null,\n      attributes: []\n    };\n\n    // Gather all vertex attributes.\n    for (const attributeName in attributeIDs) {\n      const attributeType = self[attributeTypes[attributeName]];\n      let attribute;\n      let attributeID;\n\n      // A Draco file may be created with default vertex attributes, whose attribute IDs\n      // are mapped 1:1 from their semantic name (POSITION, NORMAL, ...). Alternatively,\n      // a Draco file may contain a custom set of attributes, identified by known unique\n      // IDs. glTF files always do the latter, and `.drc` files typically do the former.\n      if (taskConfig.useUniqueIDs) {\n        attributeID = attributeIDs[attributeName];\n        attribute = decoder.GetAttributeByUniqueId(dracoGeometry, attributeID);\n      } else {\n        attributeID = decoder.GetAttributeId(dracoGeometry, draco[attributeIDs[attributeName]]);\n        if (attributeID === -1) continue;\n        attribute = decoder.GetAttribute(dracoGeometry, attributeID);\n      }\n      const attributeResult = decodeAttribute(draco, decoder, dracoGeometry, attributeName, attributeType, attribute);\n      if (attributeName === 'color') {\n        attributeResult.vertexColorSpace = taskConfig.vertexColorSpace;\n      }\n      geometry.attributes.push(attributeResult);\n    }\n\n    // Add index.\n    if (geometryType === draco.TRIANGULAR_MESH) {\n      geometry.index = decodeIndex(draco, decoder, dracoGeometry);\n    }\n    draco.destroy(dracoGeometry);\n    return geometry;\n  }\n  function decodeIndex(draco, decoder, dracoGeometry) {\n    const numFaces = dracoGeometry.num_faces();\n    const numIndices = numFaces * 3;\n    const byteLength = numIndices * 4;\n    const ptr = draco._malloc(byteLength);\n    decoder.GetTrianglesUInt32Array(dracoGeometry, byteLength, ptr);\n    const index = new Uint32Array(draco.HEAPF32.buffer, ptr, numIndices).slice();\n    draco._free(ptr);\n    return {\n      array: index,\n      itemSize: 1\n    };\n  }\n  function decodeAttribute(draco, decoder, dracoGeometry, attributeName, attributeType, attribute) {\n    const numComponents = attribute.num_components();\n    const numPoints = dracoGeometry.num_points();\n    const numValues = numPoints * numComponents;\n    const byteLength = numValues * attributeType.BYTES_PER_ELEMENT;\n    const dataType = getDracoDataType(draco, attributeType);\n    const ptr = draco._malloc(byteLength);\n    decoder.GetAttributeDataArrayForAllPoints(dracoGeometry, attribute, dataType, byteLength, ptr);\n    const array = new attributeType(draco.HEAPF32.buffer, ptr, numValues).slice();\n    draco._free(ptr);\n    return {\n      name: attributeName,\n      array: array,\n      itemSize: numComponents\n    };\n  }\n  function getDracoDataType(draco, attributeType) {\n    switch (attributeType) {\n      case Float32Array:\n        return draco.DT_FLOAT32;\n      case Int8Array:\n        return draco.DT_INT8;\n      case Int16Array:\n        return draco.DT_INT16;\n      case Int32Array:\n        return draco.DT_INT32;\n      case Uint8Array:\n        return draco.DT_UINT8;\n      case Uint16Array:\n        return draco.DT_UINT16;\n      case Uint32Array:\n        return draco.DT_UINT32;\n    }\n  }\n}\n\n/**\n * @param {BufferGeometry} geometry\n * @param {number} drawMode\n * @return {BufferGeometry}\n */\nfunction toTrianglesDrawMode(geometry, drawMode) {\n  if (drawMode === TrianglesDrawMode) {\n    console.warn('THREE.BufferGeometryUtils.toTrianglesDrawMode(): Geometry already defined as triangles.');\n    return geometry;\n  }\n  if (drawMode === TriangleFanDrawMode || drawMode === TriangleStripDrawMode) {\n    let index = geometry.getIndex();\n\n    // generate index if not present\n\n    if (index === null) {\n      const indices = [];\n      const position = geometry.getAttribute('position');\n      if (position !== undefined) {\n        for (let i = 0; i < position.count; i++) {\n          indices.push(i);\n        }\n        geometry.setIndex(indices);\n        index = geometry.getIndex();\n      } else {\n        console.error('THREE.BufferGeometryUtils.toTrianglesDrawMode(): Undefined position attribute. Processing not possible.');\n        return geometry;\n      }\n    }\n\n    //\n\n    const numberOfTriangles = index.count - 2;\n    const newIndices = [];\n    if (drawMode === TriangleFanDrawMode) {\n      // gl.TRIANGLE_FAN\n\n      for (let i = 1; i <= numberOfTriangles; i++) {\n        newIndices.push(index.getX(0));\n        newIndices.push(index.getX(i));\n        newIndices.push(index.getX(i + 1));\n      }\n    } else {\n      // gl.TRIANGLE_STRIP\n\n      for (let i = 0; i < numberOfTriangles; i++) {\n        if (i % 2 === 0) {\n          newIndices.push(index.getX(i));\n          newIndices.push(index.getX(i + 1));\n          newIndices.push(index.getX(i + 2));\n        } else {\n          newIndices.push(index.getX(i + 2));\n          newIndices.push(index.getX(i + 1));\n          newIndices.push(index.getX(i));\n        }\n      }\n    }\n    if (newIndices.length / 3 !== numberOfTriangles) {\n      console.error('THREE.BufferGeometryUtils.toTrianglesDrawMode(): Unable to generate correct amount of triangles.');\n    }\n\n    // build final geometry\n\n    const newGeometry = geometry.clone();\n    newGeometry.setIndex(newIndices);\n    newGeometry.clearGroups();\n    return newGeometry;\n  } else {\n    console.error('THREE.BufferGeometryUtils.toTrianglesDrawMode(): Unknown draw mode:', drawMode);\n    return geometry;\n  }\n}\nclass GLTFLoader extends Loader {\n  constructor(manager) {\n    super(manager);\n    this.dracoLoader = null;\n    this.ktx2Loader = null;\n    this.meshoptDecoder = null;\n    this.pluginCallbacks = [];\n    this.register(function (parser) {\n      return new GLTFMaterialsClearcoatExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsDispersionExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFTextureBasisUExtension(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFTextureWebPExtension(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFTextureAVIFExtension(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsSheenExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsTransmissionExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsVolumeExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsIorExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsEmissiveStrengthExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsSpecularExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsIridescenceExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsAnisotropyExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMaterialsBumpExtension$1(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFLightsExtension(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMeshoptCompression(parser);\n    });\n    this.register(function (parser) {\n      return new GLTFMeshGpuInstancing$1(parser);\n    });\n  }\n  load(url, onLoad, onProgress, onError) {\n    const scope = this;\n    let resourcePath;\n    if (this.resourcePath !== '') {\n      resourcePath = this.resourcePath;\n    } else if (this.path !== '') {\n      // If a base path is set, resources will be relative paths from that plus the relative path of the gltf file\n      // Example  path = 'https://my-cnd-server.com/', url = 'assets/models/model.gltf'\n      // resourcePath = 'https://my-cnd-server.com/assets/models/'\n      // referenced resource 'model.bin' will be loaded from 'https://my-cnd-server.com/assets/models/model.bin'\n      // referenced resource '../textures/texture.png' will be loaded from 'https://my-cnd-server.com/assets/textures/texture.png'\n      const relativeUrl = LoaderUtils.extractUrlBase(url);\n      resourcePath = LoaderUtils.resolveURL(relativeUrl, this.path);\n    } else {\n      resourcePath = LoaderUtils.extractUrlBase(url);\n    }\n\n    // Tells the LoadingManager to track an extra item, which resolves after\n    // the model is fully loaded. This means the count of items loaded will\n    // be incorrect, but ensures manager.onLoad() does not fire early.\n    this.manager.itemStart(url);\n    const _onError = function (e) {\n      if (onError) {\n        onError(e);\n      } else {\n        console.error(e);\n      }\n      scope.manager.itemError(url);\n      scope.manager.itemEnd(url);\n    };\n    const loader = new FileLoader(this.manager);\n    loader.setPath(this.path);\n    loader.setResponseType('arraybuffer');\n    loader.setRequestHeader(this.requestHeader);\n    loader.setWithCredentials(this.withCredentials);\n    loader.load(url, function (data) {\n      try {\n        scope.parse(data, resourcePath, function (gltf) {\n          onLoad(gltf);\n          scope.manager.itemEnd(url);\n        }, _onError);\n      } catch (e) {\n        _onError(e);\n      }\n    }, onProgress, _onError);\n  }\n  setDRACOLoader(dracoLoader) {\n    this.dracoLoader = dracoLoader;\n    return this;\n  }\n  setKTX2Loader(ktx2Loader) {\n    this.ktx2Loader = ktx2Loader;\n    return this;\n  }\n  setMeshoptDecoder(meshoptDecoder) {\n    this.meshoptDecoder = meshoptDecoder;\n    return this;\n  }\n  register(callback) {\n    if (this.pluginCallbacks.indexOf(callback) === -1) {\n      this.pluginCallbacks.push(callback);\n    }\n    return this;\n  }\n  unregister(callback) {\n    if (this.pluginCallbacks.indexOf(callback) !== -1) {\n      this.pluginCallbacks.splice(this.pluginCallbacks.indexOf(callback), 1);\n    }\n    return this;\n  }\n  parse(data, path, onLoad, onError) {\n    let json;\n    const extensions = {};\n    const plugins = {};\n    const textDecoder = new TextDecoder();\n    if (typeof data === 'string') {\n      json = JSON.parse(data);\n    } else if (data instanceof ArrayBuffer) {\n      const magic = textDecoder.decode(new Uint8Array(data, 0, 4));\n      if (magic === BINARY_EXTENSION_HEADER_MAGIC) {\n        try {\n          extensions[EXTENSIONS.KHR_BINARY_GLTF] = new GLTFBinaryExtension(data);\n        } catch (error) {\n          if (onError) onError(error);\n          return;\n        }\n        json = JSON.parse(extensions[EXTENSIONS.KHR_BINARY_GLTF].content);\n      } else {\n        json = JSON.parse(textDecoder.decode(data));\n      }\n    } else {\n      json = data;\n    }\n    if (json.asset === undefined || json.asset.version[0] < 2) {\n      if (onError) onError(new Error('THREE.GLTFLoader: Unsupported asset. glTF versions >=2.0 are supported.'));\n      return;\n    }\n    const parser = new GLTFParser(json, {\n      path: path || this.resourcePath || '',\n      crossOrigin: this.crossOrigin,\n      requestHeader: this.requestHeader,\n      manager: this.manager,\n      ktx2Loader: this.ktx2Loader,\n      meshoptDecoder: this.meshoptDecoder\n    });\n    parser.fileLoader.setRequestHeader(this.requestHeader);\n    for (let i = 0; i < this.pluginCallbacks.length; i++) {\n      const plugin = this.pluginCallbacks[i](parser);\n      if (!plugin.name) console.error('THREE.GLTFLoader: Invalid plugin found: missing name');\n      plugins[plugin.name] = plugin;\n\n      // Workaround to avoid determining as unknown extension\n      // in addUnknownExtensionsToUserData().\n      // Remove this workaround if we move all the existing\n      // extension handlers to plugin system\n      extensions[plugin.name] = true;\n    }\n    if (json.extensionsUsed) {\n      for (let i = 0; i < json.extensionsUsed.length; ++i) {\n        const extensionName = json.extensionsUsed[i];\n        const extensionsRequired = json.extensionsRequired || [];\n        switch (extensionName) {\n          case EXTENSIONS.KHR_MATERIALS_UNLIT:\n            extensions[extensionName] = new GLTFMaterialsUnlitExtension$1();\n            break;\n          case EXTENSIONS.KHR_DRACO_MESH_COMPRESSION:\n            extensions[extensionName] = new GLTFDracoMeshCompressionExtension(json, this.dracoLoader);\n            break;\n          case EXTENSIONS.KHR_TEXTURE_TRANSFORM:\n            extensions[extensionName] = new GLTFTextureTransformExtension();\n            break;\n          case EXTENSIONS.KHR_MESH_QUANTIZATION:\n            extensions[extensionName] = new GLTFMeshQuantizationExtension();\n            break;\n          default:\n            if (extensionsRequired.indexOf(extensionName) >= 0 && plugins[extensionName] === undefined) {\n              console.warn('THREE.GLTFLoader: Unknown extension \"' + extensionName + '\".');\n            }\n        }\n      }\n    }\n    parser.setExtensions(extensions);\n    parser.setPlugins(plugins);\n    parser.parse(onLoad, onError);\n  }\n  parseAsync(data, path) {\n    const scope = this;\n    return new Promise(function (resolve, reject) {\n      scope.parse(data, path, resolve, reject);\n    });\n  }\n}\n\n/* GLTFREGISTRY */\n\nfunction GLTFRegistry() {\n  let objects = {};\n  return {\n    get: function (key) {\n      return objects[key];\n    },\n    add: function (key, object) {\n      objects[key] = object;\n    },\n    remove: function (key) {\n      delete objects[key];\n    },\n    removeAll: function () {\n      objects = {};\n    }\n  };\n}\n\n/*********************************/\n/********** EXTENSIONS ***********/\n/*********************************/\n\nconst EXTENSIONS = {\n  KHR_BINARY_GLTF: 'KHR_binary_glTF',\n  KHR_DRACO_MESH_COMPRESSION: 'KHR_draco_mesh_compression',\n  KHR_LIGHTS_PUNCTUAL: 'KHR_lights_punctual',\n  KHR_MATERIALS_CLEARCOAT: 'KHR_materials_clearcoat',\n  KHR_MATERIALS_DISPERSION: 'KHR_materials_dispersion',\n  KHR_MATERIALS_IOR: 'KHR_materials_ior',\n  KHR_MATERIALS_SHEEN: 'KHR_materials_sheen',\n  KHR_MATERIALS_SPECULAR: 'KHR_materials_specular',\n  KHR_MATERIALS_TRANSMISSION: 'KHR_materials_transmission',\n  KHR_MATERIALS_IRIDESCENCE: 'KHR_materials_iridescence',\n  KHR_MATERIALS_ANISOTROPY: 'KHR_materials_anisotropy',\n  KHR_MATERIALS_UNLIT: 'KHR_materials_unlit',\n  KHR_MATERIALS_VOLUME: 'KHR_materials_volume',\n  KHR_TEXTURE_BASISU: 'KHR_texture_basisu',\n  KHR_TEXTURE_TRANSFORM: 'KHR_texture_transform',\n  KHR_MESH_QUANTIZATION: 'KHR_mesh_quantization',\n  KHR_MATERIALS_EMISSIVE_STRENGTH: 'KHR_materials_emissive_strength',\n  EXT_MATERIALS_BUMP: 'EXT_materials_bump',\n  EXT_TEXTURE_WEBP: 'EXT_texture_webp',\n  EXT_TEXTURE_AVIF: 'EXT_texture_avif',\n  EXT_MESHOPT_COMPRESSION: 'EXT_meshopt_compression',\n  EXT_MESH_GPU_INSTANCING: 'EXT_mesh_gpu_instancing'\n};\n\n/**\n * Punctual Lights Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_lights_punctual\n */\nclass GLTFLightsExtension {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_LIGHTS_PUNCTUAL;\n\n    // Object3D instance caches\n    this.cache = {\n      refs: {},\n      uses: {}\n    };\n  }\n  _markDefs() {\n    const parser = this.parser;\n    const nodeDefs = this.parser.json.nodes || [];\n    for (let nodeIndex = 0, nodeLength = nodeDefs.length; nodeIndex < nodeLength; nodeIndex++) {\n      const nodeDef = nodeDefs[nodeIndex];\n      if (nodeDef.extensions && nodeDef.extensions[this.name] && nodeDef.extensions[this.name].light !== undefined) {\n        parser._addNodeRef(this.cache, nodeDef.extensions[this.name].light);\n      }\n    }\n  }\n  _loadLight(lightIndex) {\n    const parser = this.parser;\n    const cacheKey = 'light:' + lightIndex;\n    let dependency = parser.cache.get(cacheKey);\n    if (dependency) return dependency;\n    const json = parser.json;\n    const extensions = json.extensions && json.extensions[this.name] || {};\n    const lightDefs = extensions.lights || [];\n    const lightDef = lightDefs[lightIndex];\n    let lightNode;\n    const color = new Color(0xffffff);\n    if (lightDef.color !== undefined) color.setRGB(lightDef.color[0], lightDef.color[1], lightDef.color[2], LinearSRGBColorSpace);\n    const range = lightDef.range !== undefined ? lightDef.range : 0;\n    switch (lightDef.type) {\n      case 'directional':\n        lightNode = new DirectionalLight(color);\n        lightNode.target.position.set(0, 0, -1);\n        lightNode.add(lightNode.target);\n        break;\n      case 'point':\n        lightNode = new PointLight(color);\n        lightNode.distance = range;\n        break;\n      case 'spot':\n        lightNode = new SpotLight(color);\n        lightNode.distance = range;\n        // Handle spotlight properties.\n        lightDef.spot = lightDef.spot || {};\n        lightDef.spot.innerConeAngle = lightDef.spot.innerConeAngle !== undefined ? lightDef.spot.innerConeAngle : 0;\n        lightDef.spot.outerConeAngle = lightDef.spot.outerConeAngle !== undefined ? lightDef.spot.outerConeAngle : Math.PI / 4.0;\n        lightNode.angle = lightDef.spot.outerConeAngle;\n        lightNode.penumbra = 1.0 - lightDef.spot.innerConeAngle / lightDef.spot.outerConeAngle;\n        lightNode.target.position.set(0, 0, -1);\n        lightNode.add(lightNode.target);\n        break;\n      default:\n        throw new Error('THREE.GLTFLoader: Unexpected light type: ' + lightDef.type);\n    }\n\n    // Some lights (e.g. spot) default to a position other than the origin. Reset the position\n    // here, because node-level parsing will only override position if explicitly specified.\n    lightNode.position.set(0, 0, 0);\n    lightNode.decay = 2;\n    assignExtrasToUserData(lightNode, lightDef);\n    if (lightDef.intensity !== undefined) lightNode.intensity = lightDef.intensity;\n    lightNode.name = parser.createUniqueName(lightDef.name || 'light_' + lightIndex);\n    dependency = Promise.resolve(lightNode);\n    parser.cache.add(cacheKey, dependency);\n    return dependency;\n  }\n  getDependency(type, index) {\n    if (type !== 'light') return;\n    return this._loadLight(index);\n  }\n  createNodeAttachment(nodeIndex) {\n    const self = this;\n    const parser = this.parser;\n    const json = parser.json;\n    const nodeDef = json.nodes[nodeIndex];\n    const lightDef = nodeDef.extensions && nodeDef.extensions[this.name] || {};\n    const lightIndex = lightDef.light;\n    if (lightIndex === undefined) return null;\n    return this._loadLight(lightIndex).then(function (light) {\n      return parser._getNodeRef(self.cache, lightIndex, light);\n    });\n  }\n}\n\n/**\n * Unlit Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_unlit\n */\nclass GLTFMaterialsUnlitExtension$1 {\n  constructor() {\n    this.name = EXTENSIONS.KHR_MATERIALS_UNLIT;\n  }\n  getMaterialType() {\n    return MeshBasicMaterial;\n  }\n  extendParams(materialParams, materialDef, parser) {\n    const pending = [];\n    materialParams.color = new Color(1.0, 1.0, 1.0);\n    materialParams.opacity = 1.0;\n    const metallicRoughness = materialDef.pbrMetallicRoughness;\n    if (metallicRoughness) {\n      if (Array.isArray(metallicRoughness.baseColorFactor)) {\n        const array = metallicRoughness.baseColorFactor;\n        materialParams.color.setRGB(array[0], array[1], array[2], LinearSRGBColorSpace);\n        materialParams.opacity = array[3];\n      }\n      if (metallicRoughness.baseColorTexture !== undefined) {\n        pending.push(parser.assignTexture(materialParams, 'map', metallicRoughness.baseColorTexture, SRGBColorSpace));\n      }\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Materials Emissive Strength Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/blob/5768b3ce0ef32bc39cdf1bef10b948586635ead3/extensions/2.0/Khronos/KHR_materials_emissive_strength/README.md\n */\nclass GLTFMaterialsEmissiveStrengthExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_EMISSIVE_STRENGTH;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const emissiveStrength = materialDef.extensions[this.name].emissiveStrength;\n    if (emissiveStrength !== undefined) {\n      materialParams.emissiveIntensity = emissiveStrength;\n    }\n    return Promise.resolve();\n  }\n}\n\n/**\n * Clearcoat Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_clearcoat\n */\nclass GLTFMaterialsClearcoatExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_CLEARCOAT;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    const extension = materialDef.extensions[this.name];\n    if (extension.clearcoatFactor !== undefined) {\n      materialParams.clearcoat = extension.clearcoatFactor;\n    }\n    if (extension.clearcoatTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'clearcoatMap', extension.clearcoatTexture));\n    }\n    if (extension.clearcoatRoughnessFactor !== undefined) {\n      materialParams.clearcoatRoughness = extension.clearcoatRoughnessFactor;\n    }\n    if (extension.clearcoatRoughnessTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'clearcoatRoughnessMap', extension.clearcoatRoughnessTexture));\n    }\n    if (extension.clearcoatNormalTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'clearcoatNormalMap', extension.clearcoatNormalTexture));\n      if (extension.clearcoatNormalTexture.scale !== undefined) {\n        const scale = extension.clearcoatNormalTexture.scale;\n        materialParams.clearcoatNormalScale = new Vector2(scale, scale);\n      }\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Materials dispersion Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_dispersion\n */\nclass GLTFMaterialsDispersionExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_DISPERSION;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const extension = materialDef.extensions[this.name];\n    materialParams.dispersion = extension.dispersion !== undefined ? extension.dispersion : 0;\n    return Promise.resolve();\n  }\n}\n\n/**\n * Iridescence Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_iridescence\n */\nclass GLTFMaterialsIridescenceExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_IRIDESCENCE;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    const extension = materialDef.extensions[this.name];\n    if (extension.iridescenceFactor !== undefined) {\n      materialParams.iridescence = extension.iridescenceFactor;\n    }\n    if (extension.iridescenceTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'iridescenceMap', extension.iridescenceTexture));\n    }\n    if (extension.iridescenceIor !== undefined) {\n      materialParams.iridescenceIOR = extension.iridescenceIor;\n    }\n    if (materialParams.iridescenceThicknessRange === undefined) {\n      materialParams.iridescenceThicknessRange = [100, 400];\n    }\n    if (extension.iridescenceThicknessMinimum !== undefined) {\n      materialParams.iridescenceThicknessRange[0] = extension.iridescenceThicknessMinimum;\n    }\n    if (extension.iridescenceThicknessMaximum !== undefined) {\n      materialParams.iridescenceThicknessRange[1] = extension.iridescenceThicknessMaximum;\n    }\n    if (extension.iridescenceThicknessTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'iridescenceThicknessMap', extension.iridescenceThicknessTexture));\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Sheen Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_sheen\n */\nclass GLTFMaterialsSheenExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_SHEEN;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    materialParams.sheenColor = new Color(0, 0, 0);\n    materialParams.sheenRoughness = 0;\n    materialParams.sheen = 1;\n    const extension = materialDef.extensions[this.name];\n    if (extension.sheenColorFactor !== undefined) {\n      const colorFactor = extension.sheenColorFactor;\n      materialParams.sheenColor.setRGB(colorFactor[0], colorFactor[1], colorFactor[2], LinearSRGBColorSpace);\n    }\n    if (extension.sheenRoughnessFactor !== undefined) {\n      materialParams.sheenRoughness = extension.sheenRoughnessFactor;\n    }\n    if (extension.sheenColorTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'sheenColorMap', extension.sheenColorTexture, SRGBColorSpace));\n    }\n    if (extension.sheenRoughnessTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'sheenRoughnessMap', extension.sheenRoughnessTexture));\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Transmission Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_transmission\n * Draft: https://github.com/KhronosGroup/glTF/pull/1698\n */\nclass GLTFMaterialsTransmissionExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_TRANSMISSION;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    const extension = materialDef.extensions[this.name];\n    if (extension.transmissionFactor !== undefined) {\n      materialParams.transmission = extension.transmissionFactor;\n    }\n    if (extension.transmissionTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'transmissionMap', extension.transmissionTexture));\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Materials Volume Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_volume\n */\nclass GLTFMaterialsVolumeExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_VOLUME;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    const extension = materialDef.extensions[this.name];\n    materialParams.thickness = extension.thicknessFactor !== undefined ? extension.thicknessFactor : 0;\n    if (extension.thicknessTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'thicknessMap', extension.thicknessTexture));\n    }\n    materialParams.attenuationDistance = extension.attenuationDistance || Infinity;\n    const colorArray = extension.attenuationColor || [1, 1, 1];\n    materialParams.attenuationColor = new Color().setRGB(colorArray[0], colorArray[1], colorArray[2], LinearSRGBColorSpace);\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Materials ior Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_ior\n */\nclass GLTFMaterialsIorExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_IOR;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const extension = materialDef.extensions[this.name];\n    materialParams.ior = extension.ior !== undefined ? extension.ior : 1.5;\n    return Promise.resolve();\n  }\n}\n\n/**\n * Materials specular Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_specular\n */\nclass GLTFMaterialsSpecularExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_SPECULAR;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    const extension = materialDef.extensions[this.name];\n    materialParams.specularIntensity = extension.specularFactor !== undefined ? extension.specularFactor : 1.0;\n    if (extension.specularTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'specularIntensityMap', extension.specularTexture));\n    }\n    const colorArray = extension.specularColorFactor || [1, 1, 1];\n    materialParams.specularColor = new Color().setRGB(colorArray[0], colorArray[1], colorArray[2], LinearSRGBColorSpace);\n    if (extension.specularColorTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'specularColorMap', extension.specularColorTexture, SRGBColorSpace));\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Materials bump Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/EXT_materials_bump\n */\nclass GLTFMaterialsBumpExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.EXT_MATERIALS_BUMP;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    const extension = materialDef.extensions[this.name];\n    materialParams.bumpScale = extension.bumpFactor !== undefined ? extension.bumpFactor : 1.0;\n    if (extension.bumpTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'bumpMap', extension.bumpTexture));\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * Materials anisotropy Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_anisotropy\n */\nclass GLTFMaterialsAnisotropyExtension$1 {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_MATERIALS_ANISOTROPY;\n  }\n  getMaterialType(materialIndex) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) return null;\n    return MeshPhysicalMaterial;\n  }\n  extendMaterialParams(materialIndex, materialParams) {\n    const parser = this.parser;\n    const materialDef = parser.json.materials[materialIndex];\n    if (!materialDef.extensions || !materialDef.extensions[this.name]) {\n      return Promise.resolve();\n    }\n    const pending = [];\n    const extension = materialDef.extensions[this.name];\n    if (extension.anisotropyStrength !== undefined) {\n      materialParams.anisotropy = extension.anisotropyStrength;\n    }\n    if (extension.anisotropyRotation !== undefined) {\n      materialParams.anisotropyRotation = extension.anisotropyRotation;\n    }\n    if (extension.anisotropyTexture !== undefined) {\n      pending.push(parser.assignTexture(materialParams, 'anisotropyMap', extension.anisotropyTexture));\n    }\n    return Promise.all(pending);\n  }\n}\n\n/**\n * BasisU Texture Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_texture_basisu\n */\nclass GLTFTextureBasisUExtension {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.KHR_TEXTURE_BASISU;\n  }\n  loadTexture(textureIndex) {\n    const parser = this.parser;\n    const json = parser.json;\n    const textureDef = json.textures[textureIndex];\n    if (!textureDef.extensions || !textureDef.extensions[this.name]) {\n      return null;\n    }\n    const extension = textureDef.extensions[this.name];\n    const loader = parser.options.ktx2Loader;\n    if (!loader) {\n      if (json.extensionsRequired && json.extensionsRequired.indexOf(this.name) >= 0) {\n        throw new Error('THREE.GLTFLoader: setKTX2Loader must be called before loading KTX2 textures');\n      } else {\n        // Assumes that the extension is optional and that a fallback texture is present\n        return null;\n      }\n    }\n    return parser.loadTextureImage(textureIndex, extension.source, loader);\n  }\n}\n\n/**\n * WebP Texture Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_texture_webp\n */\nclass GLTFTextureWebPExtension {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.EXT_TEXTURE_WEBP;\n    this.isSupported = null;\n  }\n  loadTexture(textureIndex) {\n    const name = this.name;\n    const parser = this.parser;\n    const json = parser.json;\n    const textureDef = json.textures[textureIndex];\n    if (!textureDef.extensions || !textureDef.extensions[name]) {\n      return null;\n    }\n    const extension = textureDef.extensions[name];\n    const source = json.images[extension.source];\n    let loader = parser.textureLoader;\n    if (source.uri) {\n      const handler = parser.options.manager.getHandler(source.uri);\n      if (handler !== null) loader = handler;\n    }\n    return this.detectSupport().then(function (isSupported) {\n      if (isSupported) return parser.loadTextureImage(textureIndex, extension.source, loader);\n      if (json.extensionsRequired && json.extensionsRequired.indexOf(name) >= 0) {\n        throw new Error('THREE.GLTFLoader: WebP required by asset but unsupported.');\n      }\n\n      // Fall back to PNG or JPEG.\n      return parser.loadTexture(textureIndex);\n    });\n  }\n  detectSupport() {\n    if (!this.isSupported) {\n      this.isSupported = new Promise(function (resolve) {\n        const image = new Image();\n\n        // Lossy test image. Support for lossy images doesn't guarantee support for all\n        // WebP images, unfortunately.\n        image.src = 'data:image/webp;base64,UklGRiIAAABXRUJQVlA4IBYAAAAwAQCdASoBAAEADsD+JaQAA3AAAAAA';\n        image.onload = image.onerror = function () {\n          resolve(image.height === 1);\n        };\n      });\n    }\n    return this.isSupported;\n  }\n}\n\n/**\n * AVIF Texture Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_texture_avif\n */\nclass GLTFTextureAVIFExtension {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = EXTENSIONS.EXT_TEXTURE_AVIF;\n    this.isSupported = null;\n  }\n  loadTexture(textureIndex) {\n    const name = this.name;\n    const parser = this.parser;\n    const json = parser.json;\n    const textureDef = json.textures[textureIndex];\n    if (!textureDef.extensions || !textureDef.extensions[name]) {\n      return null;\n    }\n    const extension = textureDef.extensions[name];\n    const source = json.images[extension.source];\n    let loader = parser.textureLoader;\n    if (source.uri) {\n      const handler = parser.options.manager.getHandler(source.uri);\n      if (handler !== null) loader = handler;\n    }\n    return this.detectSupport().then(function (isSupported) {\n      if (isSupported) return parser.loadTextureImage(textureIndex, extension.source, loader);\n      if (json.extensionsRequired && json.extensionsRequired.indexOf(name) >= 0) {\n        throw new Error('THREE.GLTFLoader: AVIF required by asset but unsupported.');\n      }\n\n      // Fall back to PNG or JPEG.\n      return parser.loadTexture(textureIndex);\n    });\n  }\n  detectSupport() {\n    if (!this.isSupported) {\n      this.isSupported = new Promise(function (resolve) {\n        const image = new Image();\n\n        // Lossy test image.\n        image.src = 'data:image/avif;base64,AAAAIGZ0eXBhdmlmAAAAAGF2aWZtaWYxbWlhZk1BMUIAAADybWV0YQAAAAAAAAAoaGRscgAAAAAAAAAAcGljdAAAAAAAAAAAAAAAAGxpYmF2aWYAAAAADnBpdG0AAAAAAAEAAAAeaWxvYwAAAABEAAABAAEAAAABAAABGgAAABcAAAAoaWluZgAAAAAAAQAAABppbmZlAgAAAAABAABhdjAxQ29sb3IAAAAAamlwcnAAAABLaXBjbwAAABRpc3BlAAAAAAAAAAEAAAABAAAAEHBpeGkAAAAAAwgICAAAAAxhdjFDgQAMAAAAABNjb2xybmNseAACAAIABoAAAAAXaXBtYQAAAAAAAAABAAEEAQKDBAAAAB9tZGF0EgAKCBgABogQEDQgMgkQAAAAB8dSLfI=';\n        image.onload = image.onerror = function () {\n          resolve(image.height === 1);\n        };\n      });\n    }\n    return this.isSupported;\n  }\n}\n\n/**\n * meshopt BufferView Compression Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_meshopt_compression\n */\nclass GLTFMeshoptCompression {\n  constructor(parser) {\n    this.name = EXTENSIONS.EXT_MESHOPT_COMPRESSION;\n    this.parser = parser;\n  }\n  loadBufferView(index) {\n    const json = this.parser.json;\n    const bufferView = json.bufferViews[index];\n    if (bufferView.extensions && bufferView.extensions[this.name]) {\n      const extensionDef = bufferView.extensions[this.name];\n      const buffer = this.parser.getDependency('buffer', extensionDef.buffer);\n      const decoder = this.parser.options.meshoptDecoder;\n      if (!decoder || !decoder.supported) {\n        if (json.extensionsRequired && json.extensionsRequired.indexOf(this.name) >= 0) {\n          throw new Error('THREE.GLTFLoader: setMeshoptDecoder must be called before loading compressed files');\n        } else {\n          // Assumes that the extension is optional and that fallback buffer data is present\n          return null;\n        }\n      }\n      return buffer.then(function (res) {\n        const byteOffset = extensionDef.byteOffset || 0;\n        const byteLength = extensionDef.byteLength || 0;\n        const count = extensionDef.count;\n        const stride = extensionDef.byteStride;\n        const source = new Uint8Array(res, byteOffset, byteLength);\n        if (decoder.decodeGltfBufferAsync) {\n          return decoder.decodeGltfBufferAsync(count, stride, source, extensionDef.mode, extensionDef.filter).then(function (res) {\n            return res.buffer;\n          });\n        } else {\n          // Support for MeshoptDecoder 0.18 or earlier, without decodeGltfBufferAsync\n          return decoder.ready.then(function () {\n            const result = new ArrayBuffer(count * stride);\n            decoder.decodeGltfBuffer(new Uint8Array(result), count, stride, source, extensionDef.mode, extensionDef.filter);\n            return result;\n          });\n        }\n      });\n    } else {\n      return null;\n    }\n  }\n}\n\n/**\n * GPU Instancing Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_mesh_gpu_instancing\n *\n */\nclass GLTFMeshGpuInstancing$1 {\n  constructor(parser) {\n    this.name = EXTENSIONS.EXT_MESH_GPU_INSTANCING;\n    this.parser = parser;\n  }\n  createNodeMesh(nodeIndex) {\n    const json = this.parser.json;\n    const nodeDef = json.nodes[nodeIndex];\n    if (!nodeDef.extensions || !nodeDef.extensions[this.name] || nodeDef.mesh === undefined) {\n      return null;\n    }\n    const meshDef = json.meshes[nodeDef.mesh];\n\n    // No Points or Lines + Instancing support yet\n\n    for (const primitive of meshDef.primitives) {\n      if (primitive.mode !== WEBGL_CONSTANTS$1.TRIANGLES && primitive.mode !== WEBGL_CONSTANTS$1.TRIANGLE_STRIP && primitive.mode !== WEBGL_CONSTANTS$1.TRIANGLE_FAN && primitive.mode !== undefined) {\n        return null;\n      }\n    }\n    const extensionDef = nodeDef.extensions[this.name];\n    const attributesDef = extensionDef.attributes;\n\n    // @TODO: Can we support InstancedMesh + SkinnedMesh?\n\n    const pending = [];\n    const attributes = {};\n    for (const key in attributesDef) {\n      pending.push(this.parser.getDependency('accessor', attributesDef[key]).then(accessor => {\n        attributes[key] = accessor;\n        return attributes[key];\n      }));\n    }\n    if (pending.length < 1) {\n      return null;\n    }\n    pending.push(this.parser.createNodeMesh(nodeIndex));\n    return Promise.all(pending).then(results => {\n      const nodeObject = results.pop();\n      const meshes = nodeObject.isGroup ? nodeObject.children : [nodeObject];\n      const count = results[0].count; // All attribute counts should be same\n      const instancedMeshes = [];\n      for (const mesh of meshes) {\n        // Temporal variables\n        const m = new Matrix4();\n        const p = new Vector3();\n        const q = new Quaternion();\n        const s = new Vector3(1, 1, 1);\n        const instancedMesh = new InstancedMesh(mesh.geometry, mesh.material, count);\n        for (let i = 0; i < count; i++) {\n          if (attributes.TRANSLATION) {\n            p.fromBufferAttribute(attributes.TRANSLATION, i);\n          }\n          if (attributes.ROTATION) {\n            q.fromBufferAttribute(attributes.ROTATION, i);\n          }\n          if (attributes.SCALE) {\n            s.fromBufferAttribute(attributes.SCALE, i);\n          }\n          instancedMesh.setMatrixAt(i, m.compose(p, q, s));\n        }\n\n        // Add instance attributes to the geometry, excluding TRS.\n        for (const attributeName in attributes) {\n          if (attributeName === '_COLOR_0') {\n            const attr = attributes[attributeName];\n            instancedMesh.instanceColor = new InstancedBufferAttribute(attr.array, attr.itemSize, attr.normalized);\n          } else if (attributeName !== 'TRANSLATION' && attributeName !== 'ROTATION' && attributeName !== 'SCALE') {\n            mesh.geometry.setAttribute(attributeName, attributes[attributeName]);\n          }\n        }\n\n        // Just in case\n        Object3D.prototype.copy.call(instancedMesh, mesh);\n        this.parser.assignFinalMaterial(instancedMesh);\n        instancedMeshes.push(instancedMesh);\n      }\n      if (nodeObject.isGroup) {\n        nodeObject.clear();\n        nodeObject.add(...instancedMeshes);\n        return nodeObject;\n      }\n      return instancedMeshes[0];\n    });\n  }\n}\n\n/* BINARY EXTENSION */\nconst BINARY_EXTENSION_HEADER_MAGIC = 'glTF';\nconst BINARY_EXTENSION_HEADER_LENGTH = 12;\nconst BINARY_EXTENSION_CHUNK_TYPES = {\n  JSON: 0x4E4F534A,\n  BIN: 0x004E4942\n};\nclass GLTFBinaryExtension {\n  constructor(data) {\n    this.name = EXTENSIONS.KHR_BINARY_GLTF;\n    this.content = null;\n    this.body = null;\n    const headerView = new DataView(data, 0, BINARY_EXTENSION_HEADER_LENGTH);\n    const textDecoder = new TextDecoder();\n    this.header = {\n      magic: textDecoder.decode(new Uint8Array(data.slice(0, 4))),\n      version: headerView.getUint32(4, true),\n      length: headerView.getUint32(8, true)\n    };\n    if (this.header.magic !== BINARY_EXTENSION_HEADER_MAGIC) {\n      throw new Error('THREE.GLTFLoader: Unsupported glTF-Binary header.');\n    } else if (this.header.version < 2.0) {\n      throw new Error('THREE.GLTFLoader: Legacy binary file detected.');\n    }\n    const chunkContentsLength = this.header.length - BINARY_EXTENSION_HEADER_LENGTH;\n    const chunkView = new DataView(data, BINARY_EXTENSION_HEADER_LENGTH);\n    let chunkIndex = 0;\n    while (chunkIndex < chunkContentsLength) {\n      const chunkLength = chunkView.getUint32(chunkIndex, true);\n      chunkIndex += 4;\n      const chunkType = chunkView.getUint32(chunkIndex, true);\n      chunkIndex += 4;\n      if (chunkType === BINARY_EXTENSION_CHUNK_TYPES.JSON) {\n        const contentArray = new Uint8Array(data, BINARY_EXTENSION_HEADER_LENGTH + chunkIndex, chunkLength);\n        this.content = textDecoder.decode(contentArray);\n      } else if (chunkType === BINARY_EXTENSION_CHUNK_TYPES.BIN) {\n        const byteOffset = BINARY_EXTENSION_HEADER_LENGTH + chunkIndex;\n        this.body = data.slice(byteOffset, byteOffset + chunkLength);\n      }\n\n      // Clients must ignore chunks with unknown types.\n\n      chunkIndex += chunkLength;\n    }\n    if (this.content === null) {\n      throw new Error('THREE.GLTFLoader: JSON content not found.');\n    }\n  }\n}\n\n/**\n * DRACO Mesh Compression Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_draco_mesh_compression\n */\nclass GLTFDracoMeshCompressionExtension {\n  constructor(json, dracoLoader) {\n    if (!dracoLoader) {\n      throw new Error('THREE.GLTFLoader: No DRACOLoader instance provided.');\n    }\n    this.name = EXTENSIONS.KHR_DRACO_MESH_COMPRESSION;\n    this.json = json;\n    this.dracoLoader = dracoLoader;\n    this.dracoLoader.preload();\n  }\n  decodePrimitive(primitive, parser) {\n    const json = this.json;\n    const dracoLoader = this.dracoLoader;\n    const bufferViewIndex = primitive.extensions[this.name].bufferView;\n    const gltfAttributeMap = primitive.extensions[this.name].attributes;\n    const threeAttributeMap = {};\n    const attributeNormalizedMap = {};\n    const attributeTypeMap = {};\n    for (const attributeName in gltfAttributeMap) {\n      const threeAttributeName = ATTRIBUTES[attributeName] || attributeName.toLowerCase();\n      threeAttributeMap[threeAttributeName] = gltfAttributeMap[attributeName];\n    }\n    for (const attributeName in primitive.attributes) {\n      const threeAttributeName = ATTRIBUTES[attributeName] || attributeName.toLowerCase();\n      if (gltfAttributeMap[attributeName] !== undefined) {\n        const accessorDef = json.accessors[primitive.attributes[attributeName]];\n        const componentType = WEBGL_COMPONENT_TYPES[accessorDef.componentType];\n        attributeTypeMap[threeAttributeName] = componentType.name;\n        attributeNormalizedMap[threeAttributeName] = accessorDef.normalized === true;\n      }\n    }\n    return parser.getDependency('bufferView', bufferViewIndex).then(function (bufferView) {\n      return new Promise(function (resolve, reject) {\n        dracoLoader.decodeDracoFile(bufferView, function (geometry) {\n          for (const attributeName in geometry.attributes) {\n            const attribute = geometry.attributes[attributeName];\n            const normalized = attributeNormalizedMap[attributeName];\n            if (normalized !== undefined) attribute.normalized = normalized;\n          }\n          resolve(geometry);\n        }, threeAttributeMap, attributeTypeMap, LinearSRGBColorSpace, reject);\n      });\n    });\n  }\n}\n\n/**\n * Texture Transform Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_texture_transform\n */\nclass GLTFTextureTransformExtension {\n  constructor() {\n    this.name = EXTENSIONS.KHR_TEXTURE_TRANSFORM;\n  }\n  extendTexture(texture, transform) {\n    if ((transform.texCoord === undefined || transform.texCoord === texture.channel) && transform.offset === undefined && transform.rotation === undefined && transform.scale === undefined) {\n      // See https://github.com/mrdoob/three.js/issues/21819.\n      return texture;\n    }\n    texture = texture.clone();\n    if (transform.texCoord !== undefined) {\n      texture.channel = transform.texCoord;\n    }\n    if (transform.offset !== undefined) {\n      texture.offset.fromArray(transform.offset);\n    }\n    if (transform.rotation !== undefined) {\n      texture.rotation = transform.rotation;\n    }\n    if (transform.scale !== undefined) {\n      texture.repeat.fromArray(transform.scale);\n    }\n    texture.needsUpdate = true;\n    return texture;\n  }\n}\n\n/**\n * Mesh Quantization Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_mesh_quantization\n */\nclass GLTFMeshQuantizationExtension {\n  constructor() {\n    this.name = EXTENSIONS.KHR_MESH_QUANTIZATION;\n  }\n}\n\n/*********************************/\n/********** INTERPOLATION ********/\n/*********************************/\n\n// Spline Interpolation\n// Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#appendix-c-spline-interpolation\nclass GLTFCubicSplineInterpolant extends Interpolant {\n  constructor(parameterPositions, sampleValues, sampleSize, resultBuffer) {\n    super(parameterPositions, sampleValues, sampleSize, resultBuffer);\n  }\n  copySampleValue_(index) {\n    // Copies a sample value to the result buffer. See description of glTF\n    // CUBICSPLINE values layout in interpolate_() function below.\n\n    const result = this.resultBuffer,\n      values = this.sampleValues,\n      valueSize = this.valueSize,\n      offset = index * valueSize * 3 + valueSize;\n    for (let i = 0; i !== valueSize; i++) {\n      result[i] = values[offset + i];\n    }\n    return result;\n  }\n  interpolate_(i1, t0, t, t1) {\n    const result = this.resultBuffer;\n    const values = this.sampleValues;\n    const stride = this.valueSize;\n    const stride2 = stride * 2;\n    const stride3 = stride * 3;\n    const td = t1 - t0;\n    const p = (t - t0) / td;\n    const pp = p * p;\n    const ppp = pp * p;\n    const offset1 = i1 * stride3;\n    const offset0 = offset1 - stride3;\n    const s2 = -2 * ppp + 3 * pp;\n    const s3 = ppp - pp;\n    const s0 = 1 - s2;\n    const s1 = s3 - pp + p;\n\n    // Layout of keyframe output values for CUBICSPLINE animations:\n    //   [ inTangent_1, splineVertex_1, outTangent_1, inTangent_2, splineVertex_2, ... ]\n    for (let i = 0; i !== stride; i++) {\n      const p0 = values[offset0 + i + stride]; // splineVertex_k\n      const m0 = values[offset0 + i + stride2] * td; // outTangent_k * (t_k+1 - t_k)\n      const p1 = values[offset1 + i + stride]; // splineVertex_k+1\n      const m1 = values[offset1 + i] * td; // inTangent_k+1 * (t_k+1 - t_k)\n\n      result[i] = s0 * p0 + s1 * m0 + s2 * p1 + s3 * m1;\n    }\n    return result;\n  }\n}\nconst _q = new Quaternion();\nclass GLTFCubicSplineQuaternionInterpolant extends GLTFCubicSplineInterpolant {\n  interpolate_(i1, t0, t, t1) {\n    const result = super.interpolate_(i1, t0, t, t1);\n    _q.fromArray(result).normalize().toArray(result);\n    return result;\n  }\n}\n\n/*********************************/\n/********** INTERNALS ************/\n/*********************************/\n\n/* CONSTANTS */\n\nconst WEBGL_CONSTANTS$1 = {\n  FLOAT: 5126,\n  //FLOAT_MAT2: 35674,\n  FLOAT_MAT3: 35675,\n  FLOAT_MAT4: 35676,\n  FLOAT_VEC2: 35664,\n  FLOAT_VEC3: 35665,\n  FLOAT_VEC4: 35666,\n  LINEAR: 9729,\n  REPEAT: 10497,\n  SAMPLER_2D: 35678,\n  POINTS: 0,\n  LINES: 1,\n  LINE_LOOP: 2,\n  LINE_STRIP: 3,\n  TRIANGLES: 4,\n  TRIANGLE_STRIP: 5,\n  TRIANGLE_FAN: 6,\n  UNSIGNED_BYTE: 5121,\n  UNSIGNED_SHORT: 5123\n};\nconst WEBGL_COMPONENT_TYPES = {\n  5120: Int8Array,\n  5121: Uint8Array,\n  5122: Int16Array,\n  5123: Uint16Array,\n  5125: Uint32Array,\n  5126: Float32Array\n};\nconst WEBGL_FILTERS = {\n  9728: NearestFilter,\n  9729: LinearFilter,\n  9984: NearestMipmapNearestFilter,\n  9985: LinearMipmapNearestFilter,\n  9986: NearestMipmapLinearFilter,\n  9987: LinearMipmapLinearFilter\n};\nconst WEBGL_WRAPPINGS = {\n  33071: ClampToEdgeWrapping,\n  33648: MirroredRepeatWrapping,\n  10497: RepeatWrapping\n};\nconst WEBGL_TYPE_SIZES = {\n  'SCALAR': 1,\n  'VEC2': 2,\n  'VEC3': 3,\n  'VEC4': 4,\n  'MAT2': 4,\n  'MAT3': 9,\n  'MAT4': 16\n};\nconst ATTRIBUTES = {\n  POSITION: 'position',\n  NORMAL: 'normal',\n  TANGENT: 'tangent',\n  TEXCOORD_0: 'uv',\n  TEXCOORD_1: 'uv1',\n  TEXCOORD_2: 'uv2',\n  TEXCOORD_3: 'uv3',\n  COLOR_0: 'color',\n  WEIGHTS_0: 'skinWeight',\n  JOINTS_0: 'skinIndex'\n};\nconst PATH_PROPERTIES$1 = {\n  scale: 'scale',\n  translation: 'position',\n  rotation: 'quaternion',\n  weights: 'morphTargetInfluences'\n};\nconst INTERPOLATION = {\n  CUBICSPLINE: undefined,\n  // We use a custom interpolant (GLTFCubicSplineInterpolation) for CUBICSPLINE tracks. Each\n  // keyframe track will be initialized with a default interpolation type, then modified.\n  LINEAR: InterpolateLinear,\n  STEP: InterpolateDiscrete\n};\nconst ALPHA_MODES = {\n  OPAQUE: 'OPAQUE',\n  MASK: 'MASK',\n  BLEND: 'BLEND'\n};\n\n/**\n * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#default-material\n */\nfunction createDefaultMaterial(cache) {\n  if (cache['DefaultMaterial'] === undefined) {\n    cache['DefaultMaterial'] = new MeshStandardMaterial({\n      color: 0xFFFFFF,\n      emissive: 0x000000,\n      metalness: 1,\n      roughness: 1,\n      transparent: false,\n      depthTest: true,\n      side: FrontSide\n    });\n  }\n  return cache['DefaultMaterial'];\n}\nfunction addUnknownExtensionsToUserData(knownExtensions, object, objectDef) {\n  // Add unknown glTF extensions to an object's userData.\n\n  for (const name in objectDef.extensions) {\n    if (knownExtensions[name] === undefined) {\n      object.userData.gltfExtensions = object.userData.gltfExtensions || {};\n      object.userData.gltfExtensions[name] = objectDef.extensions[name];\n    }\n  }\n}\n\n/**\n * @param {Object3D|Material|BufferGeometry} object\n * @param {GLTF.definition} gltfDef\n */\nfunction assignExtrasToUserData(object, gltfDef) {\n  if (gltfDef.extras !== undefined) {\n    if (typeof gltfDef.extras === 'object') {\n      Object.assign(object.userData, gltfDef.extras);\n    } else {\n      console.warn('THREE.GLTFLoader: Ignoring primitive type .extras, ' + gltfDef.extras);\n    }\n  }\n}\n\n/**\n * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#morph-targets\n *\n * @param {BufferGeometry} geometry\n * @param {Array<GLTF.Target>} targets\n * @param {GLTFParser} parser\n * @return {Promise<BufferGeometry>}\n */\nfunction addMorphTargets(geometry, targets, parser) {\n  let hasMorphPosition = false;\n  let hasMorphNormal = false;\n  let hasMorphColor = false;\n  for (let i = 0, il = targets.length; i < il; i++) {\n    const target = targets[i];\n    if (target.POSITION !== undefined) hasMorphPosition = true;\n    if (target.NORMAL !== undefined) hasMorphNormal = true;\n    if (target.COLOR_0 !== undefined) hasMorphColor = true;\n    if (hasMorphPosition && hasMorphNormal && hasMorphColor) break;\n  }\n  if (!hasMorphPosition && !hasMorphNormal && !hasMorphColor) return Promise.resolve(geometry);\n  const pendingPositionAccessors = [];\n  const pendingNormalAccessors = [];\n  const pendingColorAccessors = [];\n  for (let i = 0, il = targets.length; i < il; i++) {\n    const target = targets[i];\n    if (hasMorphPosition) {\n      const pendingAccessor = target.POSITION !== undefined ? parser.getDependency('accessor', target.POSITION) : geometry.attributes.position;\n      pendingPositionAccessors.push(pendingAccessor);\n    }\n    if (hasMorphNormal) {\n      const pendingAccessor = target.NORMAL !== undefined ? parser.getDependency('accessor', target.NORMAL) : geometry.attributes.normal;\n      pendingNormalAccessors.push(pendingAccessor);\n    }\n    if (hasMorphColor) {\n      const pendingAccessor = target.COLOR_0 !== undefined ? parser.getDependency('accessor', target.COLOR_0) : geometry.attributes.color;\n      pendingColorAccessors.push(pendingAccessor);\n    }\n  }\n  return Promise.all([Promise.all(pendingPositionAccessors), Promise.all(pendingNormalAccessors), Promise.all(pendingColorAccessors)]).then(function (accessors) {\n    const morphPositions = accessors[0];\n    const morphNormals = accessors[1];\n    const morphColors = accessors[2];\n    if (hasMorphPosition) geometry.morphAttributes.position = morphPositions;\n    if (hasMorphNormal) geometry.morphAttributes.normal = morphNormals;\n    if (hasMorphColor) geometry.morphAttributes.color = morphColors;\n    geometry.morphTargetsRelative = true;\n    return geometry;\n  });\n}\n\n/**\n * @param {Mesh} mesh\n * @param {GLTF.Mesh} meshDef\n */\nfunction updateMorphTargets(mesh, meshDef) {\n  mesh.updateMorphTargets();\n  if (meshDef.weights !== undefined) {\n    for (let i = 0, il = meshDef.weights.length; i < il; i++) {\n      mesh.morphTargetInfluences[i] = meshDef.weights[i];\n    }\n  }\n\n  // .extras has user-defined data, so check that .extras.targetNames is an array.\n  if (meshDef.extras && Array.isArray(meshDef.extras.targetNames)) {\n    const targetNames = meshDef.extras.targetNames;\n    if (mesh.morphTargetInfluences.length === targetNames.length) {\n      mesh.morphTargetDictionary = {};\n      for (let i = 0, il = targetNames.length; i < il; i++) {\n        mesh.morphTargetDictionary[targetNames[i]] = i;\n      }\n    } else {\n      console.warn('THREE.GLTFLoader: Invalid extras.targetNames length. Ignoring names.');\n    }\n  }\n}\nfunction createPrimitiveKey(primitiveDef) {\n  let geometryKey;\n  const dracoExtension = primitiveDef.extensions && primitiveDef.extensions[EXTENSIONS.KHR_DRACO_MESH_COMPRESSION];\n  if (dracoExtension) {\n    geometryKey = 'draco:' + dracoExtension.bufferView + ':' + dracoExtension.indices + ':' + createAttributesKey(dracoExtension.attributes);\n  } else {\n    geometryKey = primitiveDef.indices + ':' + createAttributesKey(primitiveDef.attributes) + ':' + primitiveDef.mode;\n  }\n  if (primitiveDef.targets !== undefined) {\n    for (let i = 0, il = primitiveDef.targets.length; i < il; i++) {\n      geometryKey += ':' + createAttributesKey(primitiveDef.targets[i]);\n    }\n  }\n  return geometryKey;\n}\nfunction createAttributesKey(attributes) {\n  let attributesKey = '';\n  const keys = Object.keys(attributes).sort();\n  for (let i = 0, il = keys.length; i < il; i++) {\n    attributesKey += keys[i] + ':' + attributes[keys[i]] + ';';\n  }\n  return attributesKey;\n}\nfunction getNormalizedComponentScale(constructor) {\n  // Reference:\n  // https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_mesh_quantization#encoding-quantized-data\n\n  switch (constructor) {\n    case Int8Array:\n      return 1 / 127;\n    case Uint8Array:\n      return 1 / 255;\n    case Int16Array:\n      return 1 / 32767;\n    case Uint16Array:\n      return 1 / 65535;\n    default:\n      throw new Error('THREE.GLTFLoader: Unsupported normalized accessor component type.');\n  }\n}\nfunction getImageURIMimeType(uri) {\n  if (uri.search(/\\.jpe?g($|\\?)/i) > 0 || uri.search(/^data\\:image\\/jpeg/) === 0) return 'image/jpeg';\n  if (uri.search(/\\.webp($|\\?)/i) > 0 || uri.search(/^data\\:image\\/webp/) === 0) return 'image/webp';\n  return 'image/png';\n}\nconst _identityMatrix = new Matrix4();\n\n/* GLTF PARSER */\n\nclass GLTFParser {\n  constructor(json = {}, options = {}) {\n    this.json = json;\n    this.extensions = {};\n    this.plugins = {};\n    this.options = options;\n\n    // loader object cache\n    this.cache = new GLTFRegistry();\n\n    // associations between Three.js objects and glTF elements\n    this.associations = new Map();\n\n    // BufferGeometry caching\n    this.primitiveCache = {};\n\n    // Node cache\n    this.nodeCache = {};\n\n    // Object3D instance caches\n    this.meshCache = {\n      refs: {},\n      uses: {}\n    };\n    this.cameraCache = {\n      refs: {},\n      uses: {}\n    };\n    this.lightCache = {\n      refs: {},\n      uses: {}\n    };\n    this.sourceCache = {};\n    this.textureCache = {};\n\n    // Track node names, to ensure no duplicates\n    this.nodeNamesUsed = {};\n\n    // Use an ImageBitmapLoader if imageBitmaps are supported. Moves much of the\n    // expensive work of uploading a texture to the GPU off the main thread.\n\n    let isSafari = false;\n    let safariVersion = -1;\n    let isFirefox = false;\n    let firefoxVersion = -1;\n    if (typeof navigator !== 'undefined') {\n      const userAgent = navigator.userAgent;\n      isSafari = /^((?!chrome|android).)*safari/i.test(userAgent) === true;\n      const safariMatch = userAgent.match(/Version\\/(\\d+)/);\n      safariVersion = isSafari && safariMatch ? parseInt(safariMatch[1], 10) : -1;\n      isFirefox = userAgent.indexOf('Firefox') > -1;\n      firefoxVersion = isFirefox ? userAgent.match(/Firefox\\/([0-9]+)\\./)[1] : -1;\n    }\n    if (typeof createImageBitmap === 'undefined' || isSafari && safariVersion < 17 || isFirefox && firefoxVersion < 98) {\n      this.textureLoader = new TextureLoader(this.options.manager);\n    } else {\n      this.textureLoader = new ImageBitmapLoader(this.options.manager);\n    }\n    this.textureLoader.setCrossOrigin(this.options.crossOrigin);\n    this.textureLoader.setRequestHeader(this.options.requestHeader);\n    this.fileLoader = new FileLoader(this.options.manager);\n    this.fileLoader.setResponseType('arraybuffer');\n    if (this.options.crossOrigin === 'use-credentials') {\n      this.fileLoader.setWithCredentials(true);\n    }\n  }\n  setExtensions(extensions) {\n    this.extensions = extensions;\n  }\n  setPlugins(plugins) {\n    this.plugins = plugins;\n  }\n  parse(onLoad, onError) {\n    const parser = this;\n    const json = this.json;\n    const extensions = this.extensions;\n\n    // Clear the loader cache\n    this.cache.removeAll();\n    this.nodeCache = {};\n\n    // Mark the special nodes/meshes in json for efficient parse\n    this._invokeAll(function (ext) {\n      return ext._markDefs && ext._markDefs();\n    });\n    Promise.all(this._invokeAll(function (ext) {\n      return ext.beforeRoot && ext.beforeRoot();\n    })).then(function () {\n      return Promise.all([parser.getDependencies('scene'), parser.getDependencies('animation'), parser.getDependencies('camera')]);\n    }).then(function (dependencies) {\n      const result = {\n        scene: dependencies[0][json.scene || 0],\n        scenes: dependencies[0],\n        animations: dependencies[1],\n        cameras: dependencies[2],\n        asset: json.asset,\n        parser: parser,\n        userData: {}\n      };\n      addUnknownExtensionsToUserData(extensions, result, json);\n      assignExtrasToUserData(result, json);\n      return Promise.all(parser._invokeAll(function (ext) {\n        return ext.afterRoot && ext.afterRoot(result);\n      })).then(function () {\n        for (const scene of result.scenes) {\n          scene.updateMatrixWorld();\n        }\n        onLoad(result);\n      });\n    }).catch(onError);\n  }\n\n  /**\n   * Marks the special nodes/meshes in json for efficient parse.\n   */\n  _markDefs() {\n    const nodeDefs = this.json.nodes || [];\n    const skinDefs = this.json.skins || [];\n    const meshDefs = this.json.meshes || [];\n\n    // Nothing in the node definition indicates whether it is a Bone or an\n    // Object3D. Use the skins' joint references to mark bones.\n    for (let skinIndex = 0, skinLength = skinDefs.length; skinIndex < skinLength; skinIndex++) {\n      const joints = skinDefs[skinIndex].joints;\n      for (let i = 0, il = joints.length; i < il; i++) {\n        nodeDefs[joints[i]].isBone = true;\n      }\n    }\n\n    // Iterate over all nodes, marking references to shared resources,\n    // as well as skeleton joints.\n    for (let nodeIndex = 0, nodeLength = nodeDefs.length; nodeIndex < nodeLength; nodeIndex++) {\n      const nodeDef = nodeDefs[nodeIndex];\n      if (nodeDef.mesh !== undefined) {\n        this._addNodeRef(this.meshCache, nodeDef.mesh);\n\n        // Nothing in the mesh definition indicates whether it is\n        // a SkinnedMesh or Mesh. Use the node's mesh reference\n        // to mark SkinnedMesh if node has skin.\n        if (nodeDef.skin !== undefined) {\n          meshDefs[nodeDef.mesh].isSkinnedMesh = true;\n        }\n      }\n      if (nodeDef.camera !== undefined) {\n        this._addNodeRef(this.cameraCache, nodeDef.camera);\n      }\n    }\n  }\n\n  /**\n   * Counts references to shared node / Object3D resources. These resources\n   * can be reused, or \"instantiated\", at multiple nodes in the scene\n   * hierarchy. Mesh, Camera, and Light instances are instantiated and must\n   * be marked. Non-scenegraph resources (like Materials, Geometries, and\n   * Textures) can be reused directly and are not marked here.\n   *\n   * Example: CesiumMilkTruck sample model reuses \"Wheel\" meshes.\n   */\n  _addNodeRef(cache, index) {\n    if (index === undefined) return;\n    if (cache.refs[index] === undefined) {\n      cache.refs[index] = cache.uses[index] = 0;\n    }\n    cache.refs[index]++;\n  }\n\n  /** Returns a reference to a shared resource, cloning it if necessary. */\n  _getNodeRef(cache, index, object) {\n    if (cache.refs[index] <= 1) return object;\n    const ref = object.clone();\n\n    // Propagates mappings to the cloned object, prevents mappings on the\n    // original object from being lost.\n    const updateMappings = (original, clone) => {\n      const mappings = this.associations.get(original);\n      if (mappings != null) {\n        this.associations.set(clone, mappings);\n      }\n      for (const [i, child] of original.children.entries()) {\n        updateMappings(child, clone.children[i]);\n      }\n    };\n    updateMappings(object, ref);\n    ref.name += '_instance_' + cache.uses[index]++;\n    return ref;\n  }\n  _invokeOne(func) {\n    const extensions = Object.values(this.plugins);\n    extensions.push(this);\n    for (let i = 0; i < extensions.length; i++) {\n      const result = func(extensions[i]);\n      if (result) return result;\n    }\n    return null;\n  }\n  _invokeAll(func) {\n    const extensions = Object.values(this.plugins);\n    extensions.unshift(this);\n    const pending = [];\n    for (let i = 0; i < extensions.length; i++) {\n      const result = func(extensions[i]);\n      if (result) pending.push(result);\n    }\n    return pending;\n  }\n\n  /**\n   * Requests the specified dependency asynchronously, with caching.\n   * @param {string} type\n   * @param {number} index\n   * @return {Promise<Object3D|Material|THREE.Texture|AnimationClip|ArrayBuffer|Object>}\n   */\n  getDependency(type, index) {\n    const cacheKey = type + ':' + index;\n    let dependency = this.cache.get(cacheKey);\n    if (!dependency) {\n      switch (type) {\n        case 'scene':\n          dependency = this.loadScene(index);\n          break;\n        case 'node':\n          dependency = this._invokeOne(function (ext) {\n            return ext.loadNode && ext.loadNode(index);\n          });\n          break;\n        case 'mesh':\n          dependency = this._invokeOne(function (ext) {\n            return ext.loadMesh && ext.loadMesh(index);\n          });\n          break;\n        case 'accessor':\n          dependency = this.loadAccessor(index);\n          break;\n        case 'bufferView':\n          dependency = this._invokeOne(function (ext) {\n            return ext.loadBufferView && ext.loadBufferView(index);\n          });\n          break;\n        case 'buffer':\n          dependency = this.loadBuffer(index);\n          break;\n        case 'material':\n          dependency = this._invokeOne(function (ext) {\n            return ext.loadMaterial && ext.loadMaterial(index);\n          });\n          break;\n        case 'texture':\n          dependency = this._invokeOne(function (ext) {\n            return ext.loadTexture && ext.loadTexture(index);\n          });\n          break;\n        case 'skin':\n          dependency = this.loadSkin(index);\n          break;\n        case 'animation':\n          dependency = this._invokeOne(function (ext) {\n            return ext.loadAnimation && ext.loadAnimation(index);\n          });\n          break;\n        case 'camera':\n          dependency = this.loadCamera(index);\n          break;\n        default:\n          dependency = this._invokeOne(function (ext) {\n            return ext != this && ext.getDependency && ext.getDependency(type, index);\n          });\n          if (!dependency) {\n            throw new Error('Unknown type: ' + type);\n          }\n          break;\n      }\n      this.cache.add(cacheKey, dependency);\n    }\n    return dependency;\n  }\n\n  /**\n   * Requests all dependencies of the specified type asynchronously, with caching.\n   * @param {string} type\n   * @return {Promise<Array<Object>>}\n   */\n  getDependencies(type) {\n    let dependencies = this.cache.get(type);\n    if (!dependencies) {\n      const parser = this;\n      const defs = this.json[type + (type === 'mesh' ? 'es' : 's')] || [];\n      dependencies = Promise.all(defs.map(function (def, index) {\n        return parser.getDependency(type, index);\n      }));\n      this.cache.add(type, dependencies);\n    }\n    return dependencies;\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#buffers-and-buffer-views\n   * @param {number} bufferIndex\n   * @return {Promise<ArrayBuffer>}\n   */\n  loadBuffer(bufferIndex) {\n    const bufferDef = this.json.buffers[bufferIndex];\n    const loader = this.fileLoader;\n    if (bufferDef.type && bufferDef.type !== 'arraybuffer') {\n      throw new Error('THREE.GLTFLoader: ' + bufferDef.type + ' buffer type is not supported.');\n    }\n\n    // If present, GLB container is required to be the first buffer.\n    if (bufferDef.uri === undefined && bufferIndex === 0) {\n      return Promise.resolve(this.extensions[EXTENSIONS.KHR_BINARY_GLTF].body);\n    }\n    const options = this.options;\n    return new Promise(function (resolve, reject) {\n      loader.load(LoaderUtils.resolveURL(bufferDef.uri, options.path), resolve, undefined, function () {\n        reject(new Error('THREE.GLTFLoader: Failed to load buffer \"' + bufferDef.uri + '\".'));\n      });\n    });\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#buffers-and-buffer-views\n   * @param {number} bufferViewIndex\n   * @return {Promise<ArrayBuffer>}\n   */\n  loadBufferView(bufferViewIndex) {\n    const bufferViewDef = this.json.bufferViews[bufferViewIndex];\n    return this.getDependency('buffer', bufferViewDef.buffer).then(function (buffer) {\n      const byteLength = bufferViewDef.byteLength || 0;\n      const byteOffset = bufferViewDef.byteOffset || 0;\n      return buffer.slice(byteOffset, byteOffset + byteLength);\n    });\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#accessors\n   * @param {number} accessorIndex\n   * @return {Promise<BufferAttribute|InterleavedBufferAttribute>}\n   */\n  loadAccessor(accessorIndex) {\n    const parser = this;\n    const json = this.json;\n    const accessorDef = this.json.accessors[accessorIndex];\n    if (accessorDef.bufferView === undefined && accessorDef.sparse === undefined) {\n      const itemSize = WEBGL_TYPE_SIZES[accessorDef.type];\n      const TypedArray = WEBGL_COMPONENT_TYPES[accessorDef.componentType];\n      const normalized = accessorDef.normalized === true;\n      const array = new TypedArray(accessorDef.count * itemSize);\n      return Promise.resolve(new BufferAttribute(array, itemSize, normalized));\n    }\n    const pendingBufferViews = [];\n    if (accessorDef.bufferView !== undefined) {\n      pendingBufferViews.push(this.getDependency('bufferView', accessorDef.bufferView));\n    } else {\n      pendingBufferViews.push(null);\n    }\n    if (accessorDef.sparse !== undefined) {\n      pendingBufferViews.push(this.getDependency('bufferView', accessorDef.sparse.indices.bufferView));\n      pendingBufferViews.push(this.getDependency('bufferView', accessorDef.sparse.values.bufferView));\n    }\n    return Promise.all(pendingBufferViews).then(function (bufferViews) {\n      const bufferView = bufferViews[0];\n      const itemSize = WEBGL_TYPE_SIZES[accessorDef.type];\n      const TypedArray = WEBGL_COMPONENT_TYPES[accessorDef.componentType];\n\n      // For VEC3: itemSize is 3, elementBytes is 4, itemBytes is 12.\n      const elementBytes = TypedArray.BYTES_PER_ELEMENT;\n      const itemBytes = elementBytes * itemSize;\n      const byteOffset = accessorDef.byteOffset || 0;\n      const byteStride = accessorDef.bufferView !== undefined ? json.bufferViews[accessorDef.bufferView].byteStride : undefined;\n      const normalized = accessorDef.normalized === true;\n      let array, bufferAttribute;\n\n      // The buffer is not interleaved if the stride is the item size in bytes.\n      if (byteStride && byteStride !== itemBytes) {\n        // Each \"slice\" of the buffer, as defined by 'count' elements of 'byteStride' bytes, gets its own InterleavedBuffer\n        // This makes sure that IBA.count reflects accessor.count properly\n        const ibSlice = Math.floor(byteOffset / byteStride);\n        const ibCacheKey = 'InterleavedBuffer:' + accessorDef.bufferView + ':' + accessorDef.componentType + ':' + ibSlice + ':' + accessorDef.count;\n        let ib = parser.cache.get(ibCacheKey);\n        if (!ib) {\n          array = new TypedArray(bufferView, ibSlice * byteStride, accessorDef.count * byteStride / elementBytes);\n\n          // Integer parameters to IB/IBA are in array elements, not bytes.\n          ib = new InterleavedBuffer(array, byteStride / elementBytes);\n          parser.cache.add(ibCacheKey, ib);\n        }\n        bufferAttribute = new InterleavedBufferAttribute(ib, itemSize, byteOffset % byteStride / elementBytes, normalized);\n      } else {\n        if (bufferView === null) {\n          array = new TypedArray(accessorDef.count * itemSize);\n        } else {\n          array = new TypedArray(bufferView, byteOffset, accessorDef.count * itemSize);\n        }\n        bufferAttribute = new BufferAttribute(array, itemSize, normalized);\n      }\n\n      // https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#sparse-accessors\n      if (accessorDef.sparse !== undefined) {\n        const itemSizeIndices = WEBGL_TYPE_SIZES.SCALAR;\n        const TypedArrayIndices = WEBGL_COMPONENT_TYPES[accessorDef.sparse.indices.componentType];\n        const byteOffsetIndices = accessorDef.sparse.indices.byteOffset || 0;\n        const byteOffsetValues = accessorDef.sparse.values.byteOffset || 0;\n        const sparseIndices = new TypedArrayIndices(bufferViews[1], byteOffsetIndices, accessorDef.sparse.count * itemSizeIndices);\n        const sparseValues = new TypedArray(bufferViews[2], byteOffsetValues, accessorDef.sparse.count * itemSize);\n        if (bufferView !== null) {\n          // Avoid modifying the original ArrayBuffer, if the bufferView wasn't initialized with zeroes.\n          bufferAttribute = new BufferAttribute(bufferAttribute.array.slice(), bufferAttribute.itemSize, bufferAttribute.normalized);\n        }\n\n        // Ignore normalized since we copy from sparse\n        bufferAttribute.normalized = false;\n        for (let i = 0, il = sparseIndices.length; i < il; i++) {\n          const index = sparseIndices[i];\n          bufferAttribute.setX(index, sparseValues[i * itemSize]);\n          if (itemSize >= 2) bufferAttribute.setY(index, sparseValues[i * itemSize + 1]);\n          if (itemSize >= 3) bufferAttribute.setZ(index, sparseValues[i * itemSize + 2]);\n          if (itemSize >= 4) bufferAttribute.setW(index, sparseValues[i * itemSize + 3]);\n          if (itemSize >= 5) throw new Error('THREE.GLTFLoader: Unsupported itemSize in sparse BufferAttribute.');\n        }\n        bufferAttribute.normalized = normalized;\n      }\n      return bufferAttribute;\n    });\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#textures\n   * @param {number} textureIndex\n   * @return {Promise<THREE.Texture|null>}\n   */\n  loadTexture(textureIndex) {\n    const json = this.json;\n    const options = this.options;\n    const textureDef = json.textures[textureIndex];\n    const sourceIndex = textureDef.source;\n    const sourceDef = json.images[sourceIndex];\n    let loader = this.textureLoader;\n    if (sourceDef.uri) {\n      const handler = options.manager.getHandler(sourceDef.uri);\n      if (handler !== null) loader = handler;\n    }\n    return this.loadTextureImage(textureIndex, sourceIndex, loader);\n  }\n  loadTextureImage(textureIndex, sourceIndex, loader) {\n    const parser = this;\n    const json = this.json;\n    const textureDef = json.textures[textureIndex];\n    const sourceDef = json.images[sourceIndex];\n    const cacheKey = (sourceDef.uri || sourceDef.bufferView) + ':' + textureDef.sampler;\n    if (this.textureCache[cacheKey]) {\n      // See https://github.com/mrdoob/three.js/issues/21559.\n      return this.textureCache[cacheKey];\n    }\n    const promise = this.loadImageSource(sourceIndex, loader).then(function (texture) {\n      texture.flipY = false;\n      texture.name = textureDef.name || sourceDef.name || '';\n      if (texture.name === '' && typeof sourceDef.uri === 'string' && sourceDef.uri.startsWith('data:image/') === false) {\n        texture.name = sourceDef.uri;\n      }\n      const samplers = json.samplers || {};\n      const sampler = samplers[textureDef.sampler] || {};\n      texture.magFilter = WEBGL_FILTERS[sampler.magFilter] || LinearFilter;\n      texture.minFilter = WEBGL_FILTERS[sampler.minFilter] || LinearMipmapLinearFilter;\n      texture.wrapS = WEBGL_WRAPPINGS[sampler.wrapS] || RepeatWrapping;\n      texture.wrapT = WEBGL_WRAPPINGS[sampler.wrapT] || RepeatWrapping;\n      parser.associations.set(texture, {\n        textures: textureIndex\n      });\n      return texture;\n    }).catch(function () {\n      return null;\n    });\n    this.textureCache[cacheKey] = promise;\n    return promise;\n  }\n  loadImageSource(sourceIndex, loader) {\n    const parser = this;\n    const json = this.json;\n    const options = this.options;\n    if (this.sourceCache[sourceIndex] !== undefined) {\n      return this.sourceCache[sourceIndex].then(texture => texture.clone());\n    }\n    const sourceDef = json.images[sourceIndex];\n    const URL = self.URL || self.webkitURL;\n    let sourceURI = sourceDef.uri || '';\n    let isObjectURL = false;\n    if (sourceDef.bufferView !== undefined) {\n      // Load binary image data from bufferView, if provided.\n\n      sourceURI = parser.getDependency('bufferView', sourceDef.bufferView).then(function (bufferView) {\n        isObjectURL = true;\n        const blob = new Blob([bufferView], {\n          type: sourceDef.mimeType\n        });\n        sourceURI = URL.createObjectURL(blob);\n        return sourceURI;\n      });\n    } else if (sourceDef.uri === undefined) {\n      throw new Error('THREE.GLTFLoader: Image ' + sourceIndex + ' is missing URI and bufferView');\n    }\n    const promise = Promise.resolve(sourceURI).then(function (sourceURI) {\n      return new Promise(function (resolve, reject) {\n        let onLoad = resolve;\n        if (loader.isImageBitmapLoader === true) {\n          onLoad = function (imageBitmap) {\n            const texture = new Texture$1(imageBitmap);\n            texture.needsUpdate = true;\n            resolve(texture);\n          };\n        }\n        loader.load(LoaderUtils.resolveURL(sourceURI, options.path), onLoad, undefined, reject);\n      });\n    }).then(function (texture) {\n      // Clean up resources and configure Texture.\n\n      if (isObjectURL === true) {\n        URL.revokeObjectURL(sourceURI);\n      }\n      assignExtrasToUserData(texture, sourceDef);\n      texture.userData.mimeType = sourceDef.mimeType || getImageURIMimeType(sourceDef.uri);\n      return texture;\n    }).catch(function (error) {\n      console.error('THREE.GLTFLoader: Couldn\\'t load texture', sourceURI);\n      throw error;\n    });\n    this.sourceCache[sourceIndex] = promise;\n    return promise;\n  }\n\n  /**\n   * Asynchronously assigns a texture to the given material parameters.\n   * @param {Object} materialParams\n   * @param {string} mapName\n   * @param {Object} mapDef\n   * @return {Promise<Texture>}\n   */\n  assignTexture(materialParams, mapName, mapDef, colorSpace) {\n    const parser = this;\n    return this.getDependency('texture', mapDef.index).then(function (texture) {\n      if (!texture) return null;\n      if (mapDef.texCoord !== undefined && mapDef.texCoord > 0) {\n        texture = texture.clone();\n        texture.channel = mapDef.texCoord;\n      }\n      if (parser.extensions[EXTENSIONS.KHR_TEXTURE_TRANSFORM]) {\n        const transform = mapDef.extensions !== undefined ? mapDef.extensions[EXTENSIONS.KHR_TEXTURE_TRANSFORM] : undefined;\n        if (transform) {\n          const gltfReference = parser.associations.get(texture);\n          texture = parser.extensions[EXTENSIONS.KHR_TEXTURE_TRANSFORM].extendTexture(texture, transform);\n          parser.associations.set(texture, gltfReference);\n        }\n      }\n      if (colorSpace !== undefined) {\n        texture.colorSpace = colorSpace;\n      }\n      materialParams[mapName] = texture;\n      return texture;\n    });\n  }\n\n  /**\n   * Assigns final material to a Mesh, Line, or Points instance. The instance\n   * already has a material (generated from the glTF material options alone)\n   * but reuse of the same glTF material may require multiple threejs materials\n   * to accommodate different primitive types, defines, etc. New materials will\n   * be created if necessary, and reused from a cache.\n   * @param  {Object3D} mesh Mesh, Line, or Points instance.\n   */\n  assignFinalMaterial(mesh) {\n    const geometry = mesh.geometry;\n    let material = mesh.material;\n    const useDerivativeTangents = geometry.attributes.tangent === undefined;\n    const useVertexColors = geometry.attributes.color !== undefined;\n    const useFlatShading = geometry.attributes.normal === undefined;\n    if (mesh.isPoints) {\n      const cacheKey = 'PointsMaterial:' + material.uuid;\n      let pointsMaterial = this.cache.get(cacheKey);\n      if (!pointsMaterial) {\n        pointsMaterial = new PointsMaterial();\n        Material$1.prototype.copy.call(pointsMaterial, material);\n        pointsMaterial.color.copy(material.color);\n        pointsMaterial.map = material.map;\n        pointsMaterial.sizeAttenuation = false; // glTF spec says points should be 1px\n\n        this.cache.add(cacheKey, pointsMaterial);\n      }\n      material = pointsMaterial;\n    } else if (mesh.isLine) {\n      const cacheKey = 'LineBasicMaterial:' + material.uuid;\n      let lineMaterial = this.cache.get(cacheKey);\n      if (!lineMaterial) {\n        lineMaterial = new LineBasicMaterial();\n        Material$1.prototype.copy.call(lineMaterial, material);\n        lineMaterial.color.copy(material.color);\n        lineMaterial.map = material.map;\n        this.cache.add(cacheKey, lineMaterial);\n      }\n      material = lineMaterial;\n    }\n\n    // Clone the material if it will be modified\n    if (useDerivativeTangents || useVertexColors || useFlatShading) {\n      let cacheKey = 'ClonedMaterial:' + material.uuid + ':';\n      if (useDerivativeTangents) cacheKey += 'derivative-tangents:';\n      if (useVertexColors) cacheKey += 'vertex-colors:';\n      if (useFlatShading) cacheKey += 'flat-shading:';\n      let cachedMaterial = this.cache.get(cacheKey);\n      if (!cachedMaterial) {\n        cachedMaterial = material.clone();\n        if (useVertexColors) cachedMaterial.vertexColors = true;\n        if (useFlatShading) cachedMaterial.flatShading = true;\n        if (useDerivativeTangents) {\n          // https://github.com/mrdoob/three.js/issues/11438#issuecomment-507003995\n          if (cachedMaterial.normalScale) cachedMaterial.normalScale.y *= -1;\n          if (cachedMaterial.clearcoatNormalScale) cachedMaterial.clearcoatNormalScale.y *= -1;\n        }\n        this.cache.add(cacheKey, cachedMaterial);\n        this.associations.set(cachedMaterial, this.associations.get(material));\n      }\n      material = cachedMaterial;\n    }\n    mesh.material = material;\n  }\n  getMaterialType(/* materialIndex */\n  ) {\n    return MeshStandardMaterial;\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#materials\n   * @param {number} materialIndex\n   * @return {Promise<Material>}\n   */\n  loadMaterial(materialIndex) {\n    const parser = this;\n    const json = this.json;\n    const extensions = this.extensions;\n    const materialDef = json.materials[materialIndex];\n    let materialType;\n    const materialParams = {};\n    const materialExtensions = materialDef.extensions || {};\n    const pending = [];\n    if (materialExtensions[EXTENSIONS.KHR_MATERIALS_UNLIT]) {\n      const kmuExtension = extensions[EXTENSIONS.KHR_MATERIALS_UNLIT];\n      materialType = kmuExtension.getMaterialType();\n      pending.push(kmuExtension.extendParams(materialParams, materialDef, parser));\n    } else {\n      // Specification:\n      // https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#metallic-roughness-material\n\n      const metallicRoughness = materialDef.pbrMetallicRoughness || {};\n      materialParams.color = new Color(1.0, 1.0, 1.0);\n      materialParams.opacity = 1.0;\n      if (Array.isArray(metallicRoughness.baseColorFactor)) {\n        const array = metallicRoughness.baseColorFactor;\n        materialParams.color.setRGB(array[0], array[1], array[2], LinearSRGBColorSpace);\n        materialParams.opacity = array[3];\n      }\n      if (metallicRoughness.baseColorTexture !== undefined) {\n        pending.push(parser.assignTexture(materialParams, 'map', metallicRoughness.baseColorTexture, SRGBColorSpace));\n      }\n      materialParams.metalness = metallicRoughness.metallicFactor !== undefined ? metallicRoughness.metallicFactor : 1.0;\n      materialParams.roughness = metallicRoughness.roughnessFactor !== undefined ? metallicRoughness.roughnessFactor : 1.0;\n      if (metallicRoughness.metallicRoughnessTexture !== undefined) {\n        pending.push(parser.assignTexture(materialParams, 'metalnessMap', metallicRoughness.metallicRoughnessTexture));\n        pending.push(parser.assignTexture(materialParams, 'roughnessMap', metallicRoughness.metallicRoughnessTexture));\n      }\n      materialType = this._invokeOne(function (ext) {\n        return ext.getMaterialType && ext.getMaterialType(materialIndex);\n      });\n      pending.push(Promise.all(this._invokeAll(function (ext) {\n        return ext.extendMaterialParams && ext.extendMaterialParams(materialIndex, materialParams);\n      })));\n    }\n    if (materialDef.doubleSided === true) {\n      materialParams.side = DoubleSide;\n    }\n    const alphaMode = materialDef.alphaMode || ALPHA_MODES.OPAQUE;\n    if (alphaMode === ALPHA_MODES.BLEND) {\n      materialParams.transparent = true;\n\n      // See: https://github.com/mrdoob/three.js/issues/17706\n      materialParams.depthWrite = false;\n    } else {\n      materialParams.transparent = false;\n      if (alphaMode === ALPHA_MODES.MASK) {\n        materialParams.alphaTest = materialDef.alphaCutoff !== undefined ? materialDef.alphaCutoff : 0.5;\n      }\n    }\n    if (materialDef.normalTexture !== undefined && materialType !== MeshBasicMaterial) {\n      pending.push(parser.assignTexture(materialParams, 'normalMap', materialDef.normalTexture));\n      materialParams.normalScale = new Vector2(1, 1);\n      if (materialDef.normalTexture.scale !== undefined) {\n        const scale = materialDef.normalTexture.scale;\n        materialParams.normalScale.set(scale, scale);\n      }\n    }\n    if (materialDef.occlusionTexture !== undefined && materialType !== MeshBasicMaterial) {\n      pending.push(parser.assignTexture(materialParams, 'aoMap', materialDef.occlusionTexture));\n      if (materialDef.occlusionTexture.strength !== undefined) {\n        materialParams.aoMapIntensity = materialDef.occlusionTexture.strength;\n      }\n    }\n    if (materialDef.emissiveFactor !== undefined && materialType !== MeshBasicMaterial) {\n      const emissiveFactor = materialDef.emissiveFactor;\n      materialParams.emissive = new Color().setRGB(emissiveFactor[0], emissiveFactor[1], emissiveFactor[2], LinearSRGBColorSpace);\n    }\n    if (materialDef.emissiveTexture !== undefined && materialType !== MeshBasicMaterial) {\n      pending.push(parser.assignTexture(materialParams, 'emissiveMap', materialDef.emissiveTexture, SRGBColorSpace));\n    }\n    return Promise.all(pending).then(function () {\n      const material = new materialType(materialParams);\n      if (materialDef.name) material.name = materialDef.name;\n      assignExtrasToUserData(material, materialDef);\n      parser.associations.set(material, {\n        materials: materialIndex\n      });\n      if (materialDef.extensions) addUnknownExtensionsToUserData(extensions, material, materialDef);\n      return material;\n    });\n  }\n\n  /** When Object3D instances are targeted by animation, they need unique names. */\n  createUniqueName(originalName) {\n    const sanitizedName = PropertyBinding.sanitizeNodeName(originalName || '');\n    if (sanitizedName in this.nodeNamesUsed) {\n      return sanitizedName + '_' + ++this.nodeNamesUsed[sanitizedName];\n    } else {\n      this.nodeNamesUsed[sanitizedName] = 0;\n      return sanitizedName;\n    }\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#geometry\n   *\n   * Creates BufferGeometries from primitives.\n   *\n   * @param {Array<GLTF.Primitive>} primitives\n   * @return {Promise<Array<BufferGeometry>>}\n   */\n  loadGeometries(primitives) {\n    const parser = this;\n    const extensions = this.extensions;\n    const cache = this.primitiveCache;\n    function createDracoPrimitive(primitive) {\n      return extensions[EXTENSIONS.KHR_DRACO_MESH_COMPRESSION].decodePrimitive(primitive, parser).then(function (geometry) {\n        return addPrimitiveAttributes(geometry, primitive, parser);\n      });\n    }\n    const pending = [];\n    for (let i = 0, il = primitives.length; i < il; i++) {\n      const primitive = primitives[i];\n      const cacheKey = createPrimitiveKey(primitive);\n\n      // See if we've already created this geometry\n      const cached = cache[cacheKey];\n      if (cached) {\n        // Use the cached geometry if it exists\n        pending.push(cached.promise);\n      } else {\n        let geometryPromise;\n        if (primitive.extensions && primitive.extensions[EXTENSIONS.KHR_DRACO_MESH_COMPRESSION]) {\n          // Use DRACO geometry if available\n          geometryPromise = createDracoPrimitive(primitive);\n        } else {\n          // Otherwise create a new geometry\n          geometryPromise = addPrimitiveAttributes(new BufferGeometry(), primitive, parser);\n        }\n\n        // Cache this geometry\n        cache[cacheKey] = {\n          primitive: primitive,\n          promise: geometryPromise\n        };\n        pending.push(geometryPromise);\n      }\n    }\n    return Promise.all(pending);\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#meshes\n   * @param {number} meshIndex\n   * @return {Promise<Group|Mesh|SkinnedMesh>}\n   */\n  loadMesh(meshIndex) {\n    const parser = this;\n    const json = this.json;\n    const extensions = this.extensions;\n    const meshDef = json.meshes[meshIndex];\n    const primitives = meshDef.primitives;\n    const pending = [];\n    for (let i = 0, il = primitives.length; i < il; i++) {\n      const material = primitives[i].material === undefined ? createDefaultMaterial(this.cache) : this.getDependency('material', primitives[i].material);\n      pending.push(material);\n    }\n    pending.push(parser.loadGeometries(primitives));\n    return Promise.all(pending).then(function (results) {\n      const materials = results.slice(0, results.length - 1);\n      const geometries = results[results.length - 1];\n      const meshes = [];\n      for (let i = 0, il = geometries.length; i < il; i++) {\n        const geometry = geometries[i];\n        const primitive = primitives[i];\n\n        // 1. create Mesh\n\n        let mesh;\n        const material = materials[i];\n        if (primitive.mode === WEBGL_CONSTANTS$1.TRIANGLES || primitive.mode === WEBGL_CONSTANTS$1.TRIANGLE_STRIP || primitive.mode === WEBGL_CONSTANTS$1.TRIANGLE_FAN || primitive.mode === undefined) {\n          // .isSkinnedMesh isn't in glTF spec. See ._markDefs()\n          mesh = meshDef.isSkinnedMesh === true ? new SkinnedMesh(geometry, material) : new Mesh(geometry, material);\n          if (mesh.isSkinnedMesh === true) {\n            // normalize skin weights to fix malformed assets (see #15319)\n            mesh.normalizeSkinWeights();\n          }\n          if (primitive.mode === WEBGL_CONSTANTS$1.TRIANGLE_STRIP) {\n            mesh.geometry = toTrianglesDrawMode(mesh.geometry, TriangleStripDrawMode);\n          } else if (primitive.mode === WEBGL_CONSTANTS$1.TRIANGLE_FAN) {\n            mesh.geometry = toTrianglesDrawMode(mesh.geometry, TriangleFanDrawMode);\n          }\n        } else if (primitive.mode === WEBGL_CONSTANTS$1.LINES) {\n          mesh = new LineSegments(geometry, material);\n        } else if (primitive.mode === WEBGL_CONSTANTS$1.LINE_STRIP) {\n          mesh = new Line(geometry, material);\n        } else if (primitive.mode === WEBGL_CONSTANTS$1.LINE_LOOP) {\n          mesh = new LineLoop(geometry, material);\n        } else if (primitive.mode === WEBGL_CONSTANTS$1.POINTS) {\n          mesh = new Points(geometry, material);\n        } else {\n          throw new Error('THREE.GLTFLoader: Primitive mode unsupported: ' + primitive.mode);\n        }\n        if (Object.keys(mesh.geometry.morphAttributes).length > 0) {\n          updateMorphTargets(mesh, meshDef);\n        }\n        mesh.name = parser.createUniqueName(meshDef.name || 'mesh_' + meshIndex);\n        assignExtrasToUserData(mesh, meshDef);\n        if (primitive.extensions) addUnknownExtensionsToUserData(extensions, mesh, primitive);\n        parser.assignFinalMaterial(mesh);\n        meshes.push(mesh);\n      }\n      for (let i = 0, il = meshes.length; i < il; i++) {\n        parser.associations.set(meshes[i], {\n          meshes: meshIndex,\n          primitives: i\n        });\n      }\n      if (meshes.length === 1) {\n        if (meshDef.extensions) addUnknownExtensionsToUserData(extensions, meshes[0], meshDef);\n        return meshes[0];\n      }\n      const group = new Group();\n      if (meshDef.extensions) addUnknownExtensionsToUserData(extensions, group, meshDef);\n      parser.associations.set(group, {\n        meshes: meshIndex\n      });\n      for (let i = 0, il = meshes.length; i < il; i++) {\n        group.add(meshes[i]);\n      }\n      return group;\n    });\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#cameras\n   * @param {number} cameraIndex\n   * @return {Promise<THREE.Camera>}\n   */\n  loadCamera(cameraIndex) {\n    let camera;\n    const cameraDef = this.json.cameras[cameraIndex];\n    const params = cameraDef[cameraDef.type];\n    if (!params) {\n      console.warn('THREE.GLTFLoader: Missing camera parameters.');\n      return;\n    }\n    if (cameraDef.type === 'perspective') {\n      camera = new PerspectiveCamera(MathUtils.radToDeg(params.yfov), params.aspectRatio || 1, params.znear || 1, params.zfar || 2e6);\n    } else if (cameraDef.type === 'orthographic') {\n      camera = new OrthographicCamera(-params.xmag, params.xmag, params.ymag, -params.ymag, params.znear, params.zfar);\n    }\n    if (cameraDef.name) camera.name = this.createUniqueName(cameraDef.name);\n    assignExtrasToUserData(camera, cameraDef);\n    return Promise.resolve(camera);\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#skins\n   * @param {number} skinIndex\n   * @return {Promise<Skeleton>}\n   */\n  loadSkin(skinIndex) {\n    const skinDef = this.json.skins[skinIndex];\n    const pending = [];\n    for (let i = 0, il = skinDef.joints.length; i < il; i++) {\n      pending.push(this._loadNodeShallow(skinDef.joints[i]));\n    }\n    if (skinDef.inverseBindMatrices !== undefined) {\n      pending.push(this.getDependency('accessor', skinDef.inverseBindMatrices));\n    } else {\n      pending.push(null);\n    }\n    return Promise.all(pending).then(function (results) {\n      const inverseBindMatrices = results.pop();\n      const jointNodes = results;\n\n      // Note that bones (joint nodes) may or may not be in the\n      // scene graph at this time.\n\n      const bones = [];\n      const boneInverses = [];\n      for (let i = 0, il = jointNodes.length; i < il; i++) {\n        const jointNode = jointNodes[i];\n        if (jointNode) {\n          bones.push(jointNode);\n          const mat = new Matrix4();\n          if (inverseBindMatrices !== null) {\n            mat.fromArray(inverseBindMatrices.array, i * 16);\n          }\n          boneInverses.push(mat);\n        } else {\n          console.warn('THREE.GLTFLoader: Joint \"%s\" could not be found.', skinDef.joints[i]);\n        }\n      }\n      return new Skeleton(bones, boneInverses);\n    });\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#animations\n   * @param {number} animationIndex\n   * @return {Promise<AnimationClip>}\n   */\n  loadAnimation(animationIndex) {\n    const json = this.json;\n    const parser = this;\n    const animationDef = json.animations[animationIndex];\n    const animationName = animationDef.name ? animationDef.name : 'animation_' + animationIndex;\n    const pendingNodes = [];\n    const pendingInputAccessors = [];\n    const pendingOutputAccessors = [];\n    const pendingSamplers = [];\n    const pendingTargets = [];\n    for (let i = 0, il = animationDef.channels.length; i < il; i++) {\n      const channel = animationDef.channels[i];\n      const sampler = animationDef.samplers[channel.sampler];\n      const target = channel.target;\n      const name = target.node;\n      const input = animationDef.parameters !== undefined ? animationDef.parameters[sampler.input] : sampler.input;\n      const output = animationDef.parameters !== undefined ? animationDef.parameters[sampler.output] : sampler.output;\n      if (target.node === undefined) continue;\n      pendingNodes.push(this.getDependency('node', name));\n      pendingInputAccessors.push(this.getDependency('accessor', input));\n      pendingOutputAccessors.push(this.getDependency('accessor', output));\n      pendingSamplers.push(sampler);\n      pendingTargets.push(target);\n    }\n    return Promise.all([Promise.all(pendingNodes), Promise.all(pendingInputAccessors), Promise.all(pendingOutputAccessors), Promise.all(pendingSamplers), Promise.all(pendingTargets)]).then(function (dependencies) {\n      const nodes = dependencies[0];\n      const inputAccessors = dependencies[1];\n      const outputAccessors = dependencies[2];\n      const samplers = dependencies[3];\n      const targets = dependencies[4];\n      const tracks = [];\n      for (let i = 0, il = nodes.length; i < il; i++) {\n        const node = nodes[i];\n        const inputAccessor = inputAccessors[i];\n        const outputAccessor = outputAccessors[i];\n        const sampler = samplers[i];\n        const target = targets[i];\n        if (node === undefined) continue;\n        if (node.updateMatrix) {\n          node.updateMatrix();\n        }\n        const createdTracks = parser._createAnimationTracks(node, inputAccessor, outputAccessor, sampler, target);\n        if (createdTracks) {\n          for (let k = 0; k < createdTracks.length; k++) {\n            tracks.push(createdTracks[k]);\n          }\n        }\n      }\n      return new AnimationClip(animationName, undefined, tracks);\n    });\n  }\n  createNodeMesh(nodeIndex) {\n    const json = this.json;\n    const parser = this;\n    const nodeDef = json.nodes[nodeIndex];\n    if (nodeDef.mesh === undefined) return null;\n    return parser.getDependency('mesh', nodeDef.mesh).then(function (mesh) {\n      const node = parser._getNodeRef(parser.meshCache, nodeDef.mesh, mesh);\n\n      // if weights are provided on the node, override weights on the mesh.\n      if (nodeDef.weights !== undefined) {\n        node.traverse(function (o) {\n          if (!o.isMesh) return;\n          for (let i = 0, il = nodeDef.weights.length; i < il; i++) {\n            o.morphTargetInfluences[i] = nodeDef.weights[i];\n          }\n        });\n      }\n      return node;\n    });\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#nodes-and-hierarchy\n   * @param {number} nodeIndex\n   * @return {Promise<Object3D>}\n   */\n  loadNode(nodeIndex) {\n    const json = this.json;\n    const parser = this;\n    const nodeDef = json.nodes[nodeIndex];\n    const nodePending = parser._loadNodeShallow(nodeIndex);\n    const childPending = [];\n    const childrenDef = nodeDef.children || [];\n    for (let i = 0, il = childrenDef.length; i < il; i++) {\n      childPending.push(parser.getDependency('node', childrenDef[i]));\n    }\n    const skeletonPending = nodeDef.skin === undefined ? Promise.resolve(null) : parser.getDependency('skin', nodeDef.skin);\n    return Promise.all([nodePending, Promise.all(childPending), skeletonPending]).then(function (results) {\n      const node = results[0];\n      const children = results[1];\n      const skeleton = results[2];\n      if (skeleton !== null) {\n        // This full traverse should be fine because\n        // child glTF nodes have not been added to this node yet.\n        node.traverse(function (mesh) {\n          if (!mesh.isSkinnedMesh) return;\n          mesh.bind(skeleton, _identityMatrix);\n        });\n      }\n      for (let i = 0, il = children.length; i < il; i++) {\n        node.add(children[i]);\n      }\n      return node;\n    });\n  }\n\n  // ._loadNodeShallow() parses a single node.\n  // skin and child nodes are created and added in .loadNode() (no '_' prefix).\n  _loadNodeShallow(nodeIndex) {\n    const json = this.json;\n    const extensions = this.extensions;\n    const parser = this;\n\n    // This method is called from .loadNode() and .loadSkin().\n    // Cache a node to avoid duplication.\n\n    if (this.nodeCache[nodeIndex] !== undefined) {\n      return this.nodeCache[nodeIndex];\n    }\n    const nodeDef = json.nodes[nodeIndex];\n\n    // reserve node's name before its dependencies, so the root has the intended name.\n    const nodeName = nodeDef.name ? parser.createUniqueName(nodeDef.name) : '';\n    const pending = [];\n    const meshPromise = parser._invokeOne(function (ext) {\n      return ext.createNodeMesh && ext.createNodeMesh(nodeIndex);\n    });\n    if (meshPromise) {\n      pending.push(meshPromise);\n    }\n    if (nodeDef.camera !== undefined) {\n      pending.push(parser.getDependency('camera', nodeDef.camera).then(function (camera) {\n        return parser._getNodeRef(parser.cameraCache, nodeDef.camera, camera);\n      }));\n    }\n    parser._invokeAll(function (ext) {\n      return ext.createNodeAttachment && ext.createNodeAttachment(nodeIndex);\n    }).forEach(function (promise) {\n      pending.push(promise);\n    });\n    this.nodeCache[nodeIndex] = Promise.all(pending).then(function (objects) {\n      let node;\n\n      // .isBone isn't in glTF spec. See ._markDefs\n      if (nodeDef.isBone === true) {\n        node = new Bone();\n      } else if (objects.length > 1) {\n        node = new Group();\n      } else if (objects.length === 1) {\n        node = objects[0];\n      } else {\n        node = new Object3D();\n      }\n      if (node !== objects[0]) {\n        for (let i = 0, il = objects.length; i < il; i++) {\n          node.add(objects[i]);\n        }\n      }\n      if (nodeDef.name) {\n        node.userData.name = nodeDef.name;\n        node.name = nodeName;\n      }\n      assignExtrasToUserData(node, nodeDef);\n      if (nodeDef.extensions) addUnknownExtensionsToUserData(extensions, node, nodeDef);\n      if (nodeDef.matrix !== undefined) {\n        const matrix = new Matrix4();\n        matrix.fromArray(nodeDef.matrix);\n        node.applyMatrix4(matrix);\n      } else {\n        if (nodeDef.translation !== undefined) {\n          node.position.fromArray(nodeDef.translation);\n        }\n        if (nodeDef.rotation !== undefined) {\n          node.quaternion.fromArray(nodeDef.rotation);\n        }\n        if (nodeDef.scale !== undefined) {\n          node.scale.fromArray(nodeDef.scale);\n        }\n      }\n      if (!parser.associations.has(node)) {\n        parser.associations.set(node, {});\n      }\n      parser.associations.get(node).nodes = nodeIndex;\n      return node;\n    });\n    return this.nodeCache[nodeIndex];\n  }\n\n  /**\n   * Specification: https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#scenes\n   * @param {number} sceneIndex\n   * @return {Promise<Group>}\n   */\n  loadScene(sceneIndex) {\n    const extensions = this.extensions;\n    const sceneDef = this.json.scenes[sceneIndex];\n    const parser = this;\n\n    // Loader returns Group, not Scene.\n    // See: https://github.com/mrdoob/three.js/issues/18342#issuecomment-578981172\n    const scene = new Group();\n    if (sceneDef.name) scene.name = parser.createUniqueName(sceneDef.name);\n    assignExtrasToUserData(scene, sceneDef);\n    if (sceneDef.extensions) addUnknownExtensionsToUserData(extensions, scene, sceneDef);\n    const nodeIds = sceneDef.nodes || [];\n    const pending = [];\n    for (let i = 0, il = nodeIds.length; i < il; i++) {\n      pending.push(parser.getDependency('node', nodeIds[i]));\n    }\n    return Promise.all(pending).then(function (nodes) {\n      for (let i = 0, il = nodes.length; i < il; i++) {\n        scene.add(nodes[i]);\n      }\n\n      // Removes dangling associations, associations that reference a node that\n      // didn't make it into the scene.\n      const reduceAssociations = node => {\n        const reducedAssociations = new Map();\n        for (const [key, value] of parser.associations) {\n          if (key instanceof Material$1 || key instanceof Texture$1) {\n            reducedAssociations.set(key, value);\n          }\n        }\n        node.traverse(node => {\n          const mappings = parser.associations.get(node);\n          if (mappings != null) {\n            reducedAssociations.set(node, mappings);\n          }\n        });\n        return reducedAssociations;\n      };\n      parser.associations = reduceAssociations(scene);\n      return scene;\n    });\n  }\n  _createAnimationTracks(node, inputAccessor, outputAccessor, sampler, target) {\n    const tracks = [];\n    const targetName = node.name ? node.name : node.uuid;\n    const targetNames = [];\n    if (PATH_PROPERTIES$1[target.path] === PATH_PROPERTIES$1.weights) {\n      node.traverse(function (object) {\n        if (object.morphTargetInfluences) {\n          targetNames.push(object.name ? object.name : object.uuid);\n        }\n      });\n    } else {\n      targetNames.push(targetName);\n    }\n    let TypedKeyframeTrack;\n    switch (PATH_PROPERTIES$1[target.path]) {\n      case PATH_PROPERTIES$1.weights:\n        TypedKeyframeTrack = NumberKeyframeTrack;\n        break;\n      case PATH_PROPERTIES$1.rotation:\n        TypedKeyframeTrack = QuaternionKeyframeTrack;\n        break;\n      case PATH_PROPERTIES$1.position:\n      case PATH_PROPERTIES$1.scale:\n        TypedKeyframeTrack = VectorKeyframeTrack;\n        break;\n      default:\n        switch (outputAccessor.itemSize) {\n          case 1:\n            TypedKeyframeTrack = NumberKeyframeTrack;\n            break;\n          case 2:\n          case 3:\n          default:\n            TypedKeyframeTrack = VectorKeyframeTrack;\n            break;\n        }\n        break;\n    }\n    const interpolation = sampler.interpolation !== undefined ? INTERPOLATION[sampler.interpolation] : InterpolateLinear;\n    const outputArray = this._getArrayFromAccessor(outputAccessor);\n    for (let j = 0, jl = targetNames.length; j < jl; j++) {\n      const track = new TypedKeyframeTrack(targetNames[j] + '.' + PATH_PROPERTIES$1[target.path], inputAccessor.array, outputArray, interpolation);\n\n      // Override interpolation with custom factory method.\n      if (sampler.interpolation === 'CUBICSPLINE') {\n        this._createCubicSplineTrackInterpolant(track);\n      }\n      tracks.push(track);\n    }\n    return tracks;\n  }\n  _getArrayFromAccessor(accessor) {\n    let outputArray = accessor.array;\n    if (accessor.normalized) {\n      const scale = getNormalizedComponentScale(outputArray.constructor);\n      const scaled = new Float32Array(outputArray.length);\n      for (let j = 0, jl = outputArray.length; j < jl; j++) {\n        scaled[j] = outputArray[j] * scale;\n      }\n      outputArray = scaled;\n    }\n    return outputArray;\n  }\n  _createCubicSplineTrackInterpolant(track) {\n    track.createInterpolant = function InterpolantFactoryMethodGLTFCubicSpline(result) {\n      // A CUBICSPLINE keyframe in glTF has three output values for each input value,\n      // representing inTangent, splineVertex, and outTangent. As a result, track.getValueSize()\n      // must be divided by three to get the interpolant's sampleSize argument.\n\n      const interpolantType = this instanceof QuaternionKeyframeTrack ? GLTFCubicSplineQuaternionInterpolant : GLTFCubicSplineInterpolant;\n      return new interpolantType(this.times, this.values, this.getValueSize() / 3, result);\n    };\n\n    // Mark as CUBICSPLINE. `track.getInterpolation()` doesn't support custom interpolants.\n    track.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline = true;\n  }\n}\n\n/**\n * @param {BufferGeometry} geometry\n * @param {GLTF.Primitive} primitiveDef\n * @param {GLTFParser} parser\n */\nfunction computeBounds(geometry, primitiveDef, parser) {\n  const attributes = primitiveDef.attributes;\n  const box = new Box3();\n  if (attributes.POSITION !== undefined) {\n    const accessor = parser.json.accessors[attributes.POSITION];\n    const min = accessor.min;\n    const max = accessor.max;\n\n    // glTF requires 'min' and 'max', but VRM (which extends glTF) currently ignores that requirement.\n\n    if (min !== undefined && max !== undefined) {\n      box.set(new Vector3(min[0], min[1], min[2]), new Vector3(max[0], max[1], max[2]));\n      if (accessor.normalized) {\n        const boxScale = getNormalizedComponentScale(WEBGL_COMPONENT_TYPES[accessor.componentType]);\n        box.min.multiplyScalar(boxScale);\n        box.max.multiplyScalar(boxScale);\n      }\n    } else {\n      console.warn('THREE.GLTFLoader: Missing min/max properties for accessor POSITION.');\n      return;\n    }\n  } else {\n    return;\n  }\n  const targets = primitiveDef.targets;\n  if (targets !== undefined) {\n    const maxDisplacement = new Vector3();\n    const vector = new Vector3();\n    for (let i = 0, il = targets.length; i < il; i++) {\n      const target = targets[i];\n      if (target.POSITION !== undefined) {\n        const accessor = parser.json.accessors[target.POSITION];\n        const min = accessor.min;\n        const max = accessor.max;\n\n        // glTF requires 'min' and 'max', but VRM (which extends glTF) currently ignores that requirement.\n\n        if (min !== undefined && max !== undefined) {\n          // we need to get max of absolute components because target weight is [-1,1]\n          vector.setX(Math.max(Math.abs(min[0]), Math.abs(max[0])));\n          vector.setY(Math.max(Math.abs(min[1]), Math.abs(max[1])));\n          vector.setZ(Math.max(Math.abs(min[2]), Math.abs(max[2])));\n          if (accessor.normalized) {\n            const boxScale = getNormalizedComponentScale(WEBGL_COMPONENT_TYPES[accessor.componentType]);\n            vector.multiplyScalar(boxScale);\n          }\n\n          // Note: this assumes that the sum of all weights is at most 1. This isn't quite correct - it's more conservative\n          // to assume that each target can have a max weight of 1. However, for some use cases - notably, when morph targets\n          // are used to implement key-frame animations and as such only two are active at a time - this results in very large\n          // boxes. So for now we make a box that's sometimes a touch too small but is hopefully mostly of reasonable size.\n          maxDisplacement.max(vector);\n        } else {\n          console.warn('THREE.GLTFLoader: Missing min/max properties for accessor POSITION.');\n        }\n      }\n    }\n\n    // As per comment above this box isn't conservative, but has a reasonable size for a very large number of morph targets.\n    box.expandByVector(maxDisplacement);\n  }\n  geometry.boundingBox = box;\n  const sphere = new Sphere();\n  box.getCenter(sphere.center);\n  sphere.radius = box.min.distanceTo(box.max) / 2;\n  geometry.boundingSphere = sphere;\n}\n\n/**\n * @param {BufferGeometry} geometry\n * @param {GLTF.Primitive} primitiveDef\n * @param {GLTFParser} parser\n * @return {Promise<BufferGeometry>}\n */\nfunction addPrimitiveAttributes(geometry, primitiveDef, parser) {\n  const attributes = primitiveDef.attributes;\n  const pending = [];\n  function assignAttributeAccessor(accessorIndex, attributeName) {\n    return parser.getDependency('accessor', accessorIndex).then(function (accessor) {\n      geometry.setAttribute(attributeName, accessor);\n    });\n  }\n  for (const gltfAttributeName in attributes) {\n    const threeAttributeName = ATTRIBUTES[gltfAttributeName] || gltfAttributeName.toLowerCase();\n\n    // Skip attributes already provided by e.g. Draco extension.\n    if (threeAttributeName in geometry.attributes) continue;\n    pending.push(assignAttributeAccessor(attributes[gltfAttributeName], threeAttributeName));\n  }\n  if (primitiveDef.indices !== undefined && !geometry.index) {\n    const accessor = parser.getDependency('accessor', primitiveDef.indices).then(function (accessor) {\n      geometry.setIndex(accessor);\n    });\n    pending.push(accessor);\n  }\n  if (ColorManagement.workingColorSpace !== LinearSRGBColorSpace && 'COLOR_0' in attributes) {\n    console.warn(`THREE.GLTFLoader: Converting vertex colors from \"srgb-linear\" to \"${ColorManagement.workingColorSpace}\" not supported.`);\n  }\n  assignExtrasToUserData(geometry, primitiveDef);\n  computeBounds(geometry, primitiveDef, parser);\n  return Promise.all(pending).then(function () {\n    return primitiveDef.targets !== undefined ? addMorphTargets(geometry, primitiveDef.targets, parser) : geometry;\n  });\n}\n\n/**\n * @author Deepkolos / https://github.com/deepkolos\n */\n\nclass WorkerPool {\n  constructor(pool = 4) {\n    this.pool = pool;\n    this.queue = [];\n    this.workers = [];\n    this.workersResolve = [];\n    this.workerStatus = 0;\n  }\n  _initWorker(workerId) {\n    if (!this.workers[workerId]) {\n      const worker = this.workerCreator();\n      worker.addEventListener('message', this._onMessage.bind(this, workerId));\n      this.workers[workerId] = worker;\n    }\n  }\n  _getIdleWorker() {\n    for (let i = 0; i < this.pool; i++) if (!(this.workerStatus & 1 << i)) return i;\n    return -1;\n  }\n  _onMessage(workerId, msg) {\n    const resolve = this.workersResolve[workerId];\n    resolve && resolve(msg);\n    if (this.queue.length) {\n      const {\n        resolve,\n        msg,\n        transfer\n      } = this.queue.shift();\n      this.workersResolve[workerId] = resolve;\n      this.workers[workerId].postMessage(msg, transfer);\n    } else {\n      this.workerStatus ^= 1 << workerId;\n    }\n  }\n  setWorkerCreator(workerCreator) {\n    this.workerCreator = workerCreator;\n  }\n  setWorkerLimit(pool) {\n    this.pool = pool;\n  }\n  postMessage(msg, transfer) {\n    return new Promise(resolve => {\n      const workerId = this._getIdleWorker();\n      if (workerId !== -1) {\n        this._initWorker(workerId);\n        this.workerStatus |= 1 << workerId;\n        this.workersResolve[workerId] = resolve;\n        this.workers[workerId].postMessage(msg, transfer);\n      } else {\n        this.queue.push({\n          resolve,\n          msg,\n          transfer\n        });\n      }\n    });\n  }\n  dispose() {\n    this.workers.forEach(worker => worker.terminate());\n    this.workersResolve.length = 0;\n    this.workers.length = 0;\n    this.queue.length = 0;\n    this.workerStatus = 0;\n  }\n}\nconst t = 0,\n  n = 2,\n  g$1 = 1,\n  u = 2,\n  T = 0,\n  C$1 = 1,\n  R = 10,\n  it = 0,\n  ct = 9,\n  yt = 15,\n  xt = 16,\n  wt = 22,\n  Ft = 37,\n  Ct = 43,\n  te$1 = 76,\n  ae = 83,\n  ge = 97,\n  ue = 100,\n  we = 103,\n  Ae = 109,\n  In = 165,\n  Sn = 166,\n  pi = 1000066e3;\nclass Ii {\n  constructor() {\n    this.vkFormat = 0, this.typeSize = 1, this.pixelWidth = 0, this.pixelHeight = 0, this.pixelDepth = 0, this.layerCount = 0, this.faceCount = 1, this.supercompressionScheme = 0, this.levels = [], this.dataFormatDescriptor = [{\n      vendorId: 0,\n      descriptorType: 0,\n      descriptorBlockSize: 0,\n      versionNumber: 2,\n      colorModel: 0,\n      colorPrimaries: 1,\n      transferFunction: 2,\n      flags: 0,\n      texelBlockDimension: [0, 0, 0, 0],\n      bytesPlane: [0, 0, 0, 0, 0, 0, 0, 0],\n      samples: []\n    }], this.keyValue = {}, this.globalData = null;\n  }\n}\nclass Si {\n  constructor(t, e, n, i) {\n    this._dataView = void 0, this._littleEndian = void 0, this._offset = void 0, this._dataView = new DataView(t.buffer, t.byteOffset + e, n), this._littleEndian = i, this._offset = 0;\n  }\n  _nextUint8() {\n    const t = this._dataView.getUint8(this._offset);\n    return this._offset += 1, t;\n  }\n  _nextUint16() {\n    const t = this._dataView.getUint16(this._offset, this._littleEndian);\n    return this._offset += 2, t;\n  }\n  _nextUint32() {\n    const t = this._dataView.getUint32(this._offset, this._littleEndian);\n    return this._offset += 4, t;\n  }\n  _nextUint64() {\n    const t = this._dataView.getUint32(this._offset, this._littleEndian) + 2 ** 32 * this._dataView.getUint32(this._offset + 4, this._littleEndian);\n    return this._offset += 8, t;\n  }\n  _nextInt32() {\n    const t = this._dataView.getInt32(this._offset, this._littleEndian);\n    return this._offset += 4, t;\n  }\n  _nextUint8Array(t) {\n    const e = new Uint8Array(this._dataView.buffer, this._dataView.byteOffset + this._offset, t);\n    return this._offset += t, e;\n  }\n  _skip(t) {\n    return this._offset += t, this;\n  }\n  _scan(t, e) {\n    void 0 === e && (e = 0);\n    const n = this._offset;\n    let i = 0;\n    for (; this._dataView.getUint8(this._offset) !== e && i < t;) i++, this._offset++;\n    return i < t && this._offset++, new Uint8Array(this._dataView.buffer, this._dataView.byteOffset + n, i);\n  }\n}\nconst Oi = [171, 75, 84, 88, 32, 50, 48, 187, 13, 10, 26, 10];\nfunction Ti(t) {\n  return new TextDecoder().decode(t);\n}\nfunction Pi(t) {\n  const e = new Uint8Array(t.buffer, t.byteOffset, Oi.length);\n  if (e[0] !== Oi[0] || e[1] !== Oi[1] || e[2] !== Oi[2] || e[3] !== Oi[3] || e[4] !== Oi[4] || e[5] !== Oi[5] || e[6] !== Oi[6] || e[7] !== Oi[7] || e[8] !== Oi[8] || e[9] !== Oi[9] || e[10] !== Oi[10] || e[11] !== Oi[11]) throw new Error(\"Missing KTX 2.0 identifier.\");\n  const n = new Ii(),\n    i = 17 * Uint32Array.BYTES_PER_ELEMENT,\n    s = new Si(t, Oi.length, i, !0);\n  n.vkFormat = s._nextUint32(), n.typeSize = s._nextUint32(), n.pixelWidth = s._nextUint32(), n.pixelHeight = s._nextUint32(), n.pixelDepth = s._nextUint32(), n.layerCount = s._nextUint32(), n.faceCount = s._nextUint32();\n  const a = s._nextUint32();\n  n.supercompressionScheme = s._nextUint32();\n  const r = s._nextUint32(),\n    o = s._nextUint32(),\n    l = s._nextUint32(),\n    f = s._nextUint32(),\n    h = s._nextUint64(),\n    U = s._nextUint64(),\n    c = new Si(t, Oi.length + i, 3 * a * 8, !0);\n  for (let e = 0; e < a; e++) n.levels.push({\n    levelData: new Uint8Array(t.buffer, t.byteOffset + c._nextUint64(), c._nextUint64()),\n    uncompressedByteLength: c._nextUint64()\n  });\n  const _ = new Si(t, r, o, !0),\n    p = {\n      vendorId: _._skip(4)._nextUint16(),\n      descriptorType: _._nextUint16(),\n      versionNumber: _._nextUint16(),\n      descriptorBlockSize: _._nextUint16(),\n      colorModel: _._nextUint8(),\n      colorPrimaries: _._nextUint8(),\n      transferFunction: _._nextUint8(),\n      flags: _._nextUint8(),\n      texelBlockDimension: [_._nextUint8(), _._nextUint8(), _._nextUint8(), _._nextUint8()],\n      bytesPlane: [_._nextUint8(), _._nextUint8(), _._nextUint8(), _._nextUint8(), _._nextUint8(), _._nextUint8(), _._nextUint8(), _._nextUint8()],\n      samples: []\n    },\n    g = (p.descriptorBlockSize / 4 - 6) / 4;\n  for (let t = 0; t < g; t++) {\n    const e = {\n      bitOffset: _._nextUint16(),\n      bitLength: _._nextUint8(),\n      channelType: _._nextUint8(),\n      samplePosition: [_._nextUint8(), _._nextUint8(), _._nextUint8(), _._nextUint8()],\n      sampleLower: -Infinity,\n      sampleUpper: Infinity\n    };\n    64 & e.channelType ? (e.sampleLower = _._nextInt32(), e.sampleUpper = _._nextInt32()) : (e.sampleLower = _._nextUint32(), e.sampleUpper = _._nextUint32()), p.samples[t] = e;\n  }\n  n.dataFormatDescriptor.length = 0, n.dataFormatDescriptor.push(p);\n  const y = new Si(t, l, f, !0);\n  for (; y._offset < f;) {\n    const t = y._nextUint32(),\n      e = y._scan(t),\n      i = Ti(e);\n    if (n.keyValue[i] = y._nextUint8Array(t - e.byteLength - 1), i.match(/^ktx/i)) {\n      const t = Ti(n.keyValue[i]);\n      n.keyValue[i] = t.substring(0, t.lastIndexOf(\"\\0\"));\n    }\n    y._skip(t % 4 ? 4 - t % 4 : 0);\n  }\n  if (U <= 0) return n;\n  const x = new Si(t, h, U, !0),\n    u = x._nextUint16(),\n    b = x._nextUint16(),\n    d = x._nextUint32(),\n    w = x._nextUint32(),\n    m = x._nextUint32(),\n    D = x._nextUint32(),\n    B = [];\n  for (let t = 0; t < a; t++) B.push({\n    imageFlags: x._nextUint32(),\n    rgbSliceByteOffset: x._nextUint32(),\n    rgbSliceByteLength: x._nextUint32(),\n    alphaSliceByteOffset: x._nextUint32(),\n    alphaSliceByteLength: x._nextUint32()\n  });\n  const L = h + x._offset,\n    v = L + d,\n    A = v + w,\n    k = A + m,\n    V = new Uint8Array(t.buffer, t.byteOffset + L, d),\n    I = new Uint8Array(t.buffer, t.byteOffset + v, w),\n    S = new Uint8Array(t.buffer, t.byteOffset + A, m),\n    F = new Uint8Array(t.buffer, t.byteOffset + k, D);\n  return n.globalData = {\n    endpointCount: u,\n    selectorCount: b,\n    imageDescs: B,\n    endpointsData: V,\n    selectorsData: I,\n    tablesData: S,\n    extendedData: F\n  }, n;\n}\nlet A, I, B;\nconst g = {\n  env: {\n    emscripten_notify_memory_growth: function (A) {\n      B = new Uint8Array(I.exports.memory.buffer);\n    }\n  }\n};\nclass Q {\n  init() {\n    return A || (A = \"undefined\" != typeof fetch ? fetch(\"data:application/wasm;base64,\" + C).then(A => A.arrayBuffer()).then(A => WebAssembly.instantiate(A, g)).then(this._init) : WebAssembly.instantiate(Buffer.from(C, \"base64\"), g).then(this._init), A);\n  }\n  _init(A) {\n    I = A.instance, g.env.emscripten_notify_memory_growth(0);\n  }\n  decode(A, g = 0) {\n    if (!I) throw new Error(\"ZSTDDecoder: Await .init() before decoding.\");\n    const Q = A.byteLength,\n      C = I.exports.malloc(Q);\n    B.set(A, C), g = g || Number(I.exports.ZSTD_findDecompressedSize(C, Q));\n    const E = I.exports.malloc(g),\n      i = I.exports.ZSTD_decompress(E, g, C, Q),\n      D = B.slice(E, E + i);\n    return I.exports.free(C), I.exports.free(E), D;\n  }\n}\nconst C = \"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\";\n\n/**\n * Loader for KTX 2.0 GPU Texture containers.\n *\n * KTX 2.0 is a container format for various GPU texture formats. The loader\n * supports Basis Universal GPU textures, which can be quickly transcoded to\n * a wide variety of GPU texture compression formats, as well as some\n * uncompressed DataTexture and Data3DTexture formats.\n *\n * References:\n * - KTX: http://github.khronos.org/KTX-Specification/\n * - DFD: https://www.khronos.org/registry/DataFormat/specs/1.3/dataformat.1.3.html#basicdescriptor\n * - BasisU HDR: https://github.com/BinomialLLC/basis_universal/wiki/UASTC-HDR-Texture-Specification-v1.0\n */\n\nconst _taskCache = new WeakMap();\nlet _activeLoaders = 0;\nlet _zstd;\nclass KTX2Loader extends Loader {\n  constructor(manager) {\n    super(manager);\n    this.transcoderPath = '';\n    this.transcoderBinary = null;\n    this.transcoderPending = null;\n    this.workerPool = new WorkerPool();\n    this.workerSourceURL = '';\n    this.workerConfig = null;\n    if (typeof MSC_TRANSCODER !== 'undefined') {\n      console.warn('THREE.KTX2Loader: Please update to latest \"basis_transcoder\".' + ' \"msc_basis_transcoder\" is no longer supported in three.js r125+.');\n    }\n  }\n  setTranscoderPath(path) {\n    this.transcoderPath = path;\n    return this;\n  }\n  setWorkerLimit(num) {\n    this.workerPool.setWorkerLimit(num);\n    return this;\n  }\n  async detectSupportAsync(renderer) {\n    this.workerConfig = {\n      astcSupported: await renderer.hasFeatureAsync('texture-compression-astc'),\n      etc1Supported: await renderer.hasFeatureAsync('texture-compression-etc1'),\n      etc2Supported: await renderer.hasFeatureAsync('texture-compression-etc2'),\n      dxtSupported: await renderer.hasFeatureAsync('texture-compression-bc'),\n      bptcSupported: await renderer.hasFeatureAsync('texture-compression-bptc'),\n      pvrtcSupported: await renderer.hasFeatureAsync('texture-compression-pvrtc')\n    };\n    return this;\n  }\n  detectSupport(renderer) {\n    if (renderer.isWebGPURenderer === true) {\n      this.workerConfig = {\n        astcSupported: renderer.hasFeature('texture-compression-astc'),\n        etc1Supported: renderer.hasFeature('texture-compression-etc1'),\n        etc2Supported: renderer.hasFeature('texture-compression-etc2'),\n        dxtSupported: renderer.hasFeature('texture-compression-bc'),\n        bptcSupported: renderer.hasFeature('texture-compression-bptc'),\n        pvrtcSupported: renderer.hasFeature('texture-compression-pvrtc')\n      };\n    } else {\n      this.workerConfig = {\n        astcSupported: renderer.extensions.has('WEBGL_compressed_texture_astc'),\n        etc1Supported: renderer.extensions.has('WEBGL_compressed_texture_etc1'),\n        etc2Supported: renderer.extensions.has('WEBGL_compressed_texture_etc'),\n        dxtSupported: renderer.extensions.has('WEBGL_compressed_texture_s3tc'),\n        bptcSupported: renderer.extensions.has('EXT_texture_compression_bptc'),\n        pvrtcSupported: renderer.extensions.has('WEBGL_compressed_texture_pvrtc') || renderer.extensions.has('WEBKIT_WEBGL_compressed_texture_pvrtc')\n      };\n    }\n    return this;\n  }\n  init() {\n    if (!this.transcoderPending) {\n      // Load transcoder wrapper.\n      const jsLoader = new FileLoader(this.manager);\n      jsLoader.setPath(this.transcoderPath);\n      jsLoader.setWithCredentials(this.withCredentials);\n      const jsContent = jsLoader.loadAsync('basis_transcoder.js');\n\n      // Load transcoder WASM binary.\n      const binaryLoader = new FileLoader(this.manager);\n      binaryLoader.setPath(this.transcoderPath);\n      binaryLoader.setResponseType('arraybuffer');\n      binaryLoader.setWithCredentials(this.withCredentials);\n      const binaryContent = binaryLoader.loadAsync('basis_transcoder.wasm');\n      this.transcoderPending = Promise.all([jsContent, binaryContent]).then(([jsContent, binaryContent]) => {\n        const fn = KTX2Loader.BasisWorker.toString();\n        const body = ['/* constants */', 'let _EngineFormat = ' + JSON.stringify(KTX2Loader.EngineFormat), 'let _TranscoderFormat = ' + JSON.stringify(KTX2Loader.TranscoderFormat), 'let _BasisFormat = ' + JSON.stringify(KTX2Loader.BasisFormat), '/* basis_transcoder.js */', jsContent, '/* worker */', fn.substring(fn.indexOf('{') + 1, fn.lastIndexOf('}'))].join('\\n');\n        this.workerSourceURL = URL.createObjectURL(new Blob([body]));\n        this.transcoderBinary = binaryContent;\n        this.workerPool.setWorkerCreator(() => {\n          const worker = new Worker(this.workerSourceURL);\n          const transcoderBinary = this.transcoderBinary.slice(0);\n          worker.postMessage({\n            type: 'init',\n            config: this.workerConfig,\n            transcoderBinary\n          }, [transcoderBinary]);\n          return worker;\n        });\n      });\n      if (_activeLoaders > 0) {\n        // Each instance loads a transcoder and allocates workers, increasing network and memory cost.\n\n        console.warn('THREE.KTX2Loader: Multiple active KTX2 loaders may cause performance issues.' + ' Use a single KTX2Loader instance, or call .dispose() on old instances.');\n      }\n      _activeLoaders++;\n    }\n    return this.transcoderPending;\n  }\n  load(url, onLoad, onProgress, onError) {\n    if (this.workerConfig === null) {\n      throw new Error('THREE.KTX2Loader: Missing initialization with `.detectSupport( renderer )`.');\n    }\n    const loader = new FileLoader(this.manager);\n    loader.setResponseType('arraybuffer');\n    loader.setWithCredentials(this.withCredentials);\n    loader.load(url, buffer => {\n      this.parse(buffer, onLoad, onError);\n    }, onProgress, onError);\n  }\n  parse(buffer, onLoad, onError) {\n    if (this.workerConfig === null) {\n      throw new Error('THREE.KTX2Loader: Missing initialization with `.detectSupport( renderer )`.');\n    }\n\n    // Check for an existing task using this buffer. A transferred buffer cannot be transferred\n    // again from this thread.\n    if (_taskCache.has(buffer)) {\n      const cachedTask = _taskCache.get(buffer);\n      return cachedTask.promise.then(onLoad).catch(onError);\n    }\n    this._createTexture(buffer).then(texture => onLoad ? onLoad(texture) : null).catch(onError);\n  }\n  _createTextureFrom(transcodeResult, container) {\n    const {\n      faces,\n      width,\n      height,\n      format,\n      type,\n      error,\n      dfdFlags\n    } = transcodeResult;\n    if (type === 'error') return Promise.reject(error);\n    let texture;\n    if (container.faceCount === 6) {\n      texture = new CompressedCubeTexture(faces, format, UnsignedByteType);\n    } else {\n      const mipmaps = faces[0].mipmaps;\n      texture = container.layerCount > 1 ? new CompressedArrayTexture(mipmaps, width, height, container.layerCount, format, UnsignedByteType) : new CompressedTexture(mipmaps, width, height, format, UnsignedByteType);\n    }\n    texture.minFilter = faces[0].mipmaps.length === 1 ? LinearFilter : LinearMipmapLinearFilter;\n    texture.magFilter = LinearFilter;\n    texture.generateMipmaps = false;\n    texture.needsUpdate = true;\n    texture.colorSpace = parseColorSpace(container);\n    texture.premultiplyAlpha = !!(dfdFlags & g$1);\n    return texture;\n  }\n\n  /**\n   * @param {ArrayBuffer} buffer\n   * @param {object?} config\n   * @return {Promise<CompressedTexture|CompressedArrayTexture|DataTexture|Data3DTexture>}\n   */\n  async _createTexture(buffer, config = {}) {\n    const container = Pi(new Uint8Array(buffer));\n    if (container.vkFormat !== it) {\n      return createRawTexture(container);\n    }\n\n    //\n    const taskConfig = config;\n    const texturePending = this.init().then(() => {\n      return this.workerPool.postMessage({\n        type: 'transcode',\n        buffer,\n        taskConfig: taskConfig\n      }, [buffer]);\n    }).then(e => this._createTextureFrom(e.data, container));\n\n    // Cache the task result.\n    _taskCache.set(buffer, {\n      promise: texturePending\n    });\n    return texturePending;\n  }\n  dispose() {\n    this.workerPool.dispose();\n    if (this.workerSourceURL) URL.revokeObjectURL(this.workerSourceURL);\n    _activeLoaders--;\n    return this;\n  }\n}\n\n/* CONSTANTS */\n\nKTX2Loader.BasisFormat = {\n  ETC1S: 0,\n  UASTC_4x4: 1\n};\nKTX2Loader.TranscoderFormat = {\n  ETC1: 0,\n  ETC2: 1,\n  BC1: 2,\n  BC3: 3,\n  BC4: 4,\n  BC5: 5,\n  BC7_M6_OPAQUE_ONLY: 6,\n  BC7_M5: 7,\n  PVRTC1_4_RGB: 8,\n  PVRTC1_4_RGBA: 9,\n  ASTC_4x4: 10,\n  ATC_RGB: 11,\n  ATC_RGBA_INTERPOLATED_ALPHA: 12,\n  RGBA32: 13,\n  RGB565: 14,\n  BGR565: 15,\n  RGBA4444: 16\n};\nKTX2Loader.EngineFormat = {\n  RGBAFormat: RGBAFormat,\n  RGBA_ASTC_4x4_Format: RGBA_ASTC_4x4_Format,\n  RGBA_BPTC_Format: RGBA_BPTC_Format,\n  RGBA_ETC2_EAC_Format: RGBA_ETC2_EAC_Format,\n  RGBA_PVRTC_4BPPV1_Format: RGBA_PVRTC_4BPPV1_Format,\n  RGBA_S3TC_DXT5_Format: RGBA_S3TC_DXT5_Format,\n  RGB_ETC1_Format: RGB_ETC1_Format,\n  RGB_ETC2_Format: RGB_ETC2_Format,\n  RGB_PVRTC_4BPPV1_Format: RGB_PVRTC_4BPPV1_Format,\n  RGBA_S3TC_DXT1_Format: RGBA_S3TC_DXT1_Format\n};\n\n/* WEB WORKER */\n\nKTX2Loader.BasisWorker = function () {\n  let config;\n  let transcoderPending;\n  let BasisModule;\n  const EngineFormat = _EngineFormat; // eslint-disable-line no-undef\n  const TranscoderFormat = _TranscoderFormat; // eslint-disable-line no-undef\n  const BasisFormat = _BasisFormat; // eslint-disable-line no-undef\n\n  self.addEventListener('message', function (e) {\n    const message = e.data;\n    switch (message.type) {\n      case 'init':\n        config = message.config;\n        init(message.transcoderBinary);\n        break;\n      case 'transcode':\n        transcoderPending.then(() => {\n          try {\n            const {\n              faces,\n              buffers,\n              width,\n              height,\n              hasAlpha,\n              format,\n              dfdFlags\n            } = transcode(message.buffer);\n            self.postMessage({\n              type: 'transcode',\n              id: message.id,\n              faces,\n              width,\n              height,\n              hasAlpha,\n              format,\n              dfdFlags\n            }, buffers);\n          } catch (error) {\n            console.error(error);\n            self.postMessage({\n              type: 'error',\n              id: message.id,\n              error: error.message\n            });\n          }\n        });\n        break;\n    }\n  });\n  function init(wasmBinary) {\n    transcoderPending = new Promise(resolve => {\n      BasisModule = {\n        wasmBinary,\n        onRuntimeInitialized: resolve\n      };\n      BASIS(BasisModule); // eslint-disable-line no-undef\n    }).then(() => {\n      BasisModule.initializeBasis();\n      if (BasisModule.KTX2File === undefined) {\n        console.warn('THREE.KTX2Loader: Please update Basis Universal transcoder.');\n      }\n    });\n  }\n  function transcode(buffer) {\n    const ktx2File = new BasisModule.KTX2File(new Uint8Array(buffer));\n    function cleanup() {\n      ktx2File.close();\n      ktx2File.delete();\n    }\n    if (!ktx2File.isValid()) {\n      cleanup();\n      throw new Error('THREE.KTX2Loader:\tInvalid or unsupported .ktx2 file');\n    }\n    const basisFormat = ktx2File.isUASTC() ? BasisFormat.UASTC_4x4 : BasisFormat.ETC1S;\n    const width = ktx2File.getWidth();\n    const height = ktx2File.getHeight();\n    const layerCount = ktx2File.getLayers() || 1;\n    const levelCount = ktx2File.getLevels();\n    const faceCount = ktx2File.getFaces();\n    const hasAlpha = ktx2File.getHasAlpha();\n    const dfdFlags = ktx2File.getDFDFlags();\n    const {\n      transcoderFormat,\n      engineFormat\n    } = getTranscoderFormat(basisFormat, width, height, hasAlpha);\n    if (!width || !height || !levelCount) {\n      cleanup();\n      throw new Error('THREE.KTX2Loader:\tInvalid texture');\n    }\n    if (!ktx2File.startTranscoding()) {\n      cleanup();\n      throw new Error('THREE.KTX2Loader: .startTranscoding failed');\n    }\n    const faces = [];\n    const buffers = [];\n    for (let face = 0; face < faceCount; face++) {\n      const mipmaps = [];\n      for (let mip = 0; mip < levelCount; mip++) {\n        const layerMips = [];\n        let mipWidth, mipHeight;\n        for (let layer = 0; layer < layerCount; layer++) {\n          const levelInfo = ktx2File.getImageLevelInfo(mip, layer, face);\n          if (face === 0 && mip === 0 && layer === 0 && (levelInfo.origWidth % 4 !== 0 || levelInfo.origHeight % 4 !== 0)) {\n            console.warn('THREE.KTX2Loader: ETC1S and UASTC textures should use multiple-of-four dimensions.');\n          }\n          if (levelCount > 1) {\n            mipWidth = levelInfo.origWidth;\n            mipHeight = levelInfo.origHeight;\n          } else {\n            // Handles non-multiple-of-four dimensions in textures without mipmaps. Textures with\n            // mipmaps must use multiple-of-four dimensions, for some texture formats and APIs.\n            // See mrdoob/three.js#25908.\n            mipWidth = levelInfo.width;\n            mipHeight = levelInfo.height;\n          }\n          const dst = new Uint8Array(ktx2File.getImageTranscodedSizeInBytes(mip, layer, 0, transcoderFormat));\n          const status = ktx2File.transcodeImage(dst, mip, layer, face, transcoderFormat, 0, -1, -1);\n          if (!status) {\n            cleanup();\n            throw new Error('THREE.KTX2Loader: .transcodeImage failed.');\n          }\n          layerMips.push(dst);\n        }\n        const mipData = concat(layerMips);\n        mipmaps.push({\n          data: mipData,\n          width: mipWidth,\n          height: mipHeight\n        });\n        buffers.push(mipData.buffer);\n      }\n      faces.push({\n        mipmaps,\n        width,\n        height,\n        format: engineFormat\n      });\n    }\n    cleanup();\n    return {\n      faces,\n      buffers,\n      width,\n      height,\n      hasAlpha,\n      format: engineFormat,\n      dfdFlags\n    };\n  }\n\n  //\n\n  // Optimal choice of a transcoder target format depends on the Basis format (ETC1S or UASTC),\n  // device capabilities, and texture dimensions. The list below ranks the formats separately\n  // for ETC1S and UASTC.\n  //\n  // In some cases, transcoding UASTC to RGBA32 might be preferred for higher quality (at\n  // significant memory cost) compared to ETC1/2, BC1/3, and PVRTC. The transcoder currently\n  // chooses RGBA32 only as a last resort and does not expose that option to the caller.\n  const FORMAT_OPTIONS = [{\n    if: 'astcSupported',\n    basisFormat: [BasisFormat.UASTC_4x4],\n    transcoderFormat: [TranscoderFormat.ASTC_4x4, TranscoderFormat.ASTC_4x4],\n    engineFormat: [EngineFormat.RGBA_ASTC_4x4_Format, EngineFormat.RGBA_ASTC_4x4_Format],\n    priorityETC1S: Infinity,\n    priorityUASTC: 1,\n    needsPowerOfTwo: false\n  }, {\n    if: 'bptcSupported',\n    basisFormat: [BasisFormat.ETC1S, BasisFormat.UASTC_4x4],\n    transcoderFormat: [TranscoderFormat.BC7_M5, TranscoderFormat.BC7_M5],\n    engineFormat: [EngineFormat.RGBA_BPTC_Format, EngineFormat.RGBA_BPTC_Format],\n    priorityETC1S: 3,\n    priorityUASTC: 2,\n    needsPowerOfTwo: false\n  }, {\n    if: 'dxtSupported',\n    basisFormat: [BasisFormat.ETC1S, BasisFormat.UASTC_4x4],\n    transcoderFormat: [TranscoderFormat.BC1, TranscoderFormat.BC3],\n    engineFormat: [EngineFormat.RGBA_S3TC_DXT1_Format, EngineFormat.RGBA_S3TC_DXT5_Format],\n    priorityETC1S: 4,\n    priorityUASTC: 5,\n    needsPowerOfTwo: false\n  }, {\n    if: 'etc2Supported',\n    basisFormat: [BasisFormat.ETC1S, BasisFormat.UASTC_4x4],\n    transcoderFormat: [TranscoderFormat.ETC1, TranscoderFormat.ETC2],\n    engineFormat: [EngineFormat.RGB_ETC2_Format, EngineFormat.RGBA_ETC2_EAC_Format],\n    priorityETC1S: 1,\n    priorityUASTC: 3,\n    needsPowerOfTwo: false\n  }, {\n    if: 'etc1Supported',\n    basisFormat: [BasisFormat.ETC1S, BasisFormat.UASTC_4x4],\n    transcoderFormat: [TranscoderFormat.ETC1],\n    engineFormat: [EngineFormat.RGB_ETC1_Format],\n    priorityETC1S: 2,\n    priorityUASTC: 4,\n    needsPowerOfTwo: false\n  }, {\n    if: 'pvrtcSupported',\n    basisFormat: [BasisFormat.ETC1S, BasisFormat.UASTC_4x4],\n    transcoderFormat: [TranscoderFormat.PVRTC1_4_RGB, TranscoderFormat.PVRTC1_4_RGBA],\n    engineFormat: [EngineFormat.RGB_PVRTC_4BPPV1_Format, EngineFormat.RGBA_PVRTC_4BPPV1_Format],\n    priorityETC1S: 5,\n    priorityUASTC: 6,\n    needsPowerOfTwo: true\n  }];\n  const ETC1S_OPTIONS = FORMAT_OPTIONS.sort(function (a, b) {\n    return a.priorityETC1S - b.priorityETC1S;\n  });\n  const UASTC_OPTIONS = FORMAT_OPTIONS.sort(function (a, b) {\n    return a.priorityUASTC - b.priorityUASTC;\n  });\n  function getTranscoderFormat(basisFormat, width, height, hasAlpha) {\n    let transcoderFormat;\n    let engineFormat;\n    const options = basisFormat === BasisFormat.ETC1S ? ETC1S_OPTIONS : UASTC_OPTIONS;\n    for (let i = 0; i < options.length; i++) {\n      const opt = options[i];\n      if (!config[opt.if]) continue;\n      if (!opt.basisFormat.includes(basisFormat)) continue;\n      if (hasAlpha && opt.transcoderFormat.length < 2) continue;\n      if (opt.needsPowerOfTwo && !(isPowerOfTwo(width) && isPowerOfTwo(height))) continue;\n      transcoderFormat = opt.transcoderFormat[hasAlpha ? 1 : 0];\n      engineFormat = opt.engineFormat[hasAlpha ? 1 : 0];\n      return {\n        transcoderFormat,\n        engineFormat\n      };\n    }\n    console.warn('THREE.KTX2Loader: No suitable compressed texture format found. Decoding to RGBA32.');\n    transcoderFormat = TranscoderFormat.RGBA32;\n    engineFormat = EngineFormat.RGBAFormat;\n    return {\n      transcoderFormat,\n      engineFormat\n    };\n  }\n  function isPowerOfTwo(value) {\n    if (value <= 2) return true;\n    return (value & value - 1) === 0 && value !== 0;\n  }\n\n  /** Concatenates N byte arrays. */\n  function concat(arrays) {\n    if (arrays.length === 1) return arrays[0];\n    let totalByteLength = 0;\n    for (let i = 0; i < arrays.length; i++) {\n      const array = arrays[i];\n      totalByteLength += array.byteLength;\n    }\n    const result = new Uint8Array(totalByteLength);\n    let byteOffset = 0;\n    for (let i = 0; i < arrays.length; i++) {\n      const array = arrays[i];\n      result.set(array, byteOffset);\n      byteOffset += array.byteLength;\n    }\n    return result;\n  }\n};\n\n// Parsing for non-Basis textures. These textures may have supercompression\n// like Zstd, but they do not require transcoding.\n\nconst UNCOMPRESSED_FORMATS = new Set([RGBAFormat, RGFormat, RedFormat]);\nconst FORMAT_MAP = {\n  [Ae]: RGBAFormat,\n  [ge]: RGBAFormat,\n  [Ft]: RGBAFormat,\n  [Ct]: RGBAFormat,\n  [we]: RGFormat,\n  [ae]: RGFormat,\n  [xt]: RGFormat,\n  [wt]: RGFormat,\n  [ue]: RedFormat,\n  [te$1]: RedFormat,\n  [yt]: RedFormat,\n  [ct]: RedFormat,\n  [pi]: RGBA_ASTC_4x4_Format,\n  [Sn]: RGBA_ASTC_6x6_Format,\n  [In]: RGBA_ASTC_6x6_Format\n};\nconst TYPE_MAP = {\n  [Ae]: FloatType,\n  [ge]: HalfFloatType,\n  [Ft]: UnsignedByteType,\n  [Ct]: UnsignedByteType,\n  [we]: FloatType,\n  [ae]: HalfFloatType,\n  [xt]: UnsignedByteType,\n  [wt]: UnsignedByteType,\n  [ue]: FloatType,\n  [te$1]: HalfFloatType,\n  [yt]: UnsignedByteType,\n  [ct]: UnsignedByteType,\n  [pi]: HalfFloatType,\n  [Sn]: UnsignedByteType,\n  [In]: UnsignedByteType\n};\nasync function createRawTexture(container) {\n  const {\n    vkFormat\n  } = container;\n  if (FORMAT_MAP[vkFormat] === undefined) {\n    throw new Error('THREE.KTX2Loader: Unsupported vkFormat.');\n  }\n\n  //\n\n  let zstd;\n  if (container.supercompressionScheme === n) {\n    if (!_zstd) {\n      _zstd = new Promise(async resolve => {\n        const zstd = new Q();\n        await zstd.init();\n        resolve(zstd);\n      });\n    }\n    zstd = await _zstd;\n  }\n\n  //\n\n  const mipmaps = [];\n  for (let levelIndex = 0; levelIndex < container.levels.length; levelIndex++) {\n    const levelWidth = Math.max(1, container.pixelWidth >> levelIndex);\n    const levelHeight = Math.max(1, container.pixelHeight >> levelIndex);\n    const levelDepth = container.pixelDepth ? Math.max(1, container.pixelDepth >> levelIndex) : 0;\n    const level = container.levels[levelIndex];\n    let levelData;\n    if (container.supercompressionScheme === t) {\n      levelData = level.levelData;\n    } else if (container.supercompressionScheme === n) {\n      levelData = zstd.decode(level.levelData, level.uncompressedByteLength);\n    } else {\n      throw new Error('THREE.KTX2Loader: Unsupported supercompressionScheme.');\n    }\n    let data;\n    if (TYPE_MAP[vkFormat] === FloatType) {\n      data = new Float32Array(levelData.buffer, levelData.byteOffset, levelData.byteLength / Float32Array.BYTES_PER_ELEMENT);\n    } else if (TYPE_MAP[vkFormat] === HalfFloatType) {\n      data = new Uint16Array(levelData.buffer, levelData.byteOffset, levelData.byteLength / Uint16Array.BYTES_PER_ELEMENT);\n    } else {\n      data = levelData;\n    }\n    mipmaps.push({\n      data: data,\n      width: levelWidth,\n      height: levelHeight,\n      depth: levelDepth\n    });\n  }\n  let texture;\n  if (UNCOMPRESSED_FORMATS.has(FORMAT_MAP[vkFormat])) {\n    texture = container.pixelDepth === 0 ? new DataTexture(mipmaps[0].data, container.pixelWidth, container.pixelHeight) : new Data3DTexture(mipmaps[0].data, container.pixelWidth, container.pixelHeight, container.pixelDepth);\n  } else {\n    if (container.pixelDepth > 0) throw new Error('THREE.KTX2Loader: Unsupported pixelDepth.');\n    texture = new CompressedTexture(mipmaps, container.pixelWidth, container.pixelHeight);\n  }\n  texture.mipmaps = mipmaps;\n  texture.type = TYPE_MAP[vkFormat];\n  texture.format = FORMAT_MAP[vkFormat];\n  texture.colorSpace = parseColorSpace(container);\n  texture.needsUpdate = true;\n\n  //\n\n  return Promise.resolve(texture);\n}\nfunction parseColorSpace(container) {\n  const dfd = container.dataFormatDescriptor[0];\n  if (dfd.colorPrimaries === C$1) {\n    return dfd.transferFunction === u ? SRGBColorSpace : LinearSRGBColorSpace;\n  } else if (dfd.colorPrimaries === R) {\n    return dfd.transferFunction === u ? DisplayP3ColorSpace : LinearDisplayP3ColorSpace;\n  } else if (dfd.colorPrimaries === T) {\n    return NoColorSpace;\n  } else {\n    console.warn(`THREE.KTX2Loader: Unsupported color primaries, \"${dfd.colorPrimaries}\"`);\n    return NoColorSpace;\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar _a$9, _b$9;\nconst $retainerCount = Symbol('retainerCount');\nconst $recentlyUsed = Symbol('recentlyUsed');\nconst $evict = Symbol('evict');\nconst $evictionThreshold = Symbol('evictionThreshold');\nconst $cache = Symbol('cache');\n/**\n * The CacheEvictionPolicy manages the lifecycle for items in a cache,\n * evicting any items outside some threshold bounds in \"recently used\" order,\n * if they are evictable.\n *\n * Items are considered cached as they are retained. When all retainers\n * of an item release it, that item is considered evictable.\n */\nclass CacheEvictionPolicy {\n  constructor(cache, evictionThreshold = 5) {\n    this[_a$9] = new Map();\n    this[_b$9] = [];\n    this[$cache] = cache;\n    this[$evictionThreshold] = evictionThreshold;\n  }\n  /**\n   * The eviction threshold is the maximum number of items to hold\n   * in cache indefinitely. Items within the threshold (in recently\n   * used order) will continue to be cached even if they have zero\n   * retainers.\n   */\n  set evictionThreshold(value) {\n    this[$evictionThreshold] = value;\n    this[$evict]();\n  }\n  get evictionThreshold() {\n    return this[$evictionThreshold];\n  }\n  /**\n   * A reference to the cache that operates under this policy\n   */\n  get cache() {\n    return this[$cache];\n  }\n  /**\n   * Given an item key, returns the number of retainers of that item\n   */\n  retainerCount(key) {\n    return this[$retainerCount].get(key) || 0;\n  }\n  /**\n   * Resets the internal tracking of cache item retainers. Use only in cases\n   * where it is certain that all retained cache items have been accounted for!\n   */\n  reset() {\n    this[$retainerCount].clear();\n    this[$recentlyUsed] = [];\n  }\n  /**\n   * Mark a given cache item as retained, where the item is represented\n   * by its key. An item can have any number of retainers.\n   */\n  retain(key) {\n    if (!this[$retainerCount].has(key)) {\n      this[$retainerCount].set(key, 0);\n    }\n    this[$retainerCount].set(key, this[$retainerCount].get(key) + 1);\n    const recentlyUsedIndex = this[$recentlyUsed].indexOf(key);\n    if (recentlyUsedIndex !== -1) {\n      this[$recentlyUsed].splice(recentlyUsedIndex, 1);\n    }\n    this[$recentlyUsed].unshift(key);\n    // Evict, in case retaining a new item pushed an evictable item beyond the\n    // eviction threshold\n    this[$evict]();\n  }\n  /**\n   * Mark a given cache item as released by one of its retainers, where the item\n   * is represented by its key. When all retainers of an item have released it,\n   * the item is considered evictable.\n   */\n  release(key) {\n    if (this[$retainerCount].has(key)) {\n      this[$retainerCount].set(key, Math.max(this[$retainerCount].get(key) - 1, 0));\n    }\n    this[$evict]();\n  }\n  [(_a$9 = $retainerCount, _b$9 = $recentlyUsed, $evict)]() {\n    if (this[$recentlyUsed].length < this[$evictionThreshold]) {\n      return;\n    }\n    for (let i = this[$recentlyUsed].length - 1; i >= this[$evictionThreshold]; --i) {\n      const key = this[$recentlyUsed][i];\n      const retainerCount = this[$retainerCount].get(key);\n      if (retainerCount === 0) {\n        this[$cache].delete(key);\n        this[$recentlyUsed].splice(i, 1);\n      }\n    }\n  }\n}\n\n/* @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * KHR_materials_variants specification allows duplicated variant names\n * but it makes handling the extension complex.\n * We ensure tha names and make it easier.\n * If you want to export the extension with the original names\n * you are recommended to write GLTFExporter plugin to restore the names.\n *\n * @param variantNames {Array<string>}\n * @return {Array<string>}\n */\nconst ensureUniqueNames = variantNames => {\n  const uniqueNames = [];\n  const knownNames = new Set();\n  for (const name of variantNames) {\n    let uniqueName = name;\n    let suffix = 0;\n    // @TODO: An easy solution.\n    //        O(N^2) in the worst scenario where N is variantNames.length.\n    //        Fix me if needed.\n    while (knownNames.has(uniqueName)) {\n      uniqueName = name + '.' + ++suffix;\n    }\n    knownNames.add(uniqueName);\n    uniqueNames.push(uniqueName);\n  }\n  return uniqueNames;\n};\n/**\n * Convert mappings array to table object to make handling the extension easier.\n *\n * @param\n *     extensionDef {glTF.meshes[n].primitive.extensions.KHR_materials_variants}\n * @param variantNames {Array<string>} Required to be unique names\n * @return {Map}\n */\nconst mappingsArrayToTable = extensionDef => {\n  const table = new Map();\n  for (const mapping of extensionDef.mappings) {\n    for (const variant of mapping.variants) {\n      table.set(variant, {\n        material: null,\n        gltfMaterialIndex: mapping.material\n      });\n    }\n  }\n  return table;\n};\nclass GLTFMaterialsVariantsExtension {\n  constructor(parser) {\n    this.parser = parser;\n    this.name = 'KHR_materials_variants';\n  }\n  // Note that the following properties will be overridden even if they are\n  // pre-defined\n  // - gltf.userData.variants\n  // - mesh.userData.variantMaterials\n  afterRoot(gltf) {\n    const parser = this.parser;\n    const json = parser.json;\n    if (json.extensions === undefined || json.extensions[this.name] === undefined) {\n      return null;\n    }\n    const extensionDef = json.extensions[this.name];\n    const variantsDef = extensionDef.variants || [];\n    const variants = ensureUniqueNames(variantsDef.map(v => v.name));\n    for (const scene of gltf.scenes) {\n      // Save the variants data under associated mesh.userData\n      scene.traverse(object => {\n        const mesh = object;\n        if (!mesh.material) {\n          return;\n        }\n        const association = parser.associations.get(mesh);\n        if (association == null || association.meshes == null || association.primitives == null) {\n          return;\n        }\n        const meshDef = json.meshes[association.meshes];\n        const primitivesDef = meshDef.primitives;\n        const primitiveDef = primitivesDef[association.primitives];\n        const extensionsDef = primitiveDef.extensions;\n        if (!extensionsDef || !extensionsDef[this.name]) {\n          return;\n        }\n        mesh.userData.variantMaterials = mappingsArrayToTable(extensionsDef[this.name]);\n      });\n    }\n    gltf.userData.variants = variants;\n    return Promise.resolve();\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar _a$8, _b$8;\nTexture$1.DEFAULT_ANISOTROPY = 4;\n/**\n * A helper to Promise-ify a Three.js GLTFLoader\n */\nconst loadWithLoader = (url, loader, progressCallback = () => {}) => {\n  const onProgress = event => {\n    const fraction = event.loaded / event.total;\n    progressCallback(Math.max(0, Math.min(1, isFinite(fraction) ? fraction : 1)));\n  };\n  return new Promise((resolve, reject) => {\n    loader.load(url, resolve, onProgress, reject);\n  });\n};\n/** Helper to load a script tag. */\nconst fetchScript = src => {\n  return new Promise((resolve, reject) => {\n    const script = document.createElement('script');\n    document.body.appendChild(script);\n    script.onload = resolve;\n    script.onerror = reject;\n    script.async = true;\n    script.src = src;\n  });\n};\nconst cache = new Map();\nconst preloaded = new Map();\nlet dracoDecoderLocation;\nconst dracoLoader = new DRACOLoader();\nlet ktx2TranscoderLocation;\nconst ktx2Loader = new KTX2Loader();\nlet meshoptDecoderLocation;\nlet meshoptDecoder;\nconst $loader = Symbol('loader');\nconst $evictionPolicy = Symbol('evictionPolicy');\nconst $GLTFInstance = Symbol('GLTFInstance');\nclass CachingGLTFLoader extends EventDispatcher {\n  constructor(GLTFInstance) {\n    super();\n    this[_b$8] = new GLTFLoader().register(parser => new GLTFMaterialsVariantsExtension(parser));\n    this[$GLTFInstance] = GLTFInstance;\n    this[$loader].setDRACOLoader(dracoLoader);\n    this[$loader].setKTX2Loader(ktx2Loader);\n  }\n  static setDRACODecoderLocation(url) {\n    dracoDecoderLocation = url;\n    dracoLoader.setDecoderPath(url);\n  }\n  static getDRACODecoderLocation() {\n    return dracoDecoderLocation;\n  }\n  static setKTX2TranscoderLocation(url) {\n    ktx2TranscoderLocation = url;\n    ktx2Loader.setTranscoderPath(url);\n  }\n  static getKTX2TranscoderLocation() {\n    return ktx2TranscoderLocation;\n  }\n  static setMeshoptDecoderLocation(url) {\n    if (meshoptDecoderLocation !== url) {\n      meshoptDecoderLocation = url;\n      meshoptDecoder = fetchScript(url).then(() => MeshoptDecoder.ready).then(() => MeshoptDecoder);\n    }\n  }\n  static getMeshoptDecoderLocation() {\n    return meshoptDecoderLocation;\n  }\n  static initializeKTX2Loader(renderer) {\n    ktx2Loader.detectSupport(renderer);\n  }\n  static get cache() {\n    return cache;\n  }\n  /** @nocollapse */\n  static clearCache() {\n    cache.forEach((_value, url) => {\n      this.delete(url);\n    });\n    this[$evictionPolicy].reset();\n  }\n  static has(url) {\n    return cache.has(url);\n  }\n  /** @nocollapse */\n  static async delete(url) {\n    if (!this.has(url)) {\n      return;\n    }\n    const gltfLoads = cache.get(url);\n    preloaded.delete(url);\n    cache.delete(url);\n    const gltf = await gltfLoads;\n    // Dispose of the cached glTF's materials and geometries:\n    gltf.dispose();\n  }\n  /**\n   * Returns true if the model that corresponds to the specified url is\n   * available in our local cache.\n   */\n  static hasFinishedLoading(url) {\n    return !!preloaded.get(url);\n  }\n  get [(_a$8 = $evictionPolicy, _b$8 = $loader, $evictionPolicy)]() {\n    return this.constructor[$evictionPolicy];\n  }\n  /**\n   * Preloads a glTF, populating the cache. Returns a promise that resolves\n   * when the cache is populated.\n   */\n  async preload(url, element, progressCallback = () => {}) {\n    this[$loader].setWithCredentials(element.withCredentials);\n    this.dispatchEvent({\n      type: 'preload',\n      element: element,\n      src: url\n    });\n    if (!cache.has(url)) {\n      if (meshoptDecoder != null) {\n        this[$loader].setMeshoptDecoder(await meshoptDecoder);\n      }\n      const rawGLTFLoads = loadWithLoader(url, this[$loader], progress => {\n        progressCallback(progress * 0.8);\n      });\n      const GLTFInstance = this[$GLTFInstance];\n      const gltfInstanceLoads = rawGLTFLoads.then(rawGLTF => {\n        return GLTFInstance.prepare(rawGLTF);\n      }).then(preparedGLTF => {\n        progressCallback(0.9);\n        return new GLTFInstance(preparedGLTF);\n      }).catch(reason => {\n        console.error(reason);\n        return new GLTFInstance();\n      });\n      cache.set(url, gltfInstanceLoads);\n    }\n    await cache.get(url);\n    preloaded.set(url, true);\n    if (progressCallback) {\n      progressCallback(1.0);\n    }\n  }\n  /**\n   * Loads a glTF from the specified url and resolves a unique clone of the\n   * glTF. If the glTF has already been loaded, makes a clone of the cached\n   * copy.\n   */\n  async load(url, element, progressCallback = () => {}) {\n    await this.preload(url, element, progressCallback);\n    const gltf = await cache.get(url);\n    const clone = await gltf.clone();\n    this[$evictionPolicy].retain(url);\n    // Patch dispose so that we can properly account for instance use\n    // in the caching layer:\n    clone.dispose = () => {\n      this[$evictionPolicy].release(url);\n    };\n    return clone;\n  }\n}\nCachingGLTFLoader[_a$8] = new CacheEvictionPolicy(CachingGLTFLoader);\nclass CSS2DObject extends Object3D {\n  constructor(element = document.createElement('div')) {\n    super();\n    this.isCSS2DObject = true;\n    this.element = element;\n    this.element.style.position = 'absolute';\n    this.element.style.userSelect = 'none';\n    this.element.setAttribute('draggable', false);\n    this.center = new Vector2(0.5, 0.5); // ( 0, 0 ) is the lower left; ( 1, 1 ) is the top right\n\n    this.addEventListener('removed', function () {\n      this.traverse(function (object) {\n        if (object.element instanceof Element && object.element.parentNode !== null) {\n          object.element.parentNode.removeChild(object.element);\n        }\n      });\n    });\n  }\n  copy(source, recursive) {\n    super.copy(source, recursive);\n    this.element = source.element.cloneNode(true);\n    this.center = source.center;\n    return this;\n  }\n}\n\n//\n\nconst _vector = new Vector3();\nconst _viewMatrix = new Matrix4();\nconst _viewProjectionMatrix = new Matrix4();\nconst _a$7 = new Vector3();\nconst _b$7 = new Vector3();\nclass CSS2DRenderer {\n  constructor(parameters = {}) {\n    const _this = this;\n    let _width, _height;\n    let _widthHalf, _heightHalf;\n    const cache = {\n      objects: new WeakMap()\n    };\n    const domElement = parameters.element !== undefined ? parameters.element : document.createElement('div');\n    domElement.style.overflow = 'hidden';\n    this.domElement = domElement;\n    this.getSize = function () {\n      return {\n        width: _width,\n        height: _height\n      };\n    };\n    this.render = function (scene, camera) {\n      if (scene.matrixWorldAutoUpdate === true) scene.updateMatrixWorld();\n      if (camera.parent === null && camera.matrixWorldAutoUpdate === true) camera.updateMatrixWorld();\n      _viewMatrix.copy(camera.matrixWorldInverse);\n      _viewProjectionMatrix.multiplyMatrices(camera.projectionMatrix, _viewMatrix);\n      renderObject(scene, scene, camera);\n      zOrder(scene);\n    };\n    this.setSize = function (width, height) {\n      _width = width;\n      _height = height;\n      _widthHalf = _width / 2;\n      _heightHalf = _height / 2;\n      domElement.style.width = width + 'px';\n      domElement.style.height = height + 'px';\n    };\n    function hideObject(object) {\n      if (object.isCSS2DObject) object.element.style.display = 'none';\n      for (let i = 0, l = object.children.length; i < l; i++) {\n        hideObject(object.children[i]);\n      }\n    }\n    function renderObject(object, scene, camera) {\n      if (object.visible === false) {\n        hideObject(object);\n        return;\n      }\n      if (object.isCSS2DObject) {\n        _vector.setFromMatrixPosition(object.matrixWorld);\n        _vector.applyMatrix4(_viewProjectionMatrix);\n        const visible = _vector.z >= -1 && _vector.z <= 1 && object.layers.test(camera.layers) === true;\n        const element = object.element;\n        element.style.display = visible === true ? '' : 'none';\n        if (visible === true) {\n          object.onBeforeRender(_this, scene, camera);\n          element.style.transform = 'translate(' + -100 * object.center.x + '%,' + -100 * object.center.y + '%)' + 'translate(' + (_vector.x * _widthHalf + _widthHalf) + 'px,' + (-_vector.y * _heightHalf + _heightHalf) + 'px)';\n          if (element.parentNode !== domElement) {\n            domElement.appendChild(element);\n          }\n          object.onAfterRender(_this, scene, camera);\n        }\n        const objectData = {\n          distanceToCameraSquared: getDistanceToSquared(camera, object)\n        };\n        cache.objects.set(object, objectData);\n      }\n      for (let i = 0, l = object.children.length; i < l; i++) {\n        renderObject(object.children[i], scene, camera);\n      }\n    }\n    function getDistanceToSquared(object1, object2) {\n      _a$7.setFromMatrixPosition(object1.matrixWorld);\n      _b$7.setFromMatrixPosition(object2.matrixWorld);\n      return _a$7.distanceToSquared(_b$7);\n    }\n    function filterAndFlatten(scene) {\n      const result = [];\n      scene.traverseVisible(function (object) {\n        if (object.isCSS2DObject) result.push(object);\n      });\n      return result;\n    }\n    function zOrder(scene) {\n      const sorted = filterAndFlatten(scene).sort(function (a, b) {\n        if (a.renderOrder !== b.renderOrder) {\n          return b.renderOrder - a.renderOrder;\n        }\n        const distanceA = cache.objects.get(a).distanceToCameraSquared;\n        const distanceB = cache.objects.get(b).distanceToCameraSquared;\n        return distanceA - distanceB;\n      });\n      const zMax = sorted.length;\n      for (let i = 0, l = sorted.length; i < l; i++) {\n        sorted[i].element.style.zIndex = zMax - i;\n      }\n    }\n  }\n}\nfunction reduceVertices(object, func, initialValue) {\n  let value = initialValue;\n  const vertex = new Vector3();\n  object.updateWorldMatrix(true, true);\n  object.traverseVisible(child => {\n    const {\n      geometry\n    } = child;\n    if (geometry !== undefined) {\n      const {\n        position\n      } = geometry.attributes;\n      if (position !== undefined) {\n        for (let i = 0, l = position.count; i < l; i++) {\n          if (child.isMesh) {\n            child.getVertexPosition(i, vertex);\n          } else {\n            vertex.fromBufferAttribute(position, i);\n          }\n          if (!child.isSkinnedMesh) {\n            vertex.applyMatrix4(child.matrixWorld);\n          }\n          value = func(value, vertex);\n        }\n      }\n    }\n  });\n  return value;\n}\nlet _renderer;\nlet fullscreenQuadGeometry;\nlet fullscreenQuadMaterial;\nlet fullscreenQuad;\nfunction decompress(texture, maxTextureSize = Infinity, renderer = null) {\n  if (!fullscreenQuadGeometry) fullscreenQuadGeometry = new PlaneGeometry(2, 2, 1, 1);\n  if (!fullscreenQuadMaterial) fullscreenQuadMaterial = new ShaderMaterial({\n    uniforms: {\n      blitTexture: new Uniform(texture)\n    },\n    vertexShader: `\n\t\t\tvarying vec2 vUv;\n\t\t\tvoid main(){\n\t\t\t\tvUv = uv;\n\t\t\t\tgl_Position = vec4(position.xy * 1.0,0.,.999999);\n\t\t\t}`,\n    fragmentShader: `\n\t\t\tuniform sampler2D blitTexture; \n\t\t\tvarying vec2 vUv;\n\n\t\t\tvoid main(){ \n\t\t\t\tgl_FragColor = vec4(vUv.xy, 0, 1);\n\t\t\t\t\n\t\t\t\t#ifdef IS_SRGB\n\t\t\t\tgl_FragColor = sRGBTransferOETF( texture2D( blitTexture, vUv) );\n\t\t\t\t#else\n\t\t\t\tgl_FragColor = texture2D( blitTexture, vUv);\n\t\t\t\t#endif\n\t\t\t}`\n  });\n  fullscreenQuadMaterial.uniforms.blitTexture.value = texture;\n  fullscreenQuadMaterial.defines.IS_SRGB = texture.colorSpace == SRGBColorSpace;\n  fullscreenQuadMaterial.needsUpdate = true;\n  if (!fullscreenQuad) {\n    fullscreenQuad = new Mesh(fullscreenQuadGeometry, fullscreenQuadMaterial);\n    fullscreenQuad.frustumCulled = false;\n  }\n  const _camera = new PerspectiveCamera();\n  const _scene = new Scene();\n  _scene.add(fullscreenQuad);\n  if (renderer === null) {\n    renderer = _renderer = new WebGLRenderer({\n      antialias: false\n    });\n  }\n  const width = Math.min(texture.image.width, maxTextureSize);\n  const height = Math.min(texture.image.height, maxTextureSize);\n  renderer.setSize(width, height);\n  renderer.clear();\n  renderer.render(_scene, _camera);\n  const canvas = document.createElement('canvas');\n  const context = canvas.getContext('2d');\n  canvas.width = width;\n  canvas.height = height;\n  context.drawImage(renderer.domElement, 0, 0, width, height);\n  const readableTexture = new CanvasTexture(canvas);\n  readableTexture.minFilter = texture.minFilter;\n  readableTexture.magFilter = texture.magFilter;\n  readableTexture.wrapS = texture.wrapS;\n  readableTexture.wrapT = texture.wrapT;\n  readableTexture.colorSpace = texture.colorSpace;\n  readableTexture.name = texture.name;\n  if (_renderer) {\n    _renderer.forceContextLoss();\n    _renderer.dispose();\n    _renderer = null;\n  }\n  return readableTexture;\n}\n\n/**\n * The KHR_mesh_quantization extension allows these extra attribute component types\n *\n * @see https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_mesh_quantization/README.md#extending-mesh-attributes\n */\nconst KHR_mesh_quantization_ExtraAttrTypes = {\n  POSITION: ['byte', 'byte normalized', 'unsigned byte', 'unsigned byte normalized', 'short', 'short normalized', 'unsigned short', 'unsigned short normalized'],\n  NORMAL: ['byte normalized', 'short normalized'],\n  TANGENT: ['byte normalized', 'short normalized'],\n  TEXCOORD: ['byte', 'byte normalized', 'unsigned byte', 'short', 'short normalized', 'unsigned short']\n};\nclass GLTFExporter {\n  constructor() {\n    this.pluginCallbacks = [];\n    this.register(function (writer) {\n      return new GLTFLightExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsUnlitExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsTransmissionExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsVolumeExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsIorExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsSpecularExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsClearcoatExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsDispersionExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsIridescenceExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsSheenExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsAnisotropyExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsEmissiveStrengthExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMaterialsBumpExtension(writer);\n    });\n    this.register(function (writer) {\n      return new GLTFMeshGpuInstancing(writer);\n    });\n  }\n  register(callback) {\n    if (this.pluginCallbacks.indexOf(callback) === -1) {\n      this.pluginCallbacks.push(callback);\n    }\n    return this;\n  }\n  unregister(callback) {\n    if (this.pluginCallbacks.indexOf(callback) !== -1) {\n      this.pluginCallbacks.splice(this.pluginCallbacks.indexOf(callback), 1);\n    }\n    return this;\n  }\n\n  /**\n   * Parse scenes and generate GLTF output\n   * @param  {Scene or [THREE.Scenes]} input   Scene or Array of THREE.Scenes\n   * @param  {Function} onDone  Callback on completed\n   * @param  {Function} onError  Callback on errors\n   * @param  {Object} options options\n   */\n  parse(input, onDone, onError, options) {\n    const writer = new GLTFWriter();\n    const plugins = [];\n    for (let i = 0, il = this.pluginCallbacks.length; i < il; i++) {\n      plugins.push(this.pluginCallbacks[i](writer));\n    }\n    writer.setPlugins(plugins);\n    writer.write(input, onDone, options).catch(onError);\n  }\n  parseAsync(input, options) {\n    const scope = this;\n    return new Promise(function (resolve, reject) {\n      scope.parse(input, resolve, reject, options);\n    });\n  }\n}\n\n//------------------------------------------------------------------------------\n// Constants\n//------------------------------------------------------------------------------\n\nconst WEBGL_CONSTANTS = {\n  POINTS: 0x0000,\n  LINES: 0x0001,\n  LINE_LOOP: 0x0002,\n  LINE_STRIP: 0x0003,\n  TRIANGLES: 0x0004,\n  TRIANGLE_STRIP: 0x0005,\n  TRIANGLE_FAN: 0x0006,\n  BYTE: 0x1400,\n  UNSIGNED_BYTE: 0x1401,\n  SHORT: 0x1402,\n  UNSIGNED_SHORT: 0x1403,\n  INT: 0x1404,\n  UNSIGNED_INT: 0x1405,\n  FLOAT: 0x1406,\n  ARRAY_BUFFER: 0x8892,\n  ELEMENT_ARRAY_BUFFER: 0x8893,\n  NEAREST: 0x2600,\n  LINEAR: 0x2601,\n  NEAREST_MIPMAP_NEAREST: 0x2700,\n  LINEAR_MIPMAP_NEAREST: 0x2701,\n  NEAREST_MIPMAP_LINEAR: 0x2702,\n  LINEAR_MIPMAP_LINEAR: 0x2703,\n  CLAMP_TO_EDGE: 33071,\n  MIRRORED_REPEAT: 33648,\n  REPEAT: 10497\n};\nconst KHR_MESH_QUANTIZATION = 'KHR_mesh_quantization';\nconst THREE_TO_WEBGL = {};\nTHREE_TO_WEBGL[NearestFilter] = WEBGL_CONSTANTS.NEAREST;\nTHREE_TO_WEBGL[NearestMipmapNearestFilter] = WEBGL_CONSTANTS.NEAREST_MIPMAP_NEAREST;\nTHREE_TO_WEBGL[NearestMipmapLinearFilter] = WEBGL_CONSTANTS.NEAREST_MIPMAP_LINEAR;\nTHREE_TO_WEBGL[LinearFilter] = WEBGL_CONSTANTS.LINEAR;\nTHREE_TO_WEBGL[LinearMipmapNearestFilter] = WEBGL_CONSTANTS.LINEAR_MIPMAP_NEAREST;\nTHREE_TO_WEBGL[LinearMipmapLinearFilter] = WEBGL_CONSTANTS.LINEAR_MIPMAP_LINEAR;\nTHREE_TO_WEBGL[ClampToEdgeWrapping] = WEBGL_CONSTANTS.CLAMP_TO_EDGE;\nTHREE_TO_WEBGL[RepeatWrapping] = WEBGL_CONSTANTS.REPEAT;\nTHREE_TO_WEBGL[MirroredRepeatWrapping] = WEBGL_CONSTANTS.MIRRORED_REPEAT;\nconst PATH_PROPERTIES = {\n  scale: 'scale',\n  position: 'translation',\n  quaternion: 'rotation',\n  morphTargetInfluences: 'weights'\n};\nconst DEFAULT_SPECULAR_COLOR = new Color();\n\n// GLB constants\n// https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#glb-file-format-specification\n\nconst GLB_HEADER_BYTES = 12;\nconst GLB_HEADER_MAGIC = 0x46546C67;\nconst GLB_VERSION = 2;\nconst GLB_CHUNK_PREFIX_BYTES = 8;\nconst GLB_CHUNK_TYPE_JSON = 0x4E4F534A;\nconst GLB_CHUNK_TYPE_BIN = 0x004E4942;\n\n//------------------------------------------------------------------------------\n// Utility functions\n//------------------------------------------------------------------------------\n\n/**\n * Compare two arrays\n * @param  {Array} array1 Array 1 to compare\n * @param  {Array} array2 Array 2 to compare\n * @return {Boolean}        Returns true if both arrays are equal\n */\nfunction equalArray(array1, array2) {\n  return array1.length === array2.length && array1.every(function (element, index) {\n    return element === array2[index];\n  });\n}\n\n/**\n * Converts a string to an ArrayBuffer.\n * @param  {string} text\n * @return {ArrayBuffer}\n */\nfunction stringToArrayBuffer(text) {\n  return new TextEncoder().encode(text).buffer;\n}\n\n/**\n * Is identity matrix\n *\n * @param {Matrix4} matrix\n * @returns {Boolean} Returns true, if parameter is identity matrix\n */\nfunction isIdentityMatrix(matrix) {\n  return equalArray(matrix.elements, [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]);\n}\n\n/**\n * Get the min and max vectors from the given attribute\n * @param  {BufferAttribute} attribute Attribute to find the min/max in range from start to start + count\n * @param  {Integer} start\n * @param  {Integer} count\n * @return {Object} Object containing the `min` and `max` values (As an array of attribute.itemSize components)\n */\nfunction getMinMax(attribute, start, count) {\n  const output = {\n    min: new Array(attribute.itemSize).fill(Number.POSITIVE_INFINITY),\n    max: new Array(attribute.itemSize).fill(Number.NEGATIVE_INFINITY)\n  };\n  for (let i = start; i < start + count; i++) {\n    for (let a = 0; a < attribute.itemSize; a++) {\n      let value;\n      if (attribute.itemSize > 4) {\n        // no support for interleaved data for itemSize > 4\n\n        value = attribute.array[i * attribute.itemSize + a];\n      } else {\n        if (a === 0) value = attribute.getX(i);else if (a === 1) value = attribute.getY(i);else if (a === 2) value = attribute.getZ(i);else if (a === 3) value = attribute.getW(i);\n        if (attribute.normalized === true) {\n          value = MathUtils.normalize(value, attribute.array);\n        }\n      }\n      output.min[a] = Math.min(output.min[a], value);\n      output.max[a] = Math.max(output.max[a], value);\n    }\n  }\n  return output;\n}\n\n/**\n * Get the required size + padding for a buffer, rounded to the next 4-byte boundary.\n * https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#data-alignment\n *\n * @param {Integer} bufferSize The size the original buffer.\n * @returns {Integer} new buffer size with required padding.\n *\n */\nfunction getPaddedBufferSize(bufferSize) {\n  return Math.ceil(bufferSize / 4) * 4;\n}\n\n/**\n * Returns a buffer aligned to 4-byte boundary.\n *\n * @param {ArrayBuffer} arrayBuffer Buffer to pad\n * @param {Integer} paddingByte (Optional)\n * @returns {ArrayBuffer} The same buffer if it's already aligned to 4-byte boundary or a new buffer\n */\nfunction getPaddedArrayBuffer(arrayBuffer, paddingByte = 0) {\n  const paddedLength = getPaddedBufferSize(arrayBuffer.byteLength);\n  if (paddedLength !== arrayBuffer.byteLength) {\n    const array = new Uint8Array(paddedLength);\n    array.set(new Uint8Array(arrayBuffer));\n    if (paddingByte !== 0) {\n      for (let i = arrayBuffer.byteLength; i < paddedLength; i++) {\n        array[i] = paddingByte;\n      }\n    }\n    return array.buffer;\n  }\n  return arrayBuffer;\n}\nfunction getCanvas() {\n  if (typeof document === 'undefined' && typeof OffscreenCanvas !== 'undefined') {\n    return new OffscreenCanvas(1, 1);\n  }\n  return document.createElement('canvas');\n}\nfunction getToBlobPromise(canvas, mimeType) {\n  if (canvas.toBlob !== undefined) {\n    return new Promise(resolve => canvas.toBlob(resolve, mimeType));\n  }\n  let quality;\n\n  // Blink's implementation of convertToBlob seems to default to a quality level of 100%\n  // Use the Blink default quality levels of toBlob instead so that file sizes are comparable.\n  if (mimeType === 'image/jpeg') {\n    quality = 0.92;\n  } else if (mimeType === 'image/webp') {\n    quality = 0.8;\n  }\n  return canvas.convertToBlob({\n    type: mimeType,\n    quality: quality\n  });\n}\n\n/**\n * Writer\n */\nclass GLTFWriter {\n  constructor() {\n    this.plugins = [];\n    this.options = {};\n    this.pending = [];\n    this.buffers = [];\n    this.byteOffset = 0;\n    this.buffers = [];\n    this.nodeMap = new Map();\n    this.skins = [];\n    this.extensionsUsed = {};\n    this.extensionsRequired = {};\n    this.uids = new Map();\n    this.uid = 0;\n    this.json = {\n      asset: {\n        version: '2.0',\n        generator: 'THREE.GLTFExporter r' + REVISION\n      }\n    };\n    this.cache = {\n      meshes: new Map(),\n      attributes: new Map(),\n      attributesNormalized: new Map(),\n      materials: new Map(),\n      textures: new Map(),\n      images: new Map()\n    };\n  }\n  setPlugins(plugins) {\n    this.plugins = plugins;\n  }\n\n  /**\n   * Parse scenes and generate GLTF output\n   * @param  {Scene or [THREE.Scenes]} input   Scene or Array of THREE.Scenes\n   * @param  {Function} onDone  Callback on completed\n   * @param  {Object} options options\n   */\n  async write(input, onDone, options = {}) {\n    this.options = Object.assign({\n      // default options\n      binary: false,\n      trs: false,\n      onlyVisible: true,\n      maxTextureSize: Infinity,\n      animations: [],\n      includeCustomExtensions: false\n    }, options);\n    if (this.options.animations.length > 0) {\n      // Only TRS properties, and not matrices, may be targeted by animation.\n      this.options.trs = true;\n    }\n    this.processInput(input);\n    await Promise.all(this.pending);\n    const writer = this;\n    const buffers = writer.buffers;\n    const json = writer.json;\n    options = writer.options;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionsRequired = writer.extensionsRequired;\n\n    // Merge buffers.\n    const blob = new Blob(buffers, {\n      type: 'application/octet-stream'\n    });\n\n    // Declare extensions.\n    const extensionsUsedList = Object.keys(extensionsUsed);\n    const extensionsRequiredList = Object.keys(extensionsRequired);\n    if (extensionsUsedList.length > 0) json.extensionsUsed = extensionsUsedList;\n    if (extensionsRequiredList.length > 0) json.extensionsRequired = extensionsRequiredList;\n\n    // Update bytelength of the single buffer.\n    if (json.buffers && json.buffers.length > 0) json.buffers[0].byteLength = blob.size;\n    if (options.binary === true) {\n      // https://github.com/KhronosGroup/glTF/blob/master/specification/2.0/README.md#glb-file-format-specification\n\n      const reader = new FileReader();\n      reader.readAsArrayBuffer(blob);\n      reader.onloadend = function () {\n        // Binary chunk.\n        const binaryChunk = getPaddedArrayBuffer(reader.result);\n        const binaryChunkPrefix = new DataView(new ArrayBuffer(GLB_CHUNK_PREFIX_BYTES));\n        binaryChunkPrefix.setUint32(0, binaryChunk.byteLength, true);\n        binaryChunkPrefix.setUint32(4, GLB_CHUNK_TYPE_BIN, true);\n\n        // JSON chunk.\n        const jsonChunk = getPaddedArrayBuffer(stringToArrayBuffer(JSON.stringify(json)), 0x20);\n        const jsonChunkPrefix = new DataView(new ArrayBuffer(GLB_CHUNK_PREFIX_BYTES));\n        jsonChunkPrefix.setUint32(0, jsonChunk.byteLength, true);\n        jsonChunkPrefix.setUint32(4, GLB_CHUNK_TYPE_JSON, true);\n\n        // GLB header.\n        const header = new ArrayBuffer(GLB_HEADER_BYTES);\n        const headerView = new DataView(header);\n        headerView.setUint32(0, GLB_HEADER_MAGIC, true);\n        headerView.setUint32(4, GLB_VERSION, true);\n        const totalByteLength = GLB_HEADER_BYTES + jsonChunkPrefix.byteLength + jsonChunk.byteLength + binaryChunkPrefix.byteLength + binaryChunk.byteLength;\n        headerView.setUint32(8, totalByteLength, true);\n        const glbBlob = new Blob([header, jsonChunkPrefix, jsonChunk, binaryChunkPrefix, binaryChunk], {\n          type: 'application/octet-stream'\n        });\n        const glbReader = new FileReader();\n        glbReader.readAsArrayBuffer(glbBlob);\n        glbReader.onloadend = function () {\n          onDone(glbReader.result);\n        };\n      };\n    } else {\n      if (json.buffers && json.buffers.length > 0) {\n        const reader = new FileReader();\n        reader.readAsDataURL(blob);\n        reader.onloadend = function () {\n          const base64data = reader.result;\n          json.buffers[0].uri = base64data;\n          onDone(json);\n        };\n      } else {\n        onDone(json);\n      }\n    }\n  }\n\n  /**\n   * Serializes a userData.\n   *\n   * @param {THREE.Object3D|THREE.Material} object\n   * @param {Object} objectDef\n   */\n  serializeUserData(object, objectDef) {\n    if (Object.keys(object.userData).length === 0) return;\n    const options = this.options;\n    const extensionsUsed = this.extensionsUsed;\n    try {\n      const json = JSON.parse(JSON.stringify(object.userData));\n      if (options.includeCustomExtensions && json.gltfExtensions) {\n        if (objectDef.extensions === undefined) objectDef.extensions = {};\n        for (const extensionName in json.gltfExtensions) {\n          objectDef.extensions[extensionName] = json.gltfExtensions[extensionName];\n          extensionsUsed[extensionName] = true;\n        }\n        delete json.gltfExtensions;\n      }\n      if (Object.keys(json).length > 0) objectDef.extras = json;\n    } catch (error) {\n      console.warn('THREE.GLTFExporter: userData of \\'' + object.name + '\\' ' + 'won\\'t be serialized because of JSON.stringify error - ' + error.message);\n    }\n  }\n\n  /**\n   * Returns ids for buffer attributes.\n   * @param  {Object} object\n   * @return {Integer}\n   */\n  getUID(attribute, isRelativeCopy = false) {\n    if (this.uids.has(attribute) === false) {\n      const uids = new Map();\n      uids.set(true, this.uid++);\n      uids.set(false, this.uid++);\n      this.uids.set(attribute, uids);\n    }\n    const uids = this.uids.get(attribute);\n    return uids.get(isRelativeCopy);\n  }\n\n  /**\n   * Checks if normal attribute values are normalized.\n   *\n   * @param {BufferAttribute} normal\n   * @returns {Boolean}\n   */\n  isNormalizedNormalAttribute(normal) {\n    const cache = this.cache;\n    if (cache.attributesNormalized.has(normal)) return false;\n    const v = new Vector3();\n    for (let i = 0, il = normal.count; i < il; i++) {\n      // 0.0005 is from glTF-validator\n      if (Math.abs(v.fromBufferAttribute(normal, i).length() - 1.0) > 0.0005) return false;\n    }\n    return true;\n  }\n\n  /**\n   * Creates normalized normal buffer attribute.\n   *\n   * @param {BufferAttribute} normal\n   * @returns {BufferAttribute}\n   *\n   */\n  createNormalizedNormalAttribute(normal) {\n    const cache = this.cache;\n    if (cache.attributesNormalized.has(normal)) return cache.attributesNormalized.get(normal);\n    const attribute = normal.clone();\n    const v = new Vector3();\n    for (let i = 0, il = attribute.count; i < il; i++) {\n      v.fromBufferAttribute(attribute, i);\n      if (v.x === 0 && v.y === 0 && v.z === 0) {\n        // if values can't be normalized set (1, 0, 0)\n        v.setX(1.0);\n      } else {\n        v.normalize();\n      }\n      attribute.setXYZ(i, v.x, v.y, v.z);\n    }\n    cache.attributesNormalized.set(normal, attribute);\n    return attribute;\n  }\n\n  /**\n   * Applies a texture transform, if present, to the map definition. Requires\n   * the KHR_texture_transform extension.\n   *\n   * @param {Object} mapDef\n   * @param {THREE.Texture} texture\n   */\n  applyTextureTransform(mapDef, texture) {\n    let didTransform = false;\n    const transformDef = {};\n    if (texture.offset.x !== 0 || texture.offset.y !== 0) {\n      transformDef.offset = texture.offset.toArray();\n      didTransform = true;\n    }\n    if (texture.rotation !== 0) {\n      transformDef.rotation = texture.rotation;\n      didTransform = true;\n    }\n    if (texture.repeat.x !== 1 || texture.repeat.y !== 1) {\n      transformDef.scale = texture.repeat.toArray();\n      didTransform = true;\n    }\n    if (didTransform) {\n      mapDef.extensions = mapDef.extensions || {};\n      mapDef.extensions['KHR_texture_transform'] = transformDef;\n      this.extensionsUsed['KHR_texture_transform'] = true;\n    }\n  }\n  buildMetalRoughTexture(metalnessMap, roughnessMap) {\n    if (metalnessMap === roughnessMap) return metalnessMap;\n    function getEncodingConversion(map) {\n      if (map.colorSpace === SRGBColorSpace) {\n        return function SRGBToLinear(c) {\n          return c < 0.04045 ? c * 0.0773993808 : Math.pow(c * 0.9478672986 + 0.0521327014, 2.4);\n        };\n      }\n      return function LinearToLinear(c) {\n        return c;\n      };\n    }\n    console.warn('THREE.GLTFExporter: Merged metalnessMap and roughnessMap textures.');\n    if (metalnessMap instanceof CompressedTexture) {\n      metalnessMap = decompress(metalnessMap);\n    }\n    if (roughnessMap instanceof CompressedTexture) {\n      roughnessMap = decompress(roughnessMap);\n    }\n    const metalness = metalnessMap ? metalnessMap.image : null;\n    const roughness = roughnessMap ? roughnessMap.image : null;\n    const width = Math.max(metalness ? metalness.width : 0, roughness ? roughness.width : 0);\n    const height = Math.max(metalness ? metalness.height : 0, roughness ? roughness.height : 0);\n    const canvas = getCanvas();\n    canvas.width = width;\n    canvas.height = height;\n    const context = canvas.getContext('2d', {\n      willReadFrequently: true\n    });\n    context.fillStyle = '#00ffff';\n    context.fillRect(0, 0, width, height);\n    const composite = context.getImageData(0, 0, width, height);\n    if (metalness) {\n      context.drawImage(metalness, 0, 0, width, height);\n      const convert = getEncodingConversion(metalnessMap);\n      const data = context.getImageData(0, 0, width, height).data;\n      for (let i = 2; i < data.length; i += 4) {\n        composite.data[i] = convert(data[i] / 256) * 256;\n      }\n    }\n    if (roughness) {\n      context.drawImage(roughness, 0, 0, width, height);\n      const convert = getEncodingConversion(roughnessMap);\n      const data = context.getImageData(0, 0, width, height).data;\n      for (let i = 1; i < data.length; i += 4) {\n        composite.data[i] = convert(data[i] / 256) * 256;\n      }\n    }\n    context.putImageData(composite, 0, 0);\n\n    //\n\n    const reference = metalnessMap || roughnessMap;\n    const texture = reference.clone();\n    texture.source = new Source(canvas);\n    texture.colorSpace = NoColorSpace;\n    texture.channel = (metalnessMap || roughnessMap).channel;\n    if (metalnessMap && roughnessMap && metalnessMap.channel !== roughnessMap.channel) {\n      console.warn('THREE.GLTFExporter: UV channels for metalnessMap and roughnessMap textures must match.');\n    }\n    return texture;\n  }\n\n  /**\n   * Process a buffer to append to the default one.\n   * @param  {ArrayBuffer} buffer\n   * @return {Integer}\n   */\n  processBuffer(buffer) {\n    const json = this.json;\n    const buffers = this.buffers;\n    if (!json.buffers) json.buffers = [{\n      byteLength: 0\n    }];\n\n    // All buffers are merged before export.\n    buffers.push(buffer);\n    return 0;\n  }\n\n  /**\n   * Process and generate a BufferView\n   * @param  {BufferAttribute} attribute\n   * @param  {number} componentType\n   * @param  {number} start\n   * @param  {number} count\n   * @param  {number} target (Optional) Target usage of the BufferView\n   * @return {Object}\n   */\n  processBufferView(attribute, componentType, start, count, target) {\n    const json = this.json;\n    if (!json.bufferViews) json.bufferViews = [];\n\n    // Create a new dataview and dump the attribute's array into it\n\n    let componentSize;\n    switch (componentType) {\n      case WEBGL_CONSTANTS.BYTE:\n      case WEBGL_CONSTANTS.UNSIGNED_BYTE:\n        componentSize = 1;\n        break;\n      case WEBGL_CONSTANTS.SHORT:\n      case WEBGL_CONSTANTS.UNSIGNED_SHORT:\n        componentSize = 2;\n        break;\n      default:\n        componentSize = 4;\n    }\n    let byteStride = attribute.itemSize * componentSize;\n    if (target === WEBGL_CONSTANTS.ARRAY_BUFFER) {\n      // Each element of a vertex attribute MUST be aligned to 4-byte boundaries\n      // inside a bufferView\n      byteStride = Math.ceil(byteStride / 4) * 4;\n    }\n    const byteLength = getPaddedBufferSize(count * byteStride);\n    const dataView = new DataView(new ArrayBuffer(byteLength));\n    let offset = 0;\n    for (let i = start; i < start + count; i++) {\n      for (let a = 0; a < attribute.itemSize; a++) {\n        let value;\n        if (attribute.itemSize > 4) {\n          // no support for interleaved data for itemSize > 4\n\n          value = attribute.array[i * attribute.itemSize + a];\n        } else {\n          if (a === 0) value = attribute.getX(i);else if (a === 1) value = attribute.getY(i);else if (a === 2) value = attribute.getZ(i);else if (a === 3) value = attribute.getW(i);\n          if (attribute.normalized === true) {\n            value = MathUtils.normalize(value, attribute.array);\n          }\n        }\n        if (componentType === WEBGL_CONSTANTS.FLOAT) {\n          dataView.setFloat32(offset, value, true);\n        } else if (componentType === WEBGL_CONSTANTS.INT) {\n          dataView.setInt32(offset, value, true);\n        } else if (componentType === WEBGL_CONSTANTS.UNSIGNED_INT) {\n          dataView.setUint32(offset, value, true);\n        } else if (componentType === WEBGL_CONSTANTS.SHORT) {\n          dataView.setInt16(offset, value, true);\n        } else if (componentType === WEBGL_CONSTANTS.UNSIGNED_SHORT) {\n          dataView.setUint16(offset, value, true);\n        } else if (componentType === WEBGL_CONSTANTS.BYTE) {\n          dataView.setInt8(offset, value);\n        } else if (componentType === WEBGL_CONSTANTS.UNSIGNED_BYTE) {\n          dataView.setUint8(offset, value);\n        }\n        offset += componentSize;\n      }\n      if (offset % byteStride !== 0) {\n        offset += byteStride - offset % byteStride;\n      }\n    }\n    const bufferViewDef = {\n      buffer: this.processBuffer(dataView.buffer),\n      byteOffset: this.byteOffset,\n      byteLength: byteLength\n    };\n    if (target !== undefined) bufferViewDef.target = target;\n    if (target === WEBGL_CONSTANTS.ARRAY_BUFFER) {\n      // Only define byteStride for vertex attributes.\n      bufferViewDef.byteStride = byteStride;\n    }\n    this.byteOffset += byteLength;\n    json.bufferViews.push(bufferViewDef);\n\n    // @TODO Merge bufferViews where possible.\n    const output = {\n      id: json.bufferViews.length - 1,\n      byteLength: 0\n    };\n    return output;\n  }\n\n  /**\n   * Process and generate a BufferView from an image Blob.\n   * @param {Blob} blob\n   * @return {Promise<Integer>}\n   */\n  processBufferViewImage(blob) {\n    const writer = this;\n    const json = writer.json;\n    if (!json.bufferViews) json.bufferViews = [];\n    return new Promise(function (resolve) {\n      const reader = new FileReader();\n      reader.readAsArrayBuffer(blob);\n      reader.onloadend = function () {\n        const buffer = getPaddedArrayBuffer(reader.result);\n        const bufferViewDef = {\n          buffer: writer.processBuffer(buffer),\n          byteOffset: writer.byteOffset,\n          byteLength: buffer.byteLength\n        };\n        writer.byteOffset += buffer.byteLength;\n        resolve(json.bufferViews.push(bufferViewDef) - 1);\n      };\n    });\n  }\n\n  /**\n   * Process attribute to generate an accessor\n   * @param  {BufferAttribute} attribute Attribute to process\n   * @param  {THREE.BufferGeometry} geometry (Optional) Geometry used for truncated draw range\n   * @param  {Integer} start (Optional)\n   * @param  {Integer} count (Optional)\n   * @return {Integer|null} Index of the processed accessor on the \"accessors\" array\n   */\n  processAccessor(attribute, geometry, start, count) {\n    const json = this.json;\n    const types = {\n      1: 'SCALAR',\n      2: 'VEC2',\n      3: 'VEC3',\n      4: 'VEC4',\n      9: 'MAT3',\n      16: 'MAT4'\n    };\n    let componentType;\n\n    // Detect the component type of the attribute array\n    if (attribute.array.constructor === Float32Array) {\n      componentType = WEBGL_CONSTANTS.FLOAT;\n    } else if (attribute.array.constructor === Int32Array) {\n      componentType = WEBGL_CONSTANTS.INT;\n    } else if (attribute.array.constructor === Uint32Array) {\n      componentType = WEBGL_CONSTANTS.UNSIGNED_INT;\n    } else if (attribute.array.constructor === Int16Array) {\n      componentType = WEBGL_CONSTANTS.SHORT;\n    } else if (attribute.array.constructor === Uint16Array) {\n      componentType = WEBGL_CONSTANTS.UNSIGNED_SHORT;\n    } else if (attribute.array.constructor === Int8Array) {\n      componentType = WEBGL_CONSTANTS.BYTE;\n    } else if (attribute.array.constructor === Uint8Array) {\n      componentType = WEBGL_CONSTANTS.UNSIGNED_BYTE;\n    } else {\n      throw new Error('THREE.GLTFExporter: Unsupported bufferAttribute component type: ' + attribute.array.constructor.name);\n    }\n    if (start === undefined) start = 0;\n    if (count === undefined || count === Infinity) count = attribute.count;\n\n    // Skip creating an accessor if the attribute doesn't have data to export\n    if (count === 0) return null;\n    const minMax = getMinMax(attribute, start, count);\n    let bufferViewTarget;\n\n    // If geometry isn't provided, don't infer the target usage of the bufferView. For\n    // animation samplers, target must not be set.\n    if (geometry !== undefined) {\n      bufferViewTarget = attribute === geometry.index ? WEBGL_CONSTANTS.ELEMENT_ARRAY_BUFFER : WEBGL_CONSTANTS.ARRAY_BUFFER;\n    }\n    const bufferView = this.processBufferView(attribute, componentType, start, count, bufferViewTarget);\n    const accessorDef = {\n      bufferView: bufferView.id,\n      byteOffset: bufferView.byteOffset,\n      componentType: componentType,\n      count: count,\n      max: minMax.max,\n      min: minMax.min,\n      type: types[attribute.itemSize]\n    };\n    if (attribute.normalized === true) accessorDef.normalized = true;\n    if (!json.accessors) json.accessors = [];\n    return json.accessors.push(accessorDef) - 1;\n  }\n\n  /**\n   * Process image\n   * @param  {Image} image to process\n   * @param  {Integer} format of the image (RGBAFormat)\n   * @param  {Boolean} flipY before writing out the image\n   * @param  {String} mimeType export format\n   * @return {Integer}     Index of the processed texture in the \"images\" array\n   */\n  processImage(image, format, flipY, mimeType = 'image/png') {\n    if (image !== null) {\n      const writer = this;\n      const cache = writer.cache;\n      const json = writer.json;\n      const options = writer.options;\n      const pending = writer.pending;\n      if (!cache.images.has(image)) cache.images.set(image, {});\n      const cachedImages = cache.images.get(image);\n      const key = mimeType + ':flipY/' + flipY.toString();\n      if (cachedImages[key] !== undefined) return cachedImages[key];\n      if (!json.images) json.images = [];\n      const imageDef = {\n        mimeType: mimeType\n      };\n      const canvas = getCanvas();\n      canvas.width = Math.min(image.width, options.maxTextureSize);\n      canvas.height = Math.min(image.height, options.maxTextureSize);\n      const ctx = canvas.getContext('2d', {\n        willReadFrequently: true\n      });\n      if (flipY === true) {\n        ctx.translate(0, canvas.height);\n        ctx.scale(1, -1);\n      }\n      if (image.data !== undefined) {\n        // THREE.DataTexture\n\n        if (format !== RGBAFormat) {\n          console.error('GLTFExporter: Only RGBAFormat is supported.', format);\n        }\n        if (image.width > options.maxTextureSize || image.height > options.maxTextureSize) {\n          console.warn('GLTFExporter: Image size is bigger than maxTextureSize', image);\n        }\n        const data = new Uint8ClampedArray(image.height * image.width * 4);\n        for (let i = 0; i < data.length; i += 4) {\n          data[i + 0] = image.data[i + 0];\n          data[i + 1] = image.data[i + 1];\n          data[i + 2] = image.data[i + 2];\n          data[i + 3] = image.data[i + 3];\n        }\n        ctx.putImageData(new ImageData(data, image.width, image.height), 0, 0);\n      } else {\n        if (typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement || typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap || typeof OffscreenCanvas !== 'undefined' && image instanceof OffscreenCanvas) {\n          ctx.drawImage(image, 0, 0, canvas.width, canvas.height);\n        } else {\n          throw new Error('THREE.GLTFExporter: Invalid image type. Use HTMLImageElement, HTMLCanvasElement, ImageBitmap or OffscreenCanvas.');\n        }\n      }\n      if (options.binary === true) {\n        pending.push(getToBlobPromise(canvas, mimeType).then(blob => writer.processBufferViewImage(blob)).then(bufferViewIndex => {\n          imageDef.bufferView = bufferViewIndex;\n        }));\n      } else {\n        if (canvas.toDataURL !== undefined) {\n          imageDef.uri = canvas.toDataURL(mimeType);\n        } else {\n          pending.push(getToBlobPromise(canvas, mimeType).then(blob => new FileReader().readAsDataURL(blob)).then(dataURL => {\n            imageDef.uri = dataURL;\n          }));\n        }\n      }\n      const index = json.images.push(imageDef) - 1;\n      cachedImages[key] = index;\n      return index;\n    } else {\n      throw new Error('THREE.GLTFExporter: No valid image data found. Unable to process texture.');\n    }\n  }\n\n  /**\n   * Process sampler\n   * @param  {Texture} map Texture to process\n   * @return {Integer}     Index of the processed texture in the \"samplers\" array\n   */\n  processSampler(map) {\n    const json = this.json;\n    if (!json.samplers) json.samplers = [];\n    const samplerDef = {\n      magFilter: THREE_TO_WEBGL[map.magFilter],\n      minFilter: THREE_TO_WEBGL[map.minFilter],\n      wrapS: THREE_TO_WEBGL[map.wrapS],\n      wrapT: THREE_TO_WEBGL[map.wrapT]\n    };\n    return json.samplers.push(samplerDef) - 1;\n  }\n\n  /**\n   * Process texture\n   * @param  {Texture} map Map to process\n   * @return {Integer} Index of the processed texture in the \"textures\" array\n   */\n  processTexture(map) {\n    const writer = this;\n    const options = writer.options;\n    const cache = this.cache;\n    const json = this.json;\n    if (cache.textures.has(map)) return cache.textures.get(map);\n    if (!json.textures) json.textures = [];\n\n    // make non-readable textures (e.g. CompressedTexture) readable by blitting them into a new texture\n    if (map instanceof CompressedTexture) {\n      map = decompress(map, options.maxTextureSize);\n    }\n    let mimeType = map.userData.mimeType;\n    if (mimeType === 'image/webp') mimeType = 'image/png';\n    const textureDef = {\n      sampler: this.processSampler(map),\n      source: this.processImage(map.image, map.format, map.flipY, mimeType)\n    };\n    if (map.name) textureDef.name = map.name;\n    this._invokeAll(function (ext) {\n      ext.writeTexture && ext.writeTexture(map, textureDef);\n    });\n    const index = json.textures.push(textureDef) - 1;\n    cache.textures.set(map, index);\n    return index;\n  }\n\n  /**\n   * Process material\n   * @param  {THREE.Material} material Material to process\n   * @return {Integer|null} Index of the processed material in the \"materials\" array\n   */\n  processMaterial(material) {\n    const cache = this.cache;\n    const json = this.json;\n    if (cache.materials.has(material)) return cache.materials.get(material);\n    if (material.isShaderMaterial) {\n      console.warn('GLTFExporter: THREE.ShaderMaterial not supported.');\n      return null;\n    }\n    if (!json.materials) json.materials = [];\n\n    // @QUESTION Should we avoid including any attribute that has the default value?\n    const materialDef = {\n      pbrMetallicRoughness: {}\n    };\n    if (material.isMeshStandardMaterial !== true && material.isMeshBasicMaterial !== true) {\n      console.warn('GLTFExporter: Use MeshStandardMaterial or MeshBasicMaterial for best results.');\n    }\n\n    // pbrMetallicRoughness.baseColorFactor\n    const color = material.color.toArray().concat([material.opacity]);\n    if (!equalArray(color, [1, 1, 1, 1])) {\n      materialDef.pbrMetallicRoughness.baseColorFactor = color;\n    }\n    if (material.isMeshStandardMaterial) {\n      materialDef.pbrMetallicRoughness.metallicFactor = material.metalness;\n      materialDef.pbrMetallicRoughness.roughnessFactor = material.roughness;\n    } else {\n      materialDef.pbrMetallicRoughness.metallicFactor = 0.5;\n      materialDef.pbrMetallicRoughness.roughnessFactor = 0.5;\n    }\n\n    // pbrMetallicRoughness.metallicRoughnessTexture\n    if (material.metalnessMap || material.roughnessMap) {\n      const metalRoughTexture = this.buildMetalRoughTexture(material.metalnessMap, material.roughnessMap);\n      const metalRoughMapDef = {\n        index: this.processTexture(metalRoughTexture),\n        channel: metalRoughTexture.channel\n      };\n      this.applyTextureTransform(metalRoughMapDef, metalRoughTexture);\n      materialDef.pbrMetallicRoughness.metallicRoughnessTexture = metalRoughMapDef;\n    }\n\n    // pbrMetallicRoughness.baseColorTexture\n    if (material.map) {\n      const baseColorMapDef = {\n        index: this.processTexture(material.map),\n        texCoord: material.map.channel\n      };\n      this.applyTextureTransform(baseColorMapDef, material.map);\n      materialDef.pbrMetallicRoughness.baseColorTexture = baseColorMapDef;\n    }\n    if (material.emissive) {\n      const emissive = material.emissive;\n      const maxEmissiveComponent = Math.max(emissive.r, emissive.g, emissive.b);\n      if (maxEmissiveComponent > 0) {\n        materialDef.emissiveFactor = material.emissive.toArray();\n      }\n\n      // emissiveTexture\n      if (material.emissiveMap) {\n        const emissiveMapDef = {\n          index: this.processTexture(material.emissiveMap),\n          texCoord: material.emissiveMap.channel\n        };\n        this.applyTextureTransform(emissiveMapDef, material.emissiveMap);\n        materialDef.emissiveTexture = emissiveMapDef;\n      }\n    }\n\n    // normalTexture\n    if (material.normalMap) {\n      const normalMapDef = {\n        index: this.processTexture(material.normalMap),\n        texCoord: material.normalMap.channel\n      };\n      if (material.normalScale && material.normalScale.x !== 1) {\n        // glTF normal scale is univariate. Ignore `y`, which may be flipped.\n        // Context: https://github.com/mrdoob/three.js/issues/11438#issuecomment-507003995\n        normalMapDef.scale = material.normalScale.x;\n      }\n      this.applyTextureTransform(normalMapDef, material.normalMap);\n      materialDef.normalTexture = normalMapDef;\n    }\n\n    // occlusionTexture\n    if (material.aoMap) {\n      const occlusionMapDef = {\n        index: this.processTexture(material.aoMap),\n        texCoord: material.aoMap.channel\n      };\n      if (material.aoMapIntensity !== 1.0) {\n        occlusionMapDef.strength = material.aoMapIntensity;\n      }\n      this.applyTextureTransform(occlusionMapDef, material.aoMap);\n      materialDef.occlusionTexture = occlusionMapDef;\n    }\n\n    // alphaMode\n    if (material.transparent) {\n      materialDef.alphaMode = 'BLEND';\n    } else {\n      if (material.alphaTest > 0.0) {\n        materialDef.alphaMode = 'MASK';\n        materialDef.alphaCutoff = material.alphaTest;\n      }\n    }\n\n    // doubleSided\n    if (material.side === DoubleSide) materialDef.doubleSided = true;\n    if (material.name !== '') materialDef.name = material.name;\n    this.serializeUserData(material, materialDef);\n    this._invokeAll(function (ext) {\n      ext.writeMaterial && ext.writeMaterial(material, materialDef);\n    });\n    const index = json.materials.push(materialDef) - 1;\n    cache.materials.set(material, index);\n    return index;\n  }\n\n  /**\n   * Process mesh\n   * @param  {THREE.Mesh} mesh Mesh to process\n   * @return {Integer|null} Index of the processed mesh in the \"meshes\" array\n   */\n  processMesh(mesh) {\n    const cache = this.cache;\n    const json = this.json;\n    const meshCacheKeyParts = [mesh.geometry.uuid];\n    if (Array.isArray(mesh.material)) {\n      for (let i = 0, l = mesh.material.length; i < l; i++) {\n        meshCacheKeyParts.push(mesh.material[i].uuid);\n      }\n    } else {\n      meshCacheKeyParts.push(mesh.material.uuid);\n    }\n    const meshCacheKey = meshCacheKeyParts.join(':');\n    if (cache.meshes.has(meshCacheKey)) return cache.meshes.get(meshCacheKey);\n    const geometry = mesh.geometry;\n    let mode;\n\n    // Use the correct mode\n    if (mesh.isLineSegments) {\n      mode = WEBGL_CONSTANTS.LINES;\n    } else if (mesh.isLineLoop) {\n      mode = WEBGL_CONSTANTS.LINE_LOOP;\n    } else if (mesh.isLine) {\n      mode = WEBGL_CONSTANTS.LINE_STRIP;\n    } else if (mesh.isPoints) {\n      mode = WEBGL_CONSTANTS.POINTS;\n    } else {\n      mode = mesh.material.wireframe ? WEBGL_CONSTANTS.LINES : WEBGL_CONSTANTS.TRIANGLES;\n    }\n    const meshDef = {};\n    const attributes = {};\n    const primitives = [];\n    const targets = [];\n\n    // Conversion between attributes names in threejs and gltf spec\n    const nameConversion = {\n      uv: 'TEXCOORD_0',\n      uv1: 'TEXCOORD_1',\n      uv2: 'TEXCOORD_2',\n      uv3: 'TEXCOORD_3',\n      color: 'COLOR_0',\n      skinWeight: 'WEIGHTS_0',\n      skinIndex: 'JOINTS_0'\n    };\n    const originalNormal = geometry.getAttribute('normal');\n    if (originalNormal !== undefined && !this.isNormalizedNormalAttribute(originalNormal)) {\n      console.warn('THREE.GLTFExporter: Creating normalized normal attribute from the non-normalized one.');\n      geometry.setAttribute('normal', this.createNormalizedNormalAttribute(originalNormal));\n    }\n\n    // @QUESTION Detect if .vertexColors = true?\n    // For every attribute create an accessor\n    let modifiedAttribute = null;\n    for (let attributeName in geometry.attributes) {\n      // Ignore morph target attributes, which are exported later.\n      if (attributeName.slice(0, 5) === 'morph') continue;\n      const attribute = geometry.attributes[attributeName];\n      attributeName = nameConversion[attributeName] || attributeName.toUpperCase();\n\n      // Prefix all geometry attributes except the ones specifically\n      // listed in the spec; non-spec attributes are considered custom.\n      const validVertexAttributes = /^(POSITION|NORMAL|TANGENT|TEXCOORD_\\d+|COLOR_\\d+|JOINTS_\\d+|WEIGHTS_\\d+)$/;\n      if (!validVertexAttributes.test(attributeName)) attributeName = '_' + attributeName;\n      if (cache.attributes.has(this.getUID(attribute))) {\n        attributes[attributeName] = cache.attributes.get(this.getUID(attribute));\n        continue;\n      }\n\n      // JOINTS_0 must be UNSIGNED_BYTE or UNSIGNED_SHORT.\n      modifiedAttribute = null;\n      const array = attribute.array;\n      if (attributeName === 'JOINTS_0' && !(array instanceof Uint16Array) && !(array instanceof Uint8Array)) {\n        console.warn('GLTFExporter: Attribute \"skinIndex\" converted to type UNSIGNED_SHORT.');\n        modifiedAttribute = new BufferAttribute(new Uint16Array(array), attribute.itemSize, attribute.normalized);\n      }\n      const accessor = this.processAccessor(modifiedAttribute || attribute, geometry);\n      if (accessor !== null) {\n        if (!attributeName.startsWith('_')) {\n          this.detectMeshQuantization(attributeName, attribute);\n        }\n        attributes[attributeName] = accessor;\n        cache.attributes.set(this.getUID(attribute), accessor);\n      }\n    }\n    if (originalNormal !== undefined) geometry.setAttribute('normal', originalNormal);\n\n    // Skip if no exportable attributes found\n    if (Object.keys(attributes).length === 0) return null;\n\n    // Morph targets\n    if (mesh.morphTargetInfluences !== undefined && mesh.morphTargetInfluences.length > 0) {\n      const weights = [];\n      const targetNames = [];\n      const reverseDictionary = {};\n      if (mesh.morphTargetDictionary !== undefined) {\n        for (const key in mesh.morphTargetDictionary) {\n          reverseDictionary[mesh.morphTargetDictionary[key]] = key;\n        }\n      }\n      for (let i = 0; i < mesh.morphTargetInfluences.length; ++i) {\n        const target = {};\n        let warned = false;\n        for (const attributeName in geometry.morphAttributes) {\n          // glTF 2.0 morph supports only POSITION/NORMAL/TANGENT.\n          // Three.js doesn't support TANGENT yet.\n\n          if (attributeName !== 'position' && attributeName !== 'normal') {\n            if (!warned) {\n              console.warn('GLTFExporter: Only POSITION and NORMAL morph are supported.');\n              warned = true;\n            }\n            continue;\n          }\n          const attribute = geometry.morphAttributes[attributeName][i];\n          const gltfAttributeName = attributeName.toUpperCase();\n\n          // Three.js morph attribute has absolute values while the one of glTF has relative values.\n          //\n          // glTF 2.0 Specification:\n          // https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#morph-targets\n\n          const baseAttribute = geometry.attributes[attributeName];\n          if (cache.attributes.has(this.getUID(attribute, true))) {\n            target[gltfAttributeName] = cache.attributes.get(this.getUID(attribute, true));\n            continue;\n          }\n\n          // Clones attribute not to override\n          const relativeAttribute = attribute.clone();\n          if (!geometry.morphTargetsRelative) {\n            for (let j = 0, jl = attribute.count; j < jl; j++) {\n              for (let a = 0; a < attribute.itemSize; a++) {\n                if (a === 0) relativeAttribute.setX(j, attribute.getX(j) - baseAttribute.getX(j));\n                if (a === 1) relativeAttribute.setY(j, attribute.getY(j) - baseAttribute.getY(j));\n                if (a === 2) relativeAttribute.setZ(j, attribute.getZ(j) - baseAttribute.getZ(j));\n                if (a === 3) relativeAttribute.setW(j, attribute.getW(j) - baseAttribute.getW(j));\n              }\n            }\n          }\n          target[gltfAttributeName] = this.processAccessor(relativeAttribute, geometry);\n          cache.attributes.set(this.getUID(baseAttribute, true), target[gltfAttributeName]);\n        }\n        targets.push(target);\n        weights.push(mesh.morphTargetInfluences[i]);\n        if (mesh.morphTargetDictionary !== undefined) targetNames.push(reverseDictionary[i]);\n      }\n      meshDef.weights = weights;\n      if (targetNames.length > 0) {\n        meshDef.extras = {};\n        meshDef.extras.targetNames = targetNames;\n      }\n    }\n    const isMultiMaterial = Array.isArray(mesh.material);\n    if (isMultiMaterial && geometry.groups.length === 0) return null;\n    let didForceIndices = false;\n    if (isMultiMaterial && geometry.index === null) {\n      const indices = [];\n      for (let i = 0, il = geometry.attributes.position.count; i < il; i++) {\n        indices[i] = i;\n      }\n      geometry.setIndex(indices);\n      didForceIndices = true;\n    }\n    const materials = isMultiMaterial ? mesh.material : [mesh.material];\n    const groups = isMultiMaterial ? geometry.groups : [{\n      materialIndex: 0,\n      start: undefined,\n      count: undefined\n    }];\n    for (let i = 0, il = groups.length; i < il; i++) {\n      const primitive = {\n        mode: mode,\n        attributes: attributes\n      };\n      this.serializeUserData(geometry, primitive);\n      if (targets.length > 0) primitive.targets = targets;\n      if (geometry.index !== null) {\n        let cacheKey = this.getUID(geometry.index);\n        if (groups[i].start !== undefined || groups[i].count !== undefined) {\n          cacheKey += ':' + groups[i].start + ':' + groups[i].count;\n        }\n        if (cache.attributes.has(cacheKey)) {\n          primitive.indices = cache.attributes.get(cacheKey);\n        } else {\n          primitive.indices = this.processAccessor(geometry.index, geometry, groups[i].start, groups[i].count);\n          cache.attributes.set(cacheKey, primitive.indices);\n        }\n        if (primitive.indices === null) delete primitive.indices;\n      }\n      const material = this.processMaterial(materials[groups[i].materialIndex]);\n      if (material !== null) primitive.material = material;\n      primitives.push(primitive);\n    }\n    if (didForceIndices === true) {\n      geometry.setIndex(null);\n    }\n    meshDef.primitives = primitives;\n    if (!json.meshes) json.meshes = [];\n    this._invokeAll(function (ext) {\n      ext.writeMesh && ext.writeMesh(mesh, meshDef);\n    });\n    const index = json.meshes.push(meshDef) - 1;\n    cache.meshes.set(meshCacheKey, index);\n    return index;\n  }\n\n  /**\n   * If a vertex attribute with a\n   * [non-standard data type](https://registry.khronos.org/glTF/specs/2.0/glTF-2.0.html#meshes-overview)\n   * is used, it is checked whether it is a valid data type according to the\n   * [KHR_mesh_quantization](https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_mesh_quantization/README.md)\n   * extension.\n   * In this case the extension is automatically added to the list of used extensions.\n   *\n   * @param {string} attributeName\n   * @param {THREE.BufferAttribute} attribute\n   */\n  detectMeshQuantization(attributeName, attribute) {\n    if (this.extensionsUsed[KHR_MESH_QUANTIZATION]) return;\n    let attrType = undefined;\n    switch (attribute.array.constructor) {\n      case Int8Array:\n        attrType = 'byte';\n        break;\n      case Uint8Array:\n        attrType = 'unsigned byte';\n        break;\n      case Int16Array:\n        attrType = 'short';\n        break;\n      case Uint16Array:\n        attrType = 'unsigned short';\n        break;\n      default:\n        return;\n    }\n    if (attribute.normalized) attrType += ' normalized';\n    const attrNamePrefix = attributeName.split('_', 1)[0];\n    if (KHR_mesh_quantization_ExtraAttrTypes[attrNamePrefix] && KHR_mesh_quantization_ExtraAttrTypes[attrNamePrefix].includes(attrType)) {\n      this.extensionsUsed[KHR_MESH_QUANTIZATION] = true;\n      this.extensionsRequired[KHR_MESH_QUANTIZATION] = true;\n    }\n  }\n\n  /**\n   * Process camera\n   * @param  {THREE.Camera} camera Camera to process\n   * @return {Integer}      Index of the processed mesh in the \"camera\" array\n   */\n  processCamera(camera) {\n    const json = this.json;\n    if (!json.cameras) json.cameras = [];\n    const isOrtho = camera.isOrthographicCamera;\n    const cameraDef = {\n      type: isOrtho ? 'orthographic' : 'perspective'\n    };\n    if (isOrtho) {\n      cameraDef.orthographic = {\n        xmag: camera.right * 2,\n        ymag: camera.top * 2,\n        zfar: camera.far <= 0 ? 0.001 : camera.far,\n        znear: camera.near < 0 ? 0 : camera.near\n      };\n    } else {\n      cameraDef.perspective = {\n        aspectRatio: camera.aspect,\n        yfov: MathUtils.degToRad(camera.fov),\n        zfar: camera.far <= 0 ? 0.001 : camera.far,\n        znear: camera.near < 0 ? 0 : camera.near\n      };\n    }\n\n    // Question: Is saving \"type\" as name intentional?\n    if (camera.name !== '') cameraDef.name = camera.type;\n    return json.cameras.push(cameraDef) - 1;\n  }\n\n  /**\n   * Creates glTF animation entry from AnimationClip object.\n   *\n   * Status:\n   * - Only properties listed in PATH_PROPERTIES may be animated.\n   *\n   * @param {THREE.AnimationClip} clip\n   * @param {THREE.Object3D} root\n   * @return {number|null}\n   */\n  processAnimation(clip, root) {\n    const json = this.json;\n    const nodeMap = this.nodeMap;\n    if (!json.animations) json.animations = [];\n    clip = GLTFExporter.Utils.mergeMorphTargetTracks(clip.clone(), root);\n    const tracks = clip.tracks;\n    const channels = [];\n    const samplers = [];\n    for (let i = 0; i < tracks.length; ++i) {\n      const track = tracks[i];\n      const trackBinding = PropertyBinding.parseTrackName(track.name);\n      let trackNode = PropertyBinding.findNode(root, trackBinding.nodeName);\n      const trackProperty = PATH_PROPERTIES[trackBinding.propertyName];\n      if (trackBinding.objectName === 'bones') {\n        if (trackNode.isSkinnedMesh === true) {\n          trackNode = trackNode.skeleton.getBoneByName(trackBinding.objectIndex);\n        } else {\n          trackNode = undefined;\n        }\n      }\n      if (!trackNode || !trackProperty) {\n        console.warn('THREE.GLTFExporter: Could not export animation track \"%s\".', track.name);\n        continue;\n      }\n      const inputItemSize = 1;\n      let outputItemSize = track.values.length / track.times.length;\n      if (trackProperty === PATH_PROPERTIES.morphTargetInfluences) {\n        outputItemSize /= trackNode.morphTargetInfluences.length;\n      }\n      let interpolation;\n\n      // @TODO export CubicInterpolant(InterpolateSmooth) as CUBICSPLINE\n\n      // Detecting glTF cubic spline interpolant by checking factory method's special property\n      // GLTFCubicSplineInterpolant is a custom interpolant and track doesn't return\n      // valid value from .getInterpolation().\n      if (track.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline === true) {\n        interpolation = 'CUBICSPLINE';\n\n        // itemSize of CUBICSPLINE keyframe is 9\n        // (VEC3 * 3: inTangent, splineVertex, and outTangent)\n        // but needs to be stored as VEC3 so dividing by 3 here.\n        outputItemSize /= 3;\n      } else if (track.getInterpolation() === InterpolateDiscrete) {\n        interpolation = 'STEP';\n      } else {\n        interpolation = 'LINEAR';\n      }\n      samplers.push({\n        input: this.processAccessor(new BufferAttribute(track.times, inputItemSize)),\n        output: this.processAccessor(new BufferAttribute(track.values, outputItemSize)),\n        interpolation: interpolation\n      });\n      channels.push({\n        sampler: samplers.length - 1,\n        target: {\n          node: nodeMap.get(trackNode),\n          path: trackProperty\n        }\n      });\n    }\n    json.animations.push({\n      name: clip.name || 'clip_' + json.animations.length,\n      samplers: samplers,\n      channels: channels\n    });\n    return json.animations.length - 1;\n  }\n\n  /**\n   * @param {THREE.Object3D} object\n   * @return {number|null}\n   */\n  processSkin(object) {\n    const json = this.json;\n    const nodeMap = this.nodeMap;\n    const node = json.nodes[nodeMap.get(object)];\n    const skeleton = object.skeleton;\n    if (skeleton === undefined) return null;\n    const rootJoint = object.skeleton.bones[0];\n    if (rootJoint === undefined) return null;\n    const joints = [];\n    const inverseBindMatrices = new Float32Array(skeleton.bones.length * 16);\n    const temporaryBoneInverse = new Matrix4();\n    for (let i = 0; i < skeleton.bones.length; ++i) {\n      joints.push(nodeMap.get(skeleton.bones[i]));\n      temporaryBoneInverse.copy(skeleton.boneInverses[i]);\n      temporaryBoneInverse.multiply(object.bindMatrix).toArray(inverseBindMatrices, i * 16);\n    }\n    if (json.skins === undefined) json.skins = [];\n    json.skins.push({\n      inverseBindMatrices: this.processAccessor(new BufferAttribute(inverseBindMatrices, 16)),\n      joints: joints,\n      skeleton: nodeMap.get(rootJoint)\n    });\n    const skinIndex = node.skin = json.skins.length - 1;\n    return skinIndex;\n  }\n\n  /**\n   * Process Object3D node\n   * @param  {THREE.Object3D} node Object3D to processNode\n   * @return {Integer} Index of the node in the nodes list\n   */\n  processNode(object) {\n    const json = this.json;\n    const options = this.options;\n    const nodeMap = this.nodeMap;\n    if (!json.nodes) json.nodes = [];\n    const nodeDef = {};\n    if (options.trs) {\n      const rotation = object.quaternion.toArray();\n      const position = object.position.toArray();\n      const scale = object.scale.toArray();\n      if (!equalArray(rotation, [0, 0, 0, 1])) {\n        nodeDef.rotation = rotation;\n      }\n      if (!equalArray(position, [0, 0, 0])) {\n        nodeDef.translation = position;\n      }\n      if (!equalArray(scale, [1, 1, 1])) {\n        nodeDef.scale = scale;\n      }\n    } else {\n      if (object.matrixAutoUpdate) {\n        object.updateMatrix();\n      }\n      if (isIdentityMatrix(object.matrix) === false) {\n        nodeDef.matrix = object.matrix.elements;\n      }\n    }\n\n    // We don't export empty strings name because it represents no-name in Three.js.\n    if (object.name !== '') nodeDef.name = String(object.name);\n    this.serializeUserData(object, nodeDef);\n    if (object.isMesh || object.isLine || object.isPoints) {\n      const meshIndex = this.processMesh(object);\n      if (meshIndex !== null) nodeDef.mesh = meshIndex;\n    } else if (object.isCamera) {\n      nodeDef.camera = this.processCamera(object);\n    }\n    if (object.isSkinnedMesh) this.skins.push(object);\n    if (object.children.length > 0) {\n      const children = [];\n      for (let i = 0, l = object.children.length; i < l; i++) {\n        const child = object.children[i];\n        if (child.visible || options.onlyVisible === false) {\n          const nodeIndex = this.processNode(child);\n          if (nodeIndex !== null) children.push(nodeIndex);\n        }\n      }\n      if (children.length > 0) nodeDef.children = children;\n    }\n    this._invokeAll(function (ext) {\n      ext.writeNode && ext.writeNode(object, nodeDef);\n    });\n    const nodeIndex = json.nodes.push(nodeDef) - 1;\n    nodeMap.set(object, nodeIndex);\n    return nodeIndex;\n  }\n\n  /**\n   * Process Scene\n   * @param  {Scene} node Scene to process\n   */\n  processScene(scene) {\n    const json = this.json;\n    const options = this.options;\n    if (!json.scenes) {\n      json.scenes = [];\n      json.scene = 0;\n    }\n    const sceneDef = {};\n    if (scene.name !== '') sceneDef.name = scene.name;\n    json.scenes.push(sceneDef);\n    const nodes = [];\n    for (let i = 0, l = scene.children.length; i < l; i++) {\n      const child = scene.children[i];\n      if (child.visible || options.onlyVisible === false) {\n        const nodeIndex = this.processNode(child);\n        if (nodeIndex !== null) nodes.push(nodeIndex);\n      }\n    }\n    if (nodes.length > 0) sceneDef.nodes = nodes;\n    this.serializeUserData(scene, sceneDef);\n  }\n\n  /**\n   * Creates a Scene to hold a list of objects and parse it\n   * @param  {Array} objects List of objects to process\n   */\n  processObjects(objects) {\n    const scene = new Scene();\n    scene.name = 'AuxScene';\n    for (let i = 0; i < objects.length; i++) {\n      // We push directly to children instead of calling `add` to prevent\n      // modify the .parent and break its original scene and hierarchy\n      scene.children.push(objects[i]);\n    }\n    this.processScene(scene);\n  }\n\n  /**\n   * @param {THREE.Object3D|Array<THREE.Object3D>} input\n   */\n  processInput(input) {\n    const options = this.options;\n    input = input instanceof Array ? input : [input];\n    this._invokeAll(function (ext) {\n      ext.beforeParse && ext.beforeParse(input);\n    });\n    const objectsWithoutScene = [];\n    for (let i = 0; i < input.length; i++) {\n      if (input[i] instanceof Scene) {\n        this.processScene(input[i]);\n      } else {\n        objectsWithoutScene.push(input[i]);\n      }\n    }\n    if (objectsWithoutScene.length > 0) this.processObjects(objectsWithoutScene);\n    for (let i = 0; i < this.skins.length; ++i) {\n      this.processSkin(this.skins[i]);\n    }\n    for (let i = 0; i < options.animations.length; ++i) {\n      this.processAnimation(options.animations[i], input[0]);\n    }\n    this._invokeAll(function (ext) {\n      ext.afterParse && ext.afterParse(input);\n    });\n  }\n  _invokeAll(func) {\n    for (let i = 0, il = this.plugins.length; i < il; i++) {\n      func(this.plugins[i]);\n    }\n  }\n}\n\n/**\n * Punctual Lights Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_lights_punctual\n */\nclass GLTFLightExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_lights_punctual';\n  }\n  writeNode(light, nodeDef) {\n    if (!light.isLight) return;\n    if (!light.isDirectionalLight && !light.isPointLight && !light.isSpotLight) {\n      console.warn('THREE.GLTFExporter: Only directional, point, and spot lights are supported.', light);\n      return;\n    }\n    const writer = this.writer;\n    const json = writer.json;\n    const extensionsUsed = writer.extensionsUsed;\n    const lightDef = {};\n    if (light.name) lightDef.name = light.name;\n    lightDef.color = light.color.toArray();\n    lightDef.intensity = light.intensity;\n    if (light.isDirectionalLight) {\n      lightDef.type = 'directional';\n    } else if (light.isPointLight) {\n      lightDef.type = 'point';\n      if (light.distance > 0) lightDef.range = light.distance;\n    } else if (light.isSpotLight) {\n      lightDef.type = 'spot';\n      if (light.distance > 0) lightDef.range = light.distance;\n      lightDef.spot = {};\n      lightDef.spot.innerConeAngle = (1.0 - light.penumbra) * light.angle;\n      lightDef.spot.outerConeAngle = light.angle;\n    }\n    if (light.decay !== undefined && light.decay !== 2) {\n      console.warn('THREE.GLTFExporter: Light decay may be lost. glTF is physically-based, ' + 'and expects light.decay=2.');\n    }\n    if (light.target && (light.target.parent !== light || light.target.position.x !== 0 || light.target.position.y !== 0 || light.target.position.z !== -1)) {\n      console.warn('THREE.GLTFExporter: Light direction may be lost. For best results, ' + 'make light.target a child of the light with position 0,0,-1.');\n    }\n    if (!extensionsUsed[this.name]) {\n      json.extensions = json.extensions || {};\n      json.extensions[this.name] = {\n        lights: []\n      };\n      extensionsUsed[this.name] = true;\n    }\n    const lights = json.extensions[this.name].lights;\n    lights.push(lightDef);\n    nodeDef.extensions = nodeDef.extensions || {};\n    nodeDef.extensions[this.name] = {\n      light: lights.length - 1\n    };\n  }\n}\n\n/**\n * Unlit Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_unlit\n */\nclass GLTFMaterialsUnlitExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_unlit';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshBasicMaterial) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = {};\n    extensionsUsed[this.name] = true;\n    materialDef.pbrMetallicRoughness.metallicFactor = 0.0;\n    materialDef.pbrMetallicRoughness.roughnessFactor = 0.9;\n  }\n}\n\n/**\n * Clearcoat Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_clearcoat\n */\nclass GLTFMaterialsClearcoatExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_clearcoat';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.clearcoat === 0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    extensionDef.clearcoatFactor = material.clearcoat;\n    if (material.clearcoatMap) {\n      const clearcoatMapDef = {\n        index: writer.processTexture(material.clearcoatMap),\n        texCoord: material.clearcoatMap.channel\n      };\n      writer.applyTextureTransform(clearcoatMapDef, material.clearcoatMap);\n      extensionDef.clearcoatTexture = clearcoatMapDef;\n    }\n    extensionDef.clearcoatRoughnessFactor = material.clearcoatRoughness;\n    if (material.clearcoatRoughnessMap) {\n      const clearcoatRoughnessMapDef = {\n        index: writer.processTexture(material.clearcoatRoughnessMap),\n        texCoord: material.clearcoatRoughnessMap.channel\n      };\n      writer.applyTextureTransform(clearcoatRoughnessMapDef, material.clearcoatRoughnessMap);\n      extensionDef.clearcoatRoughnessTexture = clearcoatRoughnessMapDef;\n    }\n    if (material.clearcoatNormalMap) {\n      const clearcoatNormalMapDef = {\n        index: writer.processTexture(material.clearcoatNormalMap),\n        texCoord: material.clearcoatNormalMap.channel\n      };\n      if (material.clearcoatNormalScale.x !== 1) clearcoatNormalMapDef.scale = material.clearcoatNormalScale.x;\n      writer.applyTextureTransform(clearcoatNormalMapDef, material.clearcoatNormalMap);\n      extensionDef.clearcoatNormalTexture = clearcoatNormalMapDef;\n    }\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Materials dispersion Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_dispersion\n */\nclass GLTFMaterialsDispersionExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_dispersion';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.dispersion === 0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    extensionDef.dispersion = material.dispersion;\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Iridescence Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_iridescence\n */\nclass GLTFMaterialsIridescenceExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_iridescence';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.iridescence === 0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    extensionDef.iridescenceFactor = material.iridescence;\n    if (material.iridescenceMap) {\n      const iridescenceMapDef = {\n        index: writer.processTexture(material.iridescenceMap),\n        texCoord: material.iridescenceMap.channel\n      };\n      writer.applyTextureTransform(iridescenceMapDef, material.iridescenceMap);\n      extensionDef.iridescenceTexture = iridescenceMapDef;\n    }\n    extensionDef.iridescenceIor = material.iridescenceIOR;\n    extensionDef.iridescenceThicknessMinimum = material.iridescenceThicknessRange[0];\n    extensionDef.iridescenceThicknessMaximum = material.iridescenceThicknessRange[1];\n    if (material.iridescenceThicknessMap) {\n      const iridescenceThicknessMapDef = {\n        index: writer.processTexture(material.iridescenceThicknessMap),\n        texCoord: material.iridescenceThicknessMap.channel\n      };\n      writer.applyTextureTransform(iridescenceThicknessMapDef, material.iridescenceThicknessMap);\n      extensionDef.iridescenceThicknessTexture = iridescenceThicknessMapDef;\n    }\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Transmission Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_transmission\n */\nclass GLTFMaterialsTransmissionExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_transmission';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.transmission === 0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    extensionDef.transmissionFactor = material.transmission;\n    if (material.transmissionMap) {\n      const transmissionMapDef = {\n        index: writer.processTexture(material.transmissionMap),\n        texCoord: material.transmissionMap.channel\n      };\n      writer.applyTextureTransform(transmissionMapDef, material.transmissionMap);\n      extensionDef.transmissionTexture = transmissionMapDef;\n    }\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Materials Volume Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_volume\n */\nclass GLTFMaterialsVolumeExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_volume';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.transmission === 0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    extensionDef.thicknessFactor = material.thickness;\n    if (material.thicknessMap) {\n      const thicknessMapDef = {\n        index: writer.processTexture(material.thicknessMap),\n        texCoord: material.thicknessMap.channel\n      };\n      writer.applyTextureTransform(thicknessMapDef, material.thicknessMap);\n      extensionDef.thicknessTexture = thicknessMapDef;\n    }\n    if (material.attenuationDistance !== Infinity) {\n      extensionDef.attenuationDistance = material.attenuationDistance;\n    }\n    extensionDef.attenuationColor = material.attenuationColor.toArray();\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Materials ior Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_ior\n */\nclass GLTFMaterialsIorExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_ior';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.ior === 1.5) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    extensionDef.ior = material.ior;\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Materials specular Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_specular\n */\nclass GLTFMaterialsSpecularExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_specular';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.specularIntensity === 1.0 && material.specularColor.equals(DEFAULT_SPECULAR_COLOR) && !material.specularIntensityMap && !material.specularColorMap) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    if (material.specularIntensityMap) {\n      const specularIntensityMapDef = {\n        index: writer.processTexture(material.specularIntensityMap),\n        texCoord: material.specularIntensityMap.channel\n      };\n      writer.applyTextureTransform(specularIntensityMapDef, material.specularIntensityMap);\n      extensionDef.specularTexture = specularIntensityMapDef;\n    }\n    if (material.specularColorMap) {\n      const specularColorMapDef = {\n        index: writer.processTexture(material.specularColorMap),\n        texCoord: material.specularColorMap.channel\n      };\n      writer.applyTextureTransform(specularColorMapDef, material.specularColorMap);\n      extensionDef.specularColorTexture = specularColorMapDef;\n    }\n    extensionDef.specularFactor = material.specularIntensity;\n    extensionDef.specularColorFactor = material.specularColor.toArray();\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Sheen Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_sheen\n */\nclass GLTFMaterialsSheenExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_sheen';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.sheen == 0.0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    if (material.sheenRoughnessMap) {\n      const sheenRoughnessMapDef = {\n        index: writer.processTexture(material.sheenRoughnessMap),\n        texCoord: material.sheenRoughnessMap.channel\n      };\n      writer.applyTextureTransform(sheenRoughnessMapDef, material.sheenRoughnessMap);\n      extensionDef.sheenRoughnessTexture = sheenRoughnessMapDef;\n    }\n    if (material.sheenColorMap) {\n      const sheenColorMapDef = {\n        index: writer.processTexture(material.sheenColorMap),\n        texCoord: material.sheenColorMap.channel\n      };\n      writer.applyTextureTransform(sheenColorMapDef, material.sheenColorMap);\n      extensionDef.sheenColorTexture = sheenColorMapDef;\n    }\n    extensionDef.sheenRoughnessFactor = material.sheenRoughness;\n    extensionDef.sheenColorFactor = material.sheenColor.toArray();\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Anisotropy Materials Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/main/extensions/2.0/Khronos/KHR_materials_anisotropy\n */\nclass GLTFMaterialsAnisotropyExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_anisotropy';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshPhysicalMaterial || material.anisotropy == 0.0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    if (material.anisotropyMap) {\n      const anisotropyMapDef = {\n        index: writer.processTexture(material.anisotropyMap)\n      };\n      writer.applyTextureTransform(anisotropyMapDef, material.anisotropyMap);\n      extensionDef.anisotropyTexture = anisotropyMapDef;\n    }\n    extensionDef.anisotropyStrength = material.anisotropy;\n    extensionDef.anisotropyRotation = material.anisotropyRotation;\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Materials Emissive Strength Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/blob/5768b3ce0ef32bc39cdf1bef10b948586635ead3/extensions/2.0/Khronos/KHR_materials_emissive_strength/README.md\n */\nclass GLTFMaterialsEmissiveStrengthExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_emissive_strength';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshStandardMaterial || material.emissiveIntensity === 1.0) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    extensionDef.emissiveStrength = material.emissiveIntensity;\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * Materials bump Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/EXT_materials_bump\n */\nclass GLTFMaterialsBumpExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'EXT_materials_bump';\n  }\n  writeMaterial(material, materialDef) {\n    if (!material.isMeshStandardMaterial || material.bumpScale === 1 && !material.bumpMap) return;\n    const writer = this.writer;\n    const extensionsUsed = writer.extensionsUsed;\n    const extensionDef = {};\n    if (material.bumpMap) {\n      const bumpMapDef = {\n        index: writer.processTexture(material.bumpMap),\n        texCoord: material.bumpMap.channel\n      };\n      writer.applyTextureTransform(bumpMapDef, material.bumpMap);\n      extensionDef.bumpTexture = bumpMapDef;\n    }\n    extensionDef.bumpFactor = material.bumpScale;\n    materialDef.extensions = materialDef.extensions || {};\n    materialDef.extensions[this.name] = extensionDef;\n    extensionsUsed[this.name] = true;\n  }\n}\n\n/**\n * GPU Instancing Extension\n *\n * Specification: https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Vendor/EXT_mesh_gpu_instancing\n */\nclass GLTFMeshGpuInstancing {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'EXT_mesh_gpu_instancing';\n  }\n  writeNode(object, nodeDef) {\n    if (!object.isInstancedMesh) return;\n    const writer = this.writer;\n    const mesh = object;\n    const translationAttr = new Float32Array(mesh.count * 3);\n    const rotationAttr = new Float32Array(mesh.count * 4);\n    const scaleAttr = new Float32Array(mesh.count * 3);\n    const matrix = new Matrix4();\n    const position = new Vector3();\n    const quaternion = new Quaternion();\n    const scale = new Vector3();\n    for (let i = 0; i < mesh.count; i++) {\n      mesh.getMatrixAt(i, matrix);\n      matrix.decompose(position, quaternion, scale);\n      position.toArray(translationAttr, i * 3);\n      quaternion.toArray(rotationAttr, i * 4);\n      scale.toArray(scaleAttr, i * 3);\n    }\n    const attributes = {\n      TRANSLATION: writer.processAccessor(new BufferAttribute(translationAttr, 3)),\n      ROTATION: writer.processAccessor(new BufferAttribute(rotationAttr, 4)),\n      SCALE: writer.processAccessor(new BufferAttribute(scaleAttr, 3))\n    };\n    if (mesh.instanceColor) attributes._COLOR_0 = writer.processAccessor(mesh.instanceColor);\n    nodeDef.extensions = nodeDef.extensions || {};\n    nodeDef.extensions[this.name] = {\n      attributes\n    };\n    writer.extensionsUsed[this.name] = true;\n    writer.extensionsRequired[this.name] = true;\n  }\n}\n\n/**\n * Static utility functions\n */\nGLTFExporter.Utils = {\n  insertKeyframe: function (track, time) {\n    const tolerance = 0.001; // 1ms\n    const valueSize = track.getValueSize();\n    const times = new track.TimeBufferType(track.times.length + 1);\n    const values = new track.ValueBufferType(track.values.length + valueSize);\n    const interpolant = track.createInterpolant(new track.ValueBufferType(valueSize));\n    let index;\n    if (track.times.length === 0) {\n      times[0] = time;\n      for (let i = 0; i < valueSize; i++) {\n        values[i] = 0;\n      }\n      index = 0;\n    } else if (time < track.times[0]) {\n      if (Math.abs(track.times[0] - time) < tolerance) return 0;\n      times[0] = time;\n      times.set(track.times, 1);\n      values.set(interpolant.evaluate(time), 0);\n      values.set(track.values, valueSize);\n      index = 0;\n    } else if (time > track.times[track.times.length - 1]) {\n      if (Math.abs(track.times[track.times.length - 1] - time) < tolerance) {\n        return track.times.length - 1;\n      }\n      times[times.length - 1] = time;\n      times.set(track.times, 0);\n      values.set(track.values, 0);\n      values.set(interpolant.evaluate(time), track.values.length);\n      index = times.length - 1;\n    } else {\n      for (let i = 0; i < track.times.length; i++) {\n        if (Math.abs(track.times[i] - time) < tolerance) return i;\n        if (track.times[i] < time && track.times[i + 1] > time) {\n          times.set(track.times.slice(0, i + 1), 0);\n          times[i + 1] = time;\n          times.set(track.times.slice(i + 1), i + 2);\n          values.set(track.values.slice(0, (i + 1) * valueSize), 0);\n          values.set(interpolant.evaluate(time), (i + 1) * valueSize);\n          values.set(track.values.slice((i + 1) * valueSize), (i + 2) * valueSize);\n          index = i + 1;\n          break;\n        }\n      }\n    }\n    track.times = times;\n    track.values = values;\n    return index;\n  },\n  mergeMorphTargetTracks: function (clip, root) {\n    const tracks = [];\n    const mergedTracks = {};\n    const sourceTracks = clip.tracks;\n    for (let i = 0; i < sourceTracks.length; ++i) {\n      let sourceTrack = sourceTracks[i];\n      const sourceTrackBinding = PropertyBinding.parseTrackName(sourceTrack.name);\n      const sourceTrackNode = PropertyBinding.findNode(root, sourceTrackBinding.nodeName);\n      if (sourceTrackBinding.propertyName !== 'morphTargetInfluences' || sourceTrackBinding.propertyIndex === undefined) {\n        // Tracks that don't affect morph targets, or that affect all morph targets together, can be left as-is.\n        tracks.push(sourceTrack);\n        continue;\n      }\n      if (sourceTrack.createInterpolant !== sourceTrack.InterpolantFactoryMethodDiscrete && sourceTrack.createInterpolant !== sourceTrack.InterpolantFactoryMethodLinear) {\n        if (sourceTrack.createInterpolant.isInterpolantFactoryMethodGLTFCubicSpline) {\n          // This should never happen, because glTF morph target animations\n          // affect all targets already.\n          throw new Error('THREE.GLTFExporter: Cannot merge tracks with glTF CUBICSPLINE interpolation.');\n        }\n        console.warn('THREE.GLTFExporter: Morph target interpolation mode not yet supported. Using LINEAR instead.');\n        sourceTrack = sourceTrack.clone();\n        sourceTrack.setInterpolation(InterpolateLinear);\n      }\n      const targetCount = sourceTrackNode.morphTargetInfluences.length;\n      const targetIndex = sourceTrackNode.morphTargetDictionary[sourceTrackBinding.propertyIndex];\n      if (targetIndex === undefined) {\n        throw new Error('THREE.GLTFExporter: Morph target name not found: ' + sourceTrackBinding.propertyIndex);\n      }\n      let mergedTrack;\n\n      // If this is the first time we've seen this object, create a new\n      // track to store merged keyframe data for each morph target.\n      if (mergedTracks[sourceTrackNode.uuid] === undefined) {\n        mergedTrack = sourceTrack.clone();\n        const values = new mergedTrack.ValueBufferType(targetCount * mergedTrack.times.length);\n        for (let j = 0; j < mergedTrack.times.length; j++) {\n          values[j * targetCount + targetIndex] = mergedTrack.values[j];\n        }\n\n        // We need to take into consideration the intended target node\n        // of our original un-merged morphTarget animation.\n        mergedTrack.name = (sourceTrackBinding.nodeName || '') + '.morphTargetInfluences';\n        mergedTrack.values = values;\n        mergedTracks[sourceTrackNode.uuid] = mergedTrack;\n        tracks.push(mergedTrack);\n        continue;\n      }\n      const sourceInterpolant = sourceTrack.createInterpolant(new sourceTrack.ValueBufferType(1));\n      mergedTrack = mergedTracks[sourceTrackNode.uuid];\n\n      // For every existing keyframe of the merged track, write a (possibly\n      // interpolated) value from the source track.\n      for (let j = 0; j < mergedTrack.times.length; j++) {\n        mergedTrack.values[j * targetCount + targetIndex] = sourceInterpolant.evaluate(mergedTrack.times[j]);\n      }\n\n      // For every existing keyframe of the source track, write a (possibly\n      // new) keyframe to the merged track. Values from the previous loop may\n      // be written again, but keyframes are de-duplicated.\n      for (let j = 0; j < sourceTrack.times.length; j++) {\n        const keyframeIndex = this.insertKeyframe(mergedTrack, sourceTrack.times[j]);\n        mergedTrack.values[keyframeIndex * targetCount + targetIndex] = sourceTrack.values[j];\n      }\n    }\n    clip.tracks = tracks;\n    return clip;\n  }\n};\n\n/* @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * @param object {THREE.Object3D}\n * @return {boolean}\n */\nconst compatibleObject = object => {\n  // @TODO: Need properer variantMaterials format validation?\n  return object.material !== undefined &&\n  // easier than (!object.isMesh && !object.isLine &&\n  // !object.isPoints)\n  object.userData &&\n  // just in case\n  object.userData.variantMaterials &&\n  // Is this line costly?\n  !!Array.from(object.userData.variantMaterials.values()).filter(m => compatibleMaterial(m.material));\n};\n/**\n * @param material {THREE.Material}\n * @return {boolean}\n */\nconst compatibleMaterial = material => {\n  // @TODO: support multi materials?\n  return material && material.isMaterial && !Array.isArray(material);\n};\nclass GLTFExporterMaterialsVariantsExtension {\n  constructor(writer) {\n    this.writer = writer;\n    this.name = 'KHR_materials_variants';\n    this.variantNames = [];\n  }\n  beforeParse(objects) {\n    // Find all variant names and store them to the table\n    const variantNameSet = new Set();\n    for (const object of objects) {\n      object.traverse(o => {\n        if (!compatibleObject(o)) {\n          return;\n        }\n        const variantMaterials = o.userData.variantMaterials;\n        const variantDataMap = o.userData.variantData;\n        for (const [variantName, variantData] of variantDataMap) {\n          const variantMaterial = variantMaterials.get(variantData.index);\n          // Ignore unloaded variant materials\n          if (variantMaterial && compatibleMaterial(variantMaterial.material)) {\n            variantNameSet.add(variantName);\n          }\n        }\n      });\n    }\n    // We may want to sort?\n    variantNameSet.forEach(name => this.variantNames.push(name));\n  }\n  writeMesh(mesh, meshDef) {\n    if (!compatibleObject(mesh)) {\n      return;\n    }\n    const userData = mesh.userData;\n    const variantMaterials = userData.variantMaterials;\n    const variantDataMap = userData.variantData;\n    const mappingTable = new Map();\n    // Removes gaps in the variant indices list (caused by deleting variants).\n    const reIndexedVariants = new Map();\n    const variants = Array.from(variantDataMap.values()).sort((a, b) => {\n      return a.index - b.index;\n    });\n    for (const [i, variantData] of variants.entries()) {\n      reIndexedVariants.set(variantData.index, i);\n    }\n    for (const variantData of variantDataMap.values()) {\n      const variantInstance = variantMaterials.get(variantData.index);\n      if (!variantInstance || !compatibleMaterial(variantInstance.material)) {\n        continue;\n      }\n      const materialIndex = this.writer.processMaterial(variantInstance.material);\n      if (!mappingTable.has(materialIndex)) {\n        mappingTable.set(materialIndex, {\n          material: materialIndex,\n          variants: []\n        });\n      }\n      mappingTable.get(materialIndex).variants.push(reIndexedVariants.get(variantData.index));\n    }\n    const mappingsDef = Array.from(mappingTable.values()).map(m => {\n      return m.variants.sort((a, b) => a - b) && m;\n    }).sort((a, b) => a.material - b.material);\n    if (mappingsDef.length === 0) {\n      return;\n    }\n    const originalMaterialIndex = compatibleMaterial(userData.originalMaterial) ? this.writer.processMaterial(userData.originalMaterial) : -1;\n    for (const primitiveDef of meshDef.primitives) {\n      // Override primitiveDef.material with original material.\n      if (originalMaterialIndex >= 0) {\n        primitiveDef.material = originalMaterialIndex;\n      }\n      primitiveDef.extensions = primitiveDef.extensions || {};\n      primitiveDef.extensions[this.name] = {\n        mappings: mappingsDef\n      };\n    }\n  }\n  afterParse() {\n    if (this.variantNames.length === 0) {\n      return;\n    }\n    const root = this.writer.json;\n    root.extensions = root.extensions || {};\n    const variantsDef = this.variantNames.map(n => {\n      return {\n        name: n\n      };\n    });\n    root.extensions[this.name] = {\n      variants: variantsDef\n    };\n    this.writer.extensionsUsed[this.name] = true;\n  }\n}\nclass SessionLightProbe {\n  constructor(xrLight, renderer, lightProbe, environmentEstimation, estimationStartCallback) {\n    this.xrLight = xrLight;\n    this.renderer = renderer;\n    this.lightProbe = lightProbe;\n    this.xrWebGLBinding = null;\n    this.estimationStartCallback = estimationStartCallback;\n    this.frameCallback = this.onXRFrame.bind(this);\n    const session = renderer.xr.getSession();\n\n    // If the XRWebGLBinding class is available then we can also query an\n    // estimated reflection cube map.\n    if (environmentEstimation && 'XRWebGLBinding' in window) {\n      // This is the simplest way I know of to initialize a WebGL cubemap in Three.\n      const cubeRenderTarget = new WebGLCubeRenderTarget(16);\n      xrLight.environment = cubeRenderTarget.texture;\n      const gl = renderer.getContext();\n\n      // Ensure that we have any extensions needed to use the preferred cube map format.\n      switch (session.preferredReflectionFormat) {\n        case 'srgba8':\n          gl.getExtension('EXT_sRGB');\n          break;\n        case 'rgba16f':\n          gl.getExtension('OES_texture_half_float');\n          break;\n      }\n      this.xrWebGLBinding = new XRWebGLBinding(session, gl);\n      this.lightProbe.addEventListener('reflectionchange', () => {\n        this.updateReflection();\n      });\n    }\n\n    // Start monitoring the XR animation frame loop to look for lighting\n    // estimation changes.\n    session.requestAnimationFrame(this.frameCallback);\n  }\n  updateReflection() {\n    const textureProperties = this.renderer.properties.get(this.xrLight.environment);\n    if (textureProperties) {\n      const cubeMap = this.xrWebGLBinding.getReflectionCubeMap(this.lightProbe);\n      if (cubeMap) {\n        textureProperties.__webglTexture = cubeMap;\n        this.xrLight.environment.needsPMREMUpdate = true;\n      }\n    }\n  }\n  onXRFrame(time, xrFrame) {\n    // If either this obejct or the XREstimatedLight has been destroyed, stop\n    // running the frame loop.\n    if (!this.xrLight) {\n      return;\n    }\n    const session = xrFrame.session;\n    session.requestAnimationFrame(this.frameCallback);\n    const lightEstimate = xrFrame.getLightEstimate(this.lightProbe);\n    if (lightEstimate) {\n      // We can copy the estimate's spherical harmonics array directly into the light probe.\n      this.xrLight.lightProbe.sh.fromArray(lightEstimate.sphericalHarmonicsCoefficients);\n      this.xrLight.lightProbe.intensity = 1.0;\n\n      // For the directional light we have to normalize the color and set the scalar as the\n      // intensity, since WebXR can return color values that exceed 1.0.\n      const intensityScalar = Math.max(1.0, Math.max(lightEstimate.primaryLightIntensity.x, Math.max(lightEstimate.primaryLightIntensity.y, lightEstimate.primaryLightIntensity.z)));\n      this.xrLight.directionalLight.color.setRGB(lightEstimate.primaryLightIntensity.x / intensityScalar, lightEstimate.primaryLightIntensity.y / intensityScalar, lightEstimate.primaryLightIntensity.z / intensityScalar);\n      this.xrLight.directionalLight.intensity = intensityScalar;\n      this.xrLight.directionalLight.position.copy(lightEstimate.primaryLightDirection);\n      if (this.estimationStartCallback) {\n        this.estimationStartCallback();\n        this.estimationStartCallback = null;\n      }\n    }\n  }\n  dispose() {\n    this.xrLight = null;\n    this.renderer = null;\n    this.lightProbe = null;\n    this.xrWebGLBinding = null;\n  }\n}\nclass XREstimatedLight extends Group {\n  constructor(renderer, environmentEstimation = true) {\n    super();\n    this.lightProbe = new LightProbe();\n    this.lightProbe.intensity = 0;\n    this.add(this.lightProbe);\n    this.directionalLight = new DirectionalLight();\n    this.directionalLight.intensity = 0;\n    this.add(this.directionalLight);\n\n    // Will be set to a cube map in the SessionLightProbe if environment estimation is\n    // available and requested.\n    this.environment = null;\n    let sessionLightProbe = null;\n    let estimationStarted = false;\n    renderer.xr.addEventListener('sessionstart', () => {\n      const session = renderer.xr.getSession();\n      if ('requestLightProbe' in session) {\n        session.requestLightProbe({\n          reflectionFormat: session.preferredReflectionFormat\n        }).then(probe => {\n          sessionLightProbe = new SessionLightProbe(this, renderer, probe, environmentEstimation, () => {\n            estimationStarted = true;\n\n            // Fired to indicate that the estimated lighting values are now being updated.\n            this.dispatchEvent({\n              type: 'estimationstart'\n            });\n          });\n        });\n      }\n    });\n    renderer.xr.addEventListener('sessionend', () => {\n      if (sessionLightProbe) {\n        sessionLightProbe.dispose();\n        sessionLightProbe = null;\n      }\n      if (estimationStarted) {\n        // Fired to indicate that the estimated lighting values are no longer being updated.\n        this.dispatchEvent({\n          type: 'estimationend'\n        });\n      }\n    });\n\n    // Done inline to provide access to sessionLightProbe.\n    this.dispose = () => {\n      if (sessionLightProbe) {\n        sessionLightProbe.dispose();\n        sessionLightProbe = null;\n      }\n      this.remove(this.lightProbe);\n      this.lightProbe = null;\n      this.remove(this.directionalLight);\n      this.directionalLight = null;\n      this.environment = null;\n    };\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst SETTLING_TIME = 10000; // plenty long enough\nconst MIN_DECAY_MILLISECONDS = 0.001;\nconst DECAY_MILLISECONDS = 50;\n/**\n * The Damper class is a generic second-order critically damped system that does\n * one linear step of the desired length of time. The only parameter is\n * DECAY_MILLISECONDS. This common parameter makes all states converge at the\n * same rate regardless of scale. xNormalization is a number to provide the\n * rough scale of x, such that NIL_SPEED clamping also happens at roughly the\n * same convergence for all states.\n */\nclass Damper {\n  constructor(decayMilliseconds = DECAY_MILLISECONDS) {\n    this.velocity = 0;\n    this.naturalFrequency = 0;\n    this.setDecayTime(decayMilliseconds);\n  }\n  setDecayTime(decayMilliseconds) {\n    this.naturalFrequency = 1 / Math.max(MIN_DECAY_MILLISECONDS, decayMilliseconds);\n  }\n  update(x, xGoal, timeStepMilliseconds, xNormalization) {\n    const nilSpeed = 0.0002 * this.naturalFrequency;\n    if (x == null || xNormalization === 0) {\n      return xGoal;\n    }\n    if (x === xGoal && this.velocity === 0) {\n      return xGoal;\n    }\n    if (timeStepMilliseconds < 0) {\n      return x;\n    }\n    // Exact solution to a critically damped second-order system, where:\n    // acceleration = this.naturalFrequency * this.naturalFrequency * (xGoal\n    // - x) - 2 * this.naturalFrequency * this.velocity;\n    const deltaX = x - xGoal;\n    const intermediateVelocity = this.velocity + this.naturalFrequency * deltaX;\n    const intermediateX = deltaX + timeStepMilliseconds * intermediateVelocity;\n    const decay = Math.exp(-this.naturalFrequency * timeStepMilliseconds);\n    const newVelocity = (intermediateVelocity - this.naturalFrequency * intermediateX) * decay;\n    const acceleration = -this.naturalFrequency * (newVelocity + intermediateVelocity * decay);\n    if (Math.abs(newVelocity) < nilSpeed * Math.abs(xNormalization) && acceleration * deltaX >= 0) {\n      // This ensures the controls settle and stop calling this function instead\n      // of asymptotically approaching their goal.\n      this.velocity = 0;\n      return xGoal;\n    } else {\n      this.velocity = newVelocity;\n      return xGoal + intermediateX * decay;\n    }\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst RADIUS = 0.2;\nconst LINE_WIDTH = 0.03;\nconst MAX_OPACITY = 0.75;\nconst SEGMENTS = 12;\nconst DELTA_PHI = Math.PI / (2 * SEGMENTS);\nconst vector2$1 = new Vector2();\n/**\n * Adds a quarter-annulus of vertices to the array, centered on cornerX,\n * cornerY.\n */\nconst addCorner = (vertices, cornerX, cornerY) => {\n  let phi = cornerX > 0 ? cornerY > 0 ? 0 : -Math.PI / 2 : cornerY > 0 ? Math.PI / 2 : Math.PI;\n  for (let i = 0; i <= SEGMENTS; ++i) {\n    vertices.push(cornerX + (RADIUS - LINE_WIDTH) * Math.cos(phi), cornerY + (RADIUS - LINE_WIDTH) * Math.sin(phi), 0, cornerX + RADIUS * Math.cos(phi), cornerY + RADIUS * Math.sin(phi), 0);\n    phi += DELTA_PHI;\n  }\n};\n/**\n * This class is a set of two coincident planes. The first is just a cute box\n * outline with rounded corners and damped opacity to indicate the floor extents\n * of a scene. It is purposely larger than the scene's bounding box by RADIUS on\n * all sides so that small scenes are still visible / selectable. Its center is\n * actually carved out by vertices to ensure its fragment shader doesn't add\n * much time.\n *\n * The child plane is a simple plane with the same extents for use in hit\n * testing (translation is triggered when the touch hits the plane, rotation\n * otherwise).\n */\nclass PlacementBox extends Mesh {\n  constructor(scene, side) {\n    const geometry = new BufferGeometry();\n    const triangles = [];\n    const vertices = [];\n    const {\n      size,\n      boundingBox\n    } = scene;\n    const x = size.x / 2;\n    const y = (side === 'back' ? size.y : size.z) / 2;\n    addCorner(vertices, x, y);\n    addCorner(vertices, -x, y);\n    addCorner(vertices, -x, -y);\n    addCorner(vertices, x, -y);\n    const numVertices = vertices.length / 3;\n    for (let i = 0; i < numVertices - 2; i += 2) {\n      triangles.push(i, i + 1, i + 3, i, i + 3, i + 2);\n    }\n    const i = numVertices - 2;\n    triangles.push(i, i + 1, 1, i, 1, 0);\n    geometry.setAttribute('position', new Float32BufferAttribute(vertices, 3));\n    geometry.setIndex(triangles);\n    super(geometry);\n    this.side = side;\n    const material = this.material;\n    material.side = DoubleSide;\n    material.transparent = true;\n    material.opacity = 0;\n    this.goalOpacity = 0;\n    this.opacityDamper = new Damper();\n    this.hitPlane = new Mesh(new PlaneGeometry(2 * (x + RADIUS), 2 * (y + RADIUS)));\n    this.hitPlane.visible = false;\n    this.hitPlane.material.side = DoubleSide;\n    this.add(this.hitPlane);\n    // The box matches the dimensions of the plane (extra radius all around),\n    // but only the top is expanded by radius, not the bottom.\n    this.hitBox = new Mesh(new BoxGeometry(size.x + 2 * RADIUS, size.y + RADIUS, size.z + 2 * RADIUS));\n    this.hitBox.visible = false;\n    this.hitBox.material.side = DoubleSide;\n    this.add(this.hitBox);\n    boundingBox.getCenter(this.position);\n    switch (side) {\n      case 'bottom':\n        this.rotateX(-Math.PI / 2);\n        this.shadowHeight = boundingBox.min.y;\n        this.position.y = this.shadowHeight;\n        break;\n      case 'back':\n        this.shadowHeight = boundingBox.min.z;\n        this.position.z = this.shadowHeight;\n    }\n    scene.target.add(this);\n    this.hitBox.position.y = (size.y + RADIUS) / 2 + boundingBox.min.y;\n    scene.target.add(this.hitBox);\n    this.offsetHeight = 0;\n  }\n  /**\n   * Get the world hit position if the touch coordinates hit the box, and null\n   * otherwise. Pass the scene in to get access to its raycaster.\n   */\n  getHit(scene, screenX, screenY) {\n    vector2$1.set(screenX, -screenY);\n    this.hitPlane.visible = true;\n    const hitResult = scene.positionAndNormalFromPoint(vector2$1, this.hitPlane);\n    this.hitPlane.visible = false;\n    return hitResult == null ? null : hitResult.position;\n  }\n  getExpandedHit(scene, screenX, screenY) {\n    this.hitPlane.scale.set(1000, 1000, 1000);\n    this.hitPlane.updateMatrixWorld();\n    const hitResult = this.getHit(scene, screenX, screenY);\n    this.hitPlane.scale.set(1, 1, 1);\n    return hitResult;\n  }\n  controllerIntersection(scene, controller) {\n    this.hitBox.visible = true;\n    const hitResult = scene.hitFromController(controller, this.hitBox);\n    this.hitBox.visible = false;\n    return hitResult;\n  }\n  /**\n   * Offset the height of the box relative to the bottom of the scene. Positive\n   * is up, so generally only negative values are used.\n   */\n  set offsetHeight(offset) {\n    offset -= 0.001; // push 1 mm below shadow to avoid z-fighting\n    if (this.side === 'back') {\n      this.position.z = this.shadowHeight + offset;\n    } else {\n      this.position.y = this.shadowHeight + offset;\n    }\n  }\n  get offsetHeight() {\n    if (this.side === 'back') {\n      return this.position.z - this.shadowHeight;\n    } else {\n      return this.position.y - this.shadowHeight;\n    }\n  }\n  /**\n   * Set the box's visibility; it will fade in and out.\n   */\n  set show(visible) {\n    this.goalOpacity = visible ? MAX_OPACITY : 0;\n  }\n  /**\n   * Call on each frame with the frame delta to fade the box.\n   */\n  updateOpacity(delta) {\n    const material = this.material;\n    material.opacity = this.opacityDamper.update(material.opacity, this.goalOpacity, delta, 1);\n    this.visible = material.opacity > 0;\n  }\n  /**\n   * Call this to clean up Three's cache when you remove the box.\n   */\n  dispose() {\n    const {\n      geometry,\n      material\n    } = this.hitPlane;\n    geometry.dispose();\n    material.dispose();\n    this.hitBox.geometry.dispose();\n    this.hitBox.material.dispose();\n    this.geometry.dispose();\n    this.material.dispose();\n    this.hitBox.removeFromParent();\n    this.removeFromParent();\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst numberNode = (value, unit) => ({\n  type: 'number',\n  number: value,\n  unit\n});\n/**\n * Given a string representing a comma-separated set of CSS-like expressions,\n * parses and returns an array of ASTs that correspond to those expressions.\n *\n * Currently supported syntax includes:\n *\n *  - functions (top-level and nested)\n *  - calc() arithmetic operators\n *  - numbers with units\n *  - hexadecimal-encoded colors in 3, 6 or 8 digit form\n *  - idents\n *\n * All syntax is intended to match the parsing rules and semantics of the actual\n * CSS spec as closely as possible.\n *\n * @see https://www.w3.org/TR/CSS2/\n * @see https://www.w3.org/TR/css-values-3/\n */\nconst parseExpressions = (() => {\n  const cache = {};\n  const MAX_PARSE_ITERATIONS = 1000; // Arbitrarily large\n  return inputString => {\n    const cacheKey = inputString;\n    if (cacheKey in cache) {\n      return cache[cacheKey];\n    }\n    const expressions = [];\n    let parseIterations = 0;\n    while (inputString) {\n      if (++parseIterations > MAX_PARSE_ITERATIONS) {\n        // Avoid a potentially infinite loop due to typos:\n        inputString = '';\n        break;\n      }\n      const expressionParseResult = parseExpression(inputString);\n      const expression = expressionParseResult.nodes[0];\n      if (expression == null || expression.terms.length === 0) {\n        break;\n      }\n      expressions.push(expression);\n      inputString = expressionParseResult.remainingInput;\n    }\n    return cache[cacheKey] = expressions;\n  };\n})();\n/**\n * Parse a single expression. For the purposes of our supported syntax, an\n * expression is the set of semantically meaningful terms that appear before the\n * next comma, or between the parens of a function invocation.\n */\nconst parseExpression = (() => {\n  const IS_IDENT_RE = /^(\\-\\-|[a-z\\u0240-\\uffff])/i;\n  const IS_OPERATOR_RE = /^([\\*\\+\\/]|[\\-]\\s)/i;\n  const IS_EXPRESSION_END_RE = /^[\\),]/;\n  const FUNCTION_ARGUMENTS_FIRST_TOKEN = '(';\n  const HEX_FIRST_TOKEN = '#';\n  return inputString => {\n    const terms = [];\n    while (inputString.length) {\n      inputString = inputString.trim();\n      if (IS_EXPRESSION_END_RE.test(inputString)) {\n        break;\n      } else if (inputString[0] === FUNCTION_ARGUMENTS_FIRST_TOKEN) {\n        const {\n          nodes,\n          remainingInput\n        } = parseFunctionArguments(inputString);\n        inputString = remainingInput;\n        terms.push({\n          type: 'function',\n          name: {\n            type: 'ident',\n            value: 'calc'\n          },\n          arguments: nodes\n        });\n      } else if (IS_IDENT_RE.test(inputString)) {\n        const identParseResult = parseIdent(inputString);\n        const identNode = identParseResult.nodes[0];\n        inputString = identParseResult.remainingInput;\n        if (inputString[0] === FUNCTION_ARGUMENTS_FIRST_TOKEN) {\n          const {\n            nodes,\n            remainingInput\n          } = parseFunctionArguments(inputString);\n          terms.push({\n            type: 'function',\n            name: identNode,\n            arguments: nodes\n          });\n          inputString = remainingInput;\n        } else {\n          terms.push(identNode);\n        }\n      } else if (IS_OPERATOR_RE.test(inputString)) {\n        // Operators are always a single character, so just pluck them out:\n        terms.push({\n          type: 'operator',\n          value: inputString[0]\n        });\n        inputString = inputString.slice(1);\n      } else {\n        const {\n          nodes,\n          remainingInput\n        } = inputString[0] === HEX_FIRST_TOKEN ? parseHex(inputString) : parseNumber(inputString);\n        // The remaining string may not have had any meaningful content. Exit\n        // early if this is the case:\n        if (nodes.length === 0) {\n          break;\n        }\n        terms.push(nodes[0]);\n        inputString = remainingInput;\n      }\n    }\n    return {\n      nodes: [{\n        type: 'expression',\n        terms\n      }],\n      remainingInput: inputString\n    };\n  };\n})();\n/**\n * An ident is something like a function name or the keyword \"auto\".\n */\nconst parseIdent = (() => {\n  const NOT_IDENT_RE = /[^a-z0-9_\\-\\u0240-\\uffff]/i;\n  return inputString => {\n    const match = inputString.match(NOT_IDENT_RE);\n    const ident = match == null ? inputString : inputString.substr(0, match.index);\n    const remainingInput = match == null ? '' : inputString.substr(match.index);\n    return {\n      nodes: [{\n        type: 'ident',\n        value: ident\n      }],\n      remainingInput\n    };\n  };\n})();\n/**\n * Parses a number. A number value can be expressed with an integer or\n * non-integer syntax, and usually includes a unit (but does not strictly\n * require one for our purposes).\n */\nconst parseNumber = (() => {\n  // @see https://www.w3.org/TR/css-syntax/#number-token-diagram\n  const VALUE_RE = /[\\+\\-]?(\\d+[\\.]\\d+|\\d+|[\\.]\\d+)([eE][\\+\\-]?\\d+)?/;\n  const UNIT_RE = /^[a-z%]+/i;\n  const ALLOWED_UNITS = /^(m|mm|cm|rad|deg|[%])$/;\n  return inputString => {\n    const valueMatch = inputString.match(VALUE_RE);\n    const value = valueMatch == null ? '0' : valueMatch[0];\n    inputString = value == null ? inputString : inputString.slice(value.length);\n    const unitMatch = inputString.match(UNIT_RE);\n    let unit = unitMatch != null && unitMatch[0] !== '' ? unitMatch[0] : null;\n    const remainingInput = unitMatch == null ? inputString : inputString.slice(unit.length);\n    if (unit != null && !ALLOWED_UNITS.test(unit)) {\n      unit = null;\n    }\n    return {\n      nodes: [{\n        type: 'number',\n        number: parseFloat(value) || 0,\n        unit: unit\n      }],\n      remainingInput\n    };\n  };\n})();\n/**\n * Parses a hexadecimal-encoded color in 3, 6 or 8 digit form.\n */\nconst parseHex = (() => {\n  // TODO(cdata): right now we don't actually enforce the number of digits\n  const HEX_RE = /^[a-f0-9]*/i;\n  return inputString => {\n    inputString = inputString.slice(1).trim();\n    const hexMatch = inputString.match(HEX_RE);\n    const nodes = hexMatch == null ? [] : [{\n      type: 'hex',\n      value: hexMatch[0]\n    }];\n    return {\n      nodes,\n      remainingInput: hexMatch == null ? inputString : inputString.slice(hexMatch[0].length)\n    };\n  };\n})();\n/**\n * Parses arguments passed to a function invocation (e.g., the expressions\n * within a matched set of parens).\n */\nconst parseFunctionArguments = inputString => {\n  const expressionNodes = [];\n  // Consume the opening paren\n  inputString = inputString.slice(1).trim();\n  while (inputString.length) {\n    const expressionParseResult = parseExpression(inputString);\n    expressionNodes.push(expressionParseResult.nodes[0]);\n    inputString = expressionParseResult.remainingInput.trim();\n    if (inputString[0] === ',') {\n      inputString = inputString.slice(1).trim();\n    } else if (inputString[0] === ')') {\n      // Consume the closing paren and stop parsing\n      inputString = inputString.slice(1);\n      break;\n    }\n  }\n  return {\n    nodes: expressionNodes,\n    remainingInput: inputString\n  };\n};\nconst $visitedTypes = Symbol('visitedTypes');\n/**\n * An ASTWalker walks an array of ASTs such as the type produced by\n * parseExpressions and invokes a callback for a configured set of nodes that\n * the user wishes to \"visit\" during the walk.\n */\nclass ASTWalker {\n  constructor(visitedTypes) {\n    this[$visitedTypes] = visitedTypes;\n  }\n  /**\n   * Walk the given set of ASTs, and invoke the provided callback for nodes that\n   * match the filtered set that the ASTWalker was constructed with.\n   */\n  walk(ast, callback) {\n    const remaining = ast.slice();\n    while (remaining.length) {\n      const next = remaining.shift();\n      if (this[$visitedTypes].indexOf(next.type) > -1) {\n        callback(next);\n      }\n      switch (next.type) {\n        case 'expression':\n          remaining.unshift(...next.terms);\n          break;\n        case 'function':\n          remaining.unshift(next.name, ...next.arguments);\n          break;\n      }\n    }\n  }\n}\nconst ZERO = Object.freeze({\n  type: 'number',\n  number: 0,\n  unit: null\n});\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * Ensures that a given number is expressed in radians. If the number is already\n * in radians, does nothing. If the value is in degrees, converts it to radians.\n * If the value has no specified unit, the unit is assumed to be radians. If the\n * value is not in radians or degrees, the value is resolved as 0 radians.\n *\n * Also accepts a second argument that is a default value to use if the input\n * numberNode number is NaN or Infinity.\n */\nconst degreesToRadians = (numberNode, fallbackRadianValue = 0) => {\n  let {\n    number,\n    unit\n  } = numberNode;\n  if (!isFinite(number)) {\n    number = fallbackRadianValue;\n    unit = 'rad';\n  } else if (numberNode.unit === 'rad' || numberNode.unit == null) {\n    return numberNode;\n  }\n  const valueIsDegrees = unit === 'deg' && number != null;\n  const value = valueIsDegrees ? number : 0;\n  const radians = value * Math.PI / 180;\n  return {\n    type: 'number',\n    number: radians,\n    unit: 'rad'\n  };\n};\n/**\n * Converts a given length to meters. Currently supported input units are\n * meters, centimeters and millimeters.\n *\n * Also accepts a second argument that is a default value to use if the input\n * numberNode number is NaN or Infinity.\n */\nconst lengthToBaseMeters = (numberNode, fallbackMeterValue = 0) => {\n  let {\n    number,\n    unit\n  } = numberNode;\n  if (!isFinite(number)) {\n    number = fallbackMeterValue;\n    unit = 'm';\n  } else if (numberNode.unit === 'm') {\n    return numberNode;\n  }\n  let scale;\n  switch (unit) {\n    default:\n      scale = 1;\n      break;\n    case 'cm':\n      scale = 1 / 100;\n      break;\n    case 'mm':\n      scale = 1 / 1000;\n      break;\n  }\n  const value = scale * number;\n  return {\n    type: 'number',\n    number: value,\n    unit: 'm'\n  };\n};\n/**\n * Normalizes the unit of a given input number so that it is expressed in a\n * preferred unit. For length nodes, the return value will be expressed in\n * meters. For angle nodes, the return value will be expressed in radians.\n *\n * Also takes a fallback number that is used when the number value is not a\n * valid number or when the unit of the given number cannot be normalized.\n */\nconst normalizeUnit = (() => {\n  const identity = node => node;\n  const unitNormalizers = {\n    'rad': identity,\n    'deg': degreesToRadians,\n    'm': identity,\n    'mm': lengthToBaseMeters,\n    'cm': lengthToBaseMeters\n  };\n  return (node, fallback = ZERO) => {\n    if (!isFinite(node.number)) {\n      node.number = fallback.number;\n      node.unit = fallback.unit;\n    }\n    const {\n      unit\n    } = node;\n    if (unit == null) {\n      return node;\n    }\n    const normalize = unitNormalizers[unit];\n    if (normalize == null) {\n      return fallback;\n    }\n    return normalize(node);\n  };\n})();\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar _a$6, _b$6, _c$4;\nconst $evaluate = Symbol('evaluate');\nconst $lastValue = Symbol('lastValue');\n/**\n * An Evaluator is used to derive a computed style from part (or all) of a CSS\n * expression AST. This construct is particularly useful for complex ASTs\n * containing function calls such as calc, var and env. Such styles could be\n * costly to re-evaluate on every frame (and in some cases we may try to do\n * that). The Evaluator construct allows us to mark sub-trees of the AST as\n * constant, so that only the dynamic parts are re-evaluated. It also separates\n * one-time AST preparation work from work that necessarily has to happen upon\n * each evaluation.\n */\nclass Evaluator {\n  constructor() {\n    this[_a$6] = null;\n  }\n  /**\n   * An Evaluatable is a NumberNode or an Evaluator that evaluates a NumberNode\n   * as the result of invoking its evaluate method. This is mainly used to\n   * ensure that CSS function nodes are cast to the corresponding Evaluators\n   * that will resolve the result of the function, but is also used to ensure\n   * that a percentage nested at arbitrary depth in the expression will always\n   * be evaluated against the correct basis.\n   */\n  static evaluatableFor(node, basis = ZERO) {\n    if (node instanceof Evaluator) {\n      return node;\n    }\n    if (node.type === 'number') {\n      if (node.unit === '%') {\n        return new PercentageEvaluator(node, basis);\n      }\n      return node;\n    }\n    switch (node.name.value) {\n      case 'calc':\n        return new CalcEvaluator(node, basis);\n      case 'env':\n        return new EnvEvaluator(node);\n    }\n    return ZERO;\n  }\n  /**\n   * If the input is an Evaluator, returns the result of evaluating it.\n   * Otherwise, returns the input.\n   *\n   * This is a helper to aide in resolving a NumberNode without conditionally\n   * checking if the Evaluatable is an Evaluator everywhere.\n   */\n  static evaluate(evaluatable) {\n    if (evaluatable instanceof Evaluator) {\n      return evaluatable.evaluate();\n    }\n    return evaluatable;\n  }\n  /**\n   * If the input is an Evaluator, returns the value of its isConstant property.\n   * Returns true for all other input values.\n   */\n  static isConstant(evaluatable) {\n    if (evaluatable instanceof Evaluator) {\n      return evaluatable.isConstant;\n    }\n    return true;\n  }\n  /**\n   * This method applies a set of structured intrinsic metadata to an evaluated\n   * result from a parsed CSS-like string of expressions. Intrinsics provide\n   * sufficient metadata (e.g., basis values, analogs for keywords) such that\n   * omitted values in the input string can be backfilled, and keywords can be\n   * converted to concrete numbers.\n   *\n   * The result of applying intrinsics is a tuple of NumberNode values whose\n   * units match the units used by the basis of the intrinsics.\n   *\n   * The following is a high-level description of how intrinsics are applied:\n   *\n   *  1. Determine the value of 'auto' for the current term\n   *  2. If there is no corresponding input value for this term, substitute the\n   *     'auto' value.\n   *  3. If the term is an IdentNode, treat it as a keyword and perform the\n   *     appropriate substitution.\n   *  4. If the term is still null, fallback to the 'auto' value\n   *  5. If the term is a percentage, apply it to the basis and return that\n   *     value\n   *  6. Normalize the unit of the term\n   *  7. If the term's unit does not match the basis unit, return the basis\n   *     value\n   *  8. Return the term as is\n   */\n  static applyIntrinsics(evaluated, intrinsics) {\n    const {\n      basis,\n      keywords\n    } = intrinsics;\n    const {\n      auto\n    } = keywords;\n    return basis.map((basisNode, index) => {\n      // Use an auto value if we have it, otherwise the auto value is the basis:\n      const autoSubstituteNode = auto[index] == null ? basisNode : auto[index];\n      // If the evaluated nodes do not have a node at the current\n      // index, fallback to the \"auto\" substitute right away:\n      let evaluatedNode = evaluated[index] ? evaluated[index] : autoSubstituteNode;\n      // Any ident node is considered a keyword:\n      if (evaluatedNode.type === 'ident') {\n        const keyword = evaluatedNode.value;\n        // Substitute any keywords for concrete values first:\n        if (keyword in keywords) {\n          evaluatedNode = keywords[keyword][index];\n        }\n      }\n      // If we don't have a NumberNode at this point, fall back to whatever\n      // is specified for auto:\n      if (evaluatedNode == null || evaluatedNode.type === 'ident') {\n        evaluatedNode = autoSubstituteNode;\n      }\n      // For percentages, we always apply the percentage to the basis value:\n      if (evaluatedNode.unit === '%') {\n        return numberNode(evaluatedNode.number / 100 * basisNode.number, basisNode.unit);\n      }\n      // Otherwise, normalize whatever we have:\n      evaluatedNode = normalizeUnit(evaluatedNode, basisNode);\n      // If the normalized units do not match, return the basis as a fallback:\n      if (evaluatedNode.unit !== basisNode.unit) {\n        return basisNode;\n      }\n      // Finally, return the evaluated node with intrinsics applied:\n      return evaluatedNode;\n    });\n  }\n  /**\n   * If true, the Evaluator will only evaluate its AST one time. If false, the\n   * Evaluator will re-evaluate the AST each time that the public evaluate\n   * method is invoked.\n   */\n  get isConstant() {\n    return false;\n  }\n  /**\n   * Evaluate the Evaluator and return the result. If the Evaluator is constant,\n   * the corresponding AST will only be evaluated once, and the result of\n   * evaluating it the first time will be returned on all subsequent\n   * evaluations.\n   */\n  evaluate() {\n    if (!this.isConstant || this[$lastValue] == null) {\n      this[$lastValue] = this[$evaluate]();\n    }\n    return this[$lastValue];\n  }\n}\n_a$6 = $lastValue;\nconst $percentage = Symbol('percentage');\nconst $basis = Symbol('basis');\n/**\n * A PercentageEvaluator scales a given basis value by a given percentage value.\n * The evaluated result is always considered to be constant.\n */\nclass PercentageEvaluator extends Evaluator {\n  constructor(percentage, basis) {\n    super();\n    this[$percentage] = percentage;\n    this[$basis] = basis;\n  }\n  get isConstant() {\n    return true;\n  }\n  [$evaluate]() {\n    return numberNode(this[$percentage].number / 100 * this[$basis].number, this[$basis].unit);\n  }\n}\nconst $identNode = Symbol('identNode');\n/**\n * Evaluator for CSS-like env() functions. Currently, only one environment\n * variable is accepted as an argument for such functions: window-scroll-y.\n *\n * The env() Evaluator is explicitly dynamic because it always refers to\n * external state that changes as the user scrolls, so it should always be\n * re-evaluated to ensure we get the most recent value.\n *\n * Some important notes about this feature include:\n *\n *  - There is no such thing as a \"window-scroll-y\" CSS environment variable in\n *    any stable browser at the time that this comment is being written.\n *  - The actual CSS env() function accepts a second argument as a fallback for\n *    the case that the specified first argument isn't set; our syntax does not\n *    support this second argument.\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/CSS/env\n */\nclass EnvEvaluator extends Evaluator {\n  constructor(envFunction) {\n    super();\n    this[_b$6] = null;\n    const identNode = envFunction.arguments.length ? envFunction.arguments[0].terms[0] : null;\n    if (identNode != null && identNode.type === 'ident') {\n      this[$identNode] = identNode;\n    }\n  }\n  get isConstant() {\n    return false;\n  }\n  [(_b$6 = $identNode, $evaluate)]() {\n    if (this[$identNode] != null) {\n      switch (this[$identNode].value) {\n        case 'window-scroll-y':\n          const verticalScrollPosition = window.pageYOffset;\n          const verticalScrollMax = Math.max(document.body.scrollHeight, document.body.offsetHeight, document.documentElement.clientHeight, document.documentElement.scrollHeight, document.documentElement.offsetHeight);\n          const scrollY = verticalScrollPosition / (verticalScrollMax - window.innerHeight) || 0;\n          return {\n            type: 'number',\n            number: scrollY,\n            unit: null\n          };\n      }\n    }\n    return ZERO;\n  }\n}\nconst IS_MULTIPLICATION_RE = /[\\*\\/]/;\nconst $evaluator = Symbol('evaluator');\n/**\n * Evaluator for CSS-like calc() functions. Our implementation of calc()\n * evaluation currently support nested function calls, an unlimited number of\n * terms, and all four algebraic operators (+, -, * and /).\n *\n * The Evaluator is marked as constant unless the calc expression contains an\n * internal env expression at any depth, in which case it will be marked as\n * dynamic.\n *\n * @see https://www.w3.org/TR/css-values-3/#calc-syntax\n * @see https://developer.mozilla.org/en-US/docs/Web/CSS/calc\n */\nclass CalcEvaluator extends Evaluator {\n  constructor(calcFunction, basis = ZERO) {\n    super();\n    this[_c$4] = null;\n    if (calcFunction.arguments.length !== 1) {\n      return;\n    }\n    const terms = calcFunction.arguments[0].terms.slice();\n    const secondOrderTerms = [];\n    while (terms.length) {\n      const term = terms.shift();\n      if (secondOrderTerms.length > 0) {\n        const previousTerm = secondOrderTerms[secondOrderTerms.length - 1];\n        if (previousTerm.type === 'operator' && IS_MULTIPLICATION_RE.test(previousTerm.value)) {\n          const operator = secondOrderTerms.pop();\n          const leftValue = secondOrderTerms.pop();\n          if (leftValue == null) {\n            return;\n          }\n          secondOrderTerms.push(new OperatorEvaluator(operator, Evaluator.evaluatableFor(leftValue, basis), Evaluator.evaluatableFor(term, basis)));\n          continue;\n        }\n      }\n      secondOrderTerms.push(term.type === 'operator' ? term : Evaluator.evaluatableFor(term, basis));\n    }\n    while (secondOrderTerms.length > 2) {\n      const [left, operator, right] = secondOrderTerms.splice(0, 3);\n      if (operator.type !== 'operator') {\n        return;\n      }\n      secondOrderTerms.unshift(new OperatorEvaluator(operator, Evaluator.evaluatableFor(left, basis), Evaluator.evaluatableFor(right, basis)));\n    }\n    // There should only be one combined evaluator at this point:\n    if (secondOrderTerms.length === 1) {\n      this[$evaluator] = secondOrderTerms[0];\n    }\n  }\n  get isConstant() {\n    return this[$evaluator] == null || Evaluator.isConstant(this[$evaluator]);\n  }\n  [(_c$4 = $evaluator, $evaluate)]() {\n    return this[$evaluator] != null ? Evaluator.evaluate(this[$evaluator]) : ZERO;\n  }\n}\nconst $operator = Symbol('operator');\nconst $left = Symbol('left');\nconst $right = Symbol('right');\n/**\n * An Evaluator for the operators found inside CSS calc() functions.\n * The evaluator accepts an operator and left/right operands. The operands can\n * be any valid expression term typically allowed inside a CSS calc function.\n *\n * As detail of this implementation, the only supported unit types are angles\n * expressed as radians or degrees, and lengths expressed as meters, centimeters\n * or millimeters.\n *\n * @see https://developer.mozilla.org/en-US/docs/Web/CSS/calc\n */\nclass OperatorEvaluator extends Evaluator {\n  constructor(operator, left, right) {\n    super();\n    this[$operator] = operator;\n    this[$left] = left;\n    this[$right] = right;\n  }\n  get isConstant() {\n    return Evaluator.isConstant(this[$left]) && Evaluator.isConstant(this[$right]);\n  }\n  [$evaluate]() {\n    const leftNode = normalizeUnit(Evaluator.evaluate(this[$left]));\n    const rightNode = normalizeUnit(Evaluator.evaluate(this[$right]));\n    const {\n      number: leftValue,\n      unit: leftUnit\n    } = leftNode;\n    const {\n      number: rightValue,\n      unit: rightUnit\n    } = rightNode;\n    // Disallow operations for mismatched normalized units e.g., m and rad:\n    if (rightUnit != null && leftUnit != null && rightUnit != leftUnit) {\n      return ZERO;\n    }\n    // NOTE(cdata): rules for calc type checking are defined here\n    // https://drafts.csswg.org/css-values-3/#calc-type-checking\n    // This is a simplification and may not hold up once we begin to support\n    // additional unit types:\n    const unit = leftUnit || rightUnit;\n    let value;\n    switch (this[$operator].value) {\n      case '+':\n        value = leftValue + rightValue;\n        break;\n      case '-':\n        value = leftValue - rightValue;\n        break;\n      case '/':\n        value = leftValue / rightValue;\n        break;\n      case '*':\n        value = leftValue * rightValue;\n        break;\n      default:\n        return ZERO;\n    }\n    return {\n      type: 'number',\n      number: value,\n      unit\n    };\n  }\n}\nconst $evaluatables = Symbol('evaluatables');\nconst $intrinsics = Symbol('intrinsics');\n/**\n * A VectorEvaluator evaluates a series of numeric terms that usually represent\n * a data structure such as a multi-dimensional vector or a spherical\n *\n * The form of the evaluator's result is determined by the Intrinsics that are\n * given to it when it is constructed. For example, spherical intrinsics would\n * establish two angle terms and a length term, so the result of evaluating the\n * evaluator that is configured with spherical intrinsics is a three element\n * array where the first two elements represent angles in radians and the third\n * element representing a length in meters.\n */\nclass StyleEvaluator extends Evaluator {\n  constructor(expressions, intrinsics) {\n    super();\n    this[$intrinsics] = intrinsics;\n    const firstExpression = expressions[0];\n    const terms = firstExpression != null ? firstExpression.terms : [];\n    this[$evaluatables] = intrinsics.basis.map((basisNode, index) => {\n      const term = terms[index];\n      if (term == null) {\n        return {\n          type: 'ident',\n          value: 'auto'\n        };\n      }\n      if (term.type === 'ident') {\n        return term;\n      }\n      return Evaluator.evaluatableFor(term, basisNode);\n    });\n  }\n  get isConstant() {\n    for (const evaluatable of this[$evaluatables]) {\n      if (!Evaluator.isConstant(evaluatable)) {\n        return false;\n      }\n    }\n    return true;\n  }\n  [$evaluate]() {\n    const evaluated = this[$evaluatables].map(evaluatable => Evaluator.evaluate(evaluatable));\n    return Evaluator.applyIntrinsics(evaluated, this[$intrinsics]).map(numberNode => numberNode.number);\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar _a$5, _b$5, _c$3, _d$2;\nconst $instances = Symbol('instances');\nconst $activateListener = Symbol('activateListener');\nconst $deactivateListener = Symbol('deactivateListener');\nconst $notifyInstances = Symbol('notifyInstances');\nconst $notify = Symbol('notify');\nconst $scrollCallback = Symbol('callback');\n/**\n * This internal helper is intended to work as a reference-counting manager of\n * scroll event listeners. Only one scroll listener is ever registered for all\n * instances of the class, and when the last ScrollObserver \"disconnects\", that\n * event listener is removed. This spares us from thrashing\n * the {add,remove}EventListener API (the binding cost of these methods has been\n * known to show up in performance analyses) as well as potential memory leaks.\n */\nclass ScrollObserver {\n  constructor(callback) {\n    this[$scrollCallback] = callback;\n  }\n  static [$notifyInstances]() {\n    for (const instance of ScrollObserver[$instances]) {\n      instance[$notify]();\n    }\n  }\n  static [(_a$5 = $instances, $activateListener)]() {\n    window.addEventListener('scroll', this[$notifyInstances], {\n      passive: true\n    });\n  }\n  static [$deactivateListener]() {\n    window.removeEventListener('scroll', this[$notifyInstances]);\n  }\n  /**\n   * Listen for scroll events. The configured callback (passed to the\n   * constructor) will be invoked for subsequent global scroll events.\n   */\n  observe() {\n    if (ScrollObserver[$instances].size === 0) {\n      ScrollObserver[$activateListener]();\n    }\n    ScrollObserver[$instances].add(this);\n  }\n  /**\n   * Stop listening for scroll events.\n   */\n  disconnect() {\n    ScrollObserver[$instances].delete(this);\n    if (ScrollObserver[$instances].size === 0) {\n      ScrollObserver[$deactivateListener]();\n    }\n  }\n  [$notify]() {\n    this[$scrollCallback]();\n  }\n}\nScrollObserver[_a$5] = new Set();\nconst $computeStyleCallback = Symbol('computeStyleCallback');\nconst $astWalker = Symbol('astWalker');\nconst $dependencies = Symbol('dependencies');\nconst $onScroll = Symbol('onScroll');\n/**\n * The StyleEffector is configured with a callback that will be invoked at the\n * optimal time that some array of CSS expression ASTs ought to be evaluated.\n *\n * For example, our CSS-like expression syntax supports usage of the env()\n * function to incorporate the current top-level scroll position into a CSS\n * expression: env(window-scroll-y).\n *\n * This \"environment variable\" will change dynamically as the user scrolls the\n * page. If an AST contains such a usage of env(), we would have to evaluate the\n * AST on every frame in order to be sure that the computed style stays up to\n * date.\n *\n * The StyleEffector spares us from evaluating the expressions on every frame by\n * correlating specific parts of an AST with observers of the external effects\n * that they refer to (if any). So, if the AST contains env(window-scroll-y),\n * the StyleEffector manages the lifetime of a global scroll event listener and\n * notifies the user at the optimal time to evaluate the computed style.\n */\nclass StyleEffector {\n  constructor(callback) {\n    this[_b$5] = {};\n    this[_c$3] = new ASTWalker(['function']);\n    this[_d$2] = () => {\n      this[$computeStyleCallback]({\n        relatedState: 'window-scroll'\n      });\n    };\n    this[$computeStyleCallback] = callback;\n  }\n  /**\n   * Sets the expressions that govern when the StyleEffector callback will be\n   * invoked.\n   */\n  observeEffectsFor(ast) {\n    const newDependencies = {};\n    const oldDependencies = this[$dependencies];\n    this[$astWalker].walk(ast, functionNode => {\n      const {\n        name\n      } = functionNode;\n      const firstArgument = functionNode.arguments[0];\n      const firstTerm = firstArgument.terms[0];\n      if (name.value !== 'env' || firstTerm == null || firstTerm.type !== 'ident') {\n        return;\n      }\n      switch (firstTerm.value) {\n        case 'window-scroll-y':\n          if (newDependencies['window-scroll'] == null) {\n            const observer = 'window-scroll' in oldDependencies ? oldDependencies['window-scroll'] : new ScrollObserver(this[$onScroll]);\n            observer.observe();\n            delete oldDependencies['window-scroll'];\n            newDependencies['window-scroll'] = observer;\n          }\n          break;\n      }\n    });\n    for (const environmentState in oldDependencies) {\n      const observer = oldDependencies[environmentState];\n      observer.disconnect();\n    }\n    this[$dependencies] = newDependencies;\n  }\n  /**\n   * Disposes of the StyleEffector by disconnecting all observers of external\n   * effects.\n   */\n  dispose() {\n    for (const environmentState in this[$dependencies]) {\n      const observer = this[$dependencies][environmentState];\n      observer.disconnect();\n    }\n  }\n}\n_b$5 = $dependencies, _c$3 = $astWalker, _d$2 = $onScroll;\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * The @style decorator is responsible for coordinating the conversion of a\n * CSS-like string property value into numbers that can be applied to\n * lower-level constructs. It also can optionally manage the lifecycle of a\n * StyleEffector which allows automatic updates for styles that use env() or\n * var() functions.\n *\n * The decorator is configured with Intrinsics and the property key for a\n * method that handles updates. The named update handler is invoked with the\n * result of parsing and evaluating the raw property string value. The format of\n * the evaluated result is derived from the basis of the configured Intrinsics,\n * and is always an array of numbers of fixed length.\n *\n * NOTE: This decorator depends on the property updating mechanism defined by\n * UpdatingElement as exported by the lit-element module. That means it *must*\n * be used in conjunction with the @property decorator, or equivalent\n * JavaScript.\n *\n * Supported configurations are:\n *\n *  - `intrinsics`: An Intrinsics struct that describes how to interpret a\n * serialized style attribute. For more detail on intrinsics see\n * ./styles/evaluators.ts\n *  - `updateHandler`: A string or Symbol that is the key of a method to be\n * invoked with the result of parsing and evaluating a serialized style string.\n *  - `observeEffects`: Optional, if set to true then styles that use env() will\n * cause their update handlers to be invoked every time the corresponding\n * environment variable changes (even if the style attribute itself remains\n * static).\n */\nconst style = config => {\n  const observeEffects = config.observeEffects || false;\n  const getIntrinsics = config.intrinsics instanceof Function ? config.intrinsics : () => config.intrinsics;\n  return (proto, propertyName) => {\n    const originalUpdated = proto.updated;\n    const originalConnectedCallback = proto.connectedCallback;\n    const originalDisconnectedCallback = proto.disconnectedCallback;\n    const $styleEffector = Symbol(`${propertyName}StyleEffector`);\n    const $styleEvaluator = Symbol(`${propertyName}StyleEvaluator`);\n    const $updateEvaluator = Symbol(`${propertyName}UpdateEvaluator`);\n    const $evaluateAndSync = Symbol(`${propertyName}EvaluateAndSync`);\n    Object.defineProperties(proto, {\n      [$styleEffector]: {\n        value: null,\n        writable: true\n      },\n      [$styleEvaluator]: {\n        value: null,\n        writable: true\n      },\n      [$updateEvaluator]: {\n        value: function () {\n          const ast = parseExpressions(this[propertyName]);\n          this[$styleEvaluator] = new StyleEvaluator(ast, getIntrinsics(this));\n          if (this[$styleEffector] == null && observeEffects) {\n            this[$styleEffector] = new StyleEffector(() => this[$evaluateAndSync]());\n          }\n          if (this[$styleEffector] != null) {\n            this[$styleEffector].observeEffectsFor(ast);\n          }\n        }\n      },\n      [$evaluateAndSync]: {\n        value: function () {\n          if (this[$styleEvaluator] == null) {\n            return;\n          }\n          const result = this[$styleEvaluator].evaluate();\n          // @see https://github.com/microsoft/TypeScript/pull/30769\n          // @see https://github.com/Microsoft/TypeScript/issues/1863\n          this[config.updateHandler](result);\n        }\n      },\n      updated: {\n        value: function (changedProperties) {\n          // Always invoke updates to styles first. This gives a class that\n          // uses this decorator the opportunity to override the effect, or\n          // respond to it, in its own implementation of `updated`.\n          if (changedProperties.has(propertyName)) {\n            this[$updateEvaluator]();\n            this[$evaluateAndSync]();\n          }\n          originalUpdated.call(this, changedProperties);\n        }\n      },\n      connectedCallback: {\n        value: function () {\n          originalConnectedCallback.call(this);\n          this.requestUpdate(propertyName, this[propertyName]);\n        }\n      },\n      disconnectedCallback: {\n        value: function () {\n          originalDisconnectedCallback.call(this);\n          if (this[$styleEffector] != null) {\n            this[$styleEffector].dispose();\n            this[$styleEffector] = null;\n          }\n        }\n      }\n    });\n  };\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// Adapted from https://gist.github.com/gre/1650294\nconst easeInOutQuad = t => t < .5 ? 2 * t * t : -1 + (4 - 2 * t) * t;\n/**\n * Creates a TimingFunction that uses a given ease to interpolate between\n * two configured number values.\n */\nconst interpolate = (start, end, ease = easeInOutQuad) => time => start + (end - start) * ease(time);\n/**\n * Creates a TimingFunction that interpolates through a weighted list\n * of other TimingFunctions (\"tracks\"). Tracks are interpolated in order, and\n * allocated a percentage of the total time based on their relative weight.\n */\nconst sequence = (tracks, weights) => {\n  const cumulativeSum = sum => value => sum += value;\n  const times = weights.map(cumulativeSum(0));\n  return time => {\n    time = clamp(time, 0, 1);\n    time *= times[times.length - 1];\n    const i = times.findIndex(val => val >= time);\n    const start = i < 1 ? 0 : times[i - 1];\n    const end = times[i];\n    return tracks[i]((time - start) / (end - start));\n  };\n};\n/**\n * Creates a \"timeline\" TimingFunction out of an initial value and a series of\n * Keyframes. The timeline function accepts value from 0-1 and returns the\n * current value based on keyframe interpolation across the total number of\n * frames. Frames are only used to indicate the relative length of each keyframe\n * transition, so interpolated values will be computed for fractional frames.\n */\nconst timeline = path => {\n  const tracks = [];\n  const weights = [];\n  let lastValue = path.initialValue;\n  for (let i = 0; i < path.keyframes.length; ++i) {\n    const keyframe = path.keyframes[i];\n    const {\n      value,\n      frames\n    } = keyframe;\n    const ease = keyframe.ease || easeInOutQuad;\n    const track = interpolate(lastValue, value, ease);\n    tracks.push(track);\n    weights.push(frames);\n    lastValue = value;\n  }\n  return sequence(tracks, weights);\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate$6 = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n// NOTE(cdata): The following \"animation\" timing functions are deliberately\n// being used in favor of CSS animations. In Safari 12.1 and 13, CSS animations\n// would cause the interaction prompt to glitch unexpectedly\n// @see https://github.com/google/model-viewer/issues/839\nconst PROMPT_ANIMATION_TIME = 5000;\n// For timing purposes, a \"frame\" is a timing agnostic relative unit of time\n// and a \"value\" is a target value for the Frame.\nconst wiggle = timeline({\n  initialValue: 0,\n  keyframes: [{\n    frames: 5,\n    value: -1\n  }, {\n    frames: 1,\n    value: -1\n  }, {\n    frames: 8,\n    value: 1\n  }, {\n    frames: 1,\n    value: 1\n  }, {\n    frames: 5,\n    value: 0\n  }, {\n    frames: 18,\n    value: 0\n  }]\n});\nconst fade = timeline({\n  initialValue: 0,\n  keyframes: [{\n    frames: 1,\n    value: 1\n  }, {\n    frames: 5,\n    value: 1\n  }, {\n    frames: 1,\n    value: 0\n  }, {\n    frames: 6,\n    value: 0\n  }]\n});\nconst DEFAULT_FOV_DEG = 30;\nconst DEFAULT_MIN_FOV_DEG = 12;\nconst DEFAULT_CAMERA_ORBIT = '0deg 75deg 105%';\nconst DEFAULT_CAMERA_TARGET = 'auto auto auto';\nconst DEFAULT_FIELD_OF_VIEW = 'auto';\nconst MINIMUM_RADIUS_RATIO = 2.2;\nconst AZIMUTHAL_QUADRANT_LABELS = ['front', 'right', 'back', 'left'];\nconst POLAR_TRIENT_LABELS = ['upper-', '', 'lower-'];\nconst DEFAULT_INTERACTION_PROMPT_THRESHOLD = 3000;\nconst INTERACTION_PROMPT = '. Use mouse, touch or arrow keys to move.';\nconst InteractionPromptStrategy = {\n  AUTO: 'auto',\n  NONE: 'none'\n};\nconst InteractionPromptStyle = {\n  BASIC: 'basic',\n  WIGGLE: 'wiggle'\n};\nconst TouchAction = {\n  PAN_Y: 'pan-y',\n  PAN_X: 'pan-x',\n  NONE: 'none'\n};\nconst fieldOfViewIntrinsics = () => {\n  return {\n    basis: [degreesToRadians(numberNode(DEFAULT_FOV_DEG, 'deg'))],\n    keywords: {\n      auto: [null]\n    }\n  };\n};\nconst minFieldOfViewIntrinsics = () => {\n  return {\n    basis: [degreesToRadians(numberNode(DEFAULT_MIN_FOV_DEG, 'deg'))],\n    keywords: {\n      auto: [null]\n    }\n  };\n};\nconst cameraOrbitIntrinsics = (() => {\n  const defaultTerms = parseExpressions(DEFAULT_CAMERA_ORBIT)[0].terms;\n  const theta = normalizeUnit(defaultTerms[0]);\n  const phi = normalizeUnit(defaultTerms[1]);\n  return element => {\n    const radius = element[$scene].idealCameraDistance();\n    return {\n      basis: [theta, phi, numberNode(radius, 'm')],\n      keywords: {\n        auto: [null, null, numberNode(105, '%')]\n      }\n    };\n  };\n})();\nconst minCameraOrbitIntrinsics = element => {\n  const radius = MINIMUM_RADIUS_RATIO * element[$scene].boundingSphere.radius;\n  return {\n    basis: [numberNode(-Infinity, 'rad'), numberNode(0, 'rad'), numberNode(radius, 'm')],\n    keywords: {\n      auto: [null, null, null]\n    }\n  };\n};\nconst maxCameraOrbitIntrinsics = element => {\n  const orbitIntrinsics = cameraOrbitIntrinsics(element);\n  const evaluator = new StyleEvaluator([], orbitIntrinsics);\n  const defaultRadius = evaluator.evaluate()[2];\n  return {\n    basis: [numberNode(Infinity, 'rad'), numberNode(Math.PI, 'rad'), numberNode(defaultRadius, 'm')],\n    keywords: {\n      auto: [null, null, null]\n    }\n  };\n};\nconst cameraTargetIntrinsics = element => {\n  const center = element[$scene].boundingBox.getCenter(new Vector3());\n  return {\n    basis: [numberNode(center.x, 'm'), numberNode(center.y, 'm'), numberNode(center.z, 'm')],\n    keywords: {\n      auto: [null, null, null]\n    }\n  };\n};\nconst HALF_PI = Math.PI / 2.0;\nconst THIRD_PI = Math.PI / 3.0;\nconst QUARTER_PI = HALF_PI / 2.0;\nconst TAU = 2.0 * Math.PI;\nconst $controls = Symbol('controls');\nconst $panElement = Symbol('panElement');\nconst $promptElement = Symbol('promptElement');\nconst $promptAnimatedContainer = Symbol('promptAnimatedContainer');\nconst $fingerAnimatedContainers = Symbol('fingerAnimatedContainers');\nconst $deferInteractionPrompt = Symbol('deferInteractionPrompt');\nconst $updateAria = Symbol('updateAria');\nconst $a11y = Symbol('a11y');\nconst $updateA11y = Symbol('updateA11y');\nconst $updateCameraForRadius = Symbol('updateCameraForRadius');\nconst $cancelPrompts = Symbol('cancelPrompts');\nconst $onChange = Symbol('onChange');\nconst $onPointerChange = Symbol('onPointerChange');\nconst $waitingToPromptUser = Symbol('waitingToPromptUser');\nconst $userHasInteracted = Symbol('userHasInteracted');\nconst $promptElementVisibleTime = Symbol('promptElementVisibleTime');\nconst $lastPromptOffset = Symbol('lastPromptOffset');\nconst $cancellationSource = Symbol('cancellationSource');\nconst $lastSpherical = Symbol('lastSpherical');\nconst $jumpCamera = Symbol('jumpCamera');\nconst $initialized = Symbol('initialized');\nconst $maintainThetaPhi = Symbol('maintainThetaPhi');\nconst $syncCameraOrbit = Symbol('syncCameraOrbit');\nconst $syncFieldOfView = Symbol('syncFieldOfView');\nconst $syncCameraTarget = Symbol('syncCameraTarget');\nconst $syncMinCameraOrbit = Symbol('syncMinCameraOrbit');\nconst $syncMaxCameraOrbit = Symbol('syncMaxCameraOrbit');\nconst $syncMinFieldOfView = Symbol('syncMinFieldOfView');\nconst $syncMaxFieldOfView = Symbol('syncMaxFieldOfView');\nconst ControlsMixin = ModelViewerElement => {\n  var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t;\n  class ControlsModelViewerElement extends ModelViewerElement {\n    constructor() {\n      super(...arguments);\n      this.cameraControls = false;\n      this.cameraOrbit = DEFAULT_CAMERA_ORBIT;\n      this.cameraTarget = DEFAULT_CAMERA_TARGET;\n      this.fieldOfView = DEFAULT_FIELD_OF_VIEW;\n      this.minCameraOrbit = 'auto';\n      this.maxCameraOrbit = 'auto';\n      this.minFieldOfView = 'auto';\n      this.maxFieldOfView = 'auto';\n      this.interactionPromptThreshold = DEFAULT_INTERACTION_PROMPT_THRESHOLD;\n      this.interactionPrompt = InteractionPromptStrategy.AUTO;\n      this.interactionPromptStyle = InteractionPromptStyle.WIGGLE;\n      this.orbitSensitivity = 1;\n      this.zoomSensitivity = 1;\n      this.panSensitivity = 1;\n      this.touchAction = TouchAction.NONE;\n      this.disableZoom = false;\n      this.disablePan = false;\n      this.disableTap = false;\n      this.interpolationDecay = DECAY_MILLISECONDS;\n      this.a11y = null;\n      this[_a] = this.shadowRoot.querySelector('.interaction-prompt');\n      this[_b] = this.shadowRoot.querySelector('#prompt');\n      this[_c] = [this.shadowRoot.querySelector('#finger0'), this.shadowRoot.querySelector('#finger1')];\n      this[_d] = this.shadowRoot.querySelector('.pan-target');\n      this[_e] = 0;\n      this[_f] = Infinity;\n      this[_g] = false;\n      this[_h] = false;\n      this[_j] = ChangeSource.AUTOMATIC;\n      this[_k] = new SmoothControls(this[$scene].camera, this[$userInputElement], this[$scene]);\n      this[_l] = new Spherical();\n      this[_m] = false;\n      this[_o] = false;\n      this[_p] = false;\n      this[_q] = {};\n      this[_r] = () => {\n        const source = this[$controls].changeSource;\n        this[$cancellationSource] = source;\n        if (source === ChangeSource.USER_INTERACTION) {\n          this[$userHasInteracted] = true;\n          this[$deferInteractionPrompt]();\n        }\n      };\n      this[_s] = () => {\n        this[$updateAria]();\n        this[$needsRender]();\n        const source = this[$controls].changeSource;\n        this.dispatchEvent(new CustomEvent('camera-change', {\n          detail: {\n            source\n          }\n        }));\n      };\n      this[_t] = event => {\n        this[$container].classList.toggle('pointer-tumbling', event.type === 'pointer-change-start');\n      };\n    }\n    get inputSensitivity() {\n      return this[$controls].inputSensitivity;\n    }\n    set inputSensitivity(value) {\n      this[$controls].inputSensitivity = value;\n    }\n    getCameraOrbit() {\n      const {\n        theta,\n        phi,\n        radius\n      } = this[$lastSpherical];\n      return {\n        theta,\n        phi,\n        radius,\n        toString() {\n          return `${this.theta}rad ${this.phi}rad ${this.radius}m`;\n        }\n      };\n    }\n    getCameraTarget() {\n      return toVector3D(this[$renderer].isPresenting ? this[$renderer].arRenderer.target : this[$scene].getDynamicTarget());\n    }\n    getFieldOfView() {\n      return this[$controls].getFieldOfView();\n    }\n    // Provided so user code does not have to parse these from attributes.\n    getMinimumFieldOfView() {\n      return this[$controls].options.minimumFieldOfView;\n    }\n    getMaximumFieldOfView() {\n      return this[$controls].options.maximumFieldOfView;\n    }\n    getIdealAspect() {\n      return this[$scene].idealAspect;\n    }\n    jumpCameraToGoal() {\n      this[$jumpCamera] = true;\n      this.requestUpdate($jumpCamera, false);\n    }\n    resetInteractionPrompt() {\n      this[$lastPromptOffset] = 0;\n      this[$promptElementVisibleTime] = Infinity;\n      this[$userHasInteracted] = false;\n      this[$waitingToPromptUser] = this.interactionPrompt === InteractionPromptStrategy.AUTO && this.cameraControls;\n    }\n    zoom(keyPresses) {\n      const event = new WheelEvent('wheel', {\n        deltaY: -30 * keyPresses\n      });\n      this[$userInputElement].dispatchEvent(event);\n    }\n    connectedCallback() {\n      super.connectedCallback();\n      this[$controls].addEventListener('user-interaction', this[$cancelPrompts]);\n      this[$controls].addEventListener('pointer-change-start', this[$onPointerChange]);\n      this[$controls].addEventListener('pointer-change-end', this[$onPointerChange]);\n    }\n    disconnectedCallback() {\n      super.disconnectedCallback();\n      this[$controls].removeEventListener('user-interaction', this[$cancelPrompts]);\n      this[$controls].removeEventListener('pointer-change-start', this[$onPointerChange]);\n      this[$controls].removeEventListener('pointer-change-end', this[$onPointerChange]);\n    }\n    updated(changedProperties) {\n      super.updated(changedProperties);\n      const controls = this[$controls];\n      const scene = this[$scene];\n      if (changedProperties.has('cameraControls')) {\n        if (this.cameraControls) {\n          controls.enableInteraction();\n          if (this.interactionPrompt === InteractionPromptStrategy.AUTO) {\n            this[$waitingToPromptUser] = true;\n          }\n        } else {\n          controls.disableInteraction();\n          this[$deferInteractionPrompt]();\n        }\n        this[$userInputElement].setAttribute('aria-label', this[$ariaLabel]);\n      }\n      if (changedProperties.has('disableZoom')) {\n        controls.disableZoom = this.disableZoom;\n      }\n      if (changedProperties.has('disablePan')) {\n        controls.enablePan = !this.disablePan;\n      }\n      if (changedProperties.has('disableTap')) {\n        controls.enableTap = !this.disableTap;\n      }\n      if (changedProperties.has('interactionPrompt') || changedProperties.has('cameraControls') || changedProperties.has('src')) {\n        if (this.interactionPrompt === InteractionPromptStrategy.AUTO && this.cameraControls && !this[$userHasInteracted]) {\n          this[$waitingToPromptUser] = true;\n        } else {\n          this[$deferInteractionPrompt]();\n        }\n      }\n      if (changedProperties.has('interactionPromptStyle')) {\n        this[$promptAnimatedContainer].style.opacity = this.interactionPromptStyle == InteractionPromptStyle.BASIC ? '1' : '0';\n      }\n      if (changedProperties.has('touchAction')) {\n        const touchAction = this.touchAction;\n        controls.applyOptions({\n          touchAction\n        });\n        controls.updateTouchActionStyle();\n      }\n      if (changedProperties.has('orbitSensitivity')) {\n        controls.orbitSensitivity = this.orbitSensitivity;\n      }\n      if (changedProperties.has('zoomSensitivity')) {\n        controls.zoomSensitivity = this.zoomSensitivity;\n      }\n      if (changedProperties.has('panSensitivity')) {\n        controls.panSensitivity = this.panSensitivity;\n      }\n      if (changedProperties.has('interpolationDecay')) {\n        controls.setDamperDecayTime(this.interpolationDecay);\n        scene.setTargetDamperDecayTime(this.interpolationDecay);\n      }\n      if (changedProperties.has('a11y')) {\n        this[$updateA11y]();\n      }\n      if (this[$jumpCamera] === true) {\n        Promise.resolve().then(() => {\n          controls.jumpToGoal();\n          scene.jumpToGoal();\n          this[$onChange]();\n          this[$jumpCamera] = false;\n        });\n      }\n    }\n    async updateFraming() {\n      const scene = this[$scene];\n      const oldFramedFoV = scene.adjustedFoV(scene.framedFoVDeg);\n      await scene.updateFraming();\n      const newFramedFoV = scene.adjustedFoV(scene.framedFoVDeg);\n      const zoom = this[$controls].getFieldOfView() / oldFramedFoV;\n      this[$controls].setFieldOfView(newFramedFoV * zoom);\n      this[$maintainThetaPhi] = true;\n      this.requestUpdate('maxFieldOfView');\n      this.requestUpdate('fieldOfView');\n      this.requestUpdate('minCameraOrbit');\n      this.requestUpdate('maxCameraOrbit');\n      this.requestUpdate('cameraOrbit');\n      await this.updateComplete;\n    }\n    interact(duration, finger0, finger1) {\n      const inputElement = this[$userInputElement];\n      const fingerElements = this[$fingerAnimatedContainers];\n      if (fingerElements[0].style.opacity === '1') {\n        console.warn('interact() failed because an existing interaction is running.');\n        return;\n      }\n      const xy = new Array();\n      xy.push({\n        x: timeline(finger0.x),\n        y: timeline(finger0.y)\n      });\n      const positions = [{\n        x: xy[0].x(0),\n        y: xy[0].y(0)\n      }];\n      if (finger1 != null) {\n        xy.push({\n          x: timeline(finger1.x),\n          y: timeline(finger1.y)\n        });\n        positions.push({\n          x: xy[1].x(0),\n          y: xy[1].y(0)\n        });\n      }\n      let startTime = performance.now();\n      const {\n        width,\n        height\n      } = this[$scene];\n      const rect = this.getBoundingClientRect();\n      const dispatchTouches = type => {\n        for (const [i, position] of positions.entries()) {\n          const {\n            style\n          } = fingerElements[i];\n          style.transform = `translateX(${width * position.x}px) translateY(${height * position.y}px)`;\n          if (type === 'pointerdown') {\n            style.opacity = '1';\n          } else if (type === 'pointerup') {\n            style.opacity = '0';\n          }\n          const init = {\n            pointerId: i - 5678,\n            pointerType: 'touch',\n            target: inputElement,\n            clientX: width * position.x + rect.x,\n            clientY: height * position.y + rect.y,\n            altKey: true // flag that this is not a user interaction\n          };\n          inputElement.dispatchEvent(new PointerEvent(type, init));\n        }\n      };\n      const moveTouches = () => {\n        // Cancel interaction if something else moves the camera or input is\n        // removed from the DOM.\n        const changeSource = this[$cancellationSource];\n        if (changeSource !== ChangeSource.AUTOMATIC || !inputElement.isConnected) {\n          for (const fingerElement of this[$fingerAnimatedContainers]) {\n            fingerElement.style.opacity = '0';\n          }\n          dispatchTouches('pointercancel');\n          this.dispatchEvent(new CustomEvent('interact-stopped', {\n            detail: {\n              source: changeSource\n            }\n          }));\n          document.removeEventListener('visibilitychange', onVisibilityChange);\n          return;\n        }\n        const time = Math.min(1, (performance.now() - startTime) / duration);\n        for (const [i, position] of positions.entries()) {\n          position.x = xy[i].x(time);\n          position.y = xy[i].y(time);\n        }\n        dispatchTouches('pointermove');\n        if (time < 1) {\n          requestAnimationFrame(moveTouches);\n        } else {\n          dispatchTouches('pointerup');\n          this.dispatchEvent(new CustomEvent('interact-stopped', {\n            detail: {\n              source: ChangeSource.AUTOMATIC\n            }\n          }));\n          document.removeEventListener('visibilitychange', onVisibilityChange);\n        }\n      };\n      const onVisibilityChange = () => {\n        let elapsed = 0;\n        if (document.visibilityState === 'hidden') {\n          elapsed = performance.now() - startTime;\n        } else {\n          startTime = performance.now() - elapsed;\n        }\n      };\n      document.addEventListener('visibilitychange', onVisibilityChange);\n      dispatchTouches('pointerdown');\n      this[$cancellationSource] = ChangeSource.AUTOMATIC;\n      requestAnimationFrame(moveTouches);\n    }\n    [(_a = $promptElement, _b = $promptAnimatedContainer, _c = $fingerAnimatedContainers, _d = $panElement, _e = $lastPromptOffset, _f = $promptElementVisibleTime, _g = $userHasInteracted, _h = $waitingToPromptUser, _j = $cancellationSource, _k = $controls, _l = $lastSpherical, _m = $jumpCamera, _o = $initialized, _p = $maintainThetaPhi, _q = $a11y, $syncFieldOfView)](style) {\n      const controls = this[$controls];\n      const scene = this[$scene];\n      scene.framedFoVDeg = style[0] * 180 / Math.PI;\n      controls.changeSource = ChangeSource.NONE;\n      controls.setFieldOfView(scene.adjustedFoV(scene.framedFoVDeg));\n      this[$cancelPrompts]();\n    }\n    [$syncCameraOrbit](style) {\n      const controls = this[$controls];\n      if (this[$maintainThetaPhi]) {\n        const {\n          theta,\n          phi\n        } = this.getCameraOrbit();\n        style[0] = theta;\n        style[1] = phi;\n        this[$maintainThetaPhi] = false;\n      }\n      controls.changeSource = ChangeSource.NONE;\n      controls.setOrbit(style[0], style[1], style[2]);\n      this[$cancelPrompts]();\n    }\n    [$syncMinCameraOrbit](style) {\n      this[$controls].applyOptions({\n        minimumAzimuthalAngle: style[0],\n        minimumPolarAngle: style[1],\n        minimumRadius: style[2]\n      });\n      this.jumpCameraToGoal();\n    }\n    [$syncMaxCameraOrbit](style) {\n      this[$controls].applyOptions({\n        maximumAzimuthalAngle: style[0],\n        maximumPolarAngle: style[1],\n        maximumRadius: style[2]\n      });\n      this[$updateCameraForRadius](style[2]);\n      this.jumpCameraToGoal();\n    }\n    [$syncMinFieldOfView](style) {\n      this[$controls].applyOptions({\n        minimumFieldOfView: style[0] * 180 / Math.PI\n      });\n      this.jumpCameraToGoal();\n    }\n    [$syncMaxFieldOfView](style) {\n      const fov = this[$scene].adjustedFoV(style[0] * 180 / Math.PI);\n      this[$controls].applyOptions({\n        maximumFieldOfView: fov\n      });\n      this.jumpCameraToGoal();\n    }\n    [$syncCameraTarget](style) {\n      const [x, y, z] = style;\n      if (!this[$renderer].arRenderer.isPresenting) {\n        this[$scene].setTarget(x, y, z);\n      }\n      this[$controls].changeSource = ChangeSource.NONE;\n      this[$renderer].arRenderer.updateTarget();\n      this[$cancelPrompts]();\n    }\n    [$tick](time, delta) {\n      super[$tick](time, delta);\n      if (this[$renderer].isPresenting || !this[$getModelIsVisible]()) {\n        return;\n      }\n      const controls = this[$controls];\n      const scene = this[$scene];\n      const now = performance.now();\n      if (this[$waitingToPromptUser]) {\n        if (this.loaded && now > this[$loadedTime] + this.interactionPromptThreshold) {\n          this[$waitingToPromptUser] = false;\n          this[$promptElementVisibleTime] = now;\n          this[$promptElement].classList.add('visible');\n        }\n      }\n      if (isFinite(this[$promptElementVisibleTime]) && this.interactionPromptStyle === InteractionPromptStyle.WIGGLE) {\n        const animationTime = (now - this[$promptElementVisibleTime]) / PROMPT_ANIMATION_TIME % 1;\n        const offset = wiggle(animationTime);\n        const opacity = fade(animationTime);\n        this[$promptAnimatedContainer].style.opacity = `${opacity}`;\n        if (offset !== this[$lastPromptOffset]) {\n          const xOffset = offset * scene.width * 0.05;\n          const deltaTheta = (offset - this[$lastPromptOffset]) * Math.PI / 16;\n          this[$promptAnimatedContainer].style.transform = `translateX(${xOffset}px)`;\n          controls.changeSource = ChangeSource.AUTOMATIC;\n          controls.adjustOrbit(deltaTheta, 0, 0);\n          this[$lastPromptOffset] = offset;\n        }\n      }\n      const cameraMoved = controls.update(time, delta);\n      const targetMoved = scene.updateTarget(delta);\n      if (cameraMoved || targetMoved) {\n        this[$onChange]();\n      }\n    }\n    [$deferInteractionPrompt]() {\n      // Effectively cancel the timer waiting for user interaction:\n      this[$waitingToPromptUser] = false;\n      this[$promptElement].classList.remove('visible');\n      this[$promptElementVisibleTime] = Infinity;\n    }\n    /**\n     * Updates the camera's near and far planes to enclose the scene when\n     * orbiting at the supplied radius.\n     */\n    [$updateCameraForRadius](radius) {\n      const maximumRadius = Math.max(this[$scene].farRadius(), radius);\n      const near = 0;\n      const far = Math.abs(2 * maximumRadius);\n      this[$controls].updateNearFar(near, far);\n    }\n    [$updateAria]() {\n      const {\n        theta,\n        phi\n      } = this[$controls].getCameraSpherical(this[$lastSpherical]);\n      const azimuthalQuadrant = (4 + Math.floor((theta % TAU + QUARTER_PI) / HALF_PI)) % 4;\n      const polarTrient = Math.floor(phi / THIRD_PI);\n      const azimuthalQuadrantLabel = AZIMUTHAL_QUADRANT_LABELS[azimuthalQuadrant];\n      const polarTrientLabel = POLAR_TRIENT_LABELS[polarTrient];\n      const position = `${polarTrientLabel}${azimuthalQuadrantLabel}`;\n      const key = position;\n      if (key in this[$a11y]) {\n        this[$updateStatus](this[$a11y][key]);\n      } else {\n        this[$updateStatus](`View from stage ${position}`);\n      }\n    }\n    get [$ariaLabel]() {\n      let interactionPrompt = INTERACTION_PROMPT;\n      if ('interaction-prompt' in this[$a11y]) {\n        interactionPrompt = `. ${this[$a11y]['interaction-prompt']}`;\n      }\n      return super[$ariaLabel].replace(/\\.$/, '') + (this.cameraControls ? interactionPrompt : '');\n    }\n    async [$onResize](event) {\n      const controls = this[$controls];\n      const scene = this[$scene];\n      const oldFramedFoV = scene.adjustedFoV(scene.framedFoVDeg);\n      // The super of $onResize may update the scene's adjustedFoV, so we\n      // compare the before and after to calculate the proper zoom.\n      super[$onResize](event);\n      const fovRatio = scene.adjustedFoV(scene.framedFoVDeg) / oldFramedFoV;\n      const fov = controls.getFieldOfView() * (isFinite(fovRatio) ? fovRatio : 1);\n      controls.updateAspect(this[$scene].aspect);\n      this.requestUpdate('maxFieldOfView', this.maxFieldOfView);\n      await this.updateComplete;\n      this[$controls].setFieldOfView(fov);\n      this.jumpCameraToGoal();\n    }\n    [$onModelLoad]() {\n      super[$onModelLoad]();\n      if (this[$initialized]) {\n        this[$maintainThetaPhi] = true;\n      } else {\n        this[$initialized] = true;\n      }\n      this.requestUpdate('maxFieldOfView', this.maxFieldOfView);\n      this.requestUpdate('fieldOfView', this.fieldOfView);\n      this.requestUpdate('minCameraOrbit', this.minCameraOrbit);\n      this.requestUpdate('maxCameraOrbit', this.maxCameraOrbit);\n      this.requestUpdate('cameraOrbit', this.cameraOrbit);\n      this.requestUpdate('cameraTarget', this.cameraTarget);\n      this.jumpCameraToGoal();\n    }\n    [(_r = $cancelPrompts, _s = $onChange, _t = $onPointerChange, $updateA11y)]() {\n      if (typeof this.a11y === 'string') {\n        if (this.a11y.startsWith('{')) {\n          try {\n            this[$a11y] = JSON.parse(this.a11y);\n          } catch (error) {\n            console.warn('Error parsing a11y JSON:', error);\n          }\n        } else if (this.a11y.length > 0) {\n          console.warn('Error not supported format, should be a JSON string:', this.a11y);\n        } else {\n          this[$a11y] = {};\n        }\n      } else if (typeof this.a11y === 'object' && this.a11y != null) {\n        this[$a11y] = Object.assign({}, this.a11y);\n      } else {\n        this[$a11y] = {};\n      }\n      this[$userInputElement].setAttribute('aria-label', this[$ariaLabel]);\n    }\n  }\n  __decorate$6([n$8({\n    type: Boolean,\n    attribute: 'camera-controls'\n  })], ControlsModelViewerElement.prototype, \"cameraControls\", void 0);\n  __decorate$6([style({\n    intrinsics: cameraOrbitIntrinsics,\n    observeEffects: true,\n    updateHandler: $syncCameraOrbit\n  }), n$8({\n    type: String,\n    attribute: 'camera-orbit',\n    hasChanged: () => true\n  })], ControlsModelViewerElement.prototype, \"cameraOrbit\", void 0);\n  __decorate$6([style({\n    intrinsics: cameraTargetIntrinsics,\n    observeEffects: true,\n    updateHandler: $syncCameraTarget\n  }), n$8({\n    type: String,\n    attribute: 'camera-target',\n    hasChanged: () => true\n  })], ControlsModelViewerElement.prototype, \"cameraTarget\", void 0);\n  __decorate$6([style({\n    intrinsics: fieldOfViewIntrinsics,\n    observeEffects: true,\n    updateHandler: $syncFieldOfView\n  }), n$8({\n    type: String,\n    attribute: 'field-of-view',\n    hasChanged: () => true\n  })], ControlsModelViewerElement.prototype, \"fieldOfView\", void 0);\n  __decorate$6([style({\n    intrinsics: minCameraOrbitIntrinsics,\n    updateHandler: $syncMinCameraOrbit\n  }), n$8({\n    type: String,\n    attribute: 'min-camera-orbit',\n    hasChanged: () => true\n  })], ControlsModelViewerElement.prototype, \"minCameraOrbit\", void 0);\n  __decorate$6([style({\n    intrinsics: maxCameraOrbitIntrinsics,\n    updateHandler: $syncMaxCameraOrbit\n  }), n$8({\n    type: String,\n    attribute: 'max-camera-orbit',\n    hasChanged: () => true\n  })], ControlsModelViewerElement.prototype, \"maxCameraOrbit\", void 0);\n  __decorate$6([style({\n    intrinsics: minFieldOfViewIntrinsics,\n    updateHandler: $syncMinFieldOfView\n  }), n$8({\n    type: String,\n    attribute: 'min-field-of-view',\n    hasChanged: () => true\n  })], ControlsModelViewerElement.prototype, \"minFieldOfView\", void 0);\n  __decorate$6([style({\n    intrinsics: fieldOfViewIntrinsics,\n    updateHandler: $syncMaxFieldOfView\n  }), n$8({\n    type: String,\n    attribute: 'max-field-of-view',\n    hasChanged: () => true\n  })], ControlsModelViewerElement.prototype, \"maxFieldOfView\", void 0);\n  __decorate$6([n$8({\n    type: Number,\n    attribute: 'interaction-prompt-threshold'\n  })], ControlsModelViewerElement.prototype, \"interactionPromptThreshold\", void 0);\n  __decorate$6([n$8({\n    type: String,\n    attribute: 'interaction-prompt'\n  })], ControlsModelViewerElement.prototype, \"interactionPrompt\", void 0);\n  __decorate$6([n$8({\n    type: String,\n    attribute: 'interaction-prompt-style'\n  })], ControlsModelViewerElement.prototype, \"interactionPromptStyle\", void 0);\n  __decorate$6([n$8({\n    type: Number,\n    attribute: 'orbit-sensitivity'\n  })], ControlsModelViewerElement.prototype, \"orbitSensitivity\", void 0);\n  __decorate$6([n$8({\n    type: Number,\n    attribute: 'zoom-sensitivity'\n  })], ControlsModelViewerElement.prototype, \"zoomSensitivity\", void 0);\n  __decorate$6([n$8({\n    type: Number,\n    attribute: 'pan-sensitivity'\n  })], ControlsModelViewerElement.prototype, \"panSensitivity\", void 0);\n  __decorate$6([n$8({\n    type: String,\n    attribute: 'touch-action'\n  })], ControlsModelViewerElement.prototype, \"touchAction\", void 0);\n  __decorate$6([n$8({\n    type: Boolean,\n    attribute: 'disable-zoom'\n  })], ControlsModelViewerElement.prototype, \"disableZoom\", void 0);\n  __decorate$6([n$8({\n    type: Boolean,\n    attribute: 'disable-pan'\n  })], ControlsModelViewerElement.prototype, \"disablePan\", void 0);\n  __decorate$6([n$8({\n    type: Boolean,\n    attribute: 'disable-tap'\n  })], ControlsModelViewerElement.prototype, \"disableTap\", void 0);\n  __decorate$6([n$8({\n    type: Number,\n    attribute: 'interpolation-decay'\n  })], ControlsModelViewerElement.prototype, \"interpolationDecay\", void 0);\n  __decorate$6([n$8()], ControlsModelViewerElement.prototype, \"a11y\", void 0);\n  return ControlsModelViewerElement;\n};\n\n/* @license\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst PAN_SENSITIVITY = 0.018;\nconst TAP_DISTANCE = 2;\nconst TAP_MS = 300;\nconst vector2 = new Vector2();\nconst vector3$2 = new Vector3();\nconst DEFAULT_OPTIONS = Object.freeze({\n  minimumRadius: 0,\n  maximumRadius: Infinity,\n  minimumPolarAngle: 0,\n  maximumPolarAngle: Math.PI,\n  minimumAzimuthalAngle: -Infinity,\n  maximumAzimuthalAngle: Infinity,\n  minimumFieldOfView: 10,\n  maximumFieldOfView: 45,\n  touchAction: 'none'\n});\n// Constants\nconst KEYBOARD_ORBIT_INCREMENT = Math.PI / 8;\nconst ZOOM_SENSITIVITY = 0.04;\n// The move size on pan key event\nconst PAN_KEY_INCREMENT = 10;\nconst ChangeSource = {\n  USER_INTERACTION: 'user-interaction',\n  NONE: 'none',\n  AUTOMATIC: 'automatic'\n};\n/**\n * SmoothControls is a Three.js helper for adding delightful pointer and\n * keyboard-based input to a staged Three.js scene. Its API is very similar to\n * OrbitControls, but it offers more opinionated (subjectively more delightful)\n * defaults, easy extensibility and subjectively better out-of-the-box keyboard\n * support.\n *\n * One important change compared to OrbitControls is that the `update` method\n * of SmoothControls must be invoked on every frame, otherwise the controls\n * will not have an effect.\n *\n * Another notable difference compared to OrbitControls is that SmoothControls\n * does not currently support panning (but probably will in a future revision).\n *\n * Like OrbitControls, SmoothControls assumes that the orientation of the camera\n * has been set in terms of position, rotation and scale, so it is important to\n * ensure that the camera's matrixWorld is in sync before using SmoothControls.\n */\nclass SmoothControls extends EventDispatcher {\n  constructor(camera, element, scene) {\n    super();\n    this.camera = camera;\n    this.element = element;\n    this.scene = scene;\n    this.orbitSensitivity = 1;\n    this.zoomSensitivity = 1;\n    this.panSensitivity = 1;\n    this.inputSensitivity = 1;\n    this.changeSource = ChangeSource.NONE;\n    this._interactionEnabled = false;\n    this._disableZoom = false;\n    this.isUserPointing = false;\n    // Pan state\n    this.enablePan = true;\n    this.enableTap = true;\n    this.panProjection = new Matrix3();\n    this.panPerPixel = 0;\n    // Internal orbital position state\n    this.spherical = new Spherical();\n    this.goalSpherical = new Spherical();\n    this.thetaDamper = new Damper();\n    this.phiDamper = new Damper();\n    this.radiusDamper = new Damper();\n    this.logFov = Math.log(DEFAULT_OPTIONS.maximumFieldOfView);\n    this.goalLogFov = this.logFov;\n    this.fovDamper = new Damper();\n    // Pointer state\n    this.touchMode = null;\n    this.pointers = [];\n    this.startTime = 0;\n    this.startPointerPosition = {\n      clientX: 0,\n      clientY: 0\n    };\n    this.lastSeparation = 0;\n    this.touchDecided = false;\n    this.onContext = event => {\n      if (this.enablePan) {\n        event.preventDefault();\n      } else {\n        for (const pointer of this.pointers) {\n          // Required because of a common browser bug where the context menu never\n          // fires a pointercancel event.\n          this.onPointerUp(new PointerEvent('pointercancel', Object.assign(Object.assign({}, this.startPointerPosition), {\n            pointerId: pointer.id\n          })));\n        }\n      }\n    };\n    this.touchModeZoom = (dx, dy) => {\n      if (!this._disableZoom) {\n        const touchDistance = this.twoTouchDistance(this.pointers[0], this.pointers[1]);\n        const deltaZoom = ZOOM_SENSITIVITY * this.zoomSensitivity * (this.lastSeparation - touchDistance) * 50 / this.scene.height;\n        this.lastSeparation = touchDistance;\n        this.userAdjustOrbit(0, 0, deltaZoom);\n      }\n      if (this.panPerPixel > 0) {\n        this.movePan(dx, dy);\n      }\n    };\n    // We implement our own version of the browser's CSS touch-action, enforced by\n    // this function, because the iOS implementation of pan-y is bad and doesn't\n    // match Android. Specifically, even if a touch gesture begins by panning X,\n    // iOS will switch to scrolling as soon as the gesture moves in the Y, rather\n    // than staying in the same mode until the end of the gesture.\n    this.disableScroll = event => {\n      event.preventDefault();\n    };\n    this.touchModeRotate = (dx, dy) => {\n      const {\n        touchAction\n      } = this._options;\n      if (!this.touchDecided && touchAction !== 'none') {\n        this.touchDecided = true;\n        const dxMag = Math.abs(dx);\n        const dyMag = Math.abs(dy);\n        // If motion is mostly vertical, assume scrolling is the intent.\n        if (this.changeSource === ChangeSource.USER_INTERACTION && (touchAction === 'pan-y' && dyMag > dxMag || touchAction === 'pan-x' && dxMag > dyMag)) {\n          this.touchMode = null;\n          return;\n        } else {\n          this.element.addEventListener('touchmove', this.disableScroll, {\n            passive: false\n          });\n        }\n      }\n      this.handleSinglePointerMove(dx, dy);\n    };\n    this.onPointerDown = event => {\n      if (this.pointers.length > 2) {\n        return;\n      }\n      const {\n        element\n      } = this;\n      if (this.pointers.length === 0) {\n        element.addEventListener('pointermove', this.onPointerMove);\n        element.addEventListener('pointerup', this.onPointerUp);\n        this.touchMode = null;\n        this.touchDecided = false;\n        this.startPointerPosition.clientX = event.clientX;\n        this.startPointerPosition.clientY = event.clientY;\n        this.startTime = performance.now();\n      }\n      try {\n        element.setPointerCapture(event.pointerId);\n      } catch (_a) {}\n      this.pointers.push({\n        clientX: event.clientX,\n        clientY: event.clientY,\n        id: event.pointerId\n      });\n      this.isUserPointing = false;\n      if (event.pointerType === 'touch') {\n        this.changeSource = event.altKey ?\n        // set by interact() in controls.ts\n        ChangeSource.AUTOMATIC : ChangeSource.USER_INTERACTION;\n        this.onTouchChange(event);\n      } else {\n        this.changeSource = ChangeSource.USER_INTERACTION;\n        this.onMouseDown(event);\n      }\n      if (this.changeSource === ChangeSource.USER_INTERACTION) {\n        this.dispatchEvent({\n          type: 'user-interaction'\n        });\n      }\n    };\n    this.onPointerMove = event => {\n      const pointer = this.pointers.find(pointer => pointer.id === event.pointerId);\n      if (pointer == null) {\n        return;\n      }\n      // In case no one gave us a pointerup or pointercancel event.\n      if (event.pointerType === 'mouse' && event.buttons === 0) {\n        this.onPointerUp(event);\n        return;\n      }\n      const numTouches = this.pointers.length;\n      const dx = (event.clientX - pointer.clientX) / numTouches;\n      const dy = (event.clientY - pointer.clientY) / numTouches;\n      if (dx === 0 && dy === 0) {\n        return;\n      }\n      pointer.clientX = event.clientX;\n      pointer.clientY = event.clientY;\n      if (event.pointerType === 'touch') {\n        this.changeSource = event.altKey ?\n        // set by interact() in controls.ts\n        ChangeSource.AUTOMATIC : ChangeSource.USER_INTERACTION;\n        if (this.touchMode !== null) {\n          this.touchMode(dx, dy);\n        }\n      } else {\n        this.changeSource = ChangeSource.USER_INTERACTION;\n        if (this.panPerPixel > 0) {\n          this.movePan(dx, dy);\n        } else {\n          this.handleSinglePointerMove(dx, dy);\n        }\n      }\n    };\n    this.onPointerUp = event => {\n      const {\n        element\n      } = this;\n      const index = this.pointers.findIndex(pointer => pointer.id === event.pointerId);\n      if (index !== -1) {\n        this.pointers.splice(index, 1);\n      }\n      // altKey indicates an interaction prompt; don't reset radius in this case\n      // as it will cause the camera to drift.\n      if (this.panPerPixel > 0 && !event.altKey) {\n        this.resetRadius();\n      }\n      if (this.pointers.length === 0) {\n        element.removeEventListener('pointermove', this.onPointerMove);\n        element.removeEventListener('pointerup', this.onPointerUp);\n        element.removeEventListener('touchmove', this.disableScroll);\n        if (this.enablePan && this.enableTap) {\n          this.recenter(event);\n        }\n      } else if (this.touchMode !== null) {\n        this.onTouchChange(event);\n      }\n      this.scene.element[$panElement].style.opacity = 0;\n      element.style.cursor = 'grab';\n      this.panPerPixel = 0;\n      if (this.isUserPointing) {\n        this.dispatchEvent({\n          type: 'pointer-change-end'\n        });\n      }\n    };\n    this.onWheel = event => {\n      this.changeSource = ChangeSource.USER_INTERACTION;\n      const deltaZoom = event.deltaY * (event.deltaMode == 1 ? 18 : 1) * ZOOM_SENSITIVITY * this.zoomSensitivity / 30;\n      this.userAdjustOrbit(0, 0, deltaZoom);\n      event.preventDefault();\n      this.dispatchEvent({\n        type: 'user-interaction'\n      });\n    };\n    this.onKeyDown = event => {\n      // We track if the key is actually one we respond to, so as not to\n      // accidentally clobber unrelated key inputs when the <model-viewer> has\n      // focus.\n      const {\n        changeSource\n      } = this;\n      this.changeSource = ChangeSource.USER_INTERACTION;\n      const relevantKey = event.shiftKey && this.enablePan ? this.panKeyCodeHandler(event) : this.orbitZoomKeyCodeHandler(event);\n      if (relevantKey) {\n        event.preventDefault();\n        this.dispatchEvent({\n          type: 'user-interaction'\n        });\n      } else {\n        this.changeSource = changeSource;\n      }\n    };\n    this._options = Object.assign({}, DEFAULT_OPTIONS);\n    this.setOrbit(0, Math.PI / 2, 1);\n    this.setFieldOfView(100);\n    this.jumpToGoal();\n  }\n  get interactionEnabled() {\n    return this._interactionEnabled;\n  }\n  enableInteraction() {\n    if (this._interactionEnabled === false) {\n      const {\n        element\n      } = this;\n      element.addEventListener('pointerdown', this.onPointerDown);\n      element.addEventListener('pointercancel', this.onPointerUp);\n      if (!this._disableZoom) {\n        element.addEventListener('wheel', this.onWheel);\n      }\n      element.addEventListener('keydown', this.onKeyDown);\n      // This little beauty is to work around a WebKit bug that otherwise makes\n      // touch events randomly not cancelable.\n      element.addEventListener('touchmove', () => {}, {\n        passive: false\n      });\n      element.addEventListener('contextmenu', this.onContext);\n      this.element.style.cursor = 'grab';\n      this._interactionEnabled = true;\n      this.updateTouchActionStyle();\n    }\n  }\n  disableInteraction() {\n    if (this._interactionEnabled === true) {\n      const {\n        element\n      } = this;\n      element.removeEventListener('pointerdown', this.onPointerDown);\n      element.removeEventListener('pointermove', this.onPointerMove);\n      element.removeEventListener('pointerup', this.onPointerUp);\n      element.removeEventListener('pointercancel', this.onPointerUp);\n      element.removeEventListener('wheel', this.onWheel);\n      element.removeEventListener('keydown', this.onKeyDown);\n      element.removeEventListener('contextmenu', this.onContext);\n      element.style.cursor = '';\n      this.touchMode = null;\n      this._interactionEnabled = false;\n      this.updateTouchActionStyle();\n    }\n  }\n  /**\n   * The options that are currently configured for the controls instance.\n   */\n  get options() {\n    return this._options;\n  }\n  set disableZoom(disable) {\n    if (this._disableZoom != disable) {\n      this._disableZoom = disable;\n      if (disable === true) {\n        this.element.removeEventListener('wheel', this.onWheel);\n      } else {\n        this.element.addEventListener('wheel', this.onWheel);\n      }\n      this.updateTouchActionStyle();\n    }\n  }\n  /**\n   * Copy the spherical values that represent the current camera orbital\n   * position relative to the configured target into a provided Spherical\n   * instance. If no Spherical is provided, a new Spherical will be allocated\n   * to copy the values into. The Spherical that values are copied into is\n   * returned.\n   */\n  getCameraSpherical(target = new Spherical()) {\n    return target.copy(this.spherical);\n  }\n  /**\n   * Returns the camera's current vertical field of view in degrees.\n   */\n  getFieldOfView() {\n    return this.camera.fov;\n  }\n  /**\n   * Configure the _options of the controls. Configured _options will be\n   * merged with whatever _options have already been configured for this\n   * controls instance.\n   */\n  applyOptions(_options) {\n    Object.assign(this._options, _options);\n    // Re-evaluates clamping based on potentially new values for min/max\n    // polar, azimuth and radius:\n    this.setOrbit();\n    this.setFieldOfView(Math.exp(this.goalLogFov));\n  }\n  /**\n   * Sets the near and far planes of the camera.\n   */\n  updateNearFar(nearPlane, farPlane) {\n    this.camera.far = farPlane === 0 ? 2 : farPlane;\n    this.camera.near = Math.max(nearPlane, this.camera.far / 1000);\n    this.camera.updateProjectionMatrix();\n  }\n  /**\n   * Sets the aspect ratio of the camera\n   */\n  updateAspect(aspect) {\n    this.camera.aspect = aspect;\n    this.camera.updateProjectionMatrix();\n  }\n  /**\n   * Set the absolute orbital goal of the camera. The change will be\n   * applied over a number of frames depending on configured acceleration and\n   * dampening _options.\n   *\n   * Returns true if invoking the method will result in the camera changing\n   * position and/or rotation, otherwise false.\n   */\n  setOrbit(goalTheta = this.goalSpherical.theta, goalPhi = this.goalSpherical.phi, goalRadius = this.goalSpherical.radius) {\n    const {\n      minimumAzimuthalAngle,\n      maximumAzimuthalAngle,\n      minimumPolarAngle,\n      maximumPolarAngle,\n      minimumRadius,\n      maximumRadius\n    } = this._options;\n    const {\n      theta,\n      phi,\n      radius\n    } = this.goalSpherical;\n    const nextTheta = clamp(goalTheta, minimumAzimuthalAngle, maximumAzimuthalAngle);\n    if (!isFinite(minimumAzimuthalAngle) && !isFinite(maximumAzimuthalAngle)) {\n      this.spherical.theta = this.wrapAngle(this.spherical.theta - nextTheta) + nextTheta;\n    }\n    const nextPhi = clamp(goalPhi, minimumPolarAngle, maximumPolarAngle);\n    const nextRadius = clamp(goalRadius, minimumRadius, maximumRadius);\n    if (nextTheta === theta && nextPhi === phi && nextRadius === radius) {\n      return false;\n    }\n    if (!isFinite(nextTheta) || !isFinite(nextPhi) || !isFinite(nextRadius)) {\n      return false;\n    }\n    this.goalSpherical.theta = nextTheta;\n    this.goalSpherical.phi = nextPhi;\n    this.goalSpherical.radius = nextRadius;\n    this.goalSpherical.makeSafe();\n    return true;\n  }\n  /**\n   * Subset of setOrbit() above, which only sets the camera's radius.\n   */\n  setRadius(radius) {\n    this.goalSpherical.radius = radius;\n    this.setOrbit();\n  }\n  /**\n   * Sets the goal field of view for the camera\n   */\n  setFieldOfView(fov) {\n    const {\n      minimumFieldOfView,\n      maximumFieldOfView\n    } = this._options;\n    fov = clamp(fov, minimumFieldOfView, maximumFieldOfView);\n    this.goalLogFov = Math.log(fov);\n  }\n  /**\n   * Sets the smoothing decay time.\n   */\n  setDamperDecayTime(decayMilliseconds) {\n    this.thetaDamper.setDecayTime(decayMilliseconds);\n    this.phiDamper.setDecayTime(decayMilliseconds);\n    this.radiusDamper.setDecayTime(decayMilliseconds);\n    this.fovDamper.setDecayTime(decayMilliseconds);\n  }\n  /**\n   * Adjust the orbital position of the camera relative to its current orbital\n   * position. Does not let the theta goal get more than pi ahead of the current\n   * theta, which ensures interpolation continues in the direction of the delta.\n   * The deltaZoom parameter adjusts both the field of view and the orbit radius\n   * such that they progress across their allowed ranges in sync.\n   */\n  adjustOrbit(deltaTheta, deltaPhi, deltaZoom) {\n    const {\n      theta,\n      phi,\n      radius\n    } = this.goalSpherical;\n    const {\n      minimumRadius,\n      maximumRadius,\n      minimumFieldOfView,\n      maximumFieldOfView\n    } = this._options;\n    const dTheta = this.spherical.theta - theta;\n    const dThetaLimit = Math.PI - 0.001;\n    const goalTheta = theta - clamp(deltaTheta, -dThetaLimit - dTheta, dThetaLimit - dTheta);\n    const goalPhi = phi - deltaPhi;\n    const deltaRatio = deltaZoom === 0 ? 0 : ((deltaZoom > 0 ? maximumRadius : minimumRadius) - radius) / (Math.log(deltaZoom > 0 ? maximumFieldOfView : minimumFieldOfView) - this.goalLogFov);\n    const goalRadius = radius + deltaZoom * (isFinite(deltaRatio) ? deltaRatio : (maximumRadius - minimumRadius) * 2);\n    this.setOrbit(goalTheta, goalPhi, goalRadius);\n    if (deltaZoom !== 0) {\n      const goalLogFov = this.goalLogFov + deltaZoom;\n      this.setFieldOfView(Math.exp(goalLogFov));\n    }\n  }\n  /**\n   * Move the camera instantly instead of accelerating toward the goal\n   * parameters.\n   */\n  jumpToGoal() {\n    this.update(0, SETTLING_TIME);\n  }\n  /**\n   * Update controls. In most cases, this will result in the camera\n   * interpolating its position and rotation until it lines up with the\n   * designated goal orbital position. Returns false if the camera did not move.\n   *\n   * Time and delta are measured in milliseconds.\n   */\n  update(_time, delta) {\n    if (this.isStationary()) {\n      return false;\n    }\n    const {\n      maximumPolarAngle,\n      maximumRadius\n    } = this._options;\n    const dTheta = this.spherical.theta - this.goalSpherical.theta;\n    if (Math.abs(dTheta) > Math.PI && !isFinite(this._options.minimumAzimuthalAngle) && !isFinite(this._options.maximumAzimuthalAngle)) {\n      this.spherical.theta -= Math.sign(dTheta) * 2 * Math.PI;\n    }\n    this.spherical.theta = this.thetaDamper.update(this.spherical.theta, this.goalSpherical.theta, delta, Math.PI);\n    this.spherical.phi = this.phiDamper.update(this.spherical.phi, this.goalSpherical.phi, delta, maximumPolarAngle);\n    this.spherical.radius = this.radiusDamper.update(this.spherical.radius, this.goalSpherical.radius, delta, maximumRadius);\n    this.logFov = this.fovDamper.update(this.logFov, this.goalLogFov, delta, 1);\n    this.moveCamera();\n    return true;\n  }\n  updateTouchActionStyle() {\n    const {\n      style\n    } = this.element;\n    if (this._interactionEnabled) {\n      const {\n        touchAction\n      } = this._options;\n      if (this._disableZoom && touchAction !== 'none') {\n        style.touchAction = 'manipulation';\n      } else {\n        style.touchAction = touchAction;\n      }\n    } else {\n      style.touchAction = '';\n    }\n  }\n  isStationary() {\n    return this.goalSpherical.theta === this.spherical.theta && this.goalSpherical.phi === this.spherical.phi && this.goalSpherical.radius === this.spherical.radius && this.goalLogFov === this.logFov;\n  }\n  moveCamera() {\n    // Derive the new camera position from the updated spherical:\n    this.spherical.makeSafe();\n    this.camera.position.setFromSpherical(this.spherical);\n    this.camera.setRotationFromEuler(new Euler(this.spherical.phi - Math.PI / 2, this.spherical.theta, 0, 'YXZ'));\n    if (this.camera.fov !== Math.exp(this.logFov)) {\n      this.camera.fov = Math.exp(this.logFov);\n      this.camera.updateProjectionMatrix();\n    }\n  }\n  userAdjustOrbit(deltaTheta, deltaPhi, deltaZoom) {\n    this.adjustOrbit(deltaTheta * this.orbitSensitivity * this.inputSensitivity, deltaPhi * this.orbitSensitivity * this.inputSensitivity, deltaZoom * this.inputSensitivity);\n  }\n  // Wraps to between -pi and pi\n  wrapAngle(radians) {\n    const normalized = (radians + Math.PI) / (2 * Math.PI);\n    const wrapped = normalized - Math.floor(normalized);\n    return wrapped * 2 * Math.PI - Math.PI;\n  }\n  pixelLengthToSphericalAngle(pixelLength) {\n    return 2 * Math.PI * pixelLength / this.scene.height;\n  }\n  twoTouchDistance(touchOne, touchTwo) {\n    const {\n      clientX: xOne,\n      clientY: yOne\n    } = touchOne;\n    const {\n      clientX: xTwo,\n      clientY: yTwo\n    } = touchTwo;\n    const xDelta = xTwo - xOne;\n    const yDelta = yTwo - yOne;\n    return Math.sqrt(xDelta * xDelta + yDelta * yDelta);\n  }\n  handleSinglePointerMove(dx, dy) {\n    const deltaTheta = this.pixelLengthToSphericalAngle(dx);\n    const deltaPhi = this.pixelLengthToSphericalAngle(dy);\n    if (this.isUserPointing === false) {\n      this.isUserPointing = true;\n      this.dispatchEvent({\n        type: 'pointer-change-start'\n      });\n    }\n    this.userAdjustOrbit(deltaTheta, deltaPhi, 0);\n  }\n  initializePan() {\n    const {\n      theta,\n      phi\n    } = this.spherical;\n    const psi = theta - this.scene.yaw;\n    this.panPerPixel = PAN_SENSITIVITY * this.panSensitivity / this.scene.height;\n    this.panProjection.set(-Math.cos(psi), -Math.cos(phi) * Math.sin(psi), 0, 0, Math.sin(phi), 0, Math.sin(psi), -Math.cos(phi) * Math.cos(psi), 0);\n  }\n  movePan(dx, dy) {\n    const {\n      scene\n    } = this;\n    const dxy = vector3$2.set(dx, dy, 0).multiplyScalar(this.inputSensitivity);\n    const metersPerPixel = this.spherical.radius * Math.exp(this.logFov) * this.panPerPixel;\n    dxy.multiplyScalar(metersPerPixel);\n    const target = scene.getTarget();\n    target.add(dxy.applyMatrix3(this.panProjection));\n    scene.boundingSphere.clampPoint(target, target);\n    scene.setTarget(target.x, target.y, target.z);\n  }\n  recenter(pointer) {\n    if (performance.now() > this.startTime + TAP_MS || Math.abs(pointer.clientX - this.startPointerPosition.clientX) > TAP_DISTANCE || Math.abs(pointer.clientY - this.startPointerPosition.clientY) > TAP_DISTANCE) {\n      return;\n    }\n    const {\n      scene\n    } = this;\n    const hit = scene.positionAndNormalFromPoint(scene.getNDC(pointer.clientX, pointer.clientY));\n    if (hit == null) {\n      const {\n        cameraTarget\n      } = scene.element;\n      scene.element.cameraTarget = '';\n      scene.element.cameraTarget = cameraTarget;\n      // Zoom all the way out.\n      this.userAdjustOrbit(0, 0, 1);\n    } else {\n      scene.target.worldToLocal(hit.position);\n      scene.setTarget(hit.position.x, hit.position.y, hit.position.z);\n    }\n  }\n  resetRadius() {\n    const {\n      scene\n    } = this;\n    const hit = scene.positionAndNormalFromPoint(vector2.set(0, 0));\n    if (hit == null) {\n      return;\n    }\n    scene.target.worldToLocal(hit.position);\n    const goalTarget = scene.getTarget();\n    const {\n      theta,\n      phi\n    } = this.spherical;\n    // Set target to surface hit point, except the target is still settling,\n    // so offset the goal accordingly so the transition is smooth even though\n    // this will drift the target slightly away from the hit point.\n    const psi = theta - scene.yaw;\n    const n = vector3$2.set(Math.sin(phi) * Math.sin(psi), Math.cos(phi), Math.sin(phi) * Math.cos(psi));\n    const dr = n.dot(hit.position.sub(goalTarget));\n    goalTarget.add(n.multiplyScalar(dr));\n    scene.setTarget(goalTarget.x, goalTarget.y, goalTarget.z);\n    // Change the camera radius to match the change in target so that the\n    // camera itself does not move, unless it hits a radius bound.\n    this.setOrbit(undefined, undefined, this.goalSpherical.radius - dr);\n  }\n  onTouchChange(event) {\n    if (this.pointers.length === 1) {\n      this.touchMode = this.touchModeRotate;\n    } else {\n      if (this._disableZoom) {\n        this.touchMode = null;\n        this.element.removeEventListener('touchmove', this.disableScroll);\n        return;\n      }\n      this.touchMode = this.touchDecided && this.touchMode === null ? null : this.touchModeZoom;\n      this.touchDecided = true;\n      this.element.addEventListener('touchmove', this.disableScroll, {\n        passive: false\n      });\n      this.lastSeparation = this.twoTouchDistance(this.pointers[0], this.pointers[1]);\n      if (this.enablePan && this.touchMode != null) {\n        this.initializePan();\n        if (!event.altKey) {\n          // user interaction, not prompt\n          this.scene.element[$panElement].style.opacity = 1;\n        }\n      }\n    }\n  }\n  onMouseDown(event) {\n    this.panPerPixel = 0;\n    if (this.enablePan && (event.button === 2 || event.ctrlKey || event.metaKey || event.shiftKey)) {\n      this.initializePan();\n      this.scene.element[$panElement].style.opacity = 1;\n    }\n    this.element.style.cursor = 'grabbing';\n  }\n  /**\n   * Handles the orbit and Zoom key presses\n   * Uses constants for the increment.\n   * @param event The keyboard event for the .key value\n   * @returns boolean to indicate if the key event has been handled\n   */\n  orbitZoomKeyCodeHandler(event) {\n    let relevantKey = true;\n    switch (event.key) {\n      case 'PageUp':\n        this.userAdjustOrbit(0, 0, ZOOM_SENSITIVITY * this.zoomSensitivity);\n        break;\n      case 'PageDown':\n        this.userAdjustOrbit(0, 0, -1 * ZOOM_SENSITIVITY * this.zoomSensitivity);\n        break;\n      case 'ArrowUp':\n        this.userAdjustOrbit(0, -KEYBOARD_ORBIT_INCREMENT, 0);\n        break;\n      case 'ArrowDown':\n        this.userAdjustOrbit(0, KEYBOARD_ORBIT_INCREMENT, 0);\n        break;\n      case 'ArrowLeft':\n        this.userAdjustOrbit(-KEYBOARD_ORBIT_INCREMENT, 0, 0);\n        break;\n      case 'ArrowRight':\n        this.userAdjustOrbit(KEYBOARD_ORBIT_INCREMENT, 0, 0);\n        break;\n      default:\n        relevantKey = false;\n        break;\n    }\n    return relevantKey;\n  }\n  /**\n   * Handles the Pan key presses\n   * Uses constants for the increment.\n   * @param event The keyboard event for the .key value\n   * @returns boolean to indicate if the key event has been handled\n   */\n  panKeyCodeHandler(event) {\n    this.initializePan();\n    let relevantKey = true;\n    switch (event.key) {\n      case 'ArrowUp':\n        this.movePan(0, -1 * PAN_KEY_INCREMENT); // This is the negative one so that the\n        // model appears to move as the arrow\n        // direction rather than the view moving\n        break;\n      case 'ArrowDown':\n        this.movePan(0, PAN_KEY_INCREMENT);\n        break;\n      case 'ArrowLeft':\n        this.movePan(-1 * PAN_KEY_INCREMENT, 0);\n        break;\n      case 'ArrowRight':\n        this.movePan(PAN_KEY_INCREMENT, 0);\n        break;\n      default:\n        relevantKey = false;\n        break;\n    }\n    return relevantKey;\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// number of initial null pose XRFrames allowed before we post not-tracking\nconst INIT_FRAMES = 30;\n// AR shadow is not user-configurable. This is to pave the way for AR lighting\n// estimation, which will be used once available in WebXR.\nconst AR_SHADOW_INTENSITY = 0.8;\nconst ROTATION_RATE = 1.5;\n// Angle down (towards bottom of screen) from camera center ray to use for hit\n// testing against the floor. This makes placement faster and more intuitive\n// assuming the phone is in portrait mode. This seems to be a reasonable\n// assumption for the start of the session and UI will lack landscape mode to\n// encourage upright use.\nconst HIT_ANGLE_DEG = 20;\nconst SCALE_SNAP = 0.2;\n// For automatic dynamic viewport scaling, don't let the scale drop below this\n// limit.\nconst MIN_VIEWPORT_SCALE = 0.25;\n// Furthest away you can move an object (meters).\nconst MAX_DISTANCE = 10;\n// Damper decay in milliseconds for the headset - screen uses default.\nconst DECAY = 150;\n// Longer controller/hand indicator line (meters).\nconst MAX_LINE_LENGTH = 5;\n// Maximum dimension of rotation indicator box on controller (meters).\nconst BOX_SIZE = 0.1;\nconst ARStatus = {\n  NOT_PRESENTING: 'not-presenting',\n  SESSION_STARTED: 'session-started',\n  OBJECT_PLACED: 'object-placed',\n  FAILED: 'failed'\n};\nconst ARTracking = {\n  TRACKING: 'tracking',\n  NOT_TRACKING: 'not-tracking'\n};\nconst vector3$1 = new Vector3();\nconst quaternion = new Quaternion();\nconst matrix4 = new Matrix4();\nconst hitPosition = new Vector3();\nconst camera = new PerspectiveCamera(45, 1, 0.1, 100);\nconst lineGeometry = new BufferGeometry().setFromPoints([new Vector3(0, 0, 0), new Vector3(0, 0, -1)]);\nconst boxGeometry = new BoxGeometry();\nclass ARRenderer extends EventDispatcher {\n  constructor(renderer) {\n    super();\n    this.renderer = renderer;\n    this.currentSession = null;\n    this.placeOnWall = false;\n    this.placementBox = null;\n    this.lastTick = null;\n    this.turntableRotation = null;\n    this.oldShadowIntensity = null;\n    this.frame = null;\n    this.initialHitSource = null;\n    this.transientHitTestSource = null;\n    this.inputSource = null;\n    this._presentedScene = null;\n    this.resolveCleanup = null;\n    this.exitWebXRButtonContainer = null;\n    this.overlay = null;\n    this.xrLight = null;\n    this.xrMode = null;\n    this.controller1 = null;\n    this.controller2 = null;\n    this.selectedController = null;\n    this.tracking = true;\n    this.frames = 0;\n    this.initialized = false;\n    this.oldTarget = new Vector3();\n    this.placementComplete = false;\n    this.isTranslating = false;\n    this.isRotating = false;\n    this.isTwoFingering = false;\n    this.lastDragPosition = new Vector3();\n    this.relativeOrientation = new Quaternion();\n    this.scaleLine = new Line(lineGeometry);\n    this.firstRatio = 0;\n    this.lastAngle = 0;\n    this.goalPosition = new Vector3();\n    this.goalYaw = 0;\n    this.goalScale = 1;\n    this.xDamper = new Damper();\n    this.yDamper = new Damper();\n    this.zDamper = new Damper();\n    this.yawDamper = new Damper();\n    this.pitchDamper = new Damper();\n    this.rollDamper = new Damper();\n    this.scaleDamper = new Damper();\n    this.onExitWebXRButtonContainerClick = () => this.stopPresenting();\n    this.onControllerSelectStart = event => {\n      const scene = this.presentedScene;\n      const controller = event.target;\n      if (this.placementBox.controllerIntersection(scene, controller) != null) {\n        if (this.selectedController != null) {\n          this.selectedController.userData.line.visible = false;\n          if (scene.canScale) {\n            this.isTwoFingering = true;\n            this.firstRatio = this.controllerSeparation() / scene.pivot.scale.x;\n            this.scaleLine.visible = true;\n          }\n        }\n        controller.attach(scene.pivot);\n        this.selectedController = controller;\n        scene.setShadowIntensity(0.01);\n      } else {\n        const otherController = controller === this.controller1 ? this.controller2 : this.controller1;\n        this.relativeOrientation.copy(controller.quaternion).invert().multiply(scene.pivot.getWorldQuaternion(quaternion));\n        otherController.userData.turning = false;\n        controller.userData.turning = true;\n        controller.userData.line.visible = false;\n      }\n    };\n    this.onControllerSelectEnd = event => {\n      const controller = event.target;\n      controller.userData.turning = false;\n      controller.userData.line.visible = true;\n      this.isTwoFingering = false;\n      this.scaleLine.visible = false;\n      if (this.selectedController != null && this.selectedController != controller) {\n        return;\n      }\n      const scene = this.presentedScene;\n      // drop on floor\n      scene.attach(scene.pivot);\n      this.selectedController = null;\n      this.goalYaw = Math.atan2(scene.pivot.matrix.elements[8], scene.pivot.matrix.elements[10]);\n      this.goalPosition.x = scene.pivot.position.x;\n      this.goalPosition.z = scene.pivot.position.z;\n    };\n    this.onUpdateScene = () => {\n      if (this.placementBox != null && this.isPresenting) {\n        this.placementBox.dispose();\n        this.placementBox = new PlacementBox(this.presentedScene, this.placeOnWall ? 'back' : 'bottom');\n      }\n    };\n    this.onSelectStart = event => {\n      const hitSource = this.transientHitTestSource;\n      if (hitSource == null) {\n        return;\n      }\n      const fingers = this.frame.getHitTestResultsForTransientInput(hitSource);\n      const scene = this.presentedScene;\n      const box = this.placementBox;\n      if (fingers.length === 1) {\n        this.inputSource = event.inputSource;\n        const {\n          axes\n        } = this.inputSource.gamepad;\n        const hitPosition = box.getHit(this.presentedScene, axes[0], axes[1]);\n        box.show = true;\n        if (hitPosition != null) {\n          this.isTranslating = true;\n          this.lastDragPosition.copy(hitPosition);\n        } else if (this.placeOnWall === false) {\n          this.isRotating = true;\n          this.lastAngle = axes[0] * ROTATION_RATE;\n        }\n      } else if (fingers.length === 2) {\n        box.show = true;\n        this.isTwoFingering = true;\n        const {\n          separation\n        } = this.fingerPolar(fingers);\n        this.firstRatio = separation / scene.pivot.scale.x;\n      }\n    };\n    this.onSelectEnd = () => {\n      this.isTranslating = false;\n      this.isRotating = false;\n      this.isTwoFingering = false;\n      this.inputSource = null;\n      this.goalPosition.y += this.placementBox.offsetHeight * this.presentedScene.scale.x;\n      this.placementBox.show = false;\n    };\n    this.threeRenderer = renderer.threeRenderer;\n    this.threeRenderer.xr.enabled = true;\n  }\n  async resolveARSession() {\n    assertIsArCandidate();\n    const session = await navigator.xr.requestSession('immersive-ar', {\n      requiredFeatures: ['hit-test'],\n      optionalFeatures: ['dom-overlay', 'light-estimation'],\n      domOverlay: this.overlay ? {\n        root: this.overlay\n      } : undefined\n    });\n    this.threeRenderer.xr.setReferenceSpaceType('local');\n    await this.threeRenderer.xr.setSession(session);\n    this.threeRenderer.xr.cameraAutoUpdate = false;\n    return session;\n  }\n  /**\n   * The currently presented scene, if any\n   */\n  get presentedScene() {\n    return this._presentedScene;\n  }\n  /**\n   * Resolves to true if the renderer has detected all the necessary qualities\n   * to support presentation in AR.\n   */\n  async supportsPresentation() {\n    try {\n      assertIsArCandidate();\n      return await navigator.xr.isSessionSupported('immersive-ar');\n    } catch (error) {\n      console.warn('Request to present in WebXR denied:');\n      console.warn(error);\n      console.warn('Falling back to next ar-mode');\n      return false;\n    }\n  }\n  /**\n   * Present a scene in AR\n   */\n  async present(scene, environmentEstimation = false) {\n    if (this.isPresenting) {\n      console.warn('Cannot present while a model is already presenting');\n    }\n    let waitForAnimationFrame = new Promise((resolve, _reject) => {\n      requestAnimationFrame(() => resolve());\n    });\n    scene.setHotspotsVisibility(false);\n    scene.queueRender();\n    // Render a frame to turn off the hotspots\n    await waitForAnimationFrame;\n    // This sets isPresenting to true\n    this._presentedScene = scene;\n    this.overlay = scene.element.shadowRoot.querySelector('div.default');\n    if (environmentEstimation === true) {\n      this.xrLight = new XREstimatedLight(this.threeRenderer);\n      this.xrLight.addEventListener('estimationstart', () => {\n        if (!this.isPresenting || this.xrLight == null) {\n          return;\n        }\n        const scene = this.presentedScene;\n        scene.add(this.xrLight);\n        scene.environment = this.xrLight.environment;\n      });\n    }\n    const currentSession = await this.resolveARSession();\n    currentSession.addEventListener('end', () => {\n      this.postSessionCleanup();\n    }, {\n      once: true\n    });\n    const exitButton = scene.element.shadowRoot.querySelector('.slot.exit-webxr-ar-button');\n    exitButton.classList.add('enabled');\n    exitButton.addEventListener('click', this.onExitWebXRButtonContainerClick);\n    this.exitWebXRButtonContainer = exitButton;\n    const viewerRefSpace = await currentSession.requestReferenceSpace('viewer');\n    this.xrMode = currentSession.interactionMode;\n    this.tracking = true;\n    this.frames = 0;\n    this.initialized = false;\n    this.turntableRotation = scene.yaw;\n    this.goalYaw = scene.yaw;\n    this.goalScale = 1;\n    scene.setBackground(null);\n    this.oldShadowIntensity = scene.shadowIntensity;\n    scene.setShadowIntensity(0.01); // invisible, but not changing the shader\n    this.oldTarget.copy(scene.getTarget());\n    scene.element.addEventListener('load', this.onUpdateScene);\n    const radians = HIT_ANGLE_DEG * Math.PI / 180;\n    const ray = this.placeOnWall === true ? undefined : new XRRay(new DOMPoint(0, 0, 0), {\n      x: 0,\n      y: -Math.sin(radians),\n      z: -Math.cos(radians)\n    });\n    currentSession.requestHitTestSource({\n      space: viewerRefSpace,\n      offsetRay: ray\n    }).then(hitTestSource => {\n      this.initialHitSource = hitTestSource;\n    });\n    if (this.xrMode !== 'screen-space') {\n      this.setupControllers();\n      this.xDamper.setDecayTime(DECAY);\n      this.yDamper.setDecayTime(DECAY);\n      this.zDamper.setDecayTime(DECAY);\n      this.yawDamper.setDecayTime(DECAY);\n      this.pitchDamper.setDecayTime(DECAY);\n      this.rollDamper.setDecayTime(DECAY);\n    }\n    this.currentSession = currentSession;\n    this.placementBox = new PlacementBox(scene, this.placeOnWall ? 'back' : 'bottom');\n    this.placementComplete = false;\n    this.lastTick = performance.now();\n    this.dispatchEvent({\n      type: 'status',\n      status: ARStatus.SESSION_STARTED\n    });\n  }\n  setupControllers() {\n    this.controller1 = this.threeRenderer.xr.getController(0);\n    this.controller1.addEventListener('selectstart', this.onControllerSelectStart);\n    this.controller1.addEventListener('selectend', this.onControllerSelectEnd);\n    this.controller2 = this.threeRenderer.xr.getController(1);\n    this.controller2.addEventListener('selectstart', this.onControllerSelectStart);\n    this.controller2.addEventListener('selectend', this.onControllerSelectEnd);\n    const scene = this.presentedScene;\n    scene.add(this.controller1);\n    scene.add(this.controller2);\n    if (!this.controller1.userData.line) {\n      const line = new Line(lineGeometry);\n      line.name = 'line';\n      line.scale.z = MAX_LINE_LENGTH;\n      this.controller1.userData.turning = false;\n      this.controller1.userData.line = line;\n      this.controller1.add(line);\n      this.controller2.userData.turning = false;\n      const line2 = line.clone();\n      this.controller2.userData.line = line2;\n      this.controller2.add(line2);\n      this.scaleLine.name = 'scale line';\n      this.scaleLine.visible = false;\n      this.controller1.add(this.scaleLine);\n      const {\n        size\n      } = scene;\n      const scale = BOX_SIZE / Math.max(size.x, size.y, size.z);\n      const box = new Mesh(boxGeometry);\n      box.name = 'box';\n      box.scale.copy(size).multiplyScalar(scale);\n      box.visible = false;\n      this.controller1.userData.box = box;\n      scene.add(box);\n      const box2 = box.clone();\n      this.controller2.userData.box = box2;\n      scene.add(box2);\n    }\n  }\n  hover(controller) {\n    // Do not highlight in mobile-ar\n    if (this.xrMode === 'screen-space' || this.selectedController == controller) {\n      return false;\n    }\n    const scene = this.presentedScene;\n    const intersection = this.placementBox.controllerIntersection(scene, controller);\n    controller.userData.box.visible = (intersection == null || controller.userData.turning) && !this.isTwoFingering;\n    controller.userData.line.scale.z = intersection == null ? MAX_LINE_LENGTH : intersection.distance;\n    return intersection != null;\n  }\n  controllerSeparation() {\n    return this.controller1.position.distanceTo(this.controller2.position);\n  }\n  /**\n   * If currently presenting a scene in AR, stops presentation and exits AR.\n   */\n  async stopPresenting() {\n    if (!this.isPresenting) {\n      return;\n    }\n    const cleanupPromise = new Promise(resolve => {\n      this.resolveCleanup = resolve;\n    });\n    try {\n      await this.currentSession.end();\n      await cleanupPromise;\n    } catch (error) {\n      console.warn('Error while trying to end WebXR AR session');\n      console.warn(error);\n      this.postSessionCleanup();\n    }\n  }\n  /**\n   * True if a scene is currently in the process of being presented in AR\n   */\n  get isPresenting() {\n    return this.presentedScene != null;\n  }\n  get target() {\n    return this.oldTarget;\n  }\n  updateTarget() {\n    const scene = this.presentedScene;\n    if (scene != null) {\n      const target = scene.getTarget();\n      this.oldTarget.copy(target);\n      if (this.placeOnWall) {\n        // Move the scene's target to the center of the back of the model's\n        // bounding box.\n        target.z = scene.boundingBox.min.z;\n      } else {\n        // Move the scene's target to the model's floor height.\n        target.y = scene.boundingBox.min.y;\n      }\n      scene.setTarget(target.x, target.y, target.z);\n    }\n  }\n  postSessionCleanup() {\n    const session = this.currentSession;\n    if (session != null) {\n      session.removeEventListener('selectstart', this.onSelectStart);\n      session.removeEventListener('selectend', this.onSelectEnd);\n      this.currentSession = null;\n    }\n    const scene = this.presentedScene;\n    this._presentedScene = null;\n    if (scene != null) {\n      const {\n        element\n      } = scene;\n      if (this.xrLight != null) {\n        scene.remove(this.xrLight);\n        this.xrLight.dispose();\n        this.xrLight = null;\n      }\n      scene.add(scene.pivot);\n      scene.pivot.quaternion.set(0, 0, 0, 1);\n      scene.pivot.position.set(0, 0, 0);\n      scene.pivot.scale.set(1, 1, 1);\n      scene.setShadowOffset(0);\n      const yaw = this.turntableRotation;\n      if (yaw != null) {\n        scene.yaw = yaw;\n      }\n      const intensity = this.oldShadowIntensity;\n      if (intensity != null) {\n        scene.setShadowIntensity(intensity);\n      }\n      scene.setEnvironmentAndSkybox(element[$currentEnvironmentMap], element[$currentBackground]);\n      const point = this.oldTarget;\n      scene.setTarget(point.x, point.y, point.z);\n      scene.xrCamera = null;\n      scene.element.removeEventListener('load', this.onUpdateScene);\n      scene.orientHotspots(0);\n      const {\n        width,\n        height\n      } = element.getBoundingClientRect();\n      scene.setSize(width, height);\n      requestAnimationFrame(() => {\n        scene.element.dispatchEvent(new CustomEvent('camera-change', {\n          detail: {\n            source: ChangeSource.NONE\n          }\n        }));\n      });\n    }\n    // Force the Renderer to update its size\n    this.renderer.height = 0;\n    const exitButton = this.exitWebXRButtonContainer;\n    if (exitButton != null) {\n      exitButton.classList.remove('enabled');\n      exitButton.removeEventListener('click', this.onExitWebXRButtonContainerClick);\n      this.exitWebXRButtonContainer = null;\n    }\n    const hitSource = this.transientHitTestSource;\n    if (hitSource != null) {\n      hitSource.cancel();\n      this.transientHitTestSource = null;\n    }\n    const hitSourceInitial = this.initialHitSource;\n    if (hitSourceInitial != null) {\n      hitSourceInitial.cancel();\n      this.initialHitSource = null;\n    }\n    if (this.placementBox != null) {\n      this.placementBox.dispose();\n      this.placementBox = null;\n    }\n    if (this.xrMode !== 'screen-space') {\n      if (this.controller1 != null) {\n        this.controller1.userData.turning = false;\n        this.controller1.userData.box.visible = false;\n        this.controller1.userData.line.visible = true;\n        this.controller1.removeEventListener('selectstart', this.onControllerSelectStart);\n        this.controller1.removeEventListener('selectend', this.onControllerSelectEnd);\n        this.controller1.removeFromParent();\n        this.controller1 = null;\n      }\n      if (this.controller2 != null) {\n        this.controller2.userData.turning = false;\n        this.controller2.userData.box.visible = false;\n        this.controller2.userData.line.visible = true;\n        this.controller2.removeEventListener('selectstart', this.onControllerSelectStart);\n        this.controller2.removeEventListener('selectend', this.onControllerSelectEnd);\n        this.controller2.removeFromParent();\n        this.controller2 = null;\n      }\n      this.selectedController = null;\n      this.scaleLine.visible = false;\n    }\n    this.isTranslating = false;\n    this.isRotating = false;\n    this.isTwoFingering = false;\n    this.lastTick = null;\n    this.turntableRotation = null;\n    this.oldShadowIntensity = null;\n    this.frame = null;\n    this.inputSource = null;\n    this.overlay = null;\n    if (this.resolveCleanup != null) {\n      this.resolveCleanup();\n    }\n    this.dispatchEvent({\n      type: 'status',\n      status: ARStatus.NOT_PRESENTING\n    });\n  }\n  updateView(view) {\n    const scene = this.presentedScene;\n    const xr = this.threeRenderer.xr;\n    xr.updateCamera(camera);\n    scene.xrCamera = xr.getCamera();\n    const {\n      elements\n    } = scene.getCamera().matrixWorld;\n    scene.orientHotspots(Math.atan2(elements[1], elements[5]));\n    if (!this.initialized) {\n      this.placeInitially();\n      this.initialized = true;\n    }\n    // Use automatic dynamic viewport scaling if supported.\n    if (view.requestViewportScale && view.recommendedViewportScale) {\n      const scale = view.recommendedViewportScale;\n      view.requestViewportScale(Math.max(scale, MIN_VIEWPORT_SCALE));\n    }\n    const layer = xr.getBaseLayer();\n    if (layer != null) {\n      const viewport = layer instanceof XRWebGLLayer ? layer.getViewport(view) : xr.getBinding().getViewSubImage(layer, view).viewport;\n      this.threeRenderer.setViewport(viewport.x, viewport.y, viewport.width, viewport.height);\n    }\n  }\n  placeInitially() {\n    const scene = this.presentedScene;\n    const {\n      pivot,\n      element\n    } = scene;\n    const {\n      position\n    } = pivot;\n    const xrCamera = scene.getCamera();\n    const {\n      width,\n      height\n    } = this.overlay.getBoundingClientRect();\n    scene.setSize(width, height);\n    xrCamera.projectionMatrixInverse.copy(xrCamera.projectionMatrix).invert();\n    const {\n      theta\n    } = element.getCameraOrbit();\n    // Orient model to match the 3D camera view\n    const cameraDirection = xrCamera.getWorldDirection(vector3$1);\n    scene.yaw = Math.atan2(-cameraDirection.x, -cameraDirection.z) - theta;\n    this.goalYaw = scene.yaw;\n    const radius = Math.max(1, 2 * scene.boundingSphere.radius);\n    position.copy(xrCamera.position).add(cameraDirection.multiplyScalar(radius));\n    this.updateTarget();\n    const target = scene.getTarget();\n    position.add(target).sub(this.oldTarget);\n    this.goalPosition.copy(position);\n    scene.setHotspotsVisibility(true);\n    if (this.xrMode === 'screen-space') {\n      const {\n        session\n      } = this.frame;\n      session.addEventListener('selectstart', this.onSelectStart);\n      session.addEventListener('selectend', this.onSelectEnd);\n      session.requestHitTestSourceForTransientInput({\n        profile: 'generic-touchscreen'\n      }).then(hitTestSource => {\n        this.transientHitTestSource = hitTestSource;\n      });\n    }\n  }\n  getTouchLocation() {\n    const {\n      axes\n    } = this.inputSource.gamepad;\n    let location = this.placementBox.getExpandedHit(this.presentedScene, axes[0], axes[1]);\n    if (location != null) {\n      vector3$1.copy(location).sub(this.presentedScene.getCamera().position);\n      if (vector3$1.length() > MAX_DISTANCE) return null;\n    }\n    return location;\n  }\n  getHitPoint(hitResult) {\n    const refSpace = this.threeRenderer.xr.getReferenceSpace();\n    const pose = hitResult.getPose(refSpace);\n    if (pose == null) {\n      return null;\n    }\n    const hitMatrix = matrix4.fromArray(pose.transform.matrix);\n    if (this.placeOnWall === true) {\n      // Orient the model to the wall's normal vector.\n      this.goalYaw = Math.atan2(hitMatrix.elements[4], hitMatrix.elements[6]);\n    }\n    // Check that the y-coordinate of the normal is large enough that the normal\n    // is pointing up for floor placement; opposite for wall placement.\n    return hitMatrix.elements[5] > 0.75 !== this.placeOnWall ? hitPosition.setFromMatrixPosition(hitMatrix) : null;\n  }\n  moveToFloor(frame) {\n    const hitSource = this.initialHitSource;\n    if (hitSource == null) {\n      return;\n    }\n    const hitTestResults = frame.getHitTestResults(hitSource);\n    if (hitTestResults.length == 0) {\n      return;\n    }\n    const hit = hitTestResults[0];\n    const hitPoint = this.getHitPoint(hit);\n    if (hitPoint == null) {\n      return;\n    }\n    this.placementBox.show = true;\n    // If the user is translating, let the finger hit-ray take precedence and\n    // ignore this hit result.\n    if (!this.isTranslating) {\n      if (this.placeOnWall) {\n        this.goalPosition.copy(hitPoint);\n      } else {\n        this.goalPosition.y = hitPoint.y;\n      }\n    }\n    hitSource.cancel();\n    this.initialHitSource = null;\n    this.dispatchEvent({\n      type: 'status',\n      status: ARStatus.OBJECT_PLACED\n    });\n  }\n  fingerPolar(fingers) {\n    const fingerOne = fingers[0].inputSource.gamepad.axes;\n    const fingerTwo = fingers[1].inputSource.gamepad.axes;\n    const deltaX = fingerTwo[0] - fingerOne[0];\n    const deltaY = fingerTwo[1] - fingerOne[1];\n    const angle = Math.atan2(deltaY, deltaX);\n    let deltaYaw = this.lastAngle - angle;\n    if (deltaYaw > Math.PI) {\n      deltaYaw -= 2 * Math.PI;\n    } else if (deltaYaw < -Math.PI) {\n      deltaYaw += 2 * Math.PI;\n    }\n    this.lastAngle = angle;\n    return {\n      separation: Math.sqrt(deltaX * deltaX + deltaY * deltaY),\n      deltaYaw: deltaYaw\n    };\n  }\n  setScale(separation) {\n    const scale = separation / this.firstRatio;\n    this.goalScale = Math.abs(scale - 1) < SCALE_SNAP ? 1 : scale;\n  }\n  processInput(frame) {\n    const hitSource = this.transientHitTestSource;\n    if (hitSource == null) {\n      return;\n    }\n    if (!this.isTranslating && !this.isTwoFingering && !this.isRotating) {\n      return;\n    }\n    const fingers = frame.getHitTestResultsForTransientInput(hitSource);\n    const scene = this.presentedScene;\n    const scale = scene.pivot.scale.x;\n    // Rotating, translating and scaling are mutually exclusive operations; only\n    // one can happen at a time, but we can switch during a gesture.\n    if (this.isTwoFingering) {\n      if (fingers.length < 2) {\n        // If we lose the second finger, stop scaling (in fact, stop processing\n        // input altogether until a new gesture starts).\n        this.isTwoFingering = false;\n      } else {\n        const {\n          separation,\n          deltaYaw\n        } = this.fingerPolar(fingers);\n        if (this.placeOnWall === false) {\n          this.goalYaw += deltaYaw;\n        }\n        if (scene.canScale) {\n          this.setScale(separation);\n        }\n      }\n      return;\n    } else if (fingers.length === 2) {\n      // If we were rotating or translating and we get a second finger, switch\n      // to scaling instead.\n      this.isTranslating = false;\n      this.isRotating = false;\n      this.isTwoFingering = true;\n      const {\n        separation\n      } = this.fingerPolar(fingers);\n      this.firstRatio = separation / scale;\n      return;\n    }\n    if (this.isRotating) {\n      const angle = this.inputSource.gamepad.axes[0] * ROTATION_RATE;\n      this.goalYaw += angle - this.lastAngle;\n      this.lastAngle = angle;\n    } else if (this.isTranslating) {\n      fingers.forEach(finger => {\n        if (finger.inputSource !== this.inputSource) {\n          return;\n        }\n        let hit = null;\n        if (finger.results.length > 0) {\n          hit = this.getHitPoint(finger.results[0]);\n        }\n        if (hit == null) {\n          hit = this.getTouchLocation();\n        }\n        if (hit == null) {\n          return;\n        }\n        this.goalPosition.sub(this.lastDragPosition);\n        if (this.placeOnWall === false) {\n          const offset = hit.y - this.lastDragPosition.y;\n          // When a lower floor is found, keep the model at the same height, but\n          // drop the placement box to the floor. The model falls on select end.\n          if (offset < 0) {\n            this.placementBox.offsetHeight = offset / scale;\n            this.presentedScene.setShadowOffset(offset);\n            // Interpolate hit ray up to drag plane\n            const cameraPosition = vector3$1.copy(scene.getCamera().position);\n            const alpha = -offset / (cameraPosition.y - hit.y);\n            cameraPosition.multiplyScalar(alpha);\n            hit.multiplyScalar(1 - alpha).add(cameraPosition);\n          }\n        }\n        this.goalPosition.add(hit);\n        this.lastDragPosition.copy(hit);\n      });\n    }\n  }\n  moveScene(delta) {\n    const scene = this.presentedScene;\n    const {\n      pivot\n    } = scene;\n    const box = this.placementBox;\n    box.updateOpacity(delta);\n    if (this.controller1) {\n      if (this.controller1.userData.turning) {\n        pivot.quaternion.copy(this.controller1.quaternion).multiply(this.relativeOrientation);\n        if (this.selectedController && this.selectedController === this.controller2) {\n          pivot.quaternion.premultiply(quaternion.copy(this.controller2.quaternion).invert());\n        }\n      }\n      this.controller1.userData.box.position.copy(this.controller1.position);\n      pivot.getWorldQuaternion(this.controller1.userData.box.quaternion);\n    }\n    if (this.controller2) {\n      if (this.controller2.userData.turning) {\n        pivot.quaternion.copy(this.controller2.quaternion).multiply(this.relativeOrientation);\n        if (this.selectedController && this.selectedController === this.controller1) {\n          pivot.quaternion.premultiply(quaternion.copy(this.controller1.quaternion).invert());\n        }\n      }\n      this.controller2.userData.box.position.copy(this.controller2.position);\n      pivot.getWorldQuaternion(this.controller2.userData.box.quaternion);\n    }\n    if (this.controller1 && this.controller2 && this.isTwoFingering) {\n      const dist = this.controllerSeparation();\n      this.setScale(dist);\n      this.scaleLine.scale.z = -dist;\n      this.scaleLine.lookAt(this.controller2.position);\n    }\n    const oldScale = scene.pivot.scale.x;\n    if (this.goalScale !== oldScale) {\n      const newScale = this.scaleDamper.update(oldScale, this.goalScale, delta, 1);\n      scene.pivot.scale.set(newScale, newScale, newScale);\n    }\n    if (pivot.parent !== scene) {\n      return; // attached to controller instead\n    }\n    const {\n      position\n    } = pivot;\n    const boundingRadius = scene.boundingSphere.radius;\n    const goal = this.goalPosition;\n    let source = ChangeSource.NONE;\n    if (!goal.equals(position)) {\n      source = ChangeSource.USER_INTERACTION;\n      let {\n        x,\n        y,\n        z\n      } = position;\n      x = this.xDamper.update(x, goal.x, delta, boundingRadius);\n      y = this.yDamper.update(y, goal.y, delta, boundingRadius);\n      z = this.zDamper.update(z, goal.z, delta, boundingRadius);\n      position.set(x, y, z);\n      if (this.xrMode === 'screen-space' && !this.isTranslating) {\n        const offset = goal.y - y;\n        if (this.placementComplete && this.placeOnWall === false) {\n          box.offsetHeight = offset / scene.pivot.scale.x;\n          scene.setShadowOffset(offset);\n        } else if (offset === 0) {\n          this.placementComplete = true;\n          box.show = false;\n          scene.setShadowIntensity(AR_SHADOW_INTENSITY);\n        }\n      }\n      if (this.xrMode !== 'screen-space' && goal.equals(position)) {\n        scene.setShadowIntensity(AR_SHADOW_INTENSITY);\n      }\n    }\n    scene.updateTarget(delta);\n    // yaw must be updated last, since this also updates the shadow position.\n    quaternion.setFromAxisAngle(vector3$1.set(0, 1, 0), this.goalYaw);\n    const angle = scene.pivot.quaternion.angleTo(quaternion);\n    const angleStep = angle - this.yawDamper.update(angle, 0, delta, Math.PI);\n    scene.pivot.quaternion.rotateTowards(quaternion, angleStep);\n    // camera changes on every frame - user-interaction only if touching the\n    // screen, plus damping time.\n    scene.element.dispatchEvent(new CustomEvent('camera-change', {\n      detail: {\n        source\n      }\n    }));\n  }\n  /**\n   * Only public to make it testable.\n   */\n  onWebXRFrame(time, frame) {\n    if (this.xrMode !== 'screen-space') {\n      const over1 = this.hover(this.controller1);\n      const over2 = this.hover(this.controller2);\n      this.placementBox.show = (over1 || over2) && !this.isTwoFingering;\n    }\n    this.frame = frame;\n    ++this.frames;\n    const refSpace = this.threeRenderer.xr.getReferenceSpace();\n    const pose = frame.getViewerPose(refSpace);\n    if (pose == null && this.tracking === true && this.frames > INIT_FRAMES) {\n      this.tracking = false;\n      this.dispatchEvent({\n        type: 'tracking',\n        status: ARTracking.NOT_TRACKING\n      });\n    }\n    const scene = this.presentedScene;\n    if (pose == null || scene == null || !scene.element.loaded) {\n      this.threeRenderer.clear();\n      return;\n    }\n    if (this.tracking === false) {\n      this.tracking = true;\n      this.dispatchEvent({\n        type: 'tracking',\n        status: ARTracking.TRACKING\n      });\n    }\n    // WebXR may return multiple views, i.e. for headset AR. This\n    // isn't really supported at this point, but make a best-effort\n    // attempt to render other views also, using the first view\n    // as the main viewpoint.\n    let isFirstView = true;\n    for (const view of pose.views) {\n      this.updateView(view);\n      if (isFirstView) {\n        this.moveToFloor(frame);\n        this.processInput(frame);\n        const delta = time - this.lastTick;\n        this.moveScene(delta);\n        this.renderer.preRender(scene, time, delta);\n        this.lastTick = time;\n        scene.renderShadow(this.threeRenderer);\n      }\n      this.threeRenderer.render(scene, scene.getCamera());\n      isFirstView = false;\n    }\n  }\n}\nfunction clone(source) {\n  const sourceLookup = new Map();\n  const cloneLookup = new Map();\n  const clone = source.clone();\n  parallelTraverse(source, clone, function (sourceNode, clonedNode) {\n    sourceLookup.set(clonedNode, sourceNode);\n    cloneLookup.set(sourceNode, clonedNode);\n  });\n  clone.traverse(function (node) {\n    if (!node.isSkinnedMesh) return;\n    const clonedMesh = node;\n    const sourceMesh = sourceLookup.get(node);\n    const sourceBones = sourceMesh.skeleton.bones;\n    clonedMesh.skeleton = sourceMesh.skeleton.clone();\n    clonedMesh.bindMatrix.copy(sourceMesh.bindMatrix);\n    clonedMesh.skeleton.bones = sourceBones.map(function (bone) {\n      return cloneLookup.get(bone);\n    });\n    clonedMesh.bind(clonedMesh.skeleton, clonedMesh.bindMatrix);\n  });\n  return clone;\n}\nfunction parallelTraverse(a, b, callback) {\n  callback(a, b);\n  for (let i = 0; i < a.children.length; i++) {\n    parallelTraverse(a.children[i], b.children[i], callback);\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst $prepared = Symbol('prepared');\nconst $prepare = Symbol('prepare');\nconst $preparedGLTF = Symbol('preparedGLTF');\nconst $clone = Symbol('clone');\n/**\n * Represents the preparation and enhancement of the output of a Three.js\n * GLTFLoader (a Three.js-flavor \"GLTF\"), to make it suitable for optimal,\n * correct viewing in a given presentation context and also make the cloning\n * process more explicit and legible.\n *\n * A GLTFInstance is API-compatible with a Three.js-flavor \"GLTF\", so it should\n * be considered to be interchangeable with the loaded result of a GLTFLoader.\n *\n * This basic implementation only implements trivial preparation and enhancement\n * of a GLTF. These operations are intended to be enhanced by inheriting\n * classes.\n */\nclass GLTFInstance {\n  constructor(preparedGLTF) {\n    this[$preparedGLTF] = preparedGLTF;\n  }\n  /**\n   * Prepares a given GLTF for presentation and future cloning. A GLTF that is\n   * prepared can safely have this method invoked on it multiple times; it will\n   * only be prepared once, including after being cloned.\n   */\n  static prepare(source) {\n    if (source.scene == null) {\n      throw new Error('Model does not have a scene');\n    }\n    if (source[$prepared]) {\n      return source;\n    }\n    const prepared = this[$prepare](source);\n    // NOTE: ES5 Symbol polyfill is not compatible with spread operator\n    // so {...prepared, [$prepared]: true} does not work\n    prepared[$prepared] = true;\n    return prepared;\n  }\n  /**\n   * Override in an inheriting class to apply specialty one-time preparations\n   * for a given input GLTF.\n   */\n  static [$prepare](source) {\n    // TODO(#195,#1003): We don't currently support multiple scenes, so we don't\n    // bother preparing extra scenes for now:\n    const {\n      scene\n    } = source;\n    const scenes = [scene];\n    return Object.assign(Object.assign({}, source), {\n      scene,\n      scenes\n    });\n  }\n  get parser() {\n    return this[$preparedGLTF].parser;\n  }\n  get animations() {\n    return this[$preparedGLTF].animations;\n  }\n  get scene() {\n    return this[$preparedGLTF].scene;\n  }\n  get scenes() {\n    return this[$preparedGLTF].scenes;\n  }\n  get cameras() {\n    return this[$preparedGLTF].cameras;\n  }\n  get asset() {\n    return this[$preparedGLTF].asset;\n  }\n  get userData() {\n    return this[$preparedGLTF].userData;\n  }\n  /**\n   * Creates and returns a copy of this instance.\n   */\n  clone() {\n    const GLTFInstanceConstructor = this.constructor;\n    const clonedGLTF = this[$clone]();\n    return new GLTFInstanceConstructor(clonedGLTF);\n  }\n  /**\n   * Cleans up any retained memory that might not otherwise be released when\n   * this instance is done being used.\n   */\n  dispose() {\n    this.scenes.forEach(scene => {\n      scene.traverse(object => {\n        const mesh = object;\n        if (!mesh.material) {\n          return;\n        }\n        const materials = Array.isArray(mesh.material) ? mesh.material : [mesh.material];\n        materials.forEach(material => {\n          // Explicitly dispose any textures assigned to this material\n          for (const propertyName in material) {\n            const texture = material[propertyName];\n            if (texture instanceof Texture$1) {\n              const image = texture.source.data;\n              if (image.close != null) {\n                image.close();\n              }\n              texture.dispose();\n            }\n          }\n          material.dispose();\n        });\n        mesh.geometry.dispose();\n      });\n    });\n  }\n  /**\n   * Override in an inheriting class to implement specialized cloning strategies\n   */\n  [$clone]() {\n    const source = this[$preparedGLTF];\n    // TODO(#195,#1003): We don't currently support multiple scenes, so we don't\n    // bother cloning extra scenes for now:\n    const scene = clone(this.scene);\n    cloneVariantMaterials(scene, this.scene);\n    const scenes = [scene];\n    const userData = source.userData ? Object.assign({}, source.userData) : {};\n    return Object.assign(Object.assign({}, source), {\n      scene,\n      scenes,\n      userData\n    });\n  }\n}\n// Variant materials and original material instances are stored under\n// object.userData.variantMaterials/originalMaterial.\n// Three.js Object3D.clone() doesn't clone Three.js objects under\n// .userData so this function is a workaround.\nconst cloneVariantMaterials = (dst, src) => {\n  traversePair(dst, src, (dst, src) => {\n    if (src.userData.variantMaterials !== undefined) {\n      dst.userData.variantMaterials = new Map(src.userData.variantMaterials);\n    }\n    if (src.userData.variantData !== undefined) {\n      dst.userData.variantData = src.userData.variantData;\n    }\n    if (src.userData.originalMaterial !== undefined) {\n      dst.userData.originalMaterial = src.userData.originalMaterial;\n    }\n  });\n};\nconst traversePair = (obj1, obj2, callback) => {\n  callback(obj1, obj2);\n  // Assume obj1 and obj2 have the same tree structure\n  for (let i = 0; i < obj1.children.length; i++) {\n    traversePair(obj1.children[i], obj2.children[i], callback);\n  }\n};\nconst $threeGLTF = Symbol('threeGLTF');\nconst $gltf = Symbol('gltf');\nconst $gltfElementMap = Symbol('gltfElementMap');\nconst $threeObjectMap = Symbol('threeObjectMap');\nconst $parallelTraverseThreeScene = Symbol('parallelTraverseThreeScene');\nconst $correlateOriginalThreeGLTF = Symbol('correlateOriginalThreeGLTF');\nconst $correlateCloneThreeGLTF = Symbol('correlateCloneThreeGLTF');\n/**\n * The Three.js GLTFLoader provides us with an in-memory representation\n * of a glTF in terms of Three.js constructs. It also provides us with a copy\n * of the deserialized glTF without any Three.js decoration, and a mapping of\n * glTF elements to their corresponding Three.js constructs.\n *\n * A CorrelatedSceneGraph exposes a synchronously available mapping of glTF\n * element references to their corresponding Three.js constructs.\n */\nclass CorrelatedSceneGraph {\n  constructor(threeGLTF, gltf, threeObjectMap, gltfElementMap) {\n    this[$threeGLTF] = threeGLTF;\n    this[$gltf] = gltf;\n    this[$gltfElementMap] = gltfElementMap;\n    this[$threeObjectMap] = threeObjectMap;\n  }\n  /**\n   * Produce a CorrelatedSceneGraph from a naturally generated Three.js GLTF.\n   * Such GLTFs are produced by Three.js' GLTFLoader, and contain cached\n   * details that expedite the correlation step.\n   *\n   * If a CorrelatedSceneGraph is provided as the second argument, re-correlates\n   * a cloned Three.js GLTF with a clone of the glTF hierarchy used to produce\n   * the upstream Three.js GLTF that the clone was created from. The result\n   * CorrelatedSceneGraph is representative of the cloned hierarchy.\n   */\n  static from(threeGLTF, upstreamCorrelatedSceneGraph) {\n    if (upstreamCorrelatedSceneGraph != null) {\n      return this[$correlateCloneThreeGLTF](threeGLTF, upstreamCorrelatedSceneGraph);\n    } else {\n      return this[$correlateOriginalThreeGLTF](threeGLTF);\n    }\n  }\n  static [$correlateOriginalThreeGLTF](threeGLTF) {\n    const gltf = threeGLTF.parser.json;\n    const associations = threeGLTF.parser.associations;\n    const gltfElementMap = new Map();\n    const defaultMaterial = {\n      name: 'Default'\n    };\n    const defaultReference = {\n      type: 'materials',\n      index: -1\n    };\n    for (const threeMaterial of associations.keys()) {\n      // Note: GLTFLoader creates a \"default\" material that has no\n      // corresponding glTF element in the case that no materials are\n      // specified in the source glTF. In this case we append a default\n      // material to allow this to be operated upon.\n      if (threeMaterial instanceof Material$1 && associations.get(threeMaterial) == null) {\n        if (defaultReference.index < 0) {\n          if (gltf.materials == null) {\n            gltf.materials = [];\n          }\n          defaultReference.index = gltf.materials.length;\n          gltf.materials.push(defaultMaterial);\n        }\n        threeMaterial.name = defaultMaterial.name;\n        associations.set(threeMaterial, {\n          materials: defaultReference.index\n        });\n      }\n    }\n    // Creates a reverse look up map (gltf-object to Three-object)\n    for (const [threeObject, gltfMappings] of associations) {\n      if (gltfMappings) {\n        threeObject.userData = threeObject.userData || {};\n        threeObject.userData.associations = gltfMappings;\n      }\n      for (const mapping in gltfMappings) {\n        if (mapping != null && mapping !== 'primitives') {\n          const type = mapping;\n          const elementArray = gltf[type] || [];\n          const gltfElement = elementArray[gltfMappings[type]];\n          if (gltfElement == null) {\n            // TODO: Maybe throw here...\n            continue;\n          }\n          let threeObjects = gltfElementMap.get(gltfElement);\n          if (threeObjects == null) {\n            threeObjects = new Set();\n            gltfElementMap.set(gltfElement, threeObjects);\n          }\n          threeObjects.add(threeObject);\n        }\n      }\n    }\n    return new CorrelatedSceneGraph(threeGLTF, gltf, associations, gltfElementMap);\n  }\n  /**\n   * Transfers the association between a raw glTF and a Three.js scene graph\n   * to a clone of the Three.js scene graph, resolved as a new\n   * CorrelatedSceneGraph instance.\n   */\n  static [$correlateCloneThreeGLTF](cloneThreeGLTF, upstreamCorrelatedSceneGraph) {\n    const originalThreeGLTF = upstreamCorrelatedSceneGraph.threeGLTF;\n    const originalGLTF = upstreamCorrelatedSceneGraph.gltf;\n    const cloneGLTF = JSON.parse(JSON.stringify(originalGLTF));\n    const cloneThreeObjectMap = new Map();\n    const cloneGLTFElementMap = new Map();\n    for (let i = 0; i < originalThreeGLTF.scenes.length; i++) {\n      this[$parallelTraverseThreeScene](originalThreeGLTF.scenes[i], cloneThreeGLTF.scenes[i], (object, cloneObject) => {\n        const elementReference = upstreamCorrelatedSceneGraph.threeObjectMap.get(object);\n        if (elementReference == null) {\n          return;\n        }\n        for (const mapping in elementReference) {\n          if (mapping != null && mapping !== 'primitives') {\n            const type = mapping;\n            const index = elementReference[type];\n            const cloneElement = cloneGLTF[type][index];\n            const mappings = cloneThreeObjectMap.get(cloneObject) || {};\n            mappings[type] = index;\n            cloneThreeObjectMap.set(cloneObject, mappings);\n            const cloneObjects = cloneGLTFElementMap.get(cloneElement) || new Set();\n            cloneObjects.add(cloneObject);\n            cloneGLTFElementMap.set(cloneElement, cloneObjects);\n          }\n        }\n      });\n    }\n    return new CorrelatedSceneGraph(cloneThreeGLTF, cloneGLTF, cloneThreeObjectMap, cloneGLTFElementMap);\n  }\n  /**\n   * Traverses two presumably identical Three.js scenes, and invokes a\n   * callback for each Object3D or Material encountered, including the initial\n   * scene. Adapted from\n   * https://github.com/mrdoob/three.js/blob/7c1424c5819ab622a346dd630ee4e6431388021e/examples/jsm/utils/SkeletonUtils.js#L586-L596\n   */\n  static [$parallelTraverseThreeScene](sceneOne, sceneTwo, callback) {\n    const traverse = (a, b) => {\n      callback(a, b);\n      if (a.isObject3D) {\n        const meshA = a;\n        const meshB = b;\n        if (meshA.material) {\n          if (Array.isArray(meshA.material)) {\n            for (let i = 0; i < meshA.material.length; ++i) {\n              callback(meshA.material[i], meshB.material[i]);\n            }\n          } else {\n            callback(meshA.material, meshB.material);\n          }\n        }\n        for (let i = 0; i < a.children.length; ++i) {\n          traverse(a.children[i], b.children[i]);\n        }\n      }\n    };\n    traverse(sceneOne, sceneTwo);\n  }\n  /**\n   * The source Three.js GLTF result given to us by a Three.js GLTFLoader.\n   */\n  get threeGLTF() {\n    return this[$threeGLTF];\n  }\n  /**\n   * The in-memory deserialized source glTF.\n   */\n  get gltf() {\n    return this[$gltf];\n  }\n  /**\n   * A Map of glTF element references to arrays of corresponding Three.js\n   * object references. Three.js objects are kept in arrays to account for\n   * cases where more than one Three.js object corresponds to a single glTF\n   * element.\n   */\n  get gltfElementMap() {\n    return this[$gltfElementMap];\n  }\n  /**\n   * A map of individual Three.js objects to corresponding elements in the\n   * source glTF.\n   */\n  get threeObjectMap() {\n    return this[$threeObjectMap];\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst $correlatedSceneGraph = Symbol('correlatedSceneGraph');\n/**\n * This specialization of GLTFInstance collects all of the processing needed\n * to prepare a model and to clone it making special considerations for\n * <model-viewer> use cases.\n */\nclass ModelViewerGLTFInstance extends GLTFInstance {\n  /**\n   * @override\n   */\n  static [$prepare](source) {\n    const prepared = super[$prepare](source);\n    if (prepared[$correlatedSceneGraph] == null) {\n      prepared[$correlatedSceneGraph] = CorrelatedSceneGraph.from(prepared);\n    }\n    const {\n      scene\n    } = prepared;\n    const nullSphere = new Sphere(undefined, Infinity);\n    scene.traverse(node => {\n      // Set a high renderOrder while we're here to ensure the model\n      // always renders on top of the sky sphere\n      node.renderOrder = 1000;\n      // Three.js seems to cull some animated models incorrectly. Since we\n      // expect to view our whole scene anyway, we turn off the frustum\n      // culling optimization here.\n      node.frustumCulled = false;\n      // Animations for objects without names target their UUID instead. When\n      // objects are cloned, they get new UUIDs which the animation can't\n      // find. To fix this, we assign their UUID as their name.\n      if (!node.name) {\n        node.name = node.uuid;\n      }\n      const mesh = node;\n      if (mesh.material) {\n        const {\n          geometry\n        } = mesh;\n        mesh.castShadow = true;\n        if (mesh.isSkinnedMesh) {\n          // Akin to disabling frustum culling above, we have to also manually\n          // disable the bounds to make raycasting correct for skinned meshes.\n          geometry.boundingSphere = nullSphere;\n          // The bounding box is set in GLTFLoader by the accessor bounds, which\n          // are not updated with animation.\n          geometry.boundingBox = null;\n        }\n        const material = mesh.material;\n        if (material.isMeshBasicMaterial === true) {\n          material.toneMapped = false;\n        }\n        // This makes shadows better for non-manifold meshes\n        material.shadowSide = FrontSide;\n        // Fixes an edge case with unused extra UV-coords being incorrectly\n        // referenced by three.js; remove when\n        // https://github.com/mrdoob/three.js/pull/23974 is merged.\n        if (material.aoMap) {\n          const {\n            gltf,\n            threeObjectMap\n          } = prepared[$correlatedSceneGraph];\n          const gltfRef = threeObjectMap.get(material);\n          if (gltf.materials != null && gltfRef != null && gltfRef.materials != null) {\n            const gltfMaterial = gltf.materials[gltfRef.materials];\n            if (gltfMaterial.occlusionTexture && gltfMaterial.occlusionTexture.texCoord === 0 && geometry.attributes.uv != null) {\n              geometry.setAttribute('uv2', geometry.attributes.uv);\n            }\n          }\n        }\n      }\n    });\n    return prepared;\n  }\n  get correlatedSceneGraph() {\n    return this[$preparedGLTF][$correlatedSceneGraph];\n  }\n  /**\n   * @override\n   */\n  [$clone]() {\n    const clone = super[$clone]();\n    const sourceUUIDToClonedMaterial = new Map();\n    clone.scene.traverse(node => {\n      // Materials aren't cloned when cloning meshes; geometry\n      // and materials are copied by reference. This is necessary\n      // for the same model to be used twice with different\n      // scene-graph operations.\n      const mesh = node;\n      if (mesh.material) {\n        const material = mesh.material;\n        if (material != null) {\n          if (sourceUUIDToClonedMaterial.has(material.uuid)) {\n            mesh.material = sourceUUIDToClonedMaterial.get(material.uuid);\n            return;\n          }\n          mesh.material = material.clone();\n          sourceUUIDToClonedMaterial.set(material.uuid, mesh.material);\n        }\n      }\n      const light = node;\n      if (light.target !== undefined) {\n        // The target's parent is lost in the cloning process, but in\n        // GLTFLoader, all light targets are children of their light.\n        light.add(light.target);\n      }\n    });\n    // Cross-correlate the scene graph by relying on information in the\n    // current scene graph; without this step, relationships between the\n    // Three.js object graph and the glTF scene graph will be lost.\n    clone[$correlatedSceneGraph] = CorrelatedSceneGraph.from(clone, this.correlatedSceneGraph);\n    return clone;\n  }\n}\n\n/**\n * @monogrid/gainmap-js v3.0.6\n * With , by MONOGRID <rnd@monogrid.com>\n */\n\nconst getBufferForType = (type, width, height) => {\n  let out;\n  switch (type) {\n    case UnsignedByteType:\n      out = new Uint8ClampedArray(width * height * 4);\n      break;\n    case HalfFloatType:\n      out = new Uint16Array(width * height * 4);\n      break;\n    case UnsignedIntType:\n      out = new Uint32Array(width * height * 4);\n      break;\n    case ByteType:\n      out = new Int8Array(width * height * 4);\n      break;\n    case ShortType:\n      out = new Int16Array(width * height * 4);\n      break;\n    case IntType:\n      out = new Int32Array(width * height * 4);\n      break;\n    case FloatType:\n      out = new Float32Array(width * height * 4);\n      break;\n    default:\n      throw new Error('Unsupported data type');\n  }\n  return out;\n};\nlet _canReadPixelsResult;\n/**\n * Test if this browser implementation can correctly read pixels from the specified\n * Render target type.\n *\n * Runs only once\n *\n * @param type\n * @param renderer\n * @param camera\n * @param renderTargetOptions\n * @returns\n */\nconst canReadPixels = (type, renderer, camera, renderTargetOptions) => {\n  if (_canReadPixelsResult !== undefined) return _canReadPixelsResult;\n  const testRT = new WebGLRenderTarget(1, 1, renderTargetOptions);\n  renderer.setRenderTarget(testRT);\n  const mesh = new Mesh(new PlaneGeometry(), new MeshBasicMaterial({\n    color: 0xffffff\n  }));\n  renderer.render(mesh, camera);\n  renderer.setRenderTarget(null);\n  const out = getBufferForType(type, testRT.width, testRT.height);\n  renderer.readRenderTargetPixels(testRT, 0, 0, testRT.width, testRT.height, out);\n  testRT.dispose();\n  mesh.geometry.dispose();\n  mesh.material.dispose();\n  _canReadPixelsResult = out[0] !== 0;\n  return _canReadPixelsResult;\n};\n/**\n * Utility class used for rendering a texture with a material\n *\n * @category Core\n * @group Core\n */\nclass QuadRenderer {\n  /**\n   * Constructs a new QuadRenderer\n   *\n   * @param options Parameters for this QuadRenderer\n   */\n  constructor(options) {\n    var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o, _p, _q, _r;\n    this._rendererIsDisposable = false;\n    this._supportsReadPixels = true;\n    /**\n     * Renders the input texture using the specified material\n     */\n    this.render = () => {\n      this._renderer.setRenderTarget(this._renderTarget);\n      try {\n        this._renderer.render(this._scene, this._camera);\n      } catch (e) {\n        this._renderer.setRenderTarget(null);\n        throw e;\n      }\n      this._renderer.setRenderTarget(null);\n    };\n    this._width = options.width;\n    this._height = options.height;\n    this._type = options.type;\n    this._colorSpace = options.colorSpace;\n    const rtOptions = {\n      // fixed options\n      format: RGBAFormat,\n      depthBuffer: false,\n      stencilBuffer: false,\n      // user options\n      type: this._type,\n      // set in class property\n      colorSpace: this._colorSpace,\n      // set in class property\n      anisotropy: ((_a = options.renderTargetOptions) === null || _a === void 0 ? void 0 : _a.anisotropy) !== undefined ? (_b = options.renderTargetOptions) === null || _b === void 0 ? void 0 : _b.anisotropy : 1,\n      generateMipmaps: ((_c = options.renderTargetOptions) === null || _c === void 0 ? void 0 : _c.generateMipmaps) !== undefined ? (_d = options.renderTargetOptions) === null || _d === void 0 ? void 0 : _d.generateMipmaps : false,\n      magFilter: ((_e = options.renderTargetOptions) === null || _e === void 0 ? void 0 : _e.magFilter) !== undefined ? (_f = options.renderTargetOptions) === null || _f === void 0 ? void 0 : _f.magFilter : LinearFilter,\n      minFilter: ((_g = options.renderTargetOptions) === null || _g === void 0 ? void 0 : _g.minFilter) !== undefined ? (_h = options.renderTargetOptions) === null || _h === void 0 ? void 0 : _h.minFilter : LinearFilter,\n      samples: ((_j = options.renderTargetOptions) === null || _j === void 0 ? void 0 : _j.samples) !== undefined ? (_k = options.renderTargetOptions) === null || _k === void 0 ? void 0 : _k.samples : undefined,\n      wrapS: ((_l = options.renderTargetOptions) === null || _l === void 0 ? void 0 : _l.wrapS) !== undefined ? (_m = options.renderTargetOptions) === null || _m === void 0 ? void 0 : _m.wrapS : ClampToEdgeWrapping,\n      wrapT: ((_o = options.renderTargetOptions) === null || _o === void 0 ? void 0 : _o.wrapT) !== undefined ? (_p = options.renderTargetOptions) === null || _p === void 0 ? void 0 : _p.wrapT : ClampToEdgeWrapping\n    };\n    this._material = options.material;\n    if (options.renderer) {\n      this._renderer = options.renderer;\n    } else {\n      this._renderer = QuadRenderer.instantiateRenderer();\n      this._rendererIsDisposable = true;\n    }\n    this._scene = new Scene();\n    this._camera = new OrthographicCamera();\n    this._camera.position.set(0, 0, 10);\n    this._camera.left = -0.5;\n    this._camera.right = 0.5;\n    this._camera.top = 0.5;\n    this._camera.bottom = -0.5;\n    this._camera.updateProjectionMatrix();\n    if (!canReadPixels(this._type, this._renderer, this._camera, rtOptions)) {\n      let alternativeType;\n      switch (this._type) {\n        case HalfFloatType:\n          alternativeType = this._renderer.extensions.has('EXT_color_buffer_float') ? FloatType : undefined;\n          break;\n      }\n      if (alternativeType !== undefined) {\n        console.warn(`This browser does not support reading pixels from ${this._type} RenderTargets, switching to ${FloatType}`);\n        this._type = alternativeType;\n      } else {\n        this._supportsReadPixels = false;\n        console.warn('This browser dos not support toArray or toDataTexture, calls to those methods will result in an error thrown');\n      }\n    }\n    this._quad = new Mesh(new PlaneGeometry(), this._material);\n    this._quad.geometry.computeBoundingBox();\n    this._scene.add(this._quad);\n    this._renderTarget = new WebGLRenderTarget(this.width, this.height, rtOptions);\n    this._renderTarget.texture.mapping = ((_q = options.renderTargetOptions) === null || _q === void 0 ? void 0 : _q.mapping) !== undefined ? (_r = options.renderTargetOptions) === null || _r === void 0 ? void 0 : _r.mapping : UVMapping;\n  }\n  /**\n   * Instantiates a temporary renderer\n   *\n   * @returns\n   */\n  static instantiateRenderer() {\n    const renderer = new WebGLRenderer();\n    renderer.setSize(128, 128);\n    // renderer.outputColorSpace = SRGBColorSpace\n    // renderer.toneMapping = LinearToneMapping\n    // renderer.debug.checkShaderErrors = false\n    // this._rendererIsDisposable = true\n    return renderer;\n  }\n  /**\n   * Obtains a Buffer containing the rendered texture.\n   *\n   * @throws Error if the browser cannot read pixels from this RenderTarget type.\n   * @returns a TypedArray containing RGBA values from this renderer\n   */\n  toArray() {\n    if (!this._supportsReadPixels) throw new Error('Can\\'t read pixels in this browser');\n    const out = getBufferForType(this._type, this._width, this._height);\n    this._renderer.readRenderTargetPixels(this._renderTarget, 0, 0, this._width, this._height, out);\n    return out;\n  }\n  /**\n   * Performs a readPixel operation in the renderTarget\n   * and returns a DataTexture containing the read data\n   *\n   * @param options options\n   * @returns\n   */\n  toDataTexture(options) {\n    const returnValue = new DataTexture(\n    // fixed values\n    this.toArray(), this.width, this.height, RGBAFormat, this._type,\n    // user values\n    (options === null || options === void 0 ? void 0 : options.mapping) || UVMapping, (options === null || options === void 0 ? void 0 : options.wrapS) || ClampToEdgeWrapping, (options === null || options === void 0 ? void 0 : options.wrapT) || ClampToEdgeWrapping, (options === null || options === void 0 ? void 0 : options.magFilter) || LinearFilter, (options === null || options === void 0 ? void 0 : options.minFilter) || LinearFilter, (options === null || options === void 0 ? void 0 : options.anisotropy) || 1,\n    // fixed value\n    LinearSRGBColorSpace);\n    // set this afterwards, we can't set it in constructor\n    returnValue.generateMipmaps = (options === null || options === void 0 ? void 0 : options.generateMipmaps) !== undefined ? options === null || options === void 0 ? void 0 : options.generateMipmaps : false;\n    return returnValue;\n  }\n  /**\n   * If using a disposable renderer, it will dispose it.\n   */\n  disposeOnDemandRenderer() {\n    this._renderer.setRenderTarget(null);\n    if (this._rendererIsDisposable) {\n      this._renderer.dispose();\n      this._renderer.forceContextLoss();\n    }\n  }\n  /**\n   * Will dispose of **all** assets used by this renderer.\n   *\n   *\n   * @param disposeRenderTarget will dispose of the renderTarget which will not be usable later\n   * set this to true if you passed the `renderTarget.texture` to a `PMREMGenerator`\n   * or are otherwise done with it.\n   *\n   * @example\n   * ```js\n   * const loader = new HDRJPGLoader(renderer)\n   * const result = await loader.loadAsync('gainmap.jpeg')\n   * const mesh = new Mesh(geometry, new MeshBasicMaterial({ map: result.renderTarget.texture }) )\n   * // DO NOT dispose the renderTarget here,\n   * // it is used directly in the material\n   * result.dispose()\n   * ```\n   *\n   * @example\n   * ```js\n   * const loader = new HDRJPGLoader(renderer)\n   * const pmremGenerator = new PMREMGenerator( renderer );\n   * const result = await loader.loadAsync('gainmap.jpeg')\n   * const envMap = pmremGenerator.fromEquirectangular(result.renderTarget.texture)\n   * const mesh = new Mesh(geometry, new MeshStandardMaterial({ envMap }) )\n   * // renderTarget can be disposed here\n   * // because it was used to generate a PMREM texture\n   * result.dispose(true)\n   * ```\n   */\n  dispose(disposeRenderTarget) {\n    this.disposeOnDemandRenderer();\n    if (disposeRenderTarget) {\n      this.renderTarget.dispose();\n    }\n    // dispose shader material texture uniforms\n    if (this.material instanceof ShaderMaterial) {\n      Object.values(this.material.uniforms).forEach(v => {\n        if (v.value instanceof Texture$1) v.value.dispose();\n      });\n    }\n    // dispose other material properties\n    Object.values(this.material).forEach(value => {\n      if (value instanceof Texture$1) value.dispose();\n    });\n    this.material.dispose();\n    this._quad.geometry.dispose();\n  }\n  /**\n   * Width of the texture\n   */\n  get width() {\n    return this._width;\n  }\n  set width(value) {\n    this._width = value;\n    this._renderTarget.setSize(this._width, this._height);\n  }\n  /**\n   * Height of the texture\n   */\n  get height() {\n    return this._height;\n  }\n  set height(value) {\n    this._height = value;\n    this._renderTarget.setSize(this._width, this._height);\n  }\n  /**\n   * The renderer used\n   */\n  get renderer() {\n    return this._renderer;\n  }\n  /**\n   * The `WebGLRenderTarget` used.\n   */\n  get renderTarget() {\n    return this._renderTarget;\n  }\n  set renderTarget(value) {\n    this._renderTarget = value;\n    this._width = value.width;\n    this._height = value.height;\n    // this._type = value.texture.type\n  }\n  /**\n   * The `Material` used.\n   */\n  get material() {\n    return this._material;\n  }\n  /**\n   *\n   */\n  get type() {\n    return this._type;\n  }\n  get colorSpace() {\n    return this._colorSpace;\n  }\n}\n\n/**\n * @monogrid/gainmap-js v3.0.6\n * With , by MONOGRID <rnd@monogrid.com>\n */\n\nconst vertexShader = /* glsl */`\nvarying vec2 vUv;\n\nvoid main() {\n  vUv = uv;\n  gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);\n}\n`;\nconst fragmentShader = /* glsl */`\n// min half float value\n#define HALF_FLOAT_MIN vec3( -65504, -65504, -65504 )\n// max half float value\n#define HALF_FLOAT_MAX vec3( 65504, 65504, 65504 )\n\nuniform sampler2D sdr;\nuniform sampler2D gainMap;\nuniform vec3 gamma;\nuniform vec3 offsetHdr;\nuniform vec3 offsetSdr;\nuniform vec3 gainMapMin;\nuniform vec3 gainMapMax;\nuniform float weightFactor;\n\nvarying vec2 vUv;\n\nvoid main() {\n  vec3 rgb = texture2D( sdr, vUv ).rgb;\n  vec3 recovery = texture2D( gainMap, vUv ).rgb;\n  vec3 logRecovery = pow( recovery, gamma );\n  vec3 logBoost = gainMapMin * ( 1.0 - logRecovery ) + gainMapMax * logRecovery;\n  vec3 hdrColor = (rgb + offsetSdr) * exp2( logBoost * weightFactor ) - offsetHdr;\n  vec3 clampedHdrColor = max( HALF_FLOAT_MIN, min( HALF_FLOAT_MAX, hdrColor ));\n  gl_FragColor = vec4( clampedHdrColor , 1.0 );\n}\n`;\n/**\n * A Material which is able to decode the Gainmap into a full HDR Representation\n *\n * @category Materials\n * @group Materials\n */\nclass GainMapDecoderMaterial extends ShaderMaterial {\n  /**\n   *\n   * @param params\n   */\n  constructor({\n    gamma,\n    offsetHdr,\n    offsetSdr,\n    gainMapMin,\n    gainMapMax,\n    maxDisplayBoost,\n    hdrCapacityMin,\n    hdrCapacityMax,\n    sdr,\n    gainMap\n  }) {\n    super({\n      name: 'GainMapDecoderMaterial',\n      vertexShader,\n      fragmentShader,\n      uniforms: {\n        sdr: {\n          value: sdr\n        },\n        gainMap: {\n          value: gainMap\n        },\n        gamma: {\n          value: new Vector3(1.0 / gamma[0], 1.0 / gamma[1], 1.0 / gamma[2])\n        },\n        offsetHdr: {\n          value: new Vector3().fromArray(offsetHdr)\n        },\n        offsetSdr: {\n          value: new Vector3().fromArray(offsetSdr)\n        },\n        gainMapMin: {\n          value: new Vector3().fromArray(gainMapMin)\n        },\n        gainMapMax: {\n          value: new Vector3().fromArray(gainMapMax)\n        },\n        weightFactor: {\n          value: (Math.log2(maxDisplayBoost) - hdrCapacityMin) / (hdrCapacityMax - hdrCapacityMin)\n        }\n      },\n      blending: NoBlending,\n      depthTest: false,\n      depthWrite: false\n    });\n    this._maxDisplayBoost = maxDisplayBoost;\n    this._hdrCapacityMin = hdrCapacityMin;\n    this._hdrCapacityMax = hdrCapacityMax;\n    this.needsUpdate = true;\n    this.uniformsNeedUpdate = true;\n  }\n  get sdr() {\n    return this.uniforms.sdr.value;\n  }\n  set sdr(value) {\n    this.uniforms.sdr.value = value;\n  }\n  get gainMap() {\n    return this.uniforms.gainMap.value;\n  }\n  set gainMap(value) {\n    this.uniforms.gainMap.value = value;\n  }\n  /**\n   * @see {@link GainMapMetadata.offsetHdr}\n   */\n  get offsetHdr() {\n    return this.uniforms.offsetHdr.value.toArray();\n  }\n  set offsetHdr(value) {\n    this.uniforms.offsetHdr.value.fromArray(value);\n  }\n  /**\n   * @see {@link GainMapMetadata.offsetSdr}\n   */\n  get offsetSdr() {\n    return this.uniforms.offsetSdr.value.toArray();\n  }\n  set offsetSdr(value) {\n    this.uniforms.offsetSdr.value.fromArray(value);\n  }\n  /**\n   * @see {@link GainMapMetadata.gainMapMin}\n   */\n  get gainMapMin() {\n    return this.uniforms.gainMapMin.value.toArray();\n  }\n  set gainMapMin(value) {\n    this.uniforms.gainMapMin.value.fromArray(value);\n  }\n  /**\n   * @see {@link GainMapMetadata.gainMapMax}\n   */\n  get gainMapMax() {\n    return this.uniforms.gainMapMax.value.toArray();\n  }\n  set gainMapMax(value) {\n    this.uniforms.gainMapMax.value.fromArray(value);\n  }\n  /**\n   * @see {@link GainMapMetadata.gamma}\n   */\n  get gamma() {\n    const g = this.uniforms.gamma.value;\n    return [1 / g.x, 1 / g.y, 1 / g.z];\n  }\n  set gamma(value) {\n    const g = this.uniforms.gamma.value;\n    g.x = 1.0 / value[0];\n    g.y = 1.0 / value[1];\n    g.z = 1.0 / value[2];\n  }\n  /**\n   * @see {@link GainMapMetadata.hdrCapacityMin}\n   * @remarks Logarithmic space\n   */\n  get hdrCapacityMin() {\n    return this._hdrCapacityMin;\n  }\n  set hdrCapacityMin(value) {\n    this._hdrCapacityMin = value;\n    this.calculateWeight();\n  }\n  /**\n   * @see {@link GainMapMetadata.hdrCapacityMin}\n   * @remarks Logarithmic space\n   */\n  get hdrCapacityMax() {\n    return this._hdrCapacityMax;\n  }\n  set hdrCapacityMax(value) {\n    this._hdrCapacityMax = value;\n    this.calculateWeight();\n  }\n  /**\n   * @see {@link GainmapDecodingParameters.maxDisplayBoost}\n   * @remarks Non Logarithmic space\n   */\n  get maxDisplayBoost() {\n    return this._maxDisplayBoost;\n  }\n  set maxDisplayBoost(value) {\n    this._maxDisplayBoost = Math.max(1, Math.min(65504, value));\n    this.calculateWeight();\n  }\n  calculateWeight() {\n    const val = (Math.log2(this._maxDisplayBoost) - this._hdrCapacityMin) / (this._hdrCapacityMax - this._hdrCapacityMin);\n    this.uniforms.weightFactor.value = Math.max(0, Math.min(1, val));\n  }\n}\nclass GainMapNotFoundError extends Error {}\nclass XMPMetadataNotFoundError extends Error {}\nconst getAttribute = (description, name, defaultValue) => {\n  var _a;\n  let returnValue;\n  const parsedValue = (_a = description.attributes.getNamedItem(name)) === null || _a === void 0 ? void 0 : _a.nodeValue;\n  if (!parsedValue) {\n    const node = description.getElementsByTagName(name)[0];\n    if (node) {\n      const values = node.getElementsByTagName('rdf:li');\n      if (values.length === 3) {\n        returnValue = Array.from(values).map(v => v.innerHTML);\n      } else {\n        throw new Error(`Gainmap metadata contains an array of items for ${name} but its length is not 3`);\n      }\n    } else {\n      if (defaultValue) return defaultValue;else throw new Error(`Can't find ${name} in gainmap metadata`);\n    }\n  } else {\n    returnValue = parsedValue;\n  }\n  return returnValue;\n};\n/**\n *\n * @param input\n * @returns\n */\nconst extractXMP = input => {\n  var _a, _b;\n  let str;\n  // support node test environment\n  if (typeof TextDecoder !== 'undefined') str = new TextDecoder().decode(input);else str = input.toString();\n  let start = str.indexOf('<x:xmpmeta');\n  const parser = new DOMParser();\n  while (start !== -1) {\n    const end = str.indexOf('x:xmpmeta>', start);\n    str.slice(start, end + 10);\n    const xmpBlock = str.slice(start, end + 10);\n    try {\n      const xmlDocument = parser.parseFromString(xmpBlock, 'text/xml');\n      const description = xmlDocument.getElementsByTagName('rdf:Description')[0];\n      const gainMapMin = getAttribute(description, 'hdrgm:GainMapMin', '0');\n      const gainMapMax = getAttribute(description, 'hdrgm:GainMapMax');\n      const gamma = getAttribute(description, 'hdrgm:Gamma', '1');\n      const offsetSDR = getAttribute(description, 'hdrgm:OffsetSDR', '0.015625');\n      const offsetHDR = getAttribute(description, 'hdrgm:OffsetHDR', '0.015625');\n      let hdrCapacityMin = (_a = description.attributes.getNamedItem('hdrgm:HDRCapacityMin')) === null || _a === void 0 ? void 0 : _a.nodeValue;\n      if (!hdrCapacityMin) hdrCapacityMin = '0';\n      const hdrCapacityMax = (_b = description.attributes.getNamedItem('hdrgm:HDRCapacityMax')) === null || _b === void 0 ? void 0 : _b.nodeValue;\n      if (!hdrCapacityMax) throw new Error('Incomplete gainmap metadata');\n      return {\n        gainMapMin: Array.isArray(gainMapMin) ? gainMapMin.map(v => parseFloat(v)) : [parseFloat(gainMapMin), parseFloat(gainMapMin), parseFloat(gainMapMin)],\n        gainMapMax: Array.isArray(gainMapMax) ? gainMapMax.map(v => parseFloat(v)) : [parseFloat(gainMapMax), parseFloat(gainMapMax), parseFloat(gainMapMax)],\n        gamma: Array.isArray(gamma) ? gamma.map(v => parseFloat(v)) : [parseFloat(gamma), parseFloat(gamma), parseFloat(gamma)],\n        offsetSdr: Array.isArray(offsetSDR) ? offsetSDR.map(v => parseFloat(v)) : [parseFloat(offsetSDR), parseFloat(offsetSDR), parseFloat(offsetSDR)],\n        offsetHdr: Array.isArray(offsetHDR) ? offsetHDR.map(v => parseFloat(v)) : [parseFloat(offsetHDR), parseFloat(offsetHDR), parseFloat(offsetHDR)],\n        hdrCapacityMin: parseFloat(hdrCapacityMin),\n        hdrCapacityMax: parseFloat(hdrCapacityMax)\n      };\n    } catch (e) {}\n    start = str.indexOf('<x:xmpmeta', end);\n  }\n};\n\n/**\n * MPF Extractor (Multi Picture Format Extractor)\n * By Henrik S Nilsson 2019\n *\n * Extracts images stored in images based on the MPF format (found here: https://www.cipa.jp/e/std/std-sec.html\n * under \"CIPA DC-007-Translation-2021 Multi-Picture Format\"\n *\n * Overly commented, and without intention of being complete or production ready.\n * Created to extract depth maps from iPhone images, and to learn about image metadata.\n * Kudos to: Phil Harvey (exiftool), Jaume Sanchez (android-lens-blur-depth-extractor)\n */\nclass MPFExtractor {\n  constructor(options) {\n    this.options = {\n      debug: options && options.debug !== undefined ? options.debug : false,\n      extractFII: options && options.extractFII !== undefined ? options.extractFII : true,\n      extractNonFII: options && options.extractNonFII !== undefined ? options.extractNonFII : true\n    };\n  }\n  extract(imageArrayBuffer) {\n    return new Promise((resolve, reject) => {\n      const debug = this.options.debug;\n      const dataView = new DataView(imageArrayBuffer.buffer);\n      // If you're executing this line on a big endian machine, it'll be reversed.\n      // bigEnd further down though, refers to the endianness of the image itself.\n      if (dataView.getUint16(0) !== 0xffd8) {\n        reject(new Error('Not a valid jpeg'));\n        return;\n      }\n      const length = dataView.byteLength;\n      let offset = 2;\n      let loops = 0;\n      let marker; // APP# marker\n      while (offset < length) {\n        if (++loops > 250) {\n          reject(new Error(`Found no marker after ${loops} loops `));\n          return;\n        }\n        if (dataView.getUint8(offset) !== 0xff) {\n          reject(new Error(`Not a valid marker at offset 0x${offset.toString(16)}, found: 0x${dataView.getUint8(offset).toString(16)}`));\n          return;\n        }\n        marker = dataView.getUint8(offset + 1);\n        if (debug) console.log(`Marker: ${marker.toString(16)}`);\n        if (marker === 0xe2) {\n          if (debug) console.log('Found APP2 marker (0xffe2)');\n          // Works for iPhone 8 Plus, X, and XSMax. Or any photos of MPF format.\n          // Great way to visualize image information in html is using Exiftool. E.g.:\n          // ./exiftool.exe -htmldump -wantTrailer photo.jpg > photo.html\n          const formatPt = offset + 4;\n          /*\n           *  Structure of the MP Format Identifier\n           *\n           *  Offset Addr.  | Code (Hex)  | Description\n           *  +00             ff            Marker Prefix      <-- offset\n           *  +01             e2            APP2\n           *  +02             #n            APP2 Field Length\n           *  +03             #n            APP2 Field Length\n           *  +04             4d            'M'                <-- formatPt\n           *  +05             50            'P'\n           *  +06             46            'F'\n           *  +07             00            NULL\n           *                                                   <-- tiffOffset\n           */\n          if (dataView.getUint32(formatPt) === 0x4d504600) {\n            // Found MPF tag, so we start dig out sub images\n            const tiffOffset = formatPt + 4;\n            let bigEnd; // Endianness from TIFF header\n            // Test for TIFF validity and endianness\n            // 0x4949 and 0x4D4D ('II' and 'MM') marks Little Endian and Big Endian\n            if (dataView.getUint16(tiffOffset) === 0x4949) {\n              bigEnd = false;\n            } else if (dataView.getUint16(tiffOffset) === 0x4d4d) {\n              bigEnd = true;\n            } else {\n              reject(new Error('No valid endianness marker found in TIFF header'));\n              return;\n            }\n            if (dataView.getUint16(tiffOffset + 2, !bigEnd) !== 0x002a) {\n              reject(new Error('Not valid TIFF data! (no 0x002A marker)'));\n              return;\n            }\n            // 32 bit number stating the offset from the start of the 8 Byte MP Header\n            // to MP Index IFD Least possible value is thus 8 (means 0 offset)\n            const firstIFDOffset = dataView.getUint32(tiffOffset + 4, !bigEnd);\n            if (firstIFDOffset < 0x00000008) {\n              reject(new Error('Not valid TIFF data! (First offset less than 8)'));\n              return;\n            }\n            // Move ahead to MP Index IFD\n            // Assume we're at the first IFD, so firstIFDOffset points to\n            // MP Index IFD and not MP Attributes IFD. (If we try extract from a sub image,\n            // we fail silently here due to this assumption)\n            // Count (2 Byte) | MP Index Fields a.k.a. MP Entries (count * 12 Byte) | Offset of Next IFD (4 Byte)\n            const dirStart = tiffOffset + firstIFDOffset; // Start of IFD (Image File Directory)\n            const count = dataView.getUint16(dirStart, !bigEnd); // Count of MPEntries (2 Byte)\n            // Extract info from MPEntries (starting after Count)\n            const entriesStart = dirStart + 2;\n            let numberOfImages = 0;\n            for (let i = entriesStart; i < entriesStart + 12 * count; i += 12) {\n              // Each entry is 12 Bytes long\n              // Check MP Index IFD tags, here we only take tag 0xb001 = Number of images\n              if (dataView.getUint16(i, !bigEnd) === 0xb001) {\n                // stored in Last 4 bytes of its 12 Byte entry.\n                numberOfImages = dataView.getUint32(i + 8, !bigEnd);\n              }\n            }\n            const nextIFDOffsetLen = 4; // 4 Byte offset field that appears after MP Index IFD tags\n            const MPImageListValPt = dirStart + 2 + count * 12 + nextIFDOffsetLen;\n            const images = [];\n            for (let i = MPImageListValPt; i < MPImageListValPt + numberOfImages * 16; i += 16) {\n              const image = {\n                MPType: dataView.getUint32(i, !bigEnd),\n                size: dataView.getUint32(i + 4, !bigEnd),\n                // This offset is specified relative to the address of the MP Endian\n                // field in the MP Header, unless the image is a First Individual Image,\n                // in which case the value of the offset shall be NULL (0x00000000).\n                dataOffset: dataView.getUint32(i + 8, !bigEnd),\n                dependantImages: dataView.getUint32(i + 12, !bigEnd),\n                start: -1,\n                end: -1,\n                isFII: false\n              };\n              if (!image.dataOffset) {\n                // dataOffset is 0x00000000 for First Individual Image\n                image.start = 0;\n                image.isFII = true;\n              } else {\n                image.start = tiffOffset + image.dataOffset;\n                image.isFII = false;\n              }\n              image.end = image.start + image.size;\n              images.push(image);\n            }\n            if (this.options.extractNonFII && images.length) {\n              const bufferBlob = new Blob([dataView]);\n              const imgs = [];\n              for (const image of images) {\n                if (image.isFII && !this.options.extractFII) {\n                  continue; // Skip FII\n                }\n                const imageBlob = bufferBlob.slice(image.start, image.end + 1, 'image/jpeg');\n                // we don't need this\n                // const imageUrl = URL.createObjectURL(imageBlob)\n                // image.img = document.createElement('img')\n                // image.img.src = imageUrl\n                imgs.push(imageBlob);\n              }\n              resolve(imgs);\n            }\n          }\n        }\n        offset += 2 + dataView.getUint16(offset + 2);\n      }\n    });\n  }\n}\n\n/**\n * Extracts XMP Metadata and the gain map recovery image\n * from a single JPEG file.\n *\n * @category Decoding Functions\n * @group Decoding Functions\n * @param jpegFile an `Uint8Array` containing and encoded JPEG file\n * @returns an sdr `Uint8Array` compressed in JPEG, a gainMap `Uint8Array` compressed in JPEG and the XMP parsed XMP metadata\n * @throws Error if XMP Metadata is not found\n * @throws Error if Gain map image is not found\n * @example\n * import { FileLoader } from 'three'\n * import { extractGainmapFromJPEG } from '@monogrid/gainmap-js'\n *\n * const jpegFile = await new FileLoader()\n *  .setResponseType('arraybuffer')\n *  .loadAsync('image.jpg')\n *\n * const { sdr, gainMap, metadata } = extractGainmapFromJPEG(jpegFile)\n */\nconst extractGainmapFromJPEG = async jpegFile => {\n  const metadata = extractXMP(jpegFile);\n  if (!metadata) throw new XMPMetadataNotFoundError('Gain map XMP metadata not found');\n  const mpfExtractor = new MPFExtractor({\n    extractFII: true,\n    extractNonFII: true\n  });\n  const images = await mpfExtractor.extract(jpegFile);\n  if (images.length !== 2) throw new GainMapNotFoundError('Gain map recovery image not found');\n  return {\n    sdr: new Uint8Array(await images[0].arrayBuffer()),\n    gainMap: new Uint8Array(await images[1].arrayBuffer()),\n    metadata\n  };\n};\n\n/**\n * private function, async get image from blob\n *\n * @param blob\n * @returns\n */\nconst getHTMLImageFromBlob = blob => {\n  return new Promise((resolve, reject) => {\n    const img = document.createElement('img');\n    img.onload = () => {\n      resolve(img);\n    };\n    img.onerror = e => {\n      reject(e);\n    };\n    img.src = URL.createObjectURL(blob);\n  });\n};\nclass LoaderBase extends Loader {\n  /**\n   *\n   * @param renderer\n   * @param manager\n   */\n  constructor(renderer, manager) {\n    super(manager);\n    if (renderer) this._renderer = renderer;\n    this._internalLoadingManager = new LoadingManager();\n  }\n  /**\n   * Specify the renderer to use when rendering the gain map\n   *\n   * @param renderer\n   * @returns\n   */\n  setRenderer(renderer) {\n    this._renderer = renderer;\n    return this;\n  }\n  /**\n   * Specify the renderTarget options to use when rendering the gain map\n   *\n   * @param options\n   * @returns\n   */\n  setRenderTargetOptions(options) {\n    this._renderTargetOptions = options;\n    return this;\n  }\n  /**\n   * @private\n   * @returns\n   */\n  prepareQuadRenderer() {\n    if (!this._renderer) console.warn('WARNING: An existing WebGL Renderer was not passed to this Loader constructor or in setRenderer, the result of this Loader will need to be converted to a Data Texture with toDataTexture() before you can use it in your renderer.');\n    // temporary values\n    const material = new GainMapDecoderMaterial({\n      gainMapMax: [1, 1, 1],\n      gainMapMin: [0, 0, 0],\n      gamma: [1, 1, 1],\n      offsetHdr: [1, 1, 1],\n      offsetSdr: [1, 1, 1],\n      hdrCapacityMax: 1,\n      hdrCapacityMin: 0,\n      maxDisplayBoost: 1,\n      gainMap: new Texture$1(),\n      sdr: new Texture$1()\n    });\n    return new QuadRenderer({\n      width: 16,\n      height: 16,\n      type: HalfFloatType,\n      colorSpace: LinearSRGBColorSpace,\n      material,\n      renderer: this._renderer,\n      renderTargetOptions: this._renderTargetOptions\n    });\n  }\n  /**\n  * @private\n  * @param quadRenderer\n  * @param metadata\n  * @param sdrBuffer\n  * @param gainMapBuffer\n  */\n  async render(quadRenderer, metadata, sdrBuffer, gainMapBuffer) {\n    // this is optional, will render a black gain-map if not present\n    const gainMapBlob = gainMapBuffer ? new Blob([gainMapBuffer], {\n      type: 'image/jpeg'\n    }) : undefined;\n    const sdrBlob = new Blob([sdrBuffer], {\n      type: 'image/jpeg'\n    });\n    let sdrImage;\n    let gainMapImage;\n    let needsFlip = false;\n    if (typeof createImageBitmap === 'undefined') {\n      const res = await Promise.all([gainMapBlob ? getHTMLImageFromBlob(gainMapBlob) : Promise.resolve(undefined), getHTMLImageFromBlob(sdrBlob)]);\n      gainMapImage = res[0];\n      sdrImage = res[1];\n      needsFlip = true;\n    } else {\n      const res = await Promise.all([gainMapBlob ? createImageBitmap(gainMapBlob, {\n        imageOrientation: 'flipY'\n      }) : Promise.resolve(undefined), createImageBitmap(sdrBlob, {\n        imageOrientation: 'flipY'\n      })]);\n      gainMapImage = res[0];\n      sdrImage = res[1];\n    }\n    const gainMap = new Texture$1(gainMapImage || new ImageData(2, 2), UVMapping, ClampToEdgeWrapping, ClampToEdgeWrapping, LinearFilter, LinearMipMapLinearFilter, RGBAFormat, UnsignedByteType, 1, LinearSRGBColorSpace);\n    gainMap.flipY = needsFlip;\n    gainMap.needsUpdate = true;\n    const sdr = new Texture$1(sdrImage, UVMapping, ClampToEdgeWrapping, ClampToEdgeWrapping, LinearFilter, LinearMipMapLinearFilter, RGBAFormat, UnsignedByteType, 1, SRGBColorSpace);\n    sdr.flipY = needsFlip;\n    sdr.needsUpdate = true;\n    quadRenderer.width = sdrImage.width;\n    quadRenderer.height = sdrImage.height;\n    quadRenderer.material.gainMap = gainMap;\n    quadRenderer.material.sdr = sdr;\n    quadRenderer.material.gainMapMin = metadata.gainMapMin;\n    quadRenderer.material.gainMapMax = metadata.gainMapMax;\n    quadRenderer.material.offsetHdr = metadata.offsetHdr;\n    quadRenderer.material.offsetSdr = metadata.offsetSdr;\n    quadRenderer.material.gamma = metadata.gamma;\n    quadRenderer.material.hdrCapacityMin = metadata.hdrCapacityMin;\n    quadRenderer.material.hdrCapacityMax = metadata.hdrCapacityMax;\n    quadRenderer.material.maxDisplayBoost = Math.pow(2, metadata.hdrCapacityMax);\n    quadRenderer.material.needsUpdate = true;\n    quadRenderer.render();\n  }\n}\n\n/**\n * A Three.js Loader for a JPEG with embedded gainmap metadata.\n *\n * @category Loaders\n * @group Loaders\n *\n * @example\n * import { HDRJPGLoader } from '@monogrid/gainmap-js'\n * import {\n *   EquirectangularReflectionMapping,\n *   LinearFilter,\n *   Mesh,\n *   MeshBasicMaterial,\n *   PerspectiveCamera,\n *   PlaneGeometry,\n *   Scene,\n *   WebGLRenderer\n * } from 'three'\n *\n * const renderer = new WebGLRenderer()\n *\n * const loader = new HDRJPGLoader(renderer)\n *\n * const result = await loader.loadAsync('gainmap.jpeg')\n * // `result` can be used to populate a Texture\n *\n * const scene = new Scene()\n * const mesh = new Mesh(\n *   new PlaneGeometry(),\n *   new MeshBasicMaterial({ map: result.renderTarget.texture })\n * )\n * scene.add(mesh)\n * renderer.render(scene, new PerspectiveCamera())\n *\n * // Starting from three.js r159\n * // `result.renderTarget.texture` can\n * // also be used as Equirectangular scene background\n * //\n * // it was previously needed to convert it\n * // to a DataTexture with `result.toDataTexture()`\n * scene.background = result.renderTarget.texture\n * scene.background.mapping = EquirectangularReflectionMapping\n *\n * // result must be manually disposed\n * // when you are done using it\n * result.dispose()\n *\n */\nclass HDRJPGLoader extends LoaderBase {\n  /**\n   * Loads a JPEG containing gain map metadata\n   * Renders a normal SDR image if gainmap data is not found\n   *\n   * @param url An array in the form of [sdr.jpg, gainmap.jpg, metadata.json]\n   * @param onLoad Load complete callback, will receive the result\n   * @param onProgress Progress callback, will receive a {@link ProgressEvent}\n   * @param onError Error callback\n   * @returns\n   */\n  load(url, onLoad, onProgress, onError) {\n    const quadRenderer = this.prepareQuadRenderer();\n    const loader = new FileLoader(this._internalLoadingManager);\n    loader.setResponseType('arraybuffer');\n    loader.setRequestHeader(this.requestHeader);\n    loader.setPath(this.path);\n    loader.setWithCredentials(this.withCredentials);\n    this.manager.itemStart(url);\n    loader.load(url, async jpeg => {\n      /* istanbul ignore if\n       this condition exists only because of three.js types + strict mode\n      */\n      if (typeof jpeg === 'string') throw new Error('Invalid buffer, received [string], was expecting [ArrayBuffer]');\n      const jpegBuffer = new Uint8Array(jpeg);\n      let sdrJPEG;\n      let gainMapJPEG;\n      let metadata;\n      try {\n        const extractionResult = await extractGainmapFromJPEG(jpegBuffer);\n        // gain map is successfully reconstructed\n        sdrJPEG = extractionResult.sdr;\n        gainMapJPEG = extractionResult.gainMap;\n        metadata = extractionResult.metadata;\n      } catch (e) {\n        // render the SDR version if this is not a gainmap\n        if (e instanceof XMPMetadataNotFoundError || e instanceof GainMapNotFoundError) {\n          console.warn(`Failure to reconstruct an HDR image from ${url}: Gain map metadata not found in the file, HDRJPGLoader will render the SDR jpeg`);\n          metadata = {\n            gainMapMin: [0, 0, 0],\n            gainMapMax: [1, 1, 1],\n            gamma: [1, 1, 1],\n            hdrCapacityMin: 0,\n            hdrCapacityMax: 1,\n            offsetHdr: [0, 0, 0],\n            offsetSdr: [0, 0, 0]\n          };\n          sdrJPEG = jpegBuffer;\n        } else {\n          throw e;\n        }\n      }\n      // solves #16\n      try {\n        await this.render(quadRenderer, metadata, sdrJPEG, gainMapJPEG);\n      } catch (error) {\n        this.manager.itemError(url);\n        if (typeof onError === 'function') onError(error);\n        quadRenderer.disposeOnDemandRenderer();\n        return;\n      }\n      if (typeof onLoad === 'function') onLoad(quadRenderer);\n      this.manager.itemEnd(url);\n      quadRenderer.disposeOnDemandRenderer();\n    }, onProgress, error => {\n      this.manager.itemError(url);\n      if (typeof onError === 'function') onError(error);\n    });\n    return quadRenderer;\n  }\n}\n\n// https://github.com/mrdoob/three.js/issues/5552\n// http://en.wikipedia.org/wiki/RGBE_image_format\n\nclass RGBELoader extends DataTextureLoader {\n  constructor(manager) {\n    super(manager);\n    this.type = HalfFloatType;\n  }\n\n  // adapted from http://www.graphics.cornell.edu/~bjw/rgbe.html\n\n  parse(buffer) {\n    const /* default error routine.  change this to change error handling */\n      rgbe_read_error = 1,\n      rgbe_write_error = 2,\n      rgbe_format_error = 3,\n      rgbe_memory_error = 4,\n      rgbe_error = function (rgbe_error_code, msg) {\n        switch (rgbe_error_code) {\n          case rgbe_read_error:\n            throw new Error('THREE.RGBELoader: Read Error: ' + (msg || ''));\n          case rgbe_write_error:\n            throw new Error('THREE.RGBELoader: Write Error: ' + (msg || ''));\n          case rgbe_format_error:\n            throw new Error('THREE.RGBELoader: Bad File Format: ' + (msg || ''));\n          default:\n          case rgbe_memory_error:\n            throw new Error('THREE.RGBELoader: Memory Error: ' + (msg || ''));\n        }\n      },\n      /* offsets to red, green, and blue components in a data (float) pixel */\n      //RGBE_DATA_RED = 0,\n      //RGBE_DATA_GREEN = 1,\n      //RGBE_DATA_BLUE = 2,\n\n      /* number of floats per pixel, use 4 since stored in rgba image format */\n      //RGBE_DATA_SIZE = 4,\n\n      /* flags indicating which fields in an rgbe_header_info are valid */\n      RGBE_VALID_PROGRAMTYPE = 1,\n      RGBE_VALID_FORMAT = 2,\n      RGBE_VALID_DIMENSIONS = 4,\n      NEWLINE = '\\n',\n      fgets = function (buffer, lineLimit, consume) {\n        const chunkSize = 128;\n        lineLimit = !lineLimit ? 1024 : lineLimit;\n        let p = buffer.pos,\n          i = -1,\n          len = 0,\n          s = '',\n          chunk = String.fromCharCode.apply(null, new Uint16Array(buffer.subarray(p, p + chunkSize)));\n        while (0 > (i = chunk.indexOf(NEWLINE)) && len < lineLimit && p < buffer.byteLength) {\n          s += chunk;\n          len += chunk.length;\n          p += chunkSize;\n          chunk += String.fromCharCode.apply(null, new Uint16Array(buffer.subarray(p, p + chunkSize)));\n        }\n        if (-1 < i) {\n          /*for (i=l-1; i>=0; i--) {\n          \tbyteCode = m.charCodeAt(i);\n          \tif (byteCode > 0x7f && byteCode <= 0x7ff) byteLen++;\n          \telse if (byteCode > 0x7ff && byteCode <= 0xffff) byteLen += 2;\n          \tif (byteCode >= 0xDC00 && byteCode <= 0xDFFF) i--; //trail surrogate\n          }*/\n          if (false !== consume) buffer.pos += len + i + 1;\n          return s + chunk.slice(0, i);\n        }\n        return false;\n      },\n      /* minimal header reading.  modify if you want to parse more information */\n      RGBE_ReadHeader = function (buffer) {\n        // regexes to parse header info fields\n        const magic_token_re = /^#\\?(\\S+)/,\n          gamma_re = /^\\s*GAMMA\\s*=\\s*(\\d+(\\.\\d+)?)\\s*$/,\n          exposure_re = /^\\s*EXPOSURE\\s*=\\s*(\\d+(\\.\\d+)?)\\s*$/,\n          format_re = /^\\s*FORMAT=(\\S+)\\s*$/,\n          dimensions_re = /^\\s*\\-Y\\s+(\\d+)\\s+\\+X\\s+(\\d+)\\s*$/,\n          // RGBE format header struct\n          header = {\n            valid: 0,\n            /* indicate which fields are valid */\n\n            string: '',\n            /* the actual header string */\n\n            comments: '',\n            /* comments found in header */\n\n            programtype: 'RGBE',\n            /* listed at beginning of file to identify it after \"#?\". defaults to \"RGBE\" */\n\n            format: '',\n            /* RGBE format, default 32-bit_rle_rgbe */\n\n            gamma: 1.0,\n            /* image has already been gamma corrected with given gamma. defaults to 1.0 (no correction) */\n\n            exposure: 1.0,\n            /* a value of 1.0 in an image corresponds to <exposure> watts/steradian/m^2. defaults to 1.0 */\n\n            width: 0,\n            height: 0 /* image dimensions, width/height */\n          };\n        let line, match;\n        if (buffer.pos >= buffer.byteLength || !(line = fgets(buffer))) {\n          rgbe_error(rgbe_read_error, 'no header found');\n        }\n\n        /* if you want to require the magic token then uncomment the next line */\n        if (!(match = line.match(magic_token_re))) {\n          rgbe_error(rgbe_format_error, 'bad initial token');\n        }\n        header.valid |= RGBE_VALID_PROGRAMTYPE;\n        header.programtype = match[1];\n        header.string += line + '\\n';\n        while (true) {\n          line = fgets(buffer);\n          if (false === line) break;\n          header.string += line + '\\n';\n          if ('#' === line.charAt(0)) {\n            header.comments += line + '\\n';\n            continue; // comment line\n          }\n          if (match = line.match(gamma_re)) {\n            header.gamma = parseFloat(match[1]);\n          }\n          if (match = line.match(exposure_re)) {\n            header.exposure = parseFloat(match[1]);\n          }\n          if (match = line.match(format_re)) {\n            header.valid |= RGBE_VALID_FORMAT;\n            header.format = match[1]; //'32-bit_rle_rgbe';\n          }\n          if (match = line.match(dimensions_re)) {\n            header.valid |= RGBE_VALID_DIMENSIONS;\n            header.height = parseInt(match[1], 10);\n            header.width = parseInt(match[2], 10);\n          }\n          if (header.valid & RGBE_VALID_FORMAT && header.valid & RGBE_VALID_DIMENSIONS) break;\n        }\n        if (!(header.valid & RGBE_VALID_FORMAT)) {\n          rgbe_error(rgbe_format_error, 'missing format specifier');\n        }\n        if (!(header.valid & RGBE_VALID_DIMENSIONS)) {\n          rgbe_error(rgbe_format_error, 'missing image size specifier');\n        }\n        return header;\n      },\n      RGBE_ReadPixels_RLE = function (buffer, w, h) {\n        const scanline_width = w;\n        if (\n        // run length encoding is not allowed so read flat\n        scanline_width < 8 || scanline_width > 0x7fff ||\n        // this file is not run length encoded\n        2 !== buffer[0] || 2 !== buffer[1] || buffer[2] & 0x80) {\n          // return the flat buffer\n          return new Uint8Array(buffer);\n        }\n        if (scanline_width !== (buffer[2] << 8 | buffer[3])) {\n          rgbe_error(rgbe_format_error, 'wrong scanline width');\n        }\n        const data_rgba = new Uint8Array(4 * w * h);\n        if (!data_rgba.length) {\n          rgbe_error(rgbe_memory_error, 'unable to allocate buffer space');\n        }\n        let offset = 0,\n          pos = 0;\n        const ptr_end = 4 * scanline_width;\n        const rgbeStart = new Uint8Array(4);\n        const scanline_buffer = new Uint8Array(ptr_end);\n        let num_scanlines = h;\n\n        // read in each successive scanline\n        while (num_scanlines > 0 && pos < buffer.byteLength) {\n          if (pos + 4 > buffer.byteLength) {\n            rgbe_error(rgbe_read_error);\n          }\n          rgbeStart[0] = buffer[pos++];\n          rgbeStart[1] = buffer[pos++];\n          rgbeStart[2] = buffer[pos++];\n          rgbeStart[3] = buffer[pos++];\n          if (2 != rgbeStart[0] || 2 != rgbeStart[1] || (rgbeStart[2] << 8 | rgbeStart[3]) != scanline_width) {\n            rgbe_error(rgbe_format_error, 'bad rgbe scanline format');\n          }\n\n          // read each of the four channels for the scanline into the buffer\n          // first red, then green, then blue, then exponent\n          let ptr = 0,\n            count;\n          while (ptr < ptr_end && pos < buffer.byteLength) {\n            count = buffer[pos++];\n            const isEncodedRun = count > 128;\n            if (isEncodedRun) count -= 128;\n            if (0 === count || ptr + count > ptr_end) {\n              rgbe_error(rgbe_format_error, 'bad scanline data');\n            }\n            if (isEncodedRun) {\n              // a (encoded) run of the same value\n              const byteValue = buffer[pos++];\n              for (let i = 0; i < count; i++) {\n                scanline_buffer[ptr++] = byteValue;\n              }\n              //ptr += count;\n            } else {\n              // a literal-run\n              scanline_buffer.set(buffer.subarray(pos, pos + count), ptr);\n              ptr += count;\n              pos += count;\n            }\n          }\n\n          // now convert data from buffer into rgba\n          // first red, then green, then blue, then exponent (alpha)\n          const l = scanline_width; //scanline_buffer.byteLength;\n          for (let i = 0; i < l; i++) {\n            let off = 0;\n            data_rgba[offset] = scanline_buffer[i + off];\n            off += scanline_width; //1;\n            data_rgba[offset + 1] = scanline_buffer[i + off];\n            off += scanline_width; //1;\n            data_rgba[offset + 2] = scanline_buffer[i + off];\n            off += scanline_width; //1;\n            data_rgba[offset + 3] = scanline_buffer[i + off];\n            offset += 4;\n          }\n          num_scanlines--;\n        }\n        return data_rgba;\n      };\n    const RGBEByteToRGBFloat = function (sourceArray, sourceOffset, destArray, destOffset) {\n      const e = sourceArray[sourceOffset + 3];\n      const scale = Math.pow(2.0, e - 128.0) / 255.0;\n      destArray[destOffset + 0] = sourceArray[sourceOffset + 0] * scale;\n      destArray[destOffset + 1] = sourceArray[sourceOffset + 1] * scale;\n      destArray[destOffset + 2] = sourceArray[sourceOffset + 2] * scale;\n      destArray[destOffset + 3] = 1;\n    };\n    const RGBEByteToRGBHalf = function (sourceArray, sourceOffset, destArray, destOffset) {\n      const e = sourceArray[sourceOffset + 3];\n      const scale = Math.pow(2.0, e - 128.0) / 255.0;\n\n      // clamping to 65504, the maximum representable value in float16\n      destArray[destOffset + 0] = DataUtils.toHalfFloat(Math.min(sourceArray[sourceOffset + 0] * scale, 65504));\n      destArray[destOffset + 1] = DataUtils.toHalfFloat(Math.min(sourceArray[sourceOffset + 1] * scale, 65504));\n      destArray[destOffset + 2] = DataUtils.toHalfFloat(Math.min(sourceArray[sourceOffset + 2] * scale, 65504));\n      destArray[destOffset + 3] = DataUtils.toHalfFloat(1);\n    };\n    const byteArray = new Uint8Array(buffer);\n    byteArray.pos = 0;\n    const rgbe_header_info = RGBE_ReadHeader(byteArray);\n    const w = rgbe_header_info.width,\n      h = rgbe_header_info.height,\n      image_rgba_data = RGBE_ReadPixels_RLE(byteArray.subarray(byteArray.pos), w, h);\n    let data, type;\n    let numElements;\n    switch (this.type) {\n      case FloatType:\n        numElements = image_rgba_data.length / 4;\n        const floatArray = new Float32Array(numElements * 4);\n        for (let j = 0; j < numElements; j++) {\n          RGBEByteToRGBFloat(image_rgba_data, j * 4, floatArray, j * 4);\n        }\n        data = floatArray;\n        type = FloatType;\n        break;\n      case HalfFloatType:\n        numElements = image_rgba_data.length / 4;\n        const halfArray = new Uint16Array(numElements * 4);\n        for (let j = 0; j < numElements; j++) {\n          RGBEByteToRGBHalf(image_rgba_data, j * 4, halfArray, j * 4);\n        }\n        data = halfArray;\n        type = HalfFloatType;\n        break;\n      default:\n        throw new Error('THREE.RGBELoader: Unsupported type: ' + this.type);\n    }\n    return {\n      width: w,\n      height: h,\n      data: data,\n      header: rgbe_header_info.string,\n      gamma: rgbe_header_info.gamma,\n      exposure: rgbe_header_info.exposure,\n      type: type\n    };\n  }\n  setDataType(value) {\n    this.type = value;\n    return this;\n  }\n  load(url, onLoad, onProgress, onError) {\n    function onLoadCallback(texture, texData) {\n      switch (texture.type) {\n        case FloatType:\n        case HalfFloatType:\n          texture.colorSpace = LinearSRGBColorSpace;\n          texture.minFilter = LinearFilter;\n          texture.magFilter = LinearFilter;\n          texture.generateMipmaps = false;\n          texture.flipY = true;\n          break;\n      }\n      if (onLoad) onLoad(texture, texData);\n    }\n    return super.load(url, onLoadCallback, onProgress, onError);\n  }\n}\n\n/* @license\n * Copyright 2021 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst legacy = {\n  topLight: {\n    intensity: 500,\n    position: [0.418, 16.199, 0.300]\n  },\n  room: {\n    position: [-0.757, 13.219, 0.717],\n    scale: [31.713, 28.305, 28.591]\n  },\n  boxes: [{\n    position: [-10.906, 2.009, 1.846],\n    rotation: -0.195,\n    scale: [2.328, 7.905, 4.651]\n  }, {\n    position: [-5.607, -0.754, -0.758],\n    rotation: 0.994,\n    scale: [1.970, 1.534, 3.955]\n  }, {\n    position: [6.167, 0.857, 7.803],\n    rotation: 0.561,\n    scale: [3.927, 6.285, 3.687]\n  }, {\n    position: [-2.017, 0.018, 6.124],\n    rotation: 0.333,\n    scale: [2.002, 4.566, 2.064]\n  }, {\n    position: [2.291, -0.756, -2.621],\n    rotation: -0.286,\n    scale: [1.546, 1.552, 1.496]\n  }, {\n    position: [-2.193, -0.369, -5.547],\n    rotation: 0.516,\n    scale: [3.875, 3.487, 2.986]\n  }],\n  lights: [{\n    intensity: 50,\n    position: [-16.116, 14.37, 8.208],\n    scale: [0.1, 2.428, 2.739]\n  }, {\n    intensity: 50,\n    position: [-16.109, 18.021, -8.207],\n    scale: [0.1, 2.425, 2.751]\n  }, {\n    intensity: 17,\n    position: [14.904, 12.198, -1.832],\n    scale: [0.15, 4.265, 6.331]\n  }, {\n    intensity: 43,\n    position: [-0.462, 8.89, 14.520],\n    scale: [4.38, 5.441, 0.088]\n  }, {\n    intensity: 20,\n    position: [3.235, 11.486, -12.541],\n    scale: [2.5, 2.0, 0.1]\n  }, {\n    intensity: 100,\n    position: [0.0, 20.0, 0.0],\n    scale: [1.0, 0.1, 1.0]\n  }]\n};\nconst neutral = {\n  topLight: {\n    intensity: 400,\n    position: [0.5, 14.0, 0.5]\n  },\n  room: {\n    position: [0.0, 13.2, 0.0],\n    scale: [31.5, 28.5, 31.5]\n  },\n  boxes: [{\n    position: [-10.906, -1.0, 1.846],\n    rotation: -0.195,\n    scale: [2.328, 7.905, 4.651]\n  }, {\n    position: [-5.607, -0.754, -0.758],\n    rotation: 0.994,\n    scale: [1.970, 1.534, 3.955]\n  }, {\n    position: [6.167, -0.16, 7.803],\n    rotation: 0.561,\n    scale: [3.927, 6.285, 3.687]\n  }, {\n    position: [-2.017, 0.018, 6.124],\n    rotation: 0.333,\n    scale: [2.002, 4.566, 2.064]\n  }, {\n    position: [2.291, -0.756, -2.621],\n    rotation: -0.286,\n    scale: [1.546, 1.552, 1.496]\n  }, {\n    position: [-2.193, -0.369, -5.547],\n    rotation: 0.516,\n    scale: [3.875, 3.487, 2.986]\n  }],\n  lights: [{\n    intensity: 80,\n    position: [-14.0, 10.0, 8.0],\n    scale: [0.1, 2.5, 2.5]\n  }, {\n    intensity: 80,\n    position: [-14.0, 14.0, -4.0],\n    scale: [0.1, 2.5, 2.5]\n  }, {\n    intensity: 23,\n    position: [14.0, 12.0, 0.0],\n    scale: [0.1, 5.0, 5.0]\n  }, {\n    intensity: 16,\n    position: [0.0, 9.0, 14.0],\n    scale: [5.0, 5.0, 0.1]\n  }, {\n    intensity: 80,\n    position: [7.0, 8.0, -14.0],\n    scale: [2.5, 2.5, 0.1]\n  }, {\n    intensity: 80,\n    position: [-7.0, 16.0, -14.0],\n    scale: [2.5, 2.5, 0.1]\n  }, {\n    intensity: 1,\n    position: [0.0, 20.0, 0.0],\n    scale: [0.1, 0.1, 0.1]\n  }]\n};\nclass EnvironmentScene extends Scene {\n  constructor(name) {\n    super();\n    this.position.y = -3.5;\n    const geometry = new BoxGeometry();\n    geometry.deleteAttribute('uv');\n    const roomMaterial = new MeshStandardMaterial({\n      metalness: 0,\n      side: BackSide\n    });\n    const boxMaterial = new MeshStandardMaterial({\n      metalness: 0\n    });\n    const data = name == 'legacy' ? legacy : neutral;\n    const mainLight = new PointLight(0xffffff, data.topLight.intensity, 28, 2);\n    mainLight.position.set(...data.topLight.position);\n    this.add(mainLight);\n    const room = new Mesh(geometry, roomMaterial);\n    room.position.set(...data.room.position);\n    room.scale.set(...data.room.scale);\n    this.add(room);\n    for (const box of data.boxes) {\n      const box1 = new Mesh(geometry, boxMaterial);\n      box1.position.set(...box.position);\n      box1.rotation.set(0, box.rotation, 0);\n      box1.scale.set(...box.scale);\n      this.add(box1);\n    }\n    for (const light of data.lights) {\n      const light1 = new Mesh(geometry, this.createAreaLightMaterial(light.intensity));\n      light1.position.set(...light.position);\n      light1.scale.set(...light.scale);\n      this.add(light1);\n    }\n  }\n  createAreaLightMaterial(intensity) {\n    const material = new MeshBasicMaterial();\n    material.color.setScalar(intensity);\n    return material;\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst GENERATED_SIGMA = 0.04;\n// The maximum length of the blur for loop. Smaller sigmas will use fewer\n// samples and exit early, but not recompile the shader.\nconst MAX_SAMPLES = 20;\nconst HDR_FILE_RE = /\\.hdr(\\.js)?$/;\nclass TextureUtils {\n  constructor(threeRenderer) {\n    this.threeRenderer = threeRenderer;\n    this.lottieLoaderUrl = '';\n    this._ldrLoader = null;\n    this._imageLoader = null;\n    this._hdrLoader = null;\n    this._lottieLoader = null;\n    this.generatedEnvironmentMap = null;\n    this.generatedEnvironmentMapAlt = null;\n    this.skyboxCache = new Map();\n    this.blurMaterial = null;\n    this.blurScene = null;\n  }\n  ldrLoader(withCredentials) {\n    if (this._ldrLoader == null) {\n      this._ldrLoader = new TextureLoader();\n    }\n    this._ldrLoader.setWithCredentials(withCredentials);\n    return this._ldrLoader;\n  }\n  imageLoader(withCredentials) {\n    if (this._imageLoader == null) {\n      this._imageLoader = new HDRJPGLoader(this.threeRenderer);\n    }\n    this._imageLoader.setWithCredentials(withCredentials);\n    return this._imageLoader;\n  }\n  hdrLoader(withCredentials) {\n    if (this._hdrLoader == null) {\n      this._hdrLoader = new RGBELoader();\n      this._hdrLoader.setDataType(HalfFloatType);\n    }\n    this._hdrLoader.setWithCredentials(withCredentials);\n    return this._hdrLoader;\n  }\n  async getLottieLoader(withCredentials) {\n    if (this._lottieLoader == null) {\n      const {\n        LottieLoader\n      } = await import(/* webpackIgnore: true */this.lottieLoaderUrl);\n      this._lottieLoader = new LottieLoader();\n    }\n    this._lottieLoader.setWithCredentials(withCredentials);\n    return this._lottieLoader;\n  }\n  async loadImage(url, withCredentials) {\n    const texture = await new Promise((resolve, reject) => this.ldrLoader(withCredentials).load(url, resolve, () => {}, reject));\n    texture.name = url;\n    texture.flipY = false;\n    return texture;\n  }\n  async loadLottie(url, quality, withCredentials) {\n    const loader = await this.getLottieLoader(withCredentials);\n    loader.setQuality(quality);\n    const texture = await new Promise((resolve, reject) => loader.load(url, resolve, () => {}, reject));\n    texture.name = url;\n    return texture;\n  }\n  async loadEquirect(url, withCredentials = false, progressCallback = () => {}) {\n    try {\n      const isHDR = HDR_FILE_RE.test(url);\n      const loader = isHDR ? this.hdrLoader(withCredentials) : this.imageLoader(withCredentials);\n      const texture = await new Promise((resolve, reject) => loader.load(url, result => {\n        const {\n          renderTarget\n        } = result;\n        if (renderTarget != null) {\n          const {\n            texture\n          } = renderTarget;\n          result.dispose(false);\n          resolve(texture);\n        } else {\n          resolve(result);\n        }\n      }, event => {\n        progressCallback(event.loaded / event.total * 0.9);\n      }, reject));\n      progressCallback(1.0);\n      texture.name = url;\n      texture.mapping = EquirectangularReflectionMapping;\n      if (!isHDR) {\n        texture.colorSpace = SRGBColorSpace;\n      }\n      return texture;\n    } finally {\n      if (progressCallback) {\n        progressCallback(1);\n      }\n    }\n  }\n  /**\n   * Returns a { skybox, environmentMap } object with the targets/textures\n   * accordingly. `skybox` is a WebGLRenderCubeTarget, and `environmentMap`\n   * is a Texture from a WebGLRenderCubeTarget.\n   */\n  async generateEnvironmentMapAndSkybox(skyboxUrl = null, environmentMapUrl = null, progressCallback = () => {}, withCredentials = false) {\n    const useAltEnvironment = environmentMapUrl !== 'legacy';\n    if (environmentMapUrl === 'legacy' || environmentMapUrl === 'neutral') {\n      environmentMapUrl = null;\n    }\n    environmentMapUrl = deserializeUrl(environmentMapUrl);\n    let skyboxLoads = Promise.resolve(null);\n    let environmentMapLoads;\n    // If we have a skybox URL, attempt to load it as a cubemap\n    if (!!skyboxUrl) {\n      skyboxLoads = this.loadEquirectFromUrl(skyboxUrl, withCredentials, progressCallback);\n    }\n    if (!!environmentMapUrl) {\n      // We have an available environment map URL\n      environmentMapLoads = this.loadEquirectFromUrl(environmentMapUrl, withCredentials, progressCallback);\n    } else if (!!skyboxUrl) {\n      // Fallback to deriving the environment map from an available skybox\n      environmentMapLoads = this.loadEquirectFromUrl(skyboxUrl, withCredentials, progressCallback);\n    } else {\n      // Fallback to generating the environment map\n      environmentMapLoads = useAltEnvironment ? this.loadGeneratedEnvironmentMapAlt() : this.loadGeneratedEnvironmentMap();\n    }\n    const [environmentMap, skybox] = await Promise.all([environmentMapLoads, skyboxLoads]);\n    if (environmentMap == null) {\n      throw new Error('Failed to load environment map.');\n    }\n    return {\n      environmentMap,\n      skybox\n    };\n  }\n  /**\n   * Loads an equirect Texture from a given URL, for use as a skybox.\n   */\n  async loadEquirectFromUrl(url, withCredentials, progressCallback) {\n    if (!this.skyboxCache.has(url)) {\n      const skyboxMapLoads = this.loadEquirect(url, withCredentials, progressCallback);\n      this.skyboxCache.set(url, skyboxMapLoads);\n    }\n    return this.skyboxCache.get(url);\n  }\n  async GenerateEnvironmentMap(scene, name) {\n    await timePasses();\n    const renderer = this.threeRenderer;\n    const cubeTarget = new WebGLCubeRenderTarget(256, {\n      generateMipmaps: false,\n      type: HalfFloatType,\n      format: RGBAFormat,\n      colorSpace: LinearSRGBColorSpace,\n      depthBuffer: true\n    });\n    const cubeCamera = new CubeCamera(0.1, 100, cubeTarget);\n    const generatedEnvironmentMap = cubeCamera.renderTarget.texture;\n    generatedEnvironmentMap.name = name;\n    const outputColorSpace = renderer.outputColorSpace;\n    const toneMapping = renderer.toneMapping;\n    renderer.toneMapping = NoToneMapping;\n    renderer.outputColorSpace = LinearSRGBColorSpace;\n    cubeCamera.update(renderer, scene);\n    this.blurCubemap(cubeTarget, GENERATED_SIGMA);\n    renderer.toneMapping = toneMapping;\n    renderer.outputColorSpace = outputColorSpace;\n    return generatedEnvironmentMap;\n  }\n  /**\n   * Loads a dynamically generated environment map.\n   */\n  async loadGeneratedEnvironmentMap() {\n    if (this.generatedEnvironmentMap == null) {\n      this.generatedEnvironmentMap = this.GenerateEnvironmentMap(new EnvironmentScene('legacy'), 'legacy');\n    }\n    return this.generatedEnvironmentMap;\n  }\n  /**\n   * Loads a dynamically generated environment map, designed to be neutral and\n   * color-preserving. Shows less contrast around the different sides of the\n   * object.\n   */\n  async loadGeneratedEnvironmentMapAlt() {\n    if (this.generatedEnvironmentMapAlt == null) {\n      this.generatedEnvironmentMapAlt = this.GenerateEnvironmentMap(new EnvironmentScene('neutral'), 'neutral');\n    }\n    return this.generatedEnvironmentMapAlt;\n  }\n  blurCubemap(cubeTarget, sigma) {\n    if (this.blurMaterial == null) {\n      this.blurMaterial = this.getBlurShader(MAX_SAMPLES);\n      const box = new BoxGeometry();\n      const blurMesh = new Mesh(box, this.blurMaterial);\n      this.blurScene = new Scene();\n      this.blurScene.add(blurMesh);\n    }\n    const tempTarget = cubeTarget.clone();\n    this.halfblur(cubeTarget, tempTarget, sigma, 'latitudinal');\n    this.halfblur(tempTarget, cubeTarget, sigma, 'longitudinal');\n    // Disposing this target after we're done with it somehow corrupts Safari's\n    // whole graphics driver. It's random, but occurs more frequently on\n    // lower-powered GPUs (macbooks with intel graphics, older iPhones). It goes\n    // beyond just messing up the PMREM, as it also occasionally causes\n    // visible corruption on the canvas and even on the rest of the page.\n    /** tempTarget.dispose(); */\n  }\n  halfblur(targetIn, targetOut, sigmaRadians, direction) {\n    // Number of standard deviations at which to cut off the discrete\n    // approximation.\n    const STANDARD_DEVIATIONS = 3;\n    const pixels = targetIn.width;\n    const radiansPerPixel = isFinite(sigmaRadians) ? Math.PI / (2 * pixels) : 2 * Math.PI / (2 * MAX_SAMPLES - 1);\n    const sigmaPixels = sigmaRadians / radiansPerPixel;\n    const samples = isFinite(sigmaRadians) ? 1 + Math.floor(STANDARD_DEVIATIONS * sigmaPixels) : MAX_SAMPLES;\n    if (samples > MAX_SAMPLES) {\n      console.warn(`sigmaRadians, ${sigmaRadians}, is too large and will clip, as it requested ${samples} samples when the maximum is set to ${MAX_SAMPLES}`);\n    }\n    const weights = [];\n    let sum = 0;\n    for (let i = 0; i < MAX_SAMPLES; ++i) {\n      const x = i / sigmaPixels;\n      const weight = Math.exp(-x * x / 2);\n      weights.push(weight);\n      if (i == 0) {\n        sum += weight;\n      } else if (i < samples) {\n        sum += 2 * weight;\n      }\n    }\n    for (let i = 0; i < weights.length; i++) {\n      weights[i] = weights[i] / sum;\n    }\n    const blurUniforms = this.blurMaterial.uniforms;\n    blurUniforms['envMap'].value = targetIn.texture;\n    blurUniforms['samples'].value = samples;\n    blurUniforms['weights'].value = weights;\n    blurUniforms['latitudinal'].value = direction === 'latitudinal';\n    blurUniforms['dTheta'].value = radiansPerPixel;\n    const cubeCamera = new CubeCamera(0.1, 100, targetOut);\n    cubeCamera.update(this.threeRenderer, this.blurScene);\n  }\n  getBlurShader(maxSamples) {\n    const weights = new Float32Array(maxSamples);\n    const poleAxis = new Vector3(0, 1, 0);\n    const shaderMaterial = new ShaderMaterial({\n      name: 'SphericalGaussianBlur',\n      defines: {\n        'n': maxSamples\n      },\n      uniforms: {\n        'envMap': {\n          value: null\n        },\n        'samples': {\n          value: 1\n        },\n        'weights': {\n          value: weights\n        },\n        'latitudinal': {\n          value: false\n        },\n        'dTheta': {\n          value: 0\n        },\n        'poleAxis': {\n          value: poleAxis\n        }\n      },\n      vertexShader: /* glsl */`\n      \n      varying vec3 vOutputDirection;\n  \n      void main() {\n  \n        vOutputDirection = vec3( position );\n        gl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n  \n      }\n    `,\n      fragmentShader: /* glsl */`\n        varying vec3 vOutputDirection;\n  \n        uniform samplerCube envMap;\n        uniform int samples;\n        uniform float weights[ n ];\n        uniform bool latitudinal;\n        uniform float dTheta;\n        uniform vec3 poleAxis;\n  \n        vec3 getSample( float theta, vec3 axis ) {\n  \n          float cosTheta = cos( theta );\n          // Rodrigues' axis-angle rotation\n          vec3 sampleDirection = vOutputDirection * cosTheta\n            + cross( axis, vOutputDirection ) * sin( theta )\n            + axis * dot( axis, vOutputDirection ) * ( 1.0 - cosTheta );\n  \n          return vec3( textureCube( envMap, sampleDirection ) );\n  \n        }\n  \n        void main() {\n  \n          vec3 axis = latitudinal ? poleAxis : cross( poleAxis, vOutputDirection );\n  \n          if ( all( equal( axis, vec3( 0.0 ) ) ) ) {\n  \n            axis = vec3( vOutputDirection.z, 0.0, - vOutputDirection.x );\n  \n          }\n  \n          axis = normalize( axis );\n  \n          gl_FragColor = vec4( 0.0, 0.0, 0.0, 1.0 );\n          gl_FragColor.rgb += weights[ 0 ] * getSample( 0.0, axis );\n  \n          for ( int i = 1; i < n; i++ ) {\n  \n            if ( i >= samples ) {\n  \n              break;\n  \n            }\n  \n            float theta = dTheta * float( i );\n            gl_FragColor.rgb += weights[ i ] * getSample( -1.0 * theta, axis );\n            gl_FragColor.rgb += weights[ i ] * getSample( theta, axis );\n  \n          }\n        }\n      `,\n      blending: NoBlending,\n      depthTest: false,\n      depthWrite: false,\n      side: BackSide\n    });\n    return shaderMaterial;\n  }\n  async dispose() {\n    for (const [, promise] of this.skyboxCache) {\n      const skybox = await promise;\n      skybox.dispose();\n    }\n    if (this.generatedEnvironmentMap != null) {\n      (await this.generatedEnvironmentMap).dispose();\n      this.generatedEnvironmentMap = null;\n    }\n    if (this.generatedEnvironmentMapAlt != null) {\n      (await this.generatedEnvironmentMapAlt).dispose();\n      this.generatedEnvironmentMapAlt = null;\n    }\n    if (this.blurMaterial != null) {\n      this.blurMaterial.dispose();\n    }\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// Between 0 and 1: larger means the average responds faster and is less smooth.\nconst DURATION_DECAY = 0.2;\nconst LOW_FRAME_DURATION_MS = 40;\nconst HIGH_FRAME_DURATION_MS = 60;\nconst MAX_AVG_CHANGE_MS = 5;\nconst SCALE_STEPS = [1, 0.79, 0.62, 0.5, 0.4, 0.31, 0.25];\nconst DEFAULT_LAST_STEP = 3;\nconst DEFAULT_POWER_PREFERENCE = 'high-performance';\nconst COMMERCE_EXPOSURE = 1.3;\n/**\n * Registers canvases with Canvas2DRenderingContexts and renders them\n * all in the same WebGLRenderingContext, spitting out textures to apply\n * to the canvases. Creates a fullscreen WebGL canvas that is not added\n * to the DOM, and on each frame, renders each registered canvas on a portion\n * of the WebGL canvas, and applies the texture on the registered canvas.\n *\n * In the future, can use ImageBitmapRenderingContext instead of\n * Canvas2DRenderingContext if supported for cheaper transferring of\n * the texture.\n */\nclass Renderer extends EventDispatcher {\n  constructor(options) {\n    super();\n    this.loader = new CachingGLTFLoader(ModelViewerGLTFInstance);\n    this.width = 0;\n    this.height = 0;\n    this.dpr = 1;\n    this.scenes = new Set();\n    this.multipleScenesVisible = false;\n    this.lastTick = performance.now();\n    this.renderedLastFrame = false;\n    this.scaleStep = 0;\n    this.lastStep = DEFAULT_LAST_STEP;\n    this.avgFrameDuration = (HIGH_FRAME_DURATION_MS + LOW_FRAME_DURATION_MS) / 2;\n    this.onWebGLContextLost = event => {\n      this.dispatchEvent({\n        type: 'contextlost',\n        sourceEvent: event\n      });\n    };\n    this.onWebGLContextRestored = () => {\n      var _a;\n      (_a = this.textureUtils) === null || _a === void 0 ? void 0 : _a.dispose();\n      this.textureUtils = new TextureUtils(this.threeRenderer);\n      for (const scene of this.scenes) {\n        scene.element[$updateEnvironment]();\n      }\n    };\n    this.dpr = window.devicePixelRatio;\n    this.canvas3D = document.createElement('canvas');\n    this.canvas3D.id = 'webgl-canvas';\n    this.canvas3D.classList.add('show');\n    try {\n      this.threeRenderer = new WebGLRenderer({\n        canvas: this.canvas3D,\n        alpha: true,\n        antialias: true,\n        powerPreference: options.powerPreference,\n        preserveDrawingBuffer: true\n      });\n      this.threeRenderer.autoClear = true;\n      this.threeRenderer.setPixelRatio(1); // handle pixel ratio externally\n      this.threeRenderer.debug = {\n        checkShaderErrors: !!options.debug,\n        onShaderError: null\n      };\n      // ACESFilmicToneMapping appears to be the most \"saturated\",\n      // and similar to Filament's gltf-viewer.\n      this.threeRenderer.toneMapping = ACESFilmicToneMapping;\n    } catch (error) {\n      console.warn(error);\n    }\n    this.arRenderer = new ARRenderer(this);\n    this.textureUtils = this.canRender ? new TextureUtils(this.threeRenderer) : null;\n    CachingGLTFLoader.initializeKTX2Loader(this.threeRenderer);\n    this.canvas3D.addEventListener('webglcontextlost', this.onWebGLContextLost);\n    this.canvas3D.addEventListener('webglcontextrestored', this.onWebGLContextRestored);\n    this.updateRendererSize();\n  }\n  static get singleton() {\n    if (!this._singleton) {\n      this._singleton = new Renderer({\n        powerPreference: (self.ModelViewerElement || {}).powerPreference || DEFAULT_POWER_PREFERENCE,\n        debug: isDebugMode()\n      });\n    }\n    return this._singleton;\n  }\n  static resetSingleton() {\n    const elements = this._singleton.dispose();\n    for (const element of elements) {\n      element.disconnectedCallback();\n    }\n    this._singleton = new Renderer({\n      powerPreference: (self.ModelViewerElement || {}).powerPreference || DEFAULT_POWER_PREFERENCE,\n      debug: isDebugMode()\n    });\n    for (const element of elements) {\n      element.connectedCallback();\n    }\n  }\n  get canRender() {\n    return this.threeRenderer != null;\n  }\n  get scaleFactor() {\n    return SCALE_STEPS[this.scaleStep];\n  }\n  set minScale(scale) {\n    let i = 1;\n    while (i < SCALE_STEPS.length) {\n      if (SCALE_STEPS[i] < scale) {\n        break;\n      }\n      ++i;\n    }\n    this.lastStep = i - 1;\n  }\n  registerScene(scene) {\n    this.scenes.add(scene);\n    scene.forceRescale();\n    const size = new Vector2();\n    this.threeRenderer.getSize(size);\n    scene.canvas.width = size.x;\n    scene.canvas.height = size.y;\n    if (this.canRender && this.scenes.size > 0) {\n      this.threeRenderer.setAnimationLoop((time, frame) => this.render(time, frame));\n    }\n  }\n  unregisterScene(scene) {\n    this.scenes.delete(scene);\n    if (this.canvas3D.parentElement === scene.canvas.parentElement) {\n      scene.canvas.parentElement.removeChild(this.canvas3D);\n    }\n    if (this.canRender && this.scenes.size === 0) {\n      this.threeRenderer.setAnimationLoop(null);\n    }\n  }\n  displayCanvas(scene) {\n    return scene.element.modelIsVisible && !this.multipleScenesVisible ? this.canvas3D : scene.element[$canvas];\n  }\n  /**\n   * The function enables an optimization, where when there is only a single\n   * <model-viewer> element, we can use the renderer's 3D canvas directly for\n   * display. Otherwise we need to use the element's 2D canvas and copy the\n   * renderer's result into it.\n   */\n  countVisibleScenes() {\n    const {\n      canvas3D\n    } = this;\n    let visibleScenes = 0;\n    let canvas3DScene = null;\n    for (const scene of this.scenes) {\n      const {\n        element\n      } = scene;\n      if (element.modelIsVisible && scene.externalRenderer == null) {\n        ++visibleScenes;\n      }\n      if (canvas3D.parentElement === scene.canvas.parentElement) {\n        canvas3DScene = scene;\n      }\n    }\n    const multipleScenesVisible = visibleScenes > 1;\n    if (canvas3DScene != null) {\n      const newlyMultiple = multipleScenesVisible && !this.multipleScenesVisible;\n      const disappearing = !canvas3DScene.element.modelIsVisible;\n      if (newlyMultiple || disappearing) {\n        const {\n          width,\n          height\n        } = this.sceneSize(canvas3DScene);\n        this.copyPixels(canvas3DScene, width, height);\n        canvas3D.parentElement.removeChild(canvas3D);\n      }\n    }\n    this.multipleScenesVisible = multipleScenesVisible;\n  }\n  /**\n   * Updates the renderer's size based on the largest scene and any changes to\n   * device pixel ratio.\n   */\n  updateRendererSize() {\n    var _a;\n    const dpr = window.devicePixelRatio;\n    if (dpr !== this.dpr) {\n      // If the device pixel ratio has changed due to page zoom, elements\n      // specified by % width do not fire a resize event even though their CSS\n      // pixel dimensions change, so we force them to update their size here.\n      for (const scene of this.scenes) {\n        const {\n          element\n        } = scene;\n        element[$updateSize](element.getBoundingClientRect());\n      }\n    }\n    // Make the renderer the size of the largest scene\n    let width = 0;\n    let height = 0;\n    for (const scene of this.scenes) {\n      width = Math.max(width, scene.width);\n      height = Math.max(height, scene.height);\n    }\n    if (width === this.width && height === this.height && dpr === this.dpr) {\n      return;\n    }\n    this.width = width;\n    this.height = height;\n    this.dpr = dpr;\n    width = Math.ceil(width * dpr);\n    height = Math.ceil(height * dpr);\n    if (this.canRender) {\n      this.threeRenderer.setSize(width, height, false);\n    }\n    // Each scene's canvas must match the renderer size. In general they can be\n    // larger than the element that contains them, but the overflow is hidden\n    // and only the portion that is shown is copied over.\n    for (const scene of this.scenes) {\n      const {\n        canvas\n      } = scene;\n      canvas.width = width;\n      canvas.height = height;\n      scene.forceRescale();\n      (_a = scene.effectRenderer) === null || _a === void 0 ? void 0 : _a.setSize(width, height);\n    }\n  }\n  updateRendererScale(delta) {\n    const scaleStep = this.scaleStep;\n    this.avgFrameDuration += clamp(DURATION_DECAY * (delta - this.avgFrameDuration), -MAX_AVG_CHANGE_MS, MAX_AVG_CHANGE_MS);\n    if (this.avgFrameDuration > HIGH_FRAME_DURATION_MS) {\n      ++this.scaleStep;\n    } else if (this.avgFrameDuration < LOW_FRAME_DURATION_MS && this.scaleStep > 0) {\n      --this.scaleStep;\n    }\n    this.scaleStep = Math.min(this.scaleStep, this.lastStep);\n    if (scaleStep !== this.scaleStep) {\n      this.avgFrameDuration = (HIGH_FRAME_DURATION_MS + LOW_FRAME_DURATION_MS) / 2;\n    }\n  }\n  shouldRender(scene) {\n    if (!scene.shouldRender()) {\n      // The first frame we stop rendering the scene (because it stops moving),\n      // trigger one extra render at full scale.\n      if (scene.scaleStep != 0) {\n        scene.scaleStep = 0;\n        this.rescaleCanvas(scene);\n      } else {\n        return false;\n      }\n    } else if (scene.scaleStep != this.scaleStep) {\n      // Update render scale\n      scene.scaleStep = this.scaleStep;\n      this.rescaleCanvas(scene);\n    }\n    return true;\n  }\n  rescaleCanvas(scene) {\n    const scale = SCALE_STEPS[scene.scaleStep];\n    const width = Math.ceil(this.width / scale);\n    const height = Math.ceil(this.height / scale);\n    const {\n      style\n    } = scene.canvas;\n    style.width = `${width}px`;\n    style.height = `${height}px`;\n    this.canvas3D.style.width = `${width}px`;\n    this.canvas3D.style.height = `${height}px`;\n    const renderedDpr = this.dpr * scale;\n    const reason = scale < 1 ? 'GPU throttling' : this.dpr !== window.devicePixelRatio ? 'No meta viewport tag' : '';\n    scene.element.dispatchEvent(new CustomEvent('render-scale', {\n      detail: {\n        reportedDpr: window.devicePixelRatio,\n        renderedDpr: renderedDpr,\n        minimumDpr: this.dpr * SCALE_STEPS[this.lastStep],\n        pixelWidth: Math.ceil(scene.width * renderedDpr),\n        pixelHeight: Math.ceil(scene.height * renderedDpr),\n        reason: reason\n      }\n    }));\n  }\n  sceneSize(scene) {\n    const {\n      dpr\n    } = this;\n    const scaleFactor = SCALE_STEPS[scene.scaleStep];\n    // We avoid using the Three.js PixelRatio and handle it ourselves here so\n    // that we can do proper rounding and avoid white boundary pixels.\n    const width = Math.min(Math.ceil(scene.width * scaleFactor * dpr), this.canvas3D.width);\n    const height = Math.min(Math.ceil(scene.height * scaleFactor * dpr), this.canvas3D.height);\n    return {\n      width,\n      height\n    };\n  }\n  copyPixels(scene, width, height) {\n    const context2D = scene.context;\n    if (context2D == null) {\n      console.log('could not acquire 2d context');\n      return;\n    }\n    context2D.clearRect(0, 0, width, height);\n    context2D.drawImage(this.canvas3D, 0, 0, width, height, 0, 0, width, height);\n    scene.canvas.classList.add('show');\n  }\n  /**\n   * Returns an array version of this.scenes where the non-visible ones are\n   * first. This allows eager scenes to be rendered before they are visible,\n   * without needing the multi-canvas render path.\n   */\n  orderedScenes() {\n    const scenes = [];\n    for (const visible of [false, true]) {\n      for (const scene of this.scenes) {\n        if (scene.element.modelIsVisible === visible) {\n          scenes.push(scene);\n        }\n      }\n    }\n    return scenes;\n  }\n  get isPresenting() {\n    return this.arRenderer.isPresenting;\n  }\n  /**\n   * This method takes care of updating the element and renderer state based on\n   * the time that has passed since the last rendered frame.\n   */\n  preRender(scene, t, delta) {\n    const {\n      element,\n      exposure,\n      toneMapping\n    } = scene;\n    element[$tick](t, delta);\n    const exposureIsNumber = typeof exposure === 'number' && !Number.isNaN(exposure);\n    const env = element.environmentImage;\n    const sky = element.skyboxImage;\n    const compensateExposure = toneMapping === NeutralToneMapping && (env === 'neutral' || env === 'legacy' || !env && !sky);\n    this.threeRenderer.toneMappingExposure = (exposureIsNumber ? exposure : 1.0) * (compensateExposure ? COMMERCE_EXPOSURE : 1.0);\n  }\n  render(t, frame) {\n    if (frame != null) {\n      this.arRenderer.onWebXRFrame(t, frame);\n      return;\n    }\n    const delta = t - this.lastTick;\n    this.lastTick = t;\n    if (!this.canRender || this.isPresenting) {\n      return;\n    }\n    this.countVisibleScenes();\n    this.updateRendererSize();\n    if (this.renderedLastFrame) {\n      this.updateRendererScale(delta);\n      this.renderedLastFrame = false;\n    }\n    const {\n      canvas3D\n    } = this;\n    for (const scene of this.orderedScenes()) {\n      const {\n        element\n      } = scene;\n      if (!element.loaded || !element.modelIsVisible && scene.renderCount > 0) {\n        continue;\n      }\n      this.preRender(scene, t, delta);\n      if (!this.shouldRender(scene)) {\n        continue;\n      }\n      if (scene.externalRenderer != null) {\n        const camera = scene.getCamera();\n        camera.updateMatrix();\n        const {\n          matrix,\n          projectionMatrix\n        } = camera;\n        const viewMatrix = matrix.elements.slice();\n        const target = scene.getTarget();\n        viewMatrix[12] += target.x;\n        viewMatrix[13] += target.y;\n        viewMatrix[14] += target.z;\n        scene.externalRenderer.render({\n          viewMatrix: viewMatrix,\n          projectionMatrix: projectionMatrix.elements\n        });\n        continue;\n      }\n      if (!element.modelIsVisible && !this.multipleScenesVisible) {\n        // Here we are pre-rendering on the visible canvas, so we must mark the\n        // visible scene dirty to ensure it overwrites us.\n        for (const visibleScene of this.scenes) {\n          if (visibleScene.element.modelIsVisible) {\n            visibleScene.queueRender();\n          }\n        }\n      }\n      const {\n        width,\n        height\n      } = this.sceneSize(scene);\n      scene.renderShadow(this.threeRenderer);\n      // Need to set the render target in order to prevent\n      // clearing the depth from a different buffer\n      this.threeRenderer.setRenderTarget(null);\n      this.threeRenderer.setViewport(0, Math.ceil(this.height * this.dpr) - height, width, height);\n      if (scene.effectRenderer != null) {\n        scene.effectRenderer.render(delta);\n      } else {\n        this.threeRenderer.autoClear = true; // this might get reset by the effectRenderer\n        this.threeRenderer.toneMapping = scene.toneMapping;\n        this.threeRenderer.render(scene, scene.camera);\n      }\n      if (this.multipleScenesVisible || !scene.element.modelIsVisible && scene.renderCount === 0) {\n        this.copyPixels(scene, width, height);\n      } else if (canvas3D.parentElement !== scene.canvas.parentElement) {\n        scene.canvas.parentElement.appendChild(canvas3D);\n        scene.canvas.classList.remove('show');\n      }\n      scene.hasRendered();\n      ++scene.renderCount;\n      this.renderedLastFrame = true;\n    }\n  }\n  dispose() {\n    if (this.textureUtils != null) {\n      this.textureUtils.dispose();\n    }\n    if (this.threeRenderer != null) {\n      this.threeRenderer.dispose();\n    }\n    this.textureUtils = null;\n    this.threeRenderer = null;\n    const elements = [];\n    for (const scene of this.scenes) {\n      elements.push(scene.element);\n    }\n    this.canvas3D.removeEventListener('webglcontextlost', this.onWebGLContextLost);\n    this.canvas3D.removeEventListener('webglcontextrestored', this.onWebGLContextRestored);\n    return elements;\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst $correlatedObjects = Symbol('correlatedObjects');\nconst $onUpdate$1 = Symbol('onUpdate');\n/**\n * A SerializableThreeDOMElement is the common primitive of all scene graph\n * elements that have been facaded in the host execution context. It adds\n * a common interface to these elements in support of convenient\n * serializability.\n */\nclass ThreeDOMElement {\n  constructor(onUpdate, correlatedObjects) {\n    this[$onUpdate$1] = onUpdate;\n    this[$correlatedObjects] = correlatedObjects;\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst quadMaterial = new MeshBasicMaterial();\nconst quad = new PlaneGeometry(2, 2);\nlet adhocNum = 0;\nconst $threeTexture$2 = Symbol('threeTexture');\nconst $threeTextures$1 = Symbol('threeTextures');\n/**\n * Image facade implementation for Three.js textures\n */\nclass Image$1 extends ThreeDOMElement {\n  get [$threeTexture$2]() {\n    var _a;\n    return (_a = this[$correlatedObjects]) === null || _a === void 0 ? void 0 : _a.values().next().value;\n  }\n  get [$threeTextures$1]() {\n    return this[$correlatedObjects];\n  }\n  constructor(onUpdate, texture) {\n    super(onUpdate, new Set(texture ? [texture] : []));\n    if (!this[$threeTexture$2].image.src) {\n      this[$threeTexture$2].image.src = texture.name ? texture.name : 'adhoc_image' + adhocNum++;\n    }\n    if (!this[$threeTexture$2].image.name) {\n      this[$threeTexture$2].image.name = texture && texture.image && texture.image.src ? texture.image.src.split('/').pop() : 'adhoc_image';\n    }\n  }\n  get name() {\n    return this[$threeTexture$2].image.name || '';\n  }\n  get uri() {\n    return this[$threeTexture$2].image.src;\n  }\n  get bufferView() {\n    return this[$threeTexture$2].image.bufferView;\n  }\n  get element() {\n    const texture = this[$threeTexture$2];\n    if (texture && (texture.isCanvasTexture || texture.isVideoTexture)) {\n      return texture.image;\n    }\n    return;\n  }\n  get animation() {\n    const texture = this[$threeTexture$2];\n    if (texture && texture.isCanvasTexture && texture.animation) {\n      return texture.animation;\n    }\n    return;\n  }\n  get type() {\n    return this.uri != null ? 'external' : 'embedded';\n  }\n  set name(name) {\n    for (const texture of this[$threeTextures$1]) {\n      texture.image.name = name;\n    }\n  }\n  update() {\n    const texture = this[$threeTexture$2];\n    // Applies to non-Lottie canvas textures only\n    if (texture && texture.isCanvasTexture && !texture.animation) {\n      this[$threeTexture$2].needsUpdate = true;\n      this[$onUpdate$1]();\n    }\n  }\n  async createThumbnail(width, height) {\n    const scene = new Scene();\n    quadMaterial.map = this[$threeTexture$2];\n    const mesh = new Mesh(quad, quadMaterial);\n    scene.add(mesh);\n    const camera = new OrthographicCamera(-1, 1, 1, -1, 0, 1);\n    const {\n      threeRenderer\n    } = Renderer.singleton;\n    const renderTarget = new WebGLRenderTarget(width, height);\n    threeRenderer.setRenderTarget(renderTarget);\n    threeRenderer.render(scene, camera);\n    threeRenderer.setRenderTarget(null);\n    const buffer = new Uint8Array(width * height * 4);\n    threeRenderer.readRenderTargetPixels(renderTarget, 0, 0, width, height, buffer);\n    blobCanvas.width = width;\n    blobCanvas.height = height;\n    const blobContext = blobCanvas.getContext('2d');\n    const imageData = blobContext.createImageData(width, height);\n    imageData.data.set(buffer);\n    blobContext.putImageData(imageData, 0, 0);\n    return new Promise(async (resolve, reject) => {\n      blobCanvas.toBlob(blob => {\n        if (!blob) {\n          return reject('Failed to capture thumbnail.');\n        }\n        resolve(URL.createObjectURL(blob));\n      }, 'image/png');\n    });\n  }\n}\nvar Filter;\n(function (Filter) {\n  Filter[Filter[\"Nearest\"] = 9728] = \"Nearest\";\n  Filter[Filter[\"Linear\"] = 9729] = \"Linear\";\n  Filter[Filter[\"NearestMipmapNearest\"] = 9984] = \"NearestMipmapNearest\";\n  Filter[Filter[\"LinearMipmapNearest\"] = 9985] = \"LinearMipmapNearest\";\n  Filter[Filter[\"NearestMipmapLinear\"] = 9986] = \"NearestMipmapLinear\";\n  Filter[Filter[\"LinearMipmapLinear\"] = 9987] = \"LinearMipmapLinear\";\n})(Filter || (Filter = {}));\nvar Wrap;\n(function (Wrap) {\n  Wrap[Wrap[\"ClampToEdge\"] = 33071] = \"ClampToEdge\";\n  Wrap[Wrap[\"MirroredRepeat\"] = 33648] = \"MirroredRepeat\";\n  Wrap[Wrap[\"Repeat\"] = 10497] = \"Repeat\";\n})(Wrap || (Wrap = {}));\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// Convertion between gltf standards and threejs standards.\nconst wrapModeToWrapping = new Map([[Wrap.Repeat, RepeatWrapping], [Wrap.ClampToEdge, ClampToEdgeWrapping], [Wrap.MirroredRepeat, MirroredRepeatWrapping]]);\nconst wrappingToWrapMode = new Map([[RepeatWrapping, Wrap.Repeat], [ClampToEdgeWrapping, Wrap.ClampToEdge], [MirroredRepeatWrapping, Wrap.MirroredRepeat]]);\nconst minFilterToMinification = new Map([[Filter.Nearest, NearestFilter], [Filter.Linear, LinearFilter], [Filter.NearestMipmapNearest, NearestMipmapNearestFilter], [Filter.LinearMipmapNearest, LinearMipmapNearestFilter], [Filter.NearestMipmapLinear, NearestMipmapLinearFilter], [Filter.LinearMipmapLinear, LinearMipmapLinearFilter]]);\nconst minificationToMinFilter = new Map([[NearestFilter, Filter.Nearest], [LinearFilter, Filter.Linear], [NearestMipmapNearestFilter, Filter.NearestMipmapNearest], [LinearMipmapNearestFilter, Filter.LinearMipmapNearest], [NearestMipmapLinearFilter, Filter.NearestMipmapLinear], [LinearMipmapLinearFilter, Filter.LinearMipmapLinear]]);\nconst magFilterToMagnification = new Map([[Filter.Nearest, NearestFilter], [Filter.Linear, LinearFilter]]);\nconst magnificationToMagFilter = new Map([[NearestFilter, Filter.Nearest], [LinearFilter, Filter.Linear]]);\n// Checks for threejs standards.\nconst isMinFilter = (() => {\n  return value => minificationToMinFilter.has(value);\n})();\nconst isMagFilter = (() => {\n  return value => magnificationToMagFilter.has(value);\n})();\nconst isWrapping = (() => {\n  return value => wrappingToWrapMode.has(value);\n})();\nconst isValidSamplerValue = (property, value) => {\n  switch (property) {\n    case 'minFilter':\n      return isMinFilter(value);\n    case 'magFilter':\n      return isMagFilter(value);\n    case 'wrapS':\n    case 'wrapT':\n      return isWrapping(value);\n    case 'rotation':\n    case 'repeat':\n    case 'offset':\n      return true;\n    default:\n      throw new Error(`Cannot configure property \"${property}\" on Sampler`);\n  }\n};\nconst $threeTexture$1 = Symbol('threeTexture');\nconst $threeTextures = Symbol('threeTextures');\nconst $setProperty = Symbol('setProperty');\n/**\n * Sampler facade implementation for Three.js textures\n */\nclass Sampler extends ThreeDOMElement {\n  get [$threeTexture$1]() {\n    var _a;\n    return (_a = this[$correlatedObjects]) === null || _a === void 0 ? void 0 : _a.values().next().value;\n  }\n  get [$threeTextures]() {\n    return this[$correlatedObjects];\n  }\n  constructor(onUpdate, texture) {\n    super(onUpdate, new Set(texture ? [texture] : []));\n  }\n  get name() {\n    return this[$threeTexture$1].name || '';\n  }\n  get minFilter() {\n    return minificationToMinFilter.get(this[$threeTexture$1].minFilter);\n  }\n  get magFilter() {\n    return magnificationToMagFilter.get(this[$threeTexture$1].magFilter);\n  }\n  get wrapS() {\n    return wrappingToWrapMode.get(this[$threeTexture$1].wrapS);\n  }\n  get wrapT() {\n    return wrappingToWrapMode.get(this[$threeTexture$1].wrapT);\n  }\n  get rotation() {\n    return this[$threeTexture$1].rotation;\n  }\n  get scale() {\n    return toVector2D(this[$threeTexture$1].repeat);\n  }\n  get offset() {\n    return toVector2D(this[$threeTexture$1].offset);\n  }\n  setMinFilter(filter) {\n    this[$setProperty]('minFilter', minFilterToMinification.get(filter));\n  }\n  setMagFilter(filter) {\n    this[$setProperty]('magFilter', magFilterToMagnification.get(filter));\n  }\n  setWrapS(mode) {\n    this[$setProperty]('wrapS', wrapModeToWrapping.get(mode));\n  }\n  setWrapT(mode) {\n    this[$setProperty]('wrapT', wrapModeToWrapping.get(mode));\n  }\n  setRotation(rotation) {\n    if (rotation == null) {\n      // Reset rotation.\n      rotation = 0;\n    }\n    this[$setProperty]('rotation', rotation);\n  }\n  setScale(scale) {\n    if (scale == null) {\n      // Reset scale.\n      scale = {\n        u: 1,\n        v: 1\n      };\n    }\n    this[$setProperty]('repeat', new Vector2(scale.u, scale.v));\n  }\n  setOffset(offset) {\n    if (offset == null) {\n      // Reset offset.\n      offset = {\n        u: 0,\n        v: 0\n      };\n    }\n    this[$setProperty]('offset', new Vector2(offset.u, offset.v));\n  }\n  [$setProperty](property, value) {\n    if (isValidSamplerValue(property, value)) {\n      for (const texture of this[$threeTextures]) {\n        texture[property] = value;\n        texture.needsUpdate = true;\n      }\n    }\n    this[$onUpdate$1]();\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst $image = Symbol('image');\nconst $sampler = Symbol('sampler');\nconst $threeTexture = Symbol('threeTexture');\n/**\n * Material facade implementation for Three.js materials\n */\nclass Texture extends ThreeDOMElement {\n  constructor(onUpdate, threeTexture) {\n    super(onUpdate, new Set(threeTexture ? [threeTexture] : []));\n    this[$sampler] = new Sampler(onUpdate, threeTexture);\n    this[$image] = new Image$1(onUpdate, threeTexture);\n  }\n  get [$threeTexture]() {\n    var _a;\n    return (_a = this[$correlatedObjects]) === null || _a === void 0 ? void 0 : _a.values().next().value;\n  }\n  get name() {\n    return this[$threeTexture].name || '';\n  }\n  set name(name) {\n    for (const texture of this[$correlatedObjects]) {\n      texture.name = name;\n    }\n  }\n  get sampler() {\n    return this[$sampler];\n  }\n  get source() {\n    return this[$image];\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar _a$4, _b$4, _c$2;\nconst $texture = Symbol('texture');\nconst $transform = Symbol('transform');\nconst $materials$1 = Symbol('materials');\nconst $usage = Symbol('usage');\nconst $onUpdate = Symbol('onUpdate');\nconst $activeVideo = Symbol('activeVideo');\n// Defines what a texture will be used for.\nvar TextureUsage;\n(function (TextureUsage) {\n  TextureUsage[TextureUsage[\"Base\"] = 0] = \"Base\";\n  TextureUsage[TextureUsage[\"MetallicRoughness\"] = 1] = \"MetallicRoughness\";\n  TextureUsage[TextureUsage[\"Normal\"] = 2] = \"Normal\";\n  TextureUsage[TextureUsage[\"Occlusion\"] = 3] = \"Occlusion\";\n  TextureUsage[TextureUsage[\"Emissive\"] = 4] = \"Emissive\";\n  TextureUsage[TextureUsage[\"Clearcoat\"] = 5] = \"Clearcoat\";\n  TextureUsage[TextureUsage[\"ClearcoatRoughness\"] = 6] = \"ClearcoatRoughness\";\n  TextureUsage[TextureUsage[\"ClearcoatNormal\"] = 7] = \"ClearcoatNormal\";\n  TextureUsage[TextureUsage[\"SheenColor\"] = 8] = \"SheenColor\";\n  TextureUsage[TextureUsage[\"SheenRoughness\"] = 9] = \"SheenRoughness\";\n  TextureUsage[TextureUsage[\"Transmission\"] = 10] = \"Transmission\";\n  TextureUsage[TextureUsage[\"Thickness\"] = 11] = \"Thickness\";\n  TextureUsage[TextureUsage[\"Specular\"] = 12] = \"Specular\";\n  TextureUsage[TextureUsage[\"SpecularColor\"] = 13] = \"SpecularColor\";\n  TextureUsage[TextureUsage[\"Iridescence\"] = 14] = \"Iridescence\";\n  TextureUsage[TextureUsage[\"IridescenceThickness\"] = 15] = \"IridescenceThickness\";\n  TextureUsage[TextureUsage[\"Anisotropy\"] = 16] = \"Anisotropy\";\n})(TextureUsage || (TextureUsage = {}));\n/**\n * TextureInfo facade implementation for Three.js materials\n */\nclass TextureInfo {\n  constructor(onUpdate, usage, threeTexture, material) {\n    this[_a$4] = null;\n    this[_b$4] = {\n      rotation: 0,\n      scale: new Vector2(1, 1),\n      offset: new Vector2(0, 0)\n    };\n    this[_c$2] = false;\n    // Creates image, sampler, and texture if valid texture info is provided.\n    if (threeTexture) {\n      this[$transform].rotation = threeTexture.rotation;\n      this[$transform].scale.copy(threeTexture.repeat);\n      this[$transform].offset.copy(threeTexture.offset);\n      this[$texture] = new Texture(onUpdate, threeTexture);\n    }\n    this[$onUpdate] = onUpdate;\n    this[$materials$1] = material;\n    this[$usage] = usage;\n  }\n  get texture() {\n    return this[$texture];\n  }\n  setTexture(texture) {\n    var _d, _e;\n    const threeTexture = texture != null ? texture.source[$threeTexture$2] : null;\n    const oldTexture = (_d = this[$texture]) === null || _d === void 0 ? void 0 : _d.source[$threeTexture$2];\n    if (oldTexture != null && oldTexture.isVideoTexture) {\n      this[$activeVideo] = false;\n    } else if ((_e = this[$texture]) === null || _e === void 0 ? void 0 : _e.source.animation) {\n      this[$texture].source.animation.removeEventListener('enterFrame', this[$onUpdate]);\n    }\n    this[$texture] = texture;\n    if (threeTexture != null && threeTexture.isVideoTexture) {\n      const element = threeTexture.image;\n      this[$activeVideo] = true;\n      if (element.requestVideoFrameCallback != null) {\n        const update = () => {\n          if (!this[$activeVideo]) {\n            return;\n          }\n          this[$onUpdate]();\n          element.requestVideoFrameCallback(update);\n        };\n        element.requestVideoFrameCallback(update);\n      } else {\n        const update = () => {\n          if (!this[$activeVideo]) {\n            return;\n          }\n          this[$onUpdate]();\n          requestAnimationFrame(update);\n        };\n        requestAnimationFrame(update);\n      }\n    } else if ((texture === null || texture === void 0 ? void 0 : texture.source.animation) != null) {\n      texture.source.animation.addEventListener('enterFrame', this[$onUpdate]);\n    }\n    let colorSpace = SRGBColorSpace;\n    if (this[$materials$1]) {\n      for (const material of this[$materials$1]) {\n        switch (this[$usage]) {\n          case TextureUsage.Base:\n            material.map = threeTexture;\n            break;\n          case TextureUsage.MetallicRoughness:\n            colorSpace = LinearSRGBColorSpace;\n            material.metalnessMap = threeTexture;\n            material.roughnessMap = threeTexture;\n            break;\n          case TextureUsage.Normal:\n            colorSpace = LinearSRGBColorSpace;\n            material.normalMap = threeTexture;\n            break;\n          case TextureUsage.Occlusion:\n            colorSpace = LinearSRGBColorSpace;\n            material.aoMap = threeTexture;\n            break;\n          case TextureUsage.Emissive:\n            material.emissiveMap = threeTexture;\n            break;\n          case TextureUsage.Clearcoat:\n            material.clearcoatMap = threeTexture;\n            break;\n          case TextureUsage.ClearcoatRoughness:\n            material.clearcoatRoughnessMap = threeTexture;\n            break;\n          case TextureUsage.ClearcoatNormal:\n            material.clearcoatNormalMap = threeTexture;\n            break;\n          case TextureUsage.SheenColor:\n            material.sheenColorMap = threeTexture;\n            break;\n          case TextureUsage.SheenRoughness:\n            material.sheenRoughnessMap = threeTexture;\n            break;\n          case TextureUsage.Transmission:\n            material.transmissionMap = threeTexture;\n            break;\n          case TextureUsage.Thickness:\n            material.thicknessMap = threeTexture;\n            break;\n          case TextureUsage.Specular:\n            material.specularIntensityMap = threeTexture;\n            break;\n          case TextureUsage.SpecularColor:\n            material.specularColorMap = threeTexture;\n            break;\n          case TextureUsage.Iridescence:\n            material.iridescenceMap = threeTexture;\n            break;\n          case TextureUsage.IridescenceThickness:\n            material.iridescenceThicknessMap = threeTexture;\n            break;\n          case TextureUsage.Anisotropy:\n            material.anisotropyMap = threeTexture;\n            break;\n        }\n        material.needsUpdate = true;\n      }\n    }\n    if (threeTexture) {\n      // Updates the colorSpace for the texture, affects all references.\n      threeTexture.colorSpace = colorSpace;\n      threeTexture.rotation = this[$transform].rotation;\n      threeTexture.repeat = this[$transform].scale;\n      threeTexture.offset = this[$transform].offset;\n    }\n    this[$onUpdate]();\n  }\n}\n_a$4 = $texture, _b$4 = $transform, _c$2 = $activeVideo;\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst $threeMaterial = Symbol('threeMaterial');\nconst $threeMaterials = Symbol('threeMaterials');\nconst $baseColorTexture = Symbol('baseColorTexture');\nconst $metallicRoughnessTexture = Symbol('metallicRoughnessTexture');\n/**\n * PBR material properties facade implementation for Three.js materials\n */\nclass PBRMetallicRoughness extends ThreeDOMElement {\n  constructor(onUpdate, correlatedMaterials) {\n    super(onUpdate, correlatedMaterials);\n    const {\n      map,\n      metalnessMap\n    } = correlatedMaterials.values().next().value;\n    this[$baseColorTexture] = new TextureInfo(onUpdate, TextureUsage.Base, map, correlatedMaterials);\n    this[$metallicRoughnessTexture] = new TextureInfo(onUpdate, TextureUsage.MetallicRoughness, metalnessMap, correlatedMaterials);\n  }\n  get [$threeMaterials]() {\n    return this[$correlatedObjects];\n  }\n  get [$threeMaterial]() {\n    var _a;\n    return (_a = this[$correlatedObjects]) === null || _a === void 0 ? void 0 : _a.values().next().value;\n  }\n  get baseColorFactor() {\n    const rgba = [0, 0, 0, this[$threeMaterial].opacity];\n    this[$threeMaterial].color.toArray(rgba);\n    return rgba;\n  }\n  get metallicFactor() {\n    return this[$threeMaterial].metalness;\n  }\n  get roughnessFactor() {\n    return this[$threeMaterial].roughness;\n  }\n  get baseColorTexture() {\n    return this[$baseColorTexture];\n  }\n  get metallicRoughnessTexture() {\n    return this[$metallicRoughnessTexture];\n  }\n  setBaseColorFactor(rgba) {\n    const color = new Color();\n    if (rgba instanceof Array) {\n      color.fromArray(rgba);\n    } else {\n      color.set(rgba);\n    }\n    for (const material of this[$threeMaterials]) {\n      material.color.set(color);\n      if (rgba instanceof Array && rgba.length > 3) {\n        material.opacity = rgba[3];\n      } else {\n        rgba = [0, 0, 0, material.opacity];\n        color.toArray(rgba);\n      }\n    }\n    this[$onUpdate$1]();\n  }\n  setMetallicFactor(value) {\n    for (const material of this[$threeMaterials]) {\n      material.metalness = value;\n    }\n    this[$onUpdate$1]();\n  }\n  setRoughnessFactor(value) {\n    for (const material of this[$threeMaterials]) {\n      material.roughness = value;\n    }\n    this[$onUpdate$1]();\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar _a$3, _b$3;\nconst $pbrMetallicRoughness = Symbol('pbrMetallicRoughness');\nconst $normalTexture = Symbol('normalTexture');\nconst $occlusionTexture = Symbol('occlusionTexture');\nconst $emissiveTexture = Symbol('emissiveTexture');\nconst $backingThreeMaterial = Symbol('backingThreeMaterial');\nconst $applyAlphaCutoff = Symbol('applyAlphaCutoff');\nconst $getAlphaMode = Symbol('getAlphaMode');\nconst $lazyLoadGLTFInfo = Symbol('lazyLoadGLTFInfo');\nconst $initialize = Symbol('initialize');\nconst $getLoadedMaterial = Symbol('getLoadedMaterial');\nconst $ensureMaterialIsLoaded = Symbol('ensureMaterialIsLoaded');\nconst $gltfIndex = Symbol('gltfIndex');\nconst $setActive = Symbol('setActive');\nconst $variantIndices = Symbol('variantIndices');\nconst $isActive = Symbol('isActive');\nconst $modelVariants = Symbol('modelVariants');\nconst $name = Symbol('name');\nconst $pbrTextures = Symbol('pbrTextures');\n/**\n * Material facade implementation for Three.js materials\n */\nclass Material extends ThreeDOMElement {\n  constructor(onUpdate, gltfIndex, isActive, modelVariants, correlatedMaterials, name, lazyLoadInfo = undefined) {\n    super(onUpdate, correlatedMaterials);\n    this[_a$3] = new Set();\n    this[_b$3] = new Map();\n    this[$gltfIndex] = gltfIndex;\n    this[$isActive] = isActive;\n    this[$modelVariants] = modelVariants;\n    this[$name] = name;\n    if (lazyLoadInfo == null) {\n      this[$initialize]();\n    } else {\n      this[$lazyLoadGLTFInfo] = lazyLoadInfo;\n    }\n  }\n  get [(_a$3 = $variantIndices, _b$3 = $pbrTextures, $backingThreeMaterial)]() {\n    return this[$correlatedObjects].values().next().value;\n  }\n  [$initialize]() {\n    const onUpdate = this[$onUpdate$1];\n    const correlatedMaterials = this[$correlatedObjects];\n    this[$pbrMetallicRoughness] = new PBRMetallicRoughness(onUpdate, correlatedMaterials);\n    const {\n      normalMap,\n      aoMap,\n      emissiveMap\n    } = correlatedMaterials.values().next().value;\n    this[$normalTexture] = new TextureInfo(onUpdate, TextureUsage.Normal, normalMap, correlatedMaterials);\n    this[$occlusionTexture] = new TextureInfo(onUpdate, TextureUsage.Occlusion, aoMap, correlatedMaterials);\n    this[$emissiveTexture] = new TextureInfo(onUpdate, TextureUsage.Emissive, emissiveMap, correlatedMaterials);\n    const createTextureInfo = usage => {\n      this[$pbrTextures].set(usage, new TextureInfo(onUpdate, usage, null, correlatedMaterials));\n    };\n    createTextureInfo(TextureUsage.Clearcoat);\n    createTextureInfo(TextureUsage.ClearcoatRoughness);\n    createTextureInfo(TextureUsage.ClearcoatNormal);\n    createTextureInfo(TextureUsage.SheenColor);\n    createTextureInfo(TextureUsage.SheenRoughness);\n    createTextureInfo(TextureUsage.Transmission);\n    createTextureInfo(TextureUsage.Thickness);\n    createTextureInfo(TextureUsage.Specular);\n    createTextureInfo(TextureUsage.SpecularColor);\n    createTextureInfo(TextureUsage.Iridescence);\n    createTextureInfo(TextureUsage.IridescenceThickness);\n    createTextureInfo(TextureUsage.Anisotropy);\n  }\n  async [$getLoadedMaterial]() {\n    if (this[$lazyLoadGLTFInfo] != null) {\n      const material = await this[$lazyLoadGLTFInfo].doLazyLoad();\n      this[$initialize]();\n      // Releases lazy load info.\n      this[$lazyLoadGLTFInfo] = undefined;\n      // Redefines the method as a noop method.\n      this.ensureLoaded = async () => {};\n      return material;\n    }\n    return null;\n  }\n  colorFromRgb(rgb) {\n    const color = new Color();\n    if (rgb instanceof Array) {\n      color.fromArray(rgb);\n    } else {\n      color.set(rgb);\n    }\n    return color;\n  }\n  [$ensureMaterialIsLoaded]() {\n    if (this[$lazyLoadGLTFInfo] == null) {\n      return;\n    }\n    throw new Error(`Material \"${this.name}\" has not been loaded, call 'await\n    myMaterial.ensureLoaded()' before using an unloaded material.`);\n  }\n  async ensureLoaded() {\n    await this[$getLoadedMaterial]();\n  }\n  get isLoaded() {\n    return this[$lazyLoadGLTFInfo] == null;\n  }\n  get isActive() {\n    return this[$isActive];\n  }\n  [$setActive](isActive) {\n    this[$isActive] = isActive;\n  }\n  get name() {\n    return this[$name] || '';\n  }\n  set name(name) {\n    this[$name] = name;\n    if (this[$correlatedObjects] != null) {\n      for (const threeMaterial of this[$correlatedObjects]) {\n        threeMaterial.name = name;\n      }\n    }\n  }\n  get pbrMetallicRoughness() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrMetallicRoughness];\n  }\n  get normalTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$normalTexture];\n  }\n  get occlusionTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$occlusionTexture];\n  }\n  get emissiveTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$emissiveTexture];\n  }\n  get emissiveFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].emissive.toArray();\n  }\n  get index() {\n    return this[$gltfIndex];\n  }\n  hasVariant(name) {\n    const variantData = this[$modelVariants].get(name);\n    return variantData != null && this[$variantIndices].has(variantData.index);\n  }\n  setEmissiveFactor(rgb) {\n    this[$ensureMaterialIsLoaded]();\n    const color = this.colorFromRgb(rgb);\n    for (const material of this[$correlatedObjects]) {\n      material.emissive.set(color);\n    }\n    this[$onUpdate$1]();\n  }\n  [$getAlphaMode]() {\n    // Follows implementation of GLTFExporter from three.js\n    if (this[$backingThreeMaterial].transparent) {\n      return 'BLEND';\n    } else {\n      if (this[$backingThreeMaterial].alphaTest > 0.0) {\n        return 'MASK';\n      }\n    }\n    return 'OPAQUE';\n  }\n  [$applyAlphaCutoff]() {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      if (this[$getAlphaMode]() === 'MASK') {\n        if (material.alphaTest == undefined) {\n          material.alphaTest = 0.5;\n        }\n      } else {\n        material.alphaTest = undefined;\n      }\n      material.needsUpdate = true;\n    }\n  }\n  setAlphaCutoff(cutoff) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.alphaTest = cutoff;\n      material.needsUpdate = true;\n    }\n    // Set AlphaCutoff to undefined if AlphaMode is not MASK.\n    this[$applyAlphaCutoff]();\n    this[$onUpdate$1]();\n  }\n  getAlphaCutoff() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].alphaTest;\n  }\n  setDoubleSided(doubleSided) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      // When double-sided is disabled gltf spec dictates that Back-Face culling\n      // must be disabled, in three.js parlance that would mean FrontSide\n      // rendering only.\n      // https://github.com/KhronosGroup/glTF/tree/master/specification/2.0#double-sided\n      material.side = doubleSided ? DoubleSide : FrontSide;\n      material.needsUpdate = true;\n    }\n    this[$onUpdate$1]();\n  }\n  getDoubleSided() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].side == DoubleSide;\n  }\n  setAlphaMode(alphaMode) {\n    this[$ensureMaterialIsLoaded]();\n    const enableTransparency = (material, enabled) => {\n      material.transparent = enabled;\n      material.depthWrite = !enabled;\n    };\n    for (const material of this[$correlatedObjects]) {\n      enableTransparency(material, alphaMode === 'BLEND');\n      if (alphaMode === 'MASK') {\n        material.alphaTest = 0.5;\n      } else {\n        material.alphaTest = undefined;\n      }\n      material.needsUpdate = true;\n    }\n    this[$onUpdate$1]();\n  }\n  getAlphaMode() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$getAlphaMode]();\n  }\n  /**\n   * PBR Next properties.\n   */\n  // KHR_materials_emissive_strength\n  get emissiveStrength() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].emissiveIntensity;\n  }\n  setEmissiveStrength(emissiveStrength) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.emissiveIntensity = emissiveStrength;\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_clearcoat\n  get clearcoatFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].clearcoat;\n  }\n  get clearcoatRoughnessFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].clearcoatRoughness;\n  }\n  get clearcoatTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.Clearcoat);\n  }\n  get clearcoatRoughnessTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.ClearcoatRoughness);\n  }\n  get clearcoatNormalTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.ClearcoatNormal);\n  }\n  get clearcoatNormalScale() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].clearcoatNormalScale.x;\n  }\n  setClearcoatFactor(clearcoatFactor) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.clearcoat = clearcoatFactor;\n    }\n    this[$onUpdate$1]();\n  }\n  setClearcoatRoughnessFactor(clearcoatRoughnessFactor) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.clearcoatRoughness = clearcoatRoughnessFactor;\n    }\n    this[$onUpdate$1]();\n  }\n  setClearcoatNormalScale(clearcoatNormalScale) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.clearcoatNormalScale = new Vector2(clearcoatNormalScale, clearcoatNormalScale);\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_ior\n  get ior() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].ior;\n  }\n  setIor(ior) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.ior = ior;\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_sheen\n  get sheenColorFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].sheenColor.toArray();\n  }\n  get sheenColorTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.SheenColor);\n  }\n  get sheenRoughnessFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].sheenRoughness;\n  }\n  get sheenRoughnessTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.SheenRoughness);\n  }\n  setSheenColorFactor(rgb) {\n    this[$ensureMaterialIsLoaded]();\n    const color = this.colorFromRgb(rgb);\n    for (const material of this[$correlatedObjects]) {\n      material.sheenColor.set(color);\n      // Three.js GLTFExporter checks for internal sheen value.\n      material.sheen = 1;\n    }\n    this[$onUpdate$1]();\n  }\n  setSheenRoughnessFactor(roughness) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.sheenRoughness = roughness;\n      // Three.js GLTFExporter checks for internal sheen value.\n      material.sheen = 1;\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_transmission\n  get transmissionFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].transmission;\n  }\n  get transmissionTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.Transmission);\n  }\n  setTransmissionFactor(transmission) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.transmission = transmission;\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_volume\n  get thicknessFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].thickness;\n  }\n  get thicknessTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.Thickness);\n  }\n  get attenuationDistance() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].attenuationDistance;\n  }\n  get attenuationColor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].attenuationColor.toArray();\n  }\n  setThicknessFactor(thickness) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.thickness = thickness;\n    }\n    this[$onUpdate$1]();\n  }\n  setAttenuationDistance(attenuationDistance) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.attenuationDistance = attenuationDistance;\n    }\n    this[$onUpdate$1]();\n  }\n  setAttenuationColor(rgb) {\n    this[$ensureMaterialIsLoaded]();\n    const color = this.colorFromRgb(rgb);\n    for (const material of this[$correlatedObjects]) {\n      material.attenuationColor.set(color);\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_specular\n  get specularFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].specularIntensity;\n  }\n  get specularTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.Specular);\n  }\n  get specularColorFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].specularColor.toArray();\n  }\n  get specularColorTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.SheenColor);\n  }\n  setSpecularFactor(specularFactor) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.specularIntensity = specularFactor;\n    }\n    this[$onUpdate$1]();\n  }\n  setSpecularColorFactor(rgb) {\n    this[$ensureMaterialIsLoaded]();\n    const color = this.colorFromRgb(rgb);\n    for (const material of this[$correlatedObjects]) {\n      material.specularColor.set(color);\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_iridescence\n  get iridescenceFactor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].iridescence;\n  }\n  get iridescenceTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.Iridescence);\n  }\n  get iridescenceIor() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].iridescenceIOR;\n  }\n  get iridescenceThicknessMinimum() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].iridescenceThicknessRange[0];\n  }\n  get iridescenceThicknessMaximum() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].iridescenceThicknessRange[1];\n  }\n  get iridescenceThicknessTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.IridescenceThickness);\n  }\n  setIridescenceFactor(iridescence) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.iridescence = iridescence;\n    }\n    this[$onUpdate$1]();\n  }\n  setIridescenceIor(ior) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.iridescenceIOR = ior;\n    }\n    this[$onUpdate$1]();\n  }\n  setIridescenceThicknessMinimum(thicknessMin) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.iridescenceThicknessRange[0] = thicknessMin;\n    }\n    this[$onUpdate$1]();\n  }\n  setIridescenceThicknessMaximum(thicknessMax) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.iridescenceThicknessRange[1] = thicknessMax;\n    }\n    this[$onUpdate$1]();\n  }\n  // KHR_materials_anisotropy\n  get anisotropyStrength() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].anisotropy;\n  }\n  get anisotropyRotation() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$backingThreeMaterial].anisotropyRotation;\n  }\n  get anisotropyTexture() {\n    this[$ensureMaterialIsLoaded]();\n    return this[$pbrTextures].get(TextureUsage.Anisotropy);\n  }\n  setAnisotropyStrength(strength) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.anisotropy = strength;\n    }\n    this[$onUpdate$1]();\n  }\n  setAnisotropyRotation(rotation) {\n    this[$ensureMaterialIsLoaded]();\n    for (const material of this[$correlatedObjects]) {\n      material.anisotropyRotation = rotation;\n    }\n    this[$onUpdate$1]();\n  }\n}\n\n// Defines the base level node methods and data.\nclass Node$1 {\n  constructor(name) {\n    this.name = '';\n    this.children = new Array();\n    this.name = name;\n  }\n}\n// Represents a primitive in a glTF mesh.\nclass PrimitiveNode extends Node$1 {\n  constructor(mesh, mvMaterials, modelVariants, correlatedSceneGraph) {\n    super(mesh.name);\n    // Maps glTF material index number to a material that this primitive supports.\n    this.materials = new Map();\n    // Maps variant index to material.\n    this.variantToMaterialMap = new Map();\n    this.initialMaterialIdx = 0;\n    this.activeMaterialIdx = 0;\n    this.mesh = mesh;\n    const {\n      gltf,\n      threeGLTF,\n      threeObjectMap\n    } = correlatedSceneGraph;\n    this.parser = threeGLTF.parser;\n    this.modelVariants = modelVariants;\n    this.mesh.userData.variantData = modelVariants;\n    // Captures the primitive's initial material.\n    const materialMappings = threeObjectMap.get(mesh.material);\n    if (materialMappings.materials != null) {\n      this.initialMaterialIdx = this.activeMaterialIdx = materialMappings.materials;\n    } else {\n      console.error(`Primitive (${mesh.name}) missing initial material reference.`);\n    }\n    // Gets the mesh index from the node.\n    const associations = mesh.userData.associations || {};\n    if (associations.meshes == null) {\n      console.error('Mesh is missing primitive index association');\n      return;\n    }\n    // The gltf mesh array to sample from.\n    const meshElementArray = gltf['meshes'] || [];\n    // List of primitives under the mesh.\n    const gltfPrimitives = meshElementArray[associations.meshes].primitives || [];\n    const gltfPrimitive = gltfPrimitives[associations.primitives];\n    if (gltfPrimitive == null) {\n      console.error('Mesh primitive definition is missing.');\n      return;\n    }\n    // Maps the gltfPrimitive default to a material.\n    if (gltfPrimitive.material != null) {\n      this.materials.set(gltfPrimitive.material, mvMaterials[gltfPrimitive.material]);\n    } else {\n      const defaultIdx = mvMaterials.findIndex(mat => {\n        return mat.name === 'Default';\n      });\n      if (defaultIdx >= 0) {\n        this.materials.set(defaultIdx, mvMaterials[defaultIdx]);\n      } else {\n        console.warn('gltfPrimitive has no material!');\n      }\n    }\n    if (gltfPrimitive.extensions && gltfPrimitive.extensions['KHR_materials_variants']) {\n      const variantsExtension = gltfPrimitive.extensions['KHR_materials_variants'];\n      const extensions = threeGLTF.parser.json.extensions;\n      const variantNames = extensions['KHR_materials_variants'].variants;\n      // Provides definition now that we know there are variants to\n      // support.\n      for (const mapping of variantsExtension.mappings) {\n        const mvMaterial = mvMaterials[mapping.material];\n        // Maps variant indices to Materials.\n        this.materials.set(mapping.material, mvMaterial);\n        for (const variant of mapping.variants) {\n          const {\n            name\n          } = variantNames[variant];\n          this.variantToMaterialMap.set(variant, mvMaterial);\n          // Provides variant info for material self lookup.\n          mvMaterial[$variantIndices].add(variant);\n          // Updates the models variant data.\n          if (!modelVariants.has(name)) {\n            modelVariants.set(name, {\n              name,\n              index: variant\n            });\n          }\n        }\n      }\n    }\n  }\n  async setActiveMaterial(material) {\n    const mvMaterial = this.materials.get(material);\n    if (material !== this.activeMaterialIdx) {\n      const backingMaterials = mvMaterial[$correlatedObjects];\n      const baseMaterial = await mvMaterial[$getLoadedMaterial]();\n      if (baseMaterial != null) {\n        this.mesh.material = baseMaterial;\n      } else {\n        this.mesh.material = backingMaterials.values().next().value;\n      }\n      this.parser.assignFinalMaterial(this.mesh);\n      backingMaterials.add(this.mesh.material);\n      this.activeMaterialIdx = material;\n    }\n    return this.mesh.material;\n  }\n  getActiveMaterial() {\n    return this.materials.get(this.activeMaterialIdx);\n  }\n  getMaterial(index) {\n    return this.materials.get(index);\n  }\n  async enableVariant(name) {\n    if (name == null) {\n      return this.setActiveMaterial(this.initialMaterialIdx);\n    }\n    if (this.variantToMaterialMap != null && this.modelVariants.has(name)) {\n      const modelVariants = this.modelVariants.get(name);\n      return this.enableVariantHelper(modelVariants.index);\n    }\n    return null;\n  }\n  async enableVariantHelper(index) {\n    if (this.variantToMaterialMap != null && index != null) {\n      const material = this.variantToMaterialMap.get(index);\n      if (material != null) {\n        return this.setActiveMaterial(material.index);\n      }\n    }\n    return null;\n  }\n  async instantiateVariants() {\n    if (this.variantToMaterialMap == null) {\n      return;\n    }\n    for (const index of this.variantToMaterialMap.keys()) {\n      const variantMaterial = this.mesh.userData.variantMaterials.get(index);\n      if (variantMaterial.material != null) {\n        continue;\n      }\n      const threeMaterial = await this.enableVariantHelper(index);\n      if (threeMaterial != null) {\n        variantMaterial.material = threeMaterial;\n      }\n    }\n  }\n  get variantInfo() {\n    return this.variantToMaterialMap;\n  }\n  addVariant(materialVariant, variantName) {\n    if (!this.ensureVariantIsUnused(variantName)) {\n      return false;\n    }\n    // Adds the variant to the model variants if needed.\n    if (!this.modelVariants.has(variantName)) {\n      this.modelVariants.set(variantName, {\n        name: variantName,\n        index: this.modelVariants.size\n      });\n    }\n    const modelVariantData = this.modelVariants.get(variantName);\n    const variantIndex = modelVariantData.index;\n    // Updates materials mapped to the variant.\n    materialVariant[$variantIndices].add(variantIndex);\n    // Updates internal mappings.\n    this.variantToMaterialMap.set(variantIndex, materialVariant);\n    this.materials.set(materialVariant.index, materialVariant);\n    this.updateVariantUserData(variantIndex, materialVariant);\n    return true;\n  }\n  deleteVariant(variantIndex) {\n    if (this.variantInfo.has(variantIndex)) {\n      this.variantInfo.delete(variantIndex);\n      const userDataMap = this.mesh.userData.variantMaterials;\n      if (userDataMap != null) {\n        userDataMap.delete(variantIndex);\n      }\n    }\n  }\n  updateVariantUserData(variantIndex, materialVariant) {\n    // Adds variants name to material variants set.\n    materialVariant[$variantIndices].add(variantIndex);\n    this.mesh.userData.variantData = this.modelVariants;\n    // Updates import data (see VariantMaterialLoaderPlugin.ts).\n    this.mesh.userData.variantMaterials = this.mesh.userData.variantMaterials || new Map();\n    const map = this.mesh.userData.variantMaterials;\n    map.set(variantIndex, {\n      material: materialVariant[$correlatedObjects].values().next().value,\n      gltfMaterialIndex: materialVariant.index\n    });\n  }\n  ensureVariantIsUnused(variantName) {\n    const modelVariants = this.modelVariants.get(variantName);\n    if (modelVariants != null && this.variantInfo.has(modelVariants.index)) {\n      console.warn(`Primitive cannot add variant '${variantName}' for this material, it already exists.`);\n      return false;\n    }\n    return true;\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar _a$2, _b$2, _c$1, _d$1, _e$1, _f$1;\nconst $materials = Symbol('materials');\nconst $hierarchy = Symbol('hierarchy');\nconst $roots = Symbol('roots');\nconst $primitivesList = Symbol('primitives');\nconst $prepareVariantsForExport = Symbol('prepareVariantsForExport');\nconst $switchVariant = Symbol('switchVariant');\nconst $materialFromPoint = Symbol('materialFromPoint');\nconst $nodeFromPoint = Symbol('nodeFromPoint');\nconst $nodeFromIndex = Symbol('nodeFromIndex');\nconst $variantData = Symbol('variantData');\nconst $availableVariants = Symbol('availableVariants');\nconst $modelOnUpdate = Symbol('modelOnUpdate');\nconst $cloneMaterial = Symbol('cloneMaterial');\n// Holds onto temporary scene context information needed to perform lazy loading\n// of a resource.\nclass LazyLoader {\n  constructor(gltf, gltfElementMap, mapKey, doLazyLoad) {\n    this.gltf = gltf;\n    this.gltfElementMap = gltfElementMap;\n    this.mapKey = mapKey;\n    this.doLazyLoad = doLazyLoad;\n  }\n}\n/**\n * A Model facades the top-level GLTF object returned by Three.js' GLTFLoader.\n * Currently, the model only bothers itself with the materials in the Three.js\n * scene graph.\n */\nclass Model {\n  constructor(correlatedSceneGraph, onUpdate = () => {}) {\n    this[_a$2] = new Array();\n    this[_b$2] = new Array();\n    this[_c$1] = new Array();\n    this[_d$1] = new Array();\n    this[_e$1] = () => {};\n    this[_f$1] = new Map();\n    this[$modelOnUpdate] = onUpdate;\n    const {\n      gltf,\n      threeGLTF,\n      gltfElementMap\n    } = correlatedSceneGraph;\n    for (const [i, material] of gltf.materials.entries()) {\n      const correlatedMaterial = gltfElementMap.get(material);\n      if (correlatedMaterial != null) {\n        this[$materials].push(new Material(onUpdate, i, true, this[$variantData], correlatedMaterial, material.name));\n      } else {\n        const elementArray = gltf['materials'] || [];\n        const gltfMaterialDef = elementArray[i];\n        const threeMaterialSet = new Set();\n        gltfElementMap.set(gltfMaterialDef, threeMaterialSet);\n        const materialLoadCallback = async () => {\n          const threeMaterial = await threeGLTF.parser.getDependency('material', i);\n          threeMaterialSet.add(threeMaterial);\n          return threeMaterial;\n        };\n        // Configures the material for lazy loading.\n        this[$materials].push(new Material(onUpdate, i, false, this[$variantData], threeMaterialSet, material.name, new LazyLoader(gltf, gltfElementMap, gltfMaterialDef, materialLoadCallback)));\n      }\n    }\n    // Creates a hierarchy of Nodes. Allows not just for switching which\n    // material is applied to a mesh but also exposes a way to provide API\n    // for switching materials and general assignment/modification.\n    // Prepares for scene iteration.\n    const parentMap = new Map();\n    const nodeStack = new Array();\n    for (const object of threeGLTF.scene.children) {\n      nodeStack.push(object);\n    }\n    // Walks the hierarchy and creates a node tree.\n    while (nodeStack.length > 0) {\n      const object = nodeStack.pop();\n      let node = null;\n      if (object instanceof Mesh) {\n        node = new PrimitiveNode(object, this.materials, this[$variantData], correlatedSceneGraph);\n        this[$primitivesList].push(node);\n      } else {\n        node = new Node$1(object.name);\n      }\n      const parent = parentMap.get(object);\n      if (parent != null) {\n        parent.children.push(node);\n      } else {\n        this[$roots].push(node);\n      }\n      this[$hierarchy].push(node);\n      for (const child of object.children) {\n        nodeStack.push(child);\n        parentMap.set(object, node);\n      }\n    }\n  }\n  /**\n   * Materials are listed in the order of the GLTF materials array, plus a\n   * default material at the end if one is used.\n   *\n   * TODO(#1003): How do we handle non-active scenes?\n   */\n  get materials() {\n    return this[$materials];\n  }\n  [(_a$2 = $materials, _b$2 = $hierarchy, _c$1 = $roots, _d$1 = $primitivesList, _e$1 = $modelOnUpdate, _f$1 = $variantData, $availableVariants)]() {\n    const variants = Array.from(this[$variantData].values());\n    variants.sort((a, b) => {\n      return a.index - b.index;\n    });\n    return variants.map(data => {\n      return data.name;\n    });\n  }\n  getMaterialByName(name) {\n    const matches = this[$materials].filter(material => {\n      return material.name === name;\n    });\n    if (matches.length > 0) {\n      return matches[0];\n    }\n    return null;\n  }\n  [$nodeFromIndex](mesh, primitive) {\n    const found = this[$hierarchy].find(node => {\n      if (node instanceof PrimitiveNode) {\n        const {\n          meshes,\n          primitives\n        } = node.mesh.userData.associations;\n        if (meshes == mesh && primitives == primitive) {\n          return true;\n        }\n      }\n      return false;\n    });\n    return found == null ? null : found;\n  }\n  [$nodeFromPoint](hit) {\n    return this[$hierarchy].find(node => {\n      if (node instanceof PrimitiveNode) {\n        const primitive = node;\n        if (primitive.mesh === hit.object) {\n          return true;\n        }\n      }\n      return false;\n    });\n  }\n  /**\n   * Intersects a ray with the Model and returns the first material whose\n   * object was intersected.\n   */\n  [$materialFromPoint](hit) {\n    return this[$nodeFromPoint](hit).getActiveMaterial();\n  }\n  /**\n   * Switches model variant to the variant name provided, or switches to\n   * default/initial materials if 'null' is provided.\n   */\n  async [$switchVariant](variantName) {\n    for (const primitive of this[$primitivesList]) {\n      await primitive.enableVariant(variantName);\n    }\n    for (const material of this.materials) {\n      material[$setActive](false);\n    }\n    // Marks the materials that are now in use after the variant switch.\n    for (const primitive of this[$primitivesList]) {\n      this.materials[primitive.getActiveMaterial().index][$setActive](true);\n    }\n  }\n  async [$prepareVariantsForExport]() {\n    const promises = new Array();\n    for (const primitive of this[$primitivesList]) {\n      promises.push(primitive.instantiateVariants());\n    }\n    await Promise.all(promises);\n  }\n  [$cloneMaterial](index, newMaterialName) {\n    const material = this.materials[index];\n    if (!material.isLoaded) {\n      console.error(`Cloning an unloaded material,\n           call 'material.ensureLoaded() before cloning the material.`);\n    }\n    const threeMaterialSet = material[$correlatedObjects];\n    const clonedSet = new Set();\n    for (const [i, threeMaterial] of threeMaterialSet.entries()) {\n      const clone = threeMaterial.clone();\n      clone.name = newMaterialName + (threeMaterialSet.size > 1 ? '_inst' + i : '');\n      clonedSet.add(clone);\n    }\n    const clonedMaterial = new Material(this[$modelOnUpdate], this[$materials].length, false,\n    // Cloned as inactive.\n    this[$variantData], clonedSet, newMaterialName);\n    this[$materials].push(clonedMaterial);\n    return clonedMaterial;\n  }\n  createMaterialInstanceForVariant(originalMaterialIndex, newMaterialName, variantName, activateVariant = true) {\n    let variantMaterialInstance = null;\n    for (const primitive of this[$primitivesList]) {\n      const variantData = this[$variantData].get(variantName);\n      // Skips the primitive if the variant already exists.\n      if (variantData != null && primitive.variantInfo.has(variantData.index)) {\n        continue;\n      }\n      // Skips the primitive if the source/original material does not exist.\n      if (primitive.getMaterial(originalMaterialIndex) == null) {\n        continue;\n      }\n      if (!this.hasVariant(variantName)) {\n        this.createVariant(variantName);\n      }\n      if (variantMaterialInstance == null) {\n        variantMaterialInstance = this[$cloneMaterial](originalMaterialIndex, newMaterialName);\n      }\n      primitive.addVariant(variantMaterialInstance, variantName);\n    }\n    if (activateVariant && variantMaterialInstance != null) {\n      variantMaterialInstance[$setActive](true);\n      this.materials[originalMaterialIndex][$setActive](false);\n      for (const primitive of this[$primitivesList]) {\n        primitive.enableVariant(variantName);\n      }\n    }\n    return variantMaterialInstance;\n  }\n  createVariant(variantName) {\n    if (!this[$variantData].has(variantName)) {\n      // Adds the name if it's not already in the list.\n      this[$variantData].set(variantName, {\n        name: variantName,\n        index: this[$variantData].size\n      });\n    } else {\n      console.warn(`Variant '${variantName}'' already exists`);\n    }\n  }\n  hasVariant(variantName) {\n    return this[$variantData].has(variantName);\n  }\n  setMaterialToVariant(materialIndex, targetVariantName) {\n    if (this[$availableVariants]().find(name => name === targetVariantName) == null) {\n      console.warn(`Can't add material to '${targetVariantName}', the variant does not exist.'`);\n      return;\n    }\n    if (materialIndex < 0 || materialIndex >= this.materials.length) {\n      console.error(`setMaterialToVariant(): materialIndex is out of bounds.`);\n      return;\n    }\n    for (const primitive of this[$primitivesList]) {\n      const material = primitive.getMaterial(materialIndex);\n      // Ensures the material exists on the primitive before setting it to a\n      // variant.\n      if (material != null) {\n        primitive.addVariant(material, targetVariantName);\n      }\n    }\n  }\n  updateVariantName(currentName, newName) {\n    const variantData = this[$variantData].get(currentName);\n    if (variantData == null) {\n      return;\n    }\n    variantData.name = newName;\n    this[$variantData].set(newName, variantData);\n    this[$variantData].delete(currentName);\n  }\n  deleteVariant(variantName) {\n    const variant = this[$variantData].get(variantName);\n    if (variant == null) {\n      return;\n    }\n    for (const material of this.materials) {\n      if (material.hasVariant(variantName)) {\n        material[$variantIndices].delete(variant.index);\n      }\n    }\n    for (const primitive of this[$primitivesList]) {\n      primitive.deleteVariant(variant.index);\n    }\n    this[$variantData].delete(variantName);\n  }\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate$5 = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nconst $currentGLTF = Symbol('currentGLTF');\nconst $originalGltfJson = Symbol('originalGltfJson');\nconst $model = Symbol('model');\nconst $getOnUpdateMethod = Symbol('getOnUpdateMethod');\nconst $buildTexture = Symbol('buildTexture');\n/**\n * SceneGraphMixin manages exposes a model API in order to support operations on\n * the <model-viewer> scene graph.\n */\nconst SceneGraphMixin = ModelViewerElement => {\n  var _a, _b, _c;\n  class SceneGraphModelViewerElement extends ModelViewerElement {\n    constructor() {\n      super(...arguments);\n      this[_a] = undefined;\n      this[_b] = null;\n      this[_c] = null;\n      this.variantName = null;\n      this.orientation = '0 0 0';\n      this.scale = '1 1 1';\n    }\n    // Scene-graph API:\n    /** @export */\n    get model() {\n      return this[$model];\n    }\n    get availableVariants() {\n      return this.model ? this.model[$availableVariants]() : [];\n    }\n    /**\n     * Returns a deep copy of the gltf JSON as loaded. It will not reflect\n     * changes to the scene-graph, nor will editing it have any effect.\n     */\n    get originalGltfJson() {\n      return this[$originalGltfJson];\n    }\n    [(_a = $model, _b = $currentGLTF, _c = $originalGltfJson, $getOnUpdateMethod)]() {\n      return () => {\n        this[$needsRender]();\n      };\n    }\n    [$buildTexture](texture) {\n      // Applies glTF default settings.\n      texture.colorSpace = SRGBColorSpace;\n      texture.wrapS = RepeatWrapping;\n      texture.wrapT = RepeatWrapping;\n      return new Texture(this[$getOnUpdateMethod](), texture);\n    }\n    async createTexture(uri, type = 'image/png') {\n      const {\n        textureUtils\n      } = this[$renderer];\n      const texture = await textureUtils.loadImage(uri, this.withCredentials);\n      texture.userData.mimeType = type;\n      return this[$buildTexture](texture);\n    }\n    async createLottieTexture(uri, quality = 1) {\n      const {\n        textureUtils\n      } = this[$renderer];\n      const texture = await textureUtils.loadLottie(uri, quality, this.withCredentials);\n      return this[$buildTexture](texture);\n    }\n    createVideoTexture(uri) {\n      const video = document.createElement('video');\n      video.crossOrigin = this.withCredentials ? 'use-credentials' : 'anonymous';\n      video.src = uri;\n      video.muted = true;\n      video.playsInline = true;\n      video.loop = true;\n      video.play();\n      const texture = new VideoTexture(video);\n      return this[$buildTexture](texture);\n    }\n    createCanvasTexture() {\n      const canvas = document.createElement('canvas');\n      const texture = new CanvasTexture(canvas);\n      return this[$buildTexture](texture);\n    }\n    async updated(changedProperties) {\n      super.updated(changedProperties);\n      if (changedProperties.has('variantName')) {\n        const updateVariantProgress = this[$progressTracker].beginActivity('variant-update');\n        updateVariantProgress(0.1);\n        const model = this[$model];\n        const {\n          variantName\n        } = this;\n        if (model != null) {\n          await model[$switchVariant](variantName);\n          this[$needsRender]();\n          this.dispatchEvent(new CustomEvent('variant-applied'));\n        }\n        updateVariantProgress(1.0);\n      }\n      if (changedProperties.has('orientation') || changedProperties.has('scale')) {\n        if (!this.loaded) {\n          return;\n        }\n        const scene = this[$scene];\n        scene.applyTransform();\n        scene.updateBoundingBox();\n        scene.updateShadow();\n        this[$renderer].arRenderer.onUpdateScene();\n        this[$needsRender]();\n      }\n    }\n    [$onModelLoad]() {\n      super[$onModelLoad]();\n      const {\n        currentGLTF\n      } = this[$scene];\n      if (currentGLTF != null) {\n        const {\n          correlatedSceneGraph\n        } = currentGLTF;\n        if (correlatedSceneGraph != null && currentGLTF !== this[$currentGLTF]) {\n          this[$model] = new Model(correlatedSceneGraph, this[$getOnUpdateMethod]());\n          this[$originalGltfJson] = JSON.parse(JSON.stringify(correlatedSceneGraph.gltf));\n        }\n        // KHR_materials_variants extension spec:\n        // https://github.com/KhronosGroup/glTF/tree/master/extensions/2.0/Khronos/KHR_materials_variants\n        if ('variants' in currentGLTF.userData) {\n          this.requestUpdate('variantName');\n        }\n      }\n      this[$currentGLTF] = currentGLTF;\n    }\n    /** @export */\n    async exportScene(options) {\n      const scene = this[$scene];\n      return new Promise(async (resolve, reject) => {\n        // Defaults\n        const opts = {\n          binary: true,\n          onlyVisible: true,\n          maxTextureSize: Infinity,\n          includeCustomExtensions: false,\n          forceIndices: false\n        };\n        Object.assign(opts, options);\n        // Not configurable\n        opts.animations = scene.animations;\n        opts.truncateDrawRange = true;\n        const shadow = scene.shadow;\n        let visible = false;\n        // Remove shadow from export\n        if (shadow != null) {\n          visible = shadow.visible;\n          shadow.visible = false;\n        }\n        await this[$model][$prepareVariantsForExport]();\n        const exporter = new GLTFExporter().register(writer => new GLTFExporterMaterialsVariantsExtension(writer));\n        exporter.parse(scene.model, gltf => {\n          return resolve(new Blob([opts.binary ? gltf : JSON.stringify(gltf)], {\n            type: opts.binary ? 'application/octet-stream' : 'application/json'\n          }));\n        }, () => {\n          return reject('glTF export failed');\n        }, opts);\n        if (shadow != null) {\n          shadow.visible = visible;\n        }\n      });\n    }\n    materialFromPoint(pixelX, pixelY) {\n      const model = this[$model];\n      if (model == null) {\n        return null;\n      }\n      const scene = this[$scene];\n      const ndcCoords = scene.getNDC(pixelX, pixelY);\n      const hit = scene.hitFromPoint(ndcCoords);\n      if (hit == null || hit.face == null) {\n        return null;\n      }\n      return model[$materialFromPoint](hit);\n    }\n  }\n  __decorate$5([n$8({\n    type: String,\n    attribute: 'variant-name'\n  })], SceneGraphModelViewerElement.prototype, \"variantName\", void 0);\n  __decorate$5([n$8({\n    type: String,\n    attribute: 'orientation'\n  })], SceneGraphModelViewerElement.prototype, \"orientation\", void 0);\n  __decorate$5([n$8({\n    type: String,\n    attribute: 'scale'\n  })], SceneGraphModelViewerElement.prototype, \"scale\", void 0);\n  return SceneGraphModelViewerElement;\n};\n\n/* @license\n * Copyright 2023 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nclass GroundedSkybox extends Mesh {\n  constructor() {\n    super(undefined, new MeshBasicMaterial({\n      depthWrite: false\n    }));\n    this.height = 0;\n    this.radius = 0;\n    this.resolution = 0;\n    this.userData.noHit = true;\n  }\n  get map() {\n    return this.material.map;\n  }\n  set map(skybox) {\n    this.material.map = skybox;\n  }\n  isUsable() {\n    return this.height > 0 && this.radius > 0 && this.geometry != null && this.map != null;\n  }\n  updateGeometry(height = this.height, radius = this.radius, resolution = 128) {\n    if (height != this.height || radius != this.radius || resolution != this.resolution) {\n      this.height = height;\n      this.radius = radius;\n      this.resolution = resolution;\n      if (height > 0 && radius > 0) {\n        this.geometry.dispose();\n        this.geometry = makeGeometry(height, radius, resolution);\n      }\n    }\n  }\n}\nfunction makeGeometry(height, radius, resolution) {\n  const geometry = new SphereGeometry(radius, 2 * resolution, resolution);\n  geometry.scale(1, 1, -1);\n  const pos = geometry.getAttribute('position');\n  const tmp = new Vector3();\n  for (let i = 0; i < pos.count; ++i) {\n    tmp.fromBufferAttribute(pos, i);\n    if (tmp.y < 0) {\n      // Smooth out the transition from flat floor to sphere:\n      const y1 = -height * 3 / 2;\n      const f = tmp.y < y1 ? -height / tmp.y : 1 - tmp.y * tmp.y / (3 * y1 * y1);\n      tmp.multiplyScalar(f);\n      tmp.toArray(pos.array, 3 * i);\n    }\n  }\n  pos.needsUpdate = true;\n  return geometry;\n}\n\n/* @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst a = new Vector3();\nconst b = new Vector3();\nconst c = new Vector3();\nconst mat = new Matrix3();\nconst triangle = new Triangle();\nconst quat = new Quaternion();\n/**\n * The Hotspot object is a reference-counted slot. If decrement() returns true,\n * it should be removed from the tree so it can be garbage-collected.\n */\nclass Hotspot extends CSS2DObject {\n  constructor(config) {\n    super(document.createElement('div'));\n    this.normal = new Vector3(0, 1, 0);\n    this.initialized = false;\n    this.referenceCount = 1;\n    this.pivot = document.createElement('div');\n    this.slot = document.createElement('slot');\n    this.element.classList.add('annotation-wrapper');\n    this.slot.name = config.name;\n    this.element.appendChild(this.pivot);\n    this.pivot.appendChild(this.slot);\n    this.updatePosition(config.position);\n    this.updateNormal(config.normal);\n    this.surface = config.surface;\n  }\n  get facingCamera() {\n    return !this.element.classList.contains('hide');\n  }\n  /**\n   * Sets the hotspot to be in the highly visible foreground state.\n   */\n  show() {\n    if (!this.facingCamera || !this.initialized) {\n      this.updateVisibility(true);\n    }\n  }\n  /**\n   * Sets the hotspot to be in the diminished background state.\n   */\n  hide() {\n    if (this.facingCamera || !this.initialized) {\n      this.updateVisibility(false);\n    }\n  }\n  /**\n   * Call this when adding elements to the same slot to keep track.\n   */\n  increment() {\n    this.referenceCount++;\n  }\n  /**\n   * Call this when removing elements from the slot; returns true when the slot\n   * is unused.\n   */\n  decrement() {\n    if (this.referenceCount > 0) {\n      --this.referenceCount;\n    }\n    return this.referenceCount === 0;\n  }\n  /**\n   * Change the position of the hotspot to the input string, in the same format\n   * as the data-position attribute.\n   */\n  updatePosition(position) {\n    if (position == null) return;\n    const positionNodes = parseExpressions(position)[0].terms;\n    for (let i = 0; i < 3; ++i) {\n      this.position.setComponent(i, normalizeUnit(positionNodes[i]).number);\n    }\n    this.updateMatrixWorld();\n  }\n  /**\n   * Change the hotspot's normal to the input string, in the same format as the\n   * data-normal attribute.\n   */\n  updateNormal(normal) {\n    if (normal == null) return;\n    const normalNodes = parseExpressions(normal)[0].terms;\n    for (let i = 0; i < 3; ++i) {\n      this.normal.setComponent(i, normalNodes[i].number);\n    }\n  }\n  updateSurface() {\n    const {\n      mesh,\n      tri,\n      bary\n    } = this;\n    if (mesh == null || tri == null || bary == null) {\n      return;\n    }\n    mesh.getVertexPosition(tri.x, a);\n    mesh.getVertexPosition(tri.y, b);\n    mesh.getVertexPosition(tri.z, c);\n    a.toArray(mat.elements, 0);\n    b.toArray(mat.elements, 3);\n    c.toArray(mat.elements, 6);\n    this.position.copy(bary).applyMatrix3(mat);\n    const target = this.parent;\n    target.worldToLocal(mesh.localToWorld(this.position));\n    triangle.set(a, b, c);\n    triangle.getNormal(this.normal).transformDirection(mesh.matrixWorld);\n    const pivot = target.parent;\n    quat.setFromAxisAngle(a.set(0, 1, 0), -pivot.rotation.y);\n    this.normal.applyQuaternion(quat);\n  }\n  orient(radians) {\n    this.pivot.style.transform = `rotate(${radians}rad)`;\n  }\n  updateVisibility(show) {\n    this.element.classList.toggle('hide', !show);\n    // NOTE: ShadyDOM doesn't support slot.assignedElements, otherwise we could\n    // use that here.\n    this.slot.assignedNodes().forEach(node => {\n      if (node.nodeType !== Node.ELEMENT_NODE) {\n        return;\n      }\n      const element = node;\n      // Visibility attribute can be configured per-node in the hotspot:\n      const visibilityAttribute = element.dataset.visibilityAttribute;\n      if (visibilityAttribute != null) {\n        const attributeName = `data-${visibilityAttribute}`;\n        element.toggleAttribute(attributeName, show);\n      }\n      element.dispatchEvent(new CustomEvent('hotspot-visibility', {\n        detail: {\n          visible: show\n        }\n      }));\n    });\n    this.initialized = true;\n  }\n}\n\n/**\n * Two pass Gaussian blur filter (horizontal and vertical blur shaders)\n * - see http://www.cake23.de/traveling-wavefronts-lit-up.html\n *\n * - 9 samples per pass\n * - standard deviation 2.7\n * - \"h\" and \"v\" parameters should be set to \"1 / width\" and \"1 / height\"\n */\n\nconst HorizontalBlurShader = {\n  name: 'HorizontalBlurShader',\n  uniforms: {\n    'tDiffuse': {\n      value: null\n    },\n    'h': {\n      value: 1.0 / 512.0\n    }\n  },\n  vertexShader: /* glsl */`\n\n\t\tvarying vec2 vUv;\n\n\t\tvoid main() {\n\n\t\t\tvUv = uv;\n\t\t\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n\n\t\t}`,\n  fragmentShader: /* glsl */`\n\n\t\tuniform sampler2D tDiffuse;\n\t\tuniform float h;\n\n\t\tvarying vec2 vUv;\n\n\t\tvoid main() {\n\n\t\t\tvec4 sum = vec4( 0.0 );\n\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x - 4.0 * h, vUv.y ) ) * 0.051;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x - 3.0 * h, vUv.y ) ) * 0.0918;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x - 2.0 * h, vUv.y ) ) * 0.12245;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x - 1.0 * h, vUv.y ) ) * 0.1531;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y ) ) * 0.1633;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x + 1.0 * h, vUv.y ) ) * 0.1531;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x + 2.0 * h, vUv.y ) ) * 0.12245;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x + 3.0 * h, vUv.y ) ) * 0.0918;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x + 4.0 * h, vUv.y ) ) * 0.051;\n\n\t\t\tgl_FragColor = sum;\n\n\t\t}`\n};\n\n/**\n * Two pass Gaussian blur filter (horizontal and vertical blur shaders)\n * - see http://www.cake23.de/traveling-wavefronts-lit-up.html\n *\n * - 9 samples per pass\n * - standard deviation 2.7\n * - \"h\" and \"v\" parameters should be set to \"1 / width\" and \"1 / height\"\n */\n\nconst VerticalBlurShader = {\n  name: 'VerticalBlurShader',\n  uniforms: {\n    'tDiffuse': {\n      value: null\n    },\n    'v': {\n      value: 1.0 / 512.0\n    }\n  },\n  vertexShader: /* glsl */`\n\n\t\tvarying vec2 vUv;\n\n\t\tvoid main() {\n\n\t\t\tvUv = uv;\n\t\t\tgl_Position = projectionMatrix * modelViewMatrix * vec4( position, 1.0 );\n\n\t\t}`,\n  fragmentShader: /* glsl */`\n\n\t\tuniform sampler2D tDiffuse;\n\t\tuniform float v;\n\n\t\tvarying vec2 vUv;\n\n\t\tvoid main() {\n\n\t\t\tvec4 sum = vec4( 0.0 );\n\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y - 4.0 * v ) ) * 0.051;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y - 3.0 * v ) ) * 0.0918;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y - 2.0 * v ) ) * 0.12245;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y - 1.0 * v ) ) * 0.1531;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y ) ) * 0.1633;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y + 1.0 * v ) ) * 0.1531;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y + 2.0 * v ) ) * 0.12245;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y + 3.0 * v ) ) * 0.0918;\n\t\t\tsum += texture2D( tDiffuse, vec2( vUv.x, vUv.y + 4.0 * v ) ) * 0.051;\n\n\t\t\tgl_FragColor = sum;\n\n\t\t}`\n};\n\n// https://en.wikipedia.org/wiki/Linear_interpolation\nfunction lerp(x, y, t) {\n  return (1 - t) * x + t * y;\n}\n\n/* @license\n * Copyright 2022 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n// The softness [0, 1] of the shadow is mapped to a resolution between\n// 2^LOG_MAX_RESOLUTION and 2^LOG_MIN_RESOLUTION.\nconst LOG_MAX_RESOLUTION = 9;\nconst LOG_MIN_RESOLUTION = 6;\n// Animated models are not in general contained in their bounding box, as this\n// is calculated only for their resting pose. We create a cubic shadow volume\n// for animated models sized to their largest bounding box dimension multiplied\n// by this scale factor.\nconst ANIMATION_SCALING = 2;\n// Since hard shadows are not lightened by blurring and depth, set a lower\n// default intensity to make them more perceptually similar to the intensity of\n// the soft shadows.\nconst DEFAULT_HARD_INTENSITY = 0.3;\n/**\n * The Shadow class creates a shadow that fits a given scene and follows a\n * target. This shadow will follow the scene without any updates needed so long\n * as the shadow and scene are both parented to the same object (call it the\n * scene) and this scene is passed as the target parameter to the shadow's\n * constructor. We also must constrain the scene to motion within the horizontal\n * plane and call the setRotation() method whenever the scene's Y-axis rotation\n * changes. For motion outside of the horizontal plane, this.needsUpdate must be\n * set to true.\n *\n * The softness of the shadow is controlled by changing its resolution, making\n * softer shadows faster, but less precise.\n */\nclass Shadow extends Object3D {\n  constructor(scene, softness, side) {\n    super();\n    this.camera = new OrthographicCamera();\n    // private cameraHelper = new CameraHelper(this.camera);\n    this.renderTarget = null;\n    this.renderTargetBlur = null;\n    this.depthMaterial = new MeshDepthMaterial();\n    this.horizontalBlurMaterial = new ShaderMaterial(HorizontalBlurShader);\n    this.verticalBlurMaterial = new ShaderMaterial(VerticalBlurShader);\n    this.intensity = 0;\n    this.softness = 1;\n    this.boundingBox = new Box3();\n    this.size = new Vector3();\n    this.maxDimension = 0;\n    this.isAnimated = false;\n    this.needsUpdate = false;\n    const {\n      camera\n    } = this;\n    camera.rotation.x = Math.PI / 2;\n    camera.left = -0.5;\n    camera.right = 0.5;\n    camera.bottom = -0.5;\n    camera.top = 0.5;\n    this.add(camera);\n    // this.add(this.cameraHelper);\n    // this.cameraHelper.updateMatrixWorld = function() {\n    //   this.matrixWorld = this.camera.matrixWorld;\n    // };\n    const plane = new PlaneGeometry();\n    const shadowMaterial = new MeshBasicMaterial({\n      // color: new Color(1, 0, 0),\n      opacity: 1,\n      transparent: true,\n      side: BackSide\n    });\n    this.floor = new Mesh(plane, shadowMaterial);\n    this.floor.userData.noHit = true;\n    camera.add(this.floor);\n    // the plane onto which to blur the texture\n    this.blurPlane = new Mesh(plane);\n    this.blurPlane.visible = false;\n    camera.add(this.blurPlane);\n    scene.target.add(this);\n    // like MeshDepthMaterial, but goes from black to transparent\n    this.depthMaterial.onBeforeCompile = function (shader) {\n      shader.fragmentShader = shader.fragmentShader.replace('gl_FragColor = vec4( vec3( 1.0 - fragCoordZ ), opacity );', 'gl_FragColor = vec4( vec3( 0.0 ), ( 1.0 - fragCoordZ ) * opacity );');\n    };\n    this.horizontalBlurMaterial.depthTest = false;\n    this.verticalBlurMaterial.depthTest = false;\n    this.setScene(scene, softness, side);\n  }\n  /**\n   * Update the shadow's size and position for a new scene. Softness is also\n   * needed, as this controls the shadow's resolution.\n   */\n  setScene(scene, softness, side) {\n    const {\n      boundingBox,\n      size,\n      rotation,\n      position\n    } = this;\n    this.isAnimated = scene.animationNames.length > 0;\n    this.boundingBox.copy(scene.boundingBox);\n    this.size.copy(scene.size);\n    this.maxDimension = Math.max(size.x, size.y, size.z) * (this.isAnimated ? ANIMATION_SCALING : 1);\n    this.boundingBox.getCenter(position);\n    if (side === 'back') {\n      const {\n        min,\n        max\n      } = boundingBox;\n      [min.y, min.z] = [min.z, min.y];\n      [max.y, max.z] = [max.z, max.y];\n      [size.y, size.z] = [size.z, size.y];\n      rotation.x = Math.PI / 2;\n      rotation.y = Math.PI;\n    } else {\n      rotation.x = 0;\n      rotation.y = 0;\n    }\n    if (this.isAnimated) {\n      const minY = boundingBox.min.y;\n      const maxY = boundingBox.max.y;\n      size.y = this.maxDimension;\n      boundingBox.expandByVector(size.subScalar(this.maxDimension).multiplyScalar(-0.5));\n      boundingBox.min.y = minY;\n      boundingBox.max.y = maxY;\n      size.set(this.maxDimension, maxY - minY, this.maxDimension);\n    }\n    if (side === 'bottom') {\n      position.y = boundingBox.min.y;\n    } else {\n      position.z = boundingBox.min.y;\n    }\n    this.setSoftness(softness);\n  }\n  /**\n   * Update the shadow's resolution based on softness (between 0 and 1). Should\n   * not be called frequently, as this results in reallocation.\n   */\n  setSoftness(softness) {\n    this.softness = softness;\n    const {\n      size,\n      camera\n    } = this;\n    const scaleY = this.isAnimated ? ANIMATION_SCALING : 1;\n    const resolution = scaleY * Math.pow(2, LOG_MAX_RESOLUTION - softness * (LOG_MAX_RESOLUTION - LOG_MIN_RESOLUTION));\n    this.setMapSize(resolution);\n    const softFar = size.y / 2;\n    const hardFar = size.y * scaleY;\n    camera.near = 0;\n    camera.far = lerp(hardFar, softFar, softness);\n    // we have co-opted opacity to scale the depth to clip\n    this.depthMaterial.opacity = 1.0 / softness;\n    camera.updateProjectionMatrix();\n    // this.cameraHelper.update();\n    this.setIntensity(this.intensity);\n    this.setOffset(0);\n  }\n  /**\n   * Lower-level version of the above function.\n   */\n  setMapSize(maxMapSize) {\n    const {\n      size\n    } = this;\n    if (this.isAnimated) {\n      maxMapSize *= ANIMATION_SCALING;\n    }\n    const baseWidth = Math.floor(size.x > size.z ? maxMapSize : maxMapSize * size.x / size.z);\n    const baseHeight = Math.floor(size.x > size.z ? maxMapSize * size.z / size.x : maxMapSize);\n    // width of blur filter in pixels (not adjustable)\n    const TAP_WIDTH = 10;\n    const width = TAP_WIDTH + baseWidth;\n    const height = TAP_WIDTH + baseHeight;\n    if (this.renderTarget != null && (this.renderTarget.width !== width || this.renderTarget.height !== height)) {\n      this.renderTarget.dispose();\n      this.renderTarget = null;\n      this.renderTargetBlur.dispose();\n      this.renderTargetBlur = null;\n    }\n    if (this.renderTarget == null) {\n      const params = {\n        format: RGBAFormat\n      };\n      this.renderTarget = new WebGLRenderTarget(width, height, params);\n      this.renderTargetBlur = new WebGLRenderTarget(width, height, params);\n      this.floor.material.map = this.renderTarget.texture;\n    }\n    // These pads account for the softening radius around the shadow.\n    this.camera.scale.set(size.x * (1 + TAP_WIDTH / baseWidth), size.z * (1 + TAP_WIDTH / baseHeight), 1);\n    this.needsUpdate = true;\n  }\n  /**\n   * Set the shadow's intensity (0 to 1), which is just its opacity. Turns off\n   * shadow rendering if zero.\n   */\n  setIntensity(intensity) {\n    this.intensity = intensity;\n    if (intensity > 0) {\n      this.visible = true;\n      this.floor.visible = true;\n      this.floor.material.opacity = intensity * lerp(DEFAULT_HARD_INTENSITY, 1, this.softness * this.softness);\n    } else {\n      this.visible = false;\n      this.floor.visible = false;\n    }\n  }\n  getIntensity() {\n    return this.intensity;\n  }\n  /**\n   * An offset can be specified to move the\n   * shadow vertically relative to the bottom of the scene. Positive is up, so\n   * values are generally negative. A small offset keeps our shadow from\n   * z-fighting with any baked-in shadow plane.\n   */\n  setOffset(offset) {\n    this.floor.position.z = -offset + this.gap();\n  }\n  gap() {\n    return 0.001 * this.maxDimension;\n  }\n  render(renderer, scene) {\n    // this.cameraHelper.visible = false;\n    // force the depthMaterial to everything\n    scene.overrideMaterial = this.depthMaterial;\n    // set renderer clear alpha\n    const initialClearAlpha = renderer.getClearAlpha();\n    renderer.setClearAlpha(0);\n    this.floor.visible = false;\n    // disable XR for offscreen rendering\n    const xrEnabled = renderer.xr.enabled;\n    renderer.xr.enabled = false;\n    // render to the render target to get the depths\n    const oldRenderTarget = renderer.getRenderTarget();\n    renderer.setRenderTarget(this.renderTarget);\n    renderer.render(scene, this.camera);\n    // and reset the override material\n    scene.overrideMaterial = null;\n    this.floor.visible = true;\n    this.blurShadow(renderer);\n    // reset and render the normal scene\n    renderer.xr.enabled = xrEnabled;\n    renderer.setRenderTarget(oldRenderTarget);\n    renderer.setClearAlpha(initialClearAlpha);\n    // this.cameraHelper.visible = true;\n  }\n  blurShadow(renderer) {\n    const {\n      camera,\n      horizontalBlurMaterial,\n      verticalBlurMaterial,\n      renderTarget,\n      renderTargetBlur,\n      blurPlane\n    } = this;\n    blurPlane.visible = true;\n    // blur horizontally and draw in the renderTargetBlur\n    blurPlane.material = horizontalBlurMaterial;\n    horizontalBlurMaterial.uniforms.h.value = 1 / this.renderTarget.width;\n    horizontalBlurMaterial.uniforms.tDiffuse.value = this.renderTarget.texture;\n    renderer.setRenderTarget(renderTargetBlur);\n    renderer.render(blurPlane, camera);\n    // blur vertically and draw in the main renderTarget\n    blurPlane.material = verticalBlurMaterial;\n    verticalBlurMaterial.uniforms.v.value = 1 / this.renderTarget.height;\n    verticalBlurMaterial.uniforms.tDiffuse.value = this.renderTargetBlur.texture;\n    renderer.setRenderTarget(renderTarget);\n    renderer.render(blurPlane, camera);\n    blurPlane.visible = false;\n  }\n  dispose() {\n    if (this.renderTarget != null) {\n      this.renderTarget.dispose();\n    }\n    if (this.renderTargetBlur != null) {\n      this.renderTargetBlur.dispose();\n    }\n    this.depthMaterial.dispose();\n    this.horizontalBlurMaterial.dispose();\n    this.verticalBlurMaterial.dispose();\n    this.floor.material.dispose();\n    this.floor.geometry.dispose();\n    this.blurPlane.geometry.dispose();\n    this.removeFromParent();\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst GROUNDED_SKYBOX_SIZE = 10;\nconst MIN_SHADOW_RATIO = 100;\nconst view = new Vector3();\nconst target = new Vector3();\nconst normalWorld = new Vector3();\nconst raycaster = new Raycaster();\nconst vector3 = new Vector3();\nconst ndc = new Vector2();\n/**\n * A THREE.Scene object that takes a Model and CanvasHTMLElement and\n * constructs a framed scene based off of the canvas dimensions.\n * Provides lights and cameras to be used in a renderer.\n */\nclass ModelScene extends Scene {\n  constructor({\n    canvas,\n    element,\n    width,\n    height\n  }) {\n    super();\n    this.annotationRenderer = new CSS2DRenderer();\n    this.effectRenderer = null;\n    this.schemaElement = document.createElement('script');\n    this.width = 1;\n    this.height = 1;\n    this.aspect = 1;\n    this.scaleStep = 0;\n    this.renderCount = 0;\n    this.externalRenderer = null;\n    // These default camera values are never used, as they are reset once the\n    // model is loaded and framing is computed.\n    this.camera = new PerspectiveCamera(45, 1, 0.1, 100);\n    this.xrCamera = null;\n    this.url = null;\n    this.pivot = new Object3D();\n    this.target = new Object3D();\n    this.animationNames = [];\n    this.boundingBox = new Box3();\n    this.boundingSphere = new Sphere();\n    this.size = new Vector3();\n    this.idealAspect = 0;\n    this.framedFoVDeg = 0;\n    this.shadow = null;\n    this.shadowIntensity = 0;\n    this.shadowSoftness = 1;\n    this.bakedShadows = new Set();\n    this.exposure = 1;\n    this.toneMapping = ACESFilmicToneMapping;\n    this.canScale = true;\n    this.isDirty = false;\n    this.goalTarget = new Vector3();\n    this.targetDamperX = new Damper();\n    this.targetDamperY = new Damper();\n    this.targetDamperZ = new Damper();\n    this._currentGLTF = null;\n    this._model = null;\n    this.cancelPendingSourceChange = null;\n    this.animationsByName = new Map();\n    this.currentAnimationAction = null;\n    this.groundedSkybox = new GroundedSkybox();\n    this.name = 'ModelScene';\n    this.element = element;\n    this.canvas = canvas;\n    // These default camera values are never used, as they are reset once the\n    // model is loaded and framing is computed.\n    this.camera = new PerspectiveCamera(45, 1, 0.1, 100);\n    this.camera.name = 'MainCamera';\n    this.add(this.pivot);\n    this.pivot.name = 'Pivot';\n    this.pivot.add(this.target);\n    this.setSize(width, height);\n    this.target.name = 'Target';\n    this.mixer = new AnimationMixer(this.target);\n    const {\n      domElement\n    } = this.annotationRenderer;\n    const {\n      style\n    } = domElement;\n    style.display = 'none';\n    style.pointerEvents = 'none';\n    style.position = 'absolute';\n    style.top = '0';\n    this.element.shadowRoot.querySelector('.default').appendChild(domElement);\n    this.schemaElement.setAttribute('type', 'application/ld+json');\n  }\n  /**\n   * Function to create the context lazily, as when there is only one\n   * <model-viewer> element, the renderer's 3D context can be displayed\n   * directly. This extra context is necessary to copy the renderings into when\n   * there are more than one.\n   */\n  get context() {\n    return this.canvas.getContext('2d');\n  }\n  getCamera() {\n    return this.xrCamera != null ? this.xrCamera : this.camera;\n  }\n  queueRender() {\n    this.isDirty = true;\n  }\n  shouldRender() {\n    return this.isDirty;\n  }\n  hasRendered() {\n    this.isDirty = false;\n  }\n  forceRescale() {\n    this.scaleStep = -1;\n    this.queueRender();\n  }\n  /**\n   * Pass in a THREE.Object3D to be controlled\n   * by this model.\n   */\n  async setObject(model) {\n    this.reset();\n    this._model = model;\n    this.target.add(model);\n    await this.setupScene();\n  }\n  /**\n   * Sets the model via URL.\n   */\n  async setSource(url, progressCallback = () => {}) {\n    if (!url || url === this.url) {\n      progressCallback(1);\n      return;\n    }\n    this.reset();\n    this.url = url;\n    if (this.externalRenderer != null) {\n      const framingInfo = await this.externalRenderer.load(progressCallback);\n      this.boundingSphere.radius = framingInfo.framedRadius;\n      this.idealAspect = framingInfo.fieldOfViewAspect;\n      return;\n    }\n    // If we have pending work due to a previous source change in progress,\n    // cancel it so that we do not incur a race condition:\n    if (this.cancelPendingSourceChange != null) {\n      this.cancelPendingSourceChange();\n      this.cancelPendingSourceChange = null;\n    }\n    let gltf;\n    try {\n      gltf = await new Promise(async (resolve, reject) => {\n        this.cancelPendingSourceChange = () => reject();\n        try {\n          const result = await this.element[$renderer].loader.load(url, this.element, progressCallback);\n          resolve(result);\n        } catch (error) {\n          reject(error);\n        }\n      });\n    } catch (error) {\n      if (error == null) {\n        // Loading was cancelled, so silently return\n        return;\n      }\n      throw error;\n    }\n    this.cancelPendingSourceChange = null;\n    this.reset();\n    this.url = url;\n    this._currentGLTF = gltf;\n    if (gltf != null) {\n      this._model = gltf.scene;\n      this.target.add(gltf.scene);\n    }\n    const {\n      animations\n    } = gltf;\n    const animationsByName = new Map();\n    const animationNames = [];\n    for (const animation of animations) {\n      animationsByName.set(animation.name, animation);\n      animationNames.push(animation.name);\n    }\n    this.animations = animations;\n    this.animationsByName = animationsByName;\n    this.animationNames = animationNames;\n    await this.setupScene();\n  }\n  async setupScene() {\n    this.applyTransform();\n    this.updateBoundingBox();\n    await this.updateFraming();\n    this.updateShadow();\n    this.setShadowIntensity(this.shadowIntensity);\n    this.setGroundedSkybox();\n  }\n  reset() {\n    this.url = null;\n    this.renderCount = 0;\n    this.queueRender();\n    if (this.shadow != null) {\n      this.shadow.setIntensity(0);\n    }\n    this.bakedShadows.clear();\n    const {\n      _model\n    } = this;\n    if (_model != null) {\n      _model.removeFromParent();\n      this._model = null;\n    }\n    const gltf = this._currentGLTF;\n    if (gltf != null) {\n      gltf.dispose();\n      this._currentGLTF = null;\n    }\n    if (this.currentAnimationAction != null) {\n      this.currentAnimationAction.stop();\n      this.currentAnimationAction = null;\n    }\n    this.mixer.stopAllAction();\n    this.mixer.uncacheRoot(this);\n  }\n  dispose() {\n    this.reset();\n    if (this.shadow != null) {\n      this.shadow.dispose();\n      this.shadow = null;\n    }\n    this.element[$currentGLTF] = null;\n    this.element[$originalGltfJson] = null;\n    this.element[$model] = null;\n  }\n  get currentGLTF() {\n    return this._currentGLTF;\n  }\n  /**\n   * Updates the ModelScene for a new container size in CSS pixels.\n   */\n  setSize(width, height) {\n    if (this.width === width && this.height === height) {\n      return;\n    }\n    this.width = Math.max(width, 1);\n    this.height = Math.max(height, 1);\n    this.annotationRenderer.setSize(width, height);\n    this.aspect = this.width / this.height;\n    if (this.externalRenderer != null) {\n      const dpr = window.devicePixelRatio;\n      this.externalRenderer.resize(width * dpr, height * dpr);\n    }\n    this.queueRender();\n  }\n  markBakedShadow(mesh) {\n    mesh.userData.noHit = true;\n    this.bakedShadows.add(mesh);\n  }\n  unmarkBakedShadow(mesh) {\n    mesh.userData.noHit = false;\n    mesh.visible = true;\n    this.bakedShadows.delete(mesh);\n    this.boundingBox.expandByObject(mesh);\n  }\n  findBakedShadows(group) {\n    const boundingBox = new Box3();\n    group.traverse(object => {\n      const mesh = object;\n      if (!mesh.material) {\n        return;\n      }\n      const material = mesh.material;\n      if (!material.transparent) {\n        return;\n      }\n      boundingBox.setFromObject(mesh);\n      const size = boundingBox.getSize(vector3);\n      const minDim = Math.min(size.x, size.y, size.z);\n      const maxDim = Math.max(size.x, size.y, size.z);\n      if (maxDim < MIN_SHADOW_RATIO * minDim) {\n        return;\n      }\n      this.markBakedShadow(mesh);\n    });\n  }\n  checkBakedShadows() {\n    const {\n      min,\n      max\n    } = this.boundingBox;\n    const shadowBox = new Box3();\n    this.boundingBox.getSize(this.size);\n    for (const mesh of this.bakedShadows) {\n      shadowBox.setFromObject(mesh);\n      if (shadowBox.min.y < min.y + this.size.y / MIN_SHADOW_RATIO && shadowBox.min.x <= min.x && shadowBox.max.x >= max.x && shadowBox.min.z <= min.z && shadowBox.max.z >= max.z) {\n        // floor shadow\n        continue;\n      }\n      if (shadowBox.min.z < min.z + this.size.z / MIN_SHADOW_RATIO && shadowBox.min.x <= min.x && shadowBox.max.x >= max.x && shadowBox.min.y <= min.y && shadowBox.max.y >= max.y) {\n        // wall shadow\n        continue;\n      }\n      this.unmarkBakedShadow(mesh);\n    }\n  }\n  applyTransform() {\n    const {\n      model\n    } = this;\n    if (model == null) {\n      return;\n    }\n    const orientation = parseExpressions(this.element.orientation)[0].terms;\n    const roll = normalizeUnit(orientation[0]).number;\n    const pitch = normalizeUnit(orientation[1]).number;\n    const yaw = normalizeUnit(orientation[2]).number;\n    model.quaternion.setFromEuler(new Euler(pitch, yaw, roll, 'YXZ'));\n    const scale = parseExpressions(this.element.scale)[0].terms;\n    model.scale.set(scale[0].number, scale[1].number, scale[2].number);\n  }\n  updateBoundingBox() {\n    const {\n      model\n    } = this;\n    if (model == null) {\n      return;\n    }\n    this.target.remove(model);\n    this.findBakedShadows(model);\n    const bound = (box, vertex) => {\n      return box.expandByPoint(vertex);\n    };\n    this.setBakedShadowVisibility(false);\n    this.boundingBox = reduceVertices(model, bound, new Box3());\n    // If there's nothing but the baked shadow, then it's not a baked shadow.\n    if (this.boundingBox.isEmpty()) {\n      this.setBakedShadowVisibility(true);\n      this.bakedShadows.forEach(mesh => this.unmarkBakedShadow(mesh));\n      this.boundingBox = reduceVertices(model, bound, new Box3());\n    }\n    this.checkBakedShadows();\n    this.setBakedShadowVisibility();\n    this.boundingBox.getSize(this.size);\n    this.target.add(model);\n  }\n  /**\n   * Calculates the boundingSphere and idealAspect that allows the 3D\n   * object to be framed tightly in a 2D window of any aspect ratio without\n   * clipping at any camera orbit. The camera's center target point can be\n   * optionally specified. If no center is specified, it defaults to the center\n   * of the bounding box, which means asymmetric models will tend to be tight on\n   * one side instead of both. Proper choice of center can correct this.\n   */\n  async updateFraming() {\n    const {\n      model\n    } = this;\n    if (model == null) {\n      return;\n    }\n    this.target.remove(model);\n    this.setBakedShadowVisibility(false);\n    const {\n      center\n    } = this.boundingSphere;\n    this.element.requestUpdate('cameraTarget');\n    await this.element.updateComplete;\n    center.copy(this.getTarget());\n    const radiusSquared = (value, vertex) => {\n      return Math.max(value, center.distanceToSquared(vertex));\n    };\n    this.boundingSphere.radius = Math.sqrt(reduceVertices(model, radiusSquared, 0));\n    const horizontalTanFov = (value, vertex) => {\n      vertex.sub(center);\n      const radiusXZ = Math.sqrt(vertex.x * vertex.x + vertex.z * vertex.z);\n      return Math.max(value, radiusXZ / (this.idealCameraDistance() - Math.abs(vertex.y)));\n    };\n    this.idealAspect = reduceVertices(model, horizontalTanFov, 0) / Math.tan(this.framedFoVDeg / 2 * Math.PI / 180);\n    this.setBakedShadowVisibility();\n    this.target.add(model);\n  }\n  setBakedShadowVisibility(visible = this.shadowIntensity <= 0) {\n    for (const shadow of this.bakedShadows) {\n      shadow.visible = visible;\n    }\n  }\n  idealCameraDistance() {\n    const halfFovRad = this.framedFoVDeg / 2 * Math.PI / 180;\n    return this.boundingSphere.radius / Math.sin(halfFovRad);\n  }\n  /**\n   * Set's the framedFieldOfView based on the aspect ratio of the window in\n   * order to keep the model fully visible at any camera orientation.\n   */\n  adjustedFoV(fovDeg) {\n    const vertical = Math.tan(fovDeg / 2 * Math.PI / 180) * Math.max(1, this.idealAspect / this.aspect);\n    return 2 * Math.atan(vertical) * 180 / Math.PI;\n  }\n  getNDC(clientX, clientY) {\n    if (this.xrCamera != null) {\n      ndc.set(clientX / window.screen.width, clientY / window.screen.height);\n    } else {\n      const rect = this.element.getBoundingClientRect();\n      ndc.set((clientX - rect.x) / this.width, (clientY - rect.y) / this.height);\n    }\n    ndc.multiplyScalar(2).subScalar(1);\n    ndc.y *= -1;\n    return ndc;\n  }\n  /**\n   * Returns the size of the corresponding canvas element.\n   */\n  getSize() {\n    return {\n      width: this.width,\n      height: this.height\n    };\n  }\n  setEnvironmentAndSkybox(environment, skybox) {\n    if (this.element[$renderer].arRenderer.presentedScene === this) {\n      return;\n    }\n    this.environment = environment;\n    this.setBackground(skybox);\n    this.queueRender();\n  }\n  setBackground(skybox) {\n    this.groundedSkybox.map = skybox;\n    if (this.groundedSkybox.isUsable()) {\n      this.target.add(this.groundedSkybox);\n      this.background = null;\n    } else {\n      this.target.remove(this.groundedSkybox);\n      this.background = skybox;\n    }\n  }\n  farRadius() {\n    return this.boundingSphere.radius * (this.groundedSkybox.parent != null ? GROUNDED_SKYBOX_SIZE : 1);\n  }\n  setGroundedSkybox() {\n    const heightNode = parseExpressions(this.element.skyboxHeight)[0].terms[0];\n    const height = normalizeUnit(heightNode).number;\n    const radius = GROUNDED_SKYBOX_SIZE * this.boundingSphere.radius;\n    this.groundedSkybox.updateGeometry(height, radius);\n    this.groundedSkybox.position.y = height - (this.shadow ? 2 * this.shadow.gap() : 0);\n    this.setBackground(this.groundedSkybox.map);\n  }\n  /**\n   * Sets the point in model coordinates the model should orbit/pivot around.\n   */\n  setTarget(modelX, modelY, modelZ) {\n    this.goalTarget.set(-modelX, -modelY, -modelZ);\n  }\n  /**\n   * Set the decay time of, affects the speed of target transitions.\n   */\n  setTargetDamperDecayTime(decayMilliseconds) {\n    this.targetDamperX.setDecayTime(decayMilliseconds);\n    this.targetDamperY.setDecayTime(decayMilliseconds);\n    this.targetDamperZ.setDecayTime(decayMilliseconds);\n  }\n  /**\n   * Gets the point in model coordinates the model should orbit/pivot around.\n   */\n  getTarget() {\n    return this.goalTarget.clone().multiplyScalar(-1);\n  }\n  /**\n   * Gets the current target point, which may not equal the goal returned by\n   * getTarget() due to finite input decay smoothing.\n   */\n  getDynamicTarget() {\n    return this.target.position.clone().multiplyScalar(-1);\n  }\n  /**\n   * Shifts the model to the target point immediately instead of easing in.\n   */\n  jumpToGoal() {\n    this.updateTarget(SETTLING_TIME);\n  }\n  /**\n   * This should be called every frame with the frame delta to cause the target\n   * to transition to its set point.\n   */\n  updateTarget(delta) {\n    const goal = this.goalTarget;\n    const target = this.target.position;\n    if (!goal.equals(target)) {\n      const normalization = this.boundingSphere.radius / 10;\n      let {\n        x,\n        y,\n        z\n      } = target;\n      x = this.targetDamperX.update(x, goal.x, delta, normalization);\n      y = this.targetDamperY.update(y, goal.y, delta, normalization);\n      z = this.targetDamperZ.update(z, goal.z, delta, normalization);\n      this.groundedSkybox.position.x = -x;\n      this.groundedSkybox.position.z = -z;\n      this.target.position.set(x, y, z);\n      this.target.updateMatrixWorld();\n      this.queueRender();\n      return true;\n    } else {\n      return false;\n    }\n  }\n  /**\n   * Yaw the +z (front) of the model toward the indicated world coordinates.\n   */\n  pointTowards(worldX, worldZ) {\n    const {\n      x,\n      z\n    } = this.position;\n    this.yaw = Math.atan2(worldX - x, worldZ - z);\n  }\n  get model() {\n    return this._model;\n  }\n  /**\n   * Yaw is the scene's orientation about the y-axis, around the rotation\n   * center.\n   */\n  set yaw(radiansY) {\n    this.pivot.rotation.y = radiansY;\n    this.groundedSkybox.rotation.y = -radiansY;\n    this.queueRender();\n  }\n  get yaw() {\n    return this.pivot.rotation.y;\n  }\n  set animationTime(value) {\n    this.mixer.setTime(value);\n    this.queueShadowRender();\n  }\n  get animationTime() {\n    if (this.currentAnimationAction != null) {\n      const loopCount = Math.max(this.currentAnimationAction._loopCount, 0);\n      if (this.currentAnimationAction.loop === LoopPingPong && (loopCount & 1) === 1) {\n        return this.duration - this.currentAnimationAction.time;\n      } else {\n        return this.currentAnimationAction.time;\n      }\n    }\n    return 0;\n  }\n  set animationTimeScale(value) {\n    this.mixer.timeScale = value;\n  }\n  get animationTimeScale() {\n    return this.mixer.timeScale;\n  }\n  get duration() {\n    if (this.currentAnimationAction != null && this.currentAnimationAction.getClip()) {\n      return this.currentAnimationAction.getClip().duration;\n    }\n    return 0;\n  }\n  get hasActiveAnimation() {\n    return this.currentAnimationAction != null;\n  }\n  /**\n   * Plays an animation if there are any associated with the current model.\n   * Accepts an optional string name of an animation to play. If no name is\n   * provided, or if no animation is found by the given name, always falls back\n   * to playing the first animation.\n   */\n  playAnimation(name = null, crossfadeTime = 0, loopMode = LoopRepeat, repetitionCount = Infinity) {\n    if (this._currentGLTF == null) {\n      return;\n    }\n    const {\n      animations\n    } = this;\n    if (animations == null || animations.length === 0) {\n      return;\n    }\n    let animationClip = null;\n    if (name != null) {\n      animationClip = this.animationsByName.get(name);\n      if (animationClip == null) {\n        const parsedAnimationIndex = parseInt(name);\n        if (!isNaN(parsedAnimationIndex) && parsedAnimationIndex >= 0 && parsedAnimationIndex < animations.length) {\n          animationClip = animations[parsedAnimationIndex];\n        }\n      }\n    }\n    if (animationClip == null) {\n      animationClip = animations[0];\n    }\n    try {\n      const {\n        currentAnimationAction: lastAnimationAction\n      } = this;\n      const action = this.mixer.clipAction(animationClip, this);\n      this.currentAnimationAction = action;\n      if (this.element.paused) {\n        this.mixer.stopAllAction();\n      } else {\n        action.paused = false;\n        if (lastAnimationAction != null && action !== lastAnimationAction) {\n          action.crossFadeFrom(lastAnimationAction, crossfadeTime, false);\n        } else if (this.animationTimeScale > 0 && this.animationTime == this.duration) {\n          // This is a workaround for what I believe is a three.js bug.\n          this.animationTime = 0;\n        }\n      }\n      action.setLoop(loopMode, repetitionCount);\n      action.enabled = true;\n      action.clampWhenFinished = true;\n      action.play();\n    } catch (error) {\n      console.error(error);\n    }\n  }\n  stopAnimation() {\n    this.currentAnimationAction = null;\n    this.mixer.stopAllAction();\n  }\n  updateAnimation(step) {\n    this.mixer.update(step);\n    this.queueShadowRender();\n  }\n  subscribeMixerEvent(event, callback) {\n    this.mixer.addEventListener(event, callback);\n  }\n  /**\n   * Call if the object has been changed in such a way that the shadow's shape\n   * has changed (not a rotation about the Y axis).\n   */\n  updateShadow() {\n    const shadow = this.shadow;\n    if (shadow != null) {\n      const side = this.element.arPlacement === 'wall' ? 'back' : 'bottom';\n      shadow.setScene(this, this.shadowSoftness, side);\n      shadow.needsUpdate = true;\n    }\n  }\n  renderShadow(renderer) {\n    const shadow = this.shadow;\n    if (shadow != null && shadow.needsUpdate == true) {\n      shadow.render(renderer, this);\n      shadow.needsUpdate = false;\n    }\n  }\n  queueShadowRender() {\n    if (this.shadow != null) {\n      this.shadow.needsUpdate = true;\n    }\n  }\n  /**\n   * Sets the shadow's intensity, lazily creating the shadow as necessary.\n   */\n  setShadowIntensity(shadowIntensity) {\n    this.shadowIntensity = shadowIntensity;\n    if (this._currentGLTF == null) {\n      return;\n    }\n    this.setBakedShadowVisibility();\n    if (shadowIntensity <= 0 && this.shadow == null) {\n      return;\n    }\n    if (this.shadow == null) {\n      const side = this.element.arPlacement === 'wall' ? 'back' : 'bottom';\n      this.shadow = new Shadow(this, this.shadowSoftness, side);\n    }\n    this.shadow.setIntensity(shadowIntensity);\n  }\n  /**\n   * Sets the shadow's softness by mapping a [0, 1] softness parameter to the\n   * shadow's resolution. This involves reallocation, so it should not be\n   * changed frequently. Softer shadows are cheaper to render.\n   */\n  setShadowSoftness(softness) {\n    this.shadowSoftness = softness;\n    const shadow = this.shadow;\n    if (shadow != null) {\n      shadow.setSoftness(softness);\n    }\n  }\n  /**\n   * Shift the floor vertically from the bottom of the model's bounding box by\n   * offset (should generally be negative).\n   */\n  setShadowOffset(offset) {\n    const shadow = this.shadow;\n    if (shadow != null) {\n      shadow.setOffset(offset);\n    }\n  }\n  getHit(object = this) {\n    const hits = raycaster.intersectObject(object, true);\n    return hits.find(hit => hit.object.visible && !hit.object.userData.noHit);\n  }\n  hitFromController(controller, object = this) {\n    raycaster.setFromXRController(controller);\n    return this.getHit(object);\n  }\n  hitFromPoint(ndcPosition, object = this) {\n    raycaster.setFromCamera(ndcPosition, this.getCamera());\n    return this.getHit(object);\n  }\n  /**\n   * This method returns the world position, model-space normal and texture\n   * coordinate of the point on the mesh corresponding to the input pixel\n   * coordinates given relative to the model-viewer element. If the mesh\n   * is not hit, the result is null.\n   */\n  positionAndNormalFromPoint(ndcPosition, object = this) {\n    var _a;\n    const hit = this.hitFromPoint(ndcPosition, object);\n    if (hit == null) {\n      return null;\n    }\n    const position = hit.point;\n    const normal = hit.face != null ? hit.face.normal.clone().applyNormalMatrix(new Matrix3().getNormalMatrix(hit.object.matrixWorld)) : raycaster.ray.direction.clone().multiplyScalar(-1);\n    const uv = (_a = hit.uv) !== null && _a !== void 0 ? _a : null;\n    return {\n      position,\n      normal,\n      uv\n    };\n  }\n  /**\n   * This method returns a dynamic hotspot ID string of the point on the mesh\n   * corresponding to the input pixel coordinates given relative to the\n   * model-viewer element. The ID string can be used in the data-surface\n   * attribute of the hotspot to make it follow this point on the surface even\n   * as the model animates. If the mesh is not hit, the result is null.\n   */\n  surfaceFromPoint(ndcPosition, object = this) {\n    const model = this.element.model;\n    if (model == null) {\n      return null;\n    }\n    const hit = this.hitFromPoint(ndcPosition, object);\n    if (hit == null || hit.face == null) {\n      return null;\n    }\n    const node = model[$nodeFromPoint](hit);\n    const {\n      meshes,\n      primitives\n    } = node.mesh.userData.associations;\n    const va = new Vector3();\n    const vb = new Vector3();\n    const vc = new Vector3();\n    const {\n      a,\n      b,\n      c\n    } = hit.face;\n    const mesh = hit.object;\n    mesh.getVertexPosition(a, va);\n    mesh.getVertexPosition(b, vb);\n    mesh.getVertexPosition(c, vc);\n    const tri = new Triangle(va, vb, vc);\n    const uvw = new Vector3();\n    tri.getBarycoord(mesh.worldToLocal(hit.point), uvw);\n    return `${meshes} ${primitives} ${a} ${b} ${c} ${uvw.x.toFixed(3)} ${uvw.y.toFixed(3)} ${uvw.z.toFixed(3)}`;\n  }\n  /**\n   * The following methods are for operating on the set of Hotspot objects\n   * attached to the scene. These come from DOM elements, provided to slots by\n   * the Annotation Mixin.\n   */\n  addHotspot(hotspot) {\n    this.target.add(hotspot);\n    // This happens automatically in render(), but we do it early so that\n    // the slots appear in the shadow DOM and the elements get attached,\n    // allowing us to dispatch events on them.\n    this.annotationRenderer.domElement.appendChild(hotspot.element);\n    this.updateSurfaceHotspot(hotspot);\n  }\n  removeHotspot(hotspot) {\n    this.target.remove(hotspot);\n  }\n  /**\n   * Helper method to apply a function to all hotspots.\n   */\n  forHotspots(func) {\n    const {\n      children\n    } = this.target;\n    for (let i = 0, l = children.length; i < l; i++) {\n      const hotspot = children[i];\n      if (hotspot instanceof Hotspot) {\n        func(hotspot);\n      }\n    }\n  }\n  /**\n   * Lazy initializer for surface hotspots - will only run once.\n   */\n  updateSurfaceHotspot(hotspot) {\n    if (hotspot.surface == null || this.element.model == null) {\n      return;\n    }\n    const nodes = parseExpressions(hotspot.surface)[0].terms;\n    if (nodes.length != 8) {\n      console.warn(hotspot.surface + ' does not have exactly 8 numbers.');\n      return;\n    }\n    const primitiveNode = this.element.model[$nodeFromIndex](nodes[0].number, nodes[1].number);\n    if (primitiveNode == null) {\n      console.warn(hotspot.surface + ' does not match a node/primitive in this glTF! Skipping this hotspot.');\n      return;\n    }\n    const numVert = primitiveNode.mesh.geometry.attributes.position.count;\n    const tri = new Vector3(nodes[2].number, nodes[3].number, nodes[4].number);\n    if (tri.x >= numVert || tri.y >= numVert || tri.z >= numVert) {\n      console.warn(hotspot.surface + ' vertex indices out of range in this glTF! Skipping this hotspot.');\n      return;\n    }\n    const bary = new Vector3(nodes[5].number, nodes[6].number, nodes[7].number);\n    hotspot.mesh = primitiveNode.mesh;\n    hotspot.tri = tri;\n    hotspot.bary = bary;\n    hotspot.updateSurface();\n  }\n  /**\n   * Update positions of surface hotspots to follow model animation.\n   */\n  animateSurfaceHotspots() {\n    if (this.element.paused) {\n      return;\n    }\n    this.forHotspots(hotspot => {\n      hotspot.updateSurface();\n    });\n  }\n  /**\n   * Update the CSS visibility of the hotspots based on whether their normals\n   * point toward the camera.\n   */\n  updateHotspotsVisibility(viewerPosition) {\n    this.forHotspots(hotspot => {\n      view.copy(viewerPosition);\n      target.setFromMatrixPosition(hotspot.matrixWorld);\n      view.sub(target);\n      normalWorld.copy(hotspot.normal).transformDirection(this.target.matrixWorld);\n      if (view.dot(normalWorld) < 0) {\n        hotspot.hide();\n      } else {\n        hotspot.show();\n      }\n    });\n  }\n  /**\n   * Rotate all hotspots to an absolute orientation given by the input number of\n   * radians. Zero returns them to upright.\n   */\n  orientHotspots(radians) {\n    this.forHotspots(hotspot => {\n      hotspot.orient(radians);\n    });\n  }\n  /**\n   * Set the rendering visibility of all hotspots. This is used to hide them\n   * during transitions and such.\n   */\n  setHotspotsVisibility(visible) {\n    this.forHotspots(hotspot => {\n      hotspot.visible = visible;\n    });\n  }\n  updateSchema(src) {\n    var _a;\n    const {\n      schemaElement,\n      element\n    } = this;\n    const {\n      alt,\n      poster,\n      iosSrc\n    } = element;\n    if (src != null) {\n      const encoding = [{\n        '@type': 'MediaObject',\n        contentUrl: src,\n        encodingFormat: ((_a = src.split('.').pop()) === null || _a === void 0 ? void 0 : _a.toLowerCase()) === 'gltf' ? 'model/gltf+json' : 'model/gltf-binary'\n      }];\n      if (iosSrc) {\n        encoding.push({\n          '@type': 'MediaObject',\n          contentUrl: iosSrc,\n          encodingFormat: 'model/vnd.usdz+zip'\n        });\n      }\n      const structuredData = {\n        '@context': 'http://schema.org/',\n        '@type': '3DModel',\n        image: poster !== null && poster !== void 0 ? poster : undefined,\n        name: alt !== null && alt !== void 0 ? alt : undefined,\n        encoding\n      };\n      schemaElement.textContent = JSON.stringify(structuredData);\n      document.head.appendChild(schemaElement);\n    } else if (schemaElement.parentElement != null) {\n      schemaElement.parentElement.removeChild(schemaElement);\n    }\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * ProgressTracker is an event emitter that helps to track the ongoing progress\n * of many simultaneous actions.\n *\n * ProgressTracker reports progress activity in the form of a progress event.\n * The event.detail.totalProgress value indicates the elapsed progress of all\n * activities being tracked by the ProgressTracker.\n *\n * The value of totalProgress is a number that progresses from 0 to 1. The\n * ProgressTracker allows for the lazy accumulation of tracked actions, so the\n * total progress represents an abstract, non-absolute progress towards the\n * completion of all currently tracked events.\n *\n * When all currently tracked activities are finished, the ProgressTracker\n * emits one final progress event and then resets the list of its currently\n * tracked activities. This means that from an observer's perspective,\n * ongoing activities will accumulate and collectively contribute to the notion\n * of total progress until all currently tracked ongoing activities have\n * completed.\n */\nclass ProgressTracker extends EventTarget {\n  constructor() {\n    super(...arguments);\n    this.ongoingActivities = new Set();\n    this.totalProgress = 0;\n  }\n  /**\n   * The total number of activities currently being tracked.\n   */\n  get ongoingActivityCount() {\n    return this.ongoingActivities.size;\n  }\n  /**\n   * Registers a new activity to be tracked by the progress tracker. The method\n   * returns a special callback that should be invoked whenever new progress is\n   * ready to be reported. The progress should be reported as a value between 0\n   * and 1, where 0 would represent the beginning of the action and 1 would\n   * represent its completion.\n   *\n   * There is no built-in notion of a time-out for ongoing activities, so once\n   * an ongoing activity is begun, it is up to the consumer of this API to\n   * update the progress until that activity is no longer ongoing.\n   *\n   * Progress is only allowed to move forward for any given activity. If a lower\n   * progress is reported than the previously reported progress, it will be\n   * ignored.\n   */\n  beginActivity(reason) {\n    const activity = {\n      progress: 0,\n      completed: false\n    };\n    this.ongoingActivities.add(activity);\n    if (this.ongoingActivityCount === 1) {\n      // Announce the first progress event (which should always be 0 / 1\n      // total progress):\n      this.announceTotalProgress(activity, 0, reason);\n    }\n    return progress => {\n      let nextProgress;\n      nextProgress = Math.max(clamp(progress, 0, 1), activity.progress);\n      if (nextProgress !== activity.progress) {\n        this.announceTotalProgress(activity, nextProgress, reason);\n      }\n      return activity.progress;\n    };\n  }\n  announceTotalProgress(updatedActivity, nextProgress, reason) {\n    let progressLeft = 0;\n    let completedActivities = 0;\n    if (nextProgress == 1.0) updatedActivity.completed = true;\n    for (const activity of this.ongoingActivities) {\n      const {\n        progress\n      } = activity;\n      progressLeft += 1.0 - progress;\n      if (activity.completed) {\n        completedActivities++;\n      }\n    }\n    const lastProgress = updatedActivity.progress;\n    updatedActivity.progress = nextProgress;\n    // Advance the total progress by the fraction of total remaining progress\n    // due to this activity.\n    this.totalProgress += (nextProgress - lastProgress) * (1.0 - this.totalProgress) / progressLeft;\n    const totalProgress = completedActivities === this.ongoingActivityCount ? 1.0 : this.totalProgress;\n    this.dispatchEvent(new CustomEvent('progress', {\n      detail: {\n        totalProgress,\n        reason\n      }\n    }));\n    if (completedActivities === this.ongoingActivityCount) {\n      this.totalProgress = 0.0;\n      this.ongoingActivities.clear();\n    }\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate$4 = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nvar _a$1, _b$1, _c, _d, _e, _f, _g, _h, _j, _k, _l, _m, _o;\nconst CLEAR_MODEL_TIMEOUT_MS = 10;\nconst FALLBACK_SIZE_UPDATE_THRESHOLD_MS = 50;\nconst ANNOUNCE_MODEL_VISIBILITY_DEBOUNCE_THRESHOLD = 0;\nconst UNSIZED_MEDIA_WIDTH = 300;\nconst UNSIZED_MEDIA_HEIGHT = 150;\nconst blobCanvas = document.createElement('canvas');\nconst $fallbackResizeHandler = Symbol('fallbackResizeHandler');\nconst $defaultAriaLabel = Symbol('defaultAriaLabel');\nconst $resizeObserver = Symbol('resizeObserver');\nconst $clearModelTimeout = Symbol('clearModelTimeout');\nconst $onContextLost = Symbol('onContextLost');\nconst $loaded = Symbol('loaded');\nconst $status = Symbol('status');\nconst $onFocus = Symbol('onFocus');\nconst $onBlur = Symbol('onBlur');\nconst $updateSize = Symbol('updateSize');\nconst $intersectionObserver = Symbol('intersectionObserver');\nconst $isElementInViewport = Symbol('isElementInViewport');\nconst $announceModelVisibility = Symbol('announceModelVisibility');\nconst $ariaLabel = Symbol('ariaLabel');\nconst $altDefaulted = Symbol('altDefaulted');\nconst $statusElement = Symbol('statusElement');\nconst $updateStatus = Symbol('updateStatus');\nconst $loadedTime = Symbol('loadedTime');\nconst $updateSource = Symbol('updateSource');\nconst $markLoaded = Symbol('markLoaded');\nconst $container = Symbol('container');\nconst $userInputElement = Symbol('input');\nconst $canvas = Symbol('canvas');\nconst $scene = Symbol('scene');\nconst $needsRender = Symbol('needsRender');\nconst $tick = Symbol('tick');\nconst $onModelLoad = Symbol('onModelLoad');\nconst $onResize = Symbol('onResize');\nconst $renderer = Symbol('renderer');\nconst $progressTracker = Symbol('progressTracker');\nconst $getLoaded = Symbol('getLoaded');\nconst $getModelIsVisible = Symbol('getModelIsVisible');\nconst $shouldAttemptPreload = Symbol('shouldAttemptPreload');\nconst toVector3D = v => {\n  return {\n    x: v.x,\n    y: v.y,\n    z: v.z,\n    toString() {\n      return `${this.x}m ${this.y}m ${this.z}m`;\n    }\n  };\n};\nconst toVector2D = v => {\n  return {\n    u: v.x,\n    v: v.y,\n    toString() {\n      return `${this.u} ${this.v}`;\n    }\n  };\n};\n/**\n * Definition for a basic <model-viewer> element.\n */\nclass ModelViewerElementBase extends u$1 {\n  /**\n   * Creates a new ModelViewerElement.\n   */\n  constructor() {\n    super();\n    this.alt = null;\n    this.src = null;\n    this.withCredentials = false;\n    /**\n     * Generates a 3D model schema https://schema.org/3DModel associated with\n     * the loaded src and inserts it into the header of the page for search\n     * engines to crawl.\n     */\n    this.generateSchema = false;\n    this[_a$1] = false;\n    this[_b$1] = false;\n    this[_c] = 0;\n    this[_d] = '';\n    this[_e] = null;\n    this[_f] = debounce(() => {\n      const boundingRect = this.getBoundingClientRect();\n      this[$updateSize](boundingRect);\n    }, FALLBACK_SIZE_UPDATE_THRESHOLD_MS);\n    this[_g] = debounce(oldVisibility => {\n      const newVisibility = this.modelIsVisible;\n      if (newVisibility !== oldVisibility) {\n        this.dispatchEvent(new CustomEvent('model-visibility', {\n          detail: {\n            visible: newVisibility\n          }\n        }));\n      }\n    }, ANNOUNCE_MODEL_VISIBILITY_DEBOUNCE_THRESHOLD);\n    this[_h] = null;\n    this[_j] = null;\n    this[_k] = new ProgressTracker();\n    this[_l] = () => {\n      this[$statusElement].textContent = this[$status];\n    };\n    this[_m] = () => {\n      this[$statusElement].textContent = '';\n    };\n    this[_o] = event => {\n      this.dispatchEvent(new CustomEvent('error', {\n        detail: {\n          type: 'webglcontextlost',\n          sourceError: event.sourceEvent\n        }\n      }));\n    };\n    this.attachShadow({\n      mode: 'open'\n    });\n    const shadowRoot = this.shadowRoot;\n    makeTemplate(shadowRoot);\n    this[$container] = shadowRoot.querySelector('.container');\n    this[$userInputElement] = shadowRoot.querySelector('.userInput');\n    this[$canvas] = shadowRoot.querySelector('canvas');\n    this[$statusElement] = shadowRoot.querySelector('#status');\n    this[$defaultAriaLabel] = this[$userInputElement].getAttribute('aria-label');\n    // Because of potential race conditions related to invoking the constructor\n    // we only use the bounding rect to set the initial size if the element is\n    // already connected to the document:\n    let width, height;\n    if (this.isConnected) {\n      const rect = this.getBoundingClientRect();\n      width = rect.width;\n      height = rect.height;\n    } else {\n      width = UNSIZED_MEDIA_WIDTH;\n      height = UNSIZED_MEDIA_HEIGHT;\n    }\n    // Create the underlying ModelScene.\n    this[$scene] = new ModelScene({\n      canvas: this[$canvas],\n      element: this,\n      width,\n      height\n    });\n    // Update initial size on microtask timing so that subclasses have a\n    // chance to initialize\n    Promise.resolve().then(() => {\n      this[$updateSize](this.getBoundingClientRect());\n    });\n    if (HAS_RESIZE_OBSERVER) {\n      // Set up a resize observer so we can scale our canvas\n      // if our <model-viewer> changes\n      this[$resizeObserver] = new ResizeObserver(entries => {\n        // Don't resize anything if in AR mode; otherwise the canvas\n        // scaling to fullscreen on entering AR will clobber the flat/2d\n        // dimensions of the element.\n        if (this[$renderer].isPresenting) {\n          return;\n        }\n        for (let entry of entries) {\n          if (entry.target === this) {\n            this[$updateSize](entry.contentRect);\n          }\n        }\n      });\n    }\n    if (HAS_INTERSECTION_OBSERVER) {\n      this[$intersectionObserver] = new IntersectionObserver(entries => {\n        for (let entry of entries) {\n          if (entry.target === this) {\n            const oldVisibility = this.modelIsVisible;\n            this[$isElementInViewport] = entry.isIntersecting;\n            this[$announceModelVisibility](oldVisibility);\n            if (this[$isElementInViewport] && !this.loaded) {\n              this[$updateSource]();\n            }\n          }\n        }\n      }, {\n        root: null,\n        // We used to have margin here, but it was causing animated models below\n        // the fold to steal the frame budget. Weirder still, it would also\n        // cause input events to be swallowed, sometimes for seconds on the\n        // model above the fold, but only when the animated model was completely\n        // below. Setting this margin to zero fixed it.\n        rootMargin: '0px',\n        // With zero threshold, an element adjacent to but not intersecting the\n        // viewport will be reported as intersecting, which will cause\n        // unnecessary rendering. Any slight positive threshold alleviates this.\n        threshold: 0.00001\n      });\n    } else {\n      // If there is no intersection observer, then all models should be visible\n      // at all times:\n      this[$isElementInViewport] = true;\n    }\n  }\n  static get is() {\n    return 'model-viewer';\n  }\n  /** @export */\n  static set modelCacheSize(value) {\n    CachingGLTFLoader[$evictionPolicy].evictionThreshold = value;\n  }\n  /** @export */\n  static get modelCacheSize() {\n    return CachingGLTFLoader[$evictionPolicy].evictionThreshold;\n  }\n  /** @export */\n  static set minimumRenderScale(value) {\n    if (value > 1) {\n      console.warn('<model-viewer> minimumRenderScale has been clamped to a maximum value of 1.');\n    }\n    if (value <= 0) {\n      console.warn('<model-viewer> minimumRenderScale has been clamped to a minimum value of 0.25.');\n    }\n    Renderer.singleton.minScale = value;\n  }\n  /** @export */\n  static get minimumRenderScale() {\n    return Renderer.singleton.minScale;\n  }\n  /** @export */\n  get loaded() {\n    return this[$getLoaded]();\n  }\n  get [(_a$1 = $isElementInViewport, _b$1 = $loaded, _c = $loadedTime, _d = $status, _e = $clearModelTimeout, _f = $fallbackResizeHandler, _g = $announceModelVisibility, _h = $resizeObserver, _j = $intersectionObserver, _k = $progressTracker, $renderer)]() {\n    return Renderer.singleton;\n  }\n  /** @export */\n  get modelIsVisible() {\n    return this[$getModelIsVisible]();\n  }\n  connectedCallback() {\n    super.connectedCallback && super.connectedCallback();\n    if (HAS_RESIZE_OBSERVER) {\n      this[$resizeObserver].observe(this);\n    } else {\n      self.addEventListener('resize', this[$fallbackResizeHandler]);\n    }\n    if (HAS_INTERSECTION_OBSERVER) {\n      this[$intersectionObserver].observe(this);\n    }\n    this.addEventListener('focus', this[$onFocus]);\n    this.addEventListener('blur', this[$onBlur]);\n    const renderer = this[$renderer];\n    renderer.addEventListener('contextlost', this[$onContextLost]);\n    renderer.registerScene(this[$scene]);\n    if (this[$clearModelTimeout] != null) {\n      self.clearTimeout(this[$clearModelTimeout]);\n      this[$clearModelTimeout] = null;\n      // Force an update in case the model has been evicted from our GLTF cache\n      // @see https://lit-element.polymer-project.org/guide/lifecycle#requestupdate\n      this.requestUpdate('src', null);\n    }\n  }\n  disconnectedCallback() {\n    super.disconnectedCallback && super.disconnectedCallback();\n    if (HAS_RESIZE_OBSERVER) {\n      this[$resizeObserver].unobserve(this);\n    } else {\n      self.removeEventListener('resize', this[$fallbackResizeHandler]);\n    }\n    if (HAS_INTERSECTION_OBSERVER) {\n      this[$intersectionObserver].unobserve(this);\n    }\n    this.removeEventListener('focus', this[$onFocus]);\n    this.removeEventListener('blur', this[$onBlur]);\n    const renderer = this[$renderer];\n    renderer.removeEventListener('contextlost', this[$onContextLost]);\n    renderer.unregisterScene(this[$scene]);\n    this[$clearModelTimeout] = self.setTimeout(() => {\n      this[$scene].dispose();\n      this[$clearModelTimeout] = null;\n    }, CLEAR_MODEL_TIMEOUT_MS);\n  }\n  updated(changedProperties) {\n    super.updated(changedProperties);\n    // NOTE(cdata): If a property changes from values A -> B -> A in the space\n    // of a microtask, LitElement/UpdatingElement will notify of a change even\n    // though the value has effectively not changed, so we need to check to make\n    // sure that the value has actually changed before changing the loaded flag.\n    if (changedProperties.has('src')) {\n      if (this.src == null) {\n        this[$loaded] = false;\n        this[$loadedTime] = 0;\n        this[$scene].reset();\n      } else if (this.src !== this[$scene].url) {\n        this[$loaded] = false;\n        this[$loadedTime] = 0;\n        this[$updateSource]();\n      }\n    }\n    if (changedProperties.has('alt')) {\n      this[$userInputElement].setAttribute('aria-label', this[$ariaLabel]);\n    }\n    if (changedProperties.has('generateSchema')) {\n      if (this.generateSchema) {\n        this[$scene].updateSchema(this.src);\n      } else {\n        this[$scene].updateSchema(null);\n      }\n    }\n  }\n  /** @export */\n  toDataURL(type, encoderOptions) {\n    return this[$renderer].displayCanvas(this[$scene]).toDataURL(type, encoderOptions);\n  }\n  /** @export */\n  async toBlob(options) {\n    const mimeType = options ? options.mimeType : undefined;\n    const qualityArgument = options ? options.qualityArgument : undefined;\n    const useIdealAspect = options ? options.idealAspect : undefined;\n    const {\n      width,\n      height,\n      idealAspect,\n      aspect\n    } = this[$scene];\n    const {\n      dpr,\n      scaleFactor\n    } = this[$renderer];\n    let outputWidth = width * scaleFactor * dpr;\n    let outputHeight = height * scaleFactor * dpr;\n    let offsetX = 0;\n    let offsetY = 0;\n    if (useIdealAspect === true) {\n      if (idealAspect > aspect) {\n        const oldHeight = outputHeight;\n        outputHeight = Math.round(outputWidth / idealAspect);\n        offsetY = (oldHeight - outputHeight) / 2;\n      } else {\n        const oldWidth = outputWidth;\n        outputWidth = Math.round(outputHeight * idealAspect);\n        offsetX = (oldWidth - outputWidth) / 2;\n      }\n    }\n    blobCanvas.width = outputWidth;\n    blobCanvas.height = outputHeight;\n    try {\n      return new Promise(async (resolve, reject) => {\n        blobCanvas.getContext('2d').drawImage(this[$renderer].displayCanvas(this[$scene]), offsetX, offsetY, outputWidth, outputHeight, 0, 0, outputWidth, outputHeight);\n        blobCanvas.toBlob(blob => {\n          if (!blob) {\n            return reject(new Error('Unable to retrieve canvas blob'));\n          }\n          resolve(blob);\n        }, mimeType, qualityArgument);\n      });\n    } finally {\n      this[$updateSize]({\n        width,\n        height\n      });\n    }\n  }\n  /**\n   * Registers a new EffectComposer as the main rendering pipeline,\n   * instead of the default ThreeJs renderer.\n   * This method also calls setRenderer, setMainScene, and setMainCamera on\n   * your effectComposer.\n   * @param effectComposer An EffectComposer from `pmndrs/postprocessing`\n   */\n  registerEffectComposer(effectComposer) {\n    effectComposer.setRenderer(this[$renderer].threeRenderer);\n    effectComposer.setMainCamera(this[$scene].getCamera());\n    effectComposer.setMainScene(this[$scene]);\n    this[$scene].effectRenderer = effectComposer;\n  }\n  /**\n   * Removes the registered EffectComposer\n   */\n  unregisterEffectComposer() {\n    this[$scene].effectRenderer = null;\n  }\n  registerRenderer(renderer) {\n    this[$scene].externalRenderer = renderer;\n  }\n  unregisterRenderer() {\n    this[$scene].externalRenderer = null;\n  }\n  get [$ariaLabel]() {\n    return this[$altDefaulted];\n  }\n  get [$altDefaulted]() {\n    return this.alt == null || this.alt === 'null' ? this[$defaultAriaLabel] : this.alt;\n  }\n  // NOTE(cdata): Although this may seem extremely redundant, it is required in\n  // order to support overloading when TypeScript is compiled to ES5\n  // @see https://github.com/Polymer/lit-element/pull/745\n  // @see https://github.com/microsoft/TypeScript/issues/338\n  [$getLoaded]() {\n    return this[$loaded];\n  }\n  // @see [$getLoaded]\n  [$getModelIsVisible]() {\n    return this.loaded && this[$isElementInViewport];\n  }\n  [$shouldAttemptPreload]() {\n    return !!this.src && this[$isElementInViewport];\n  }\n  /**\n   * Called on initialization and when the resize observer fires.\n   */\n  [$updateSize]({\n    width,\n    height\n  }) {\n    if (width === 0 || height === 0) {\n      return;\n    }\n    this[$container].style.width = `${width}px`;\n    this[$container].style.height = `${height}px`;\n    this[$onResize]({\n      width,\n      height\n    });\n  }\n  [$tick](time, delta) {\n    var _p;\n    (_p = this[$scene].effectRenderer) === null || _p === void 0 ? void 0 : _p.beforeRender(time, delta);\n  }\n  [$markLoaded]() {\n    if (this[$loaded]) {\n      return;\n    }\n    this[$loaded] = true;\n    this[$loadedTime] = performance.now();\n  }\n  [$needsRender]() {\n    this[$scene].queueRender();\n  }\n  [$onModelLoad]() {}\n  [$updateStatus](status) {\n    this[$status] = status;\n    const rootNode = this.getRootNode();\n    // Only change the aria-label if <model-viewer> is currently focused:\n    if (rootNode != null && rootNode.activeElement === this && this[$statusElement].textContent != status) {\n      this[$statusElement].textContent = status;\n    }\n  }\n  [(_l = $onFocus, _m = $onBlur, $onResize)](e) {\n    this[$scene].setSize(e.width, e.height);\n  }\n  /**\n   * Parses the element for an appropriate source URL and\n   * sets the views to use the new model based.\n   */\n  async [(_o = $onContextLost, $updateSource)]() {\n    const scene = this[$scene];\n    if (this.loaded || !this[$shouldAttemptPreload]() || this.src === scene.url) {\n      return;\n    }\n    if (this.generateSchema) {\n      scene.updateSchema(this.src);\n    }\n    this[$updateStatus]('Loading');\n    // If we are loading a new model, we need to stop the animation of\n    // the current one (if any is playing). Otherwise, we might lose\n    // the reference to the scene root and running actions start to\n    // throw exceptions and/or behave in unexpected ways:\n    scene.stopAnimation();\n    const updateSourceProgress = this[$progressTracker].beginActivity('model-load');\n    const source = this.src;\n    try {\n      const srcUpdated = scene.setSource(source, progress => updateSourceProgress(clamp(progress, 0, 1) * 0.95));\n      const envUpdated = this[$updateEnvironment]();\n      await Promise.all([srcUpdated, envUpdated]);\n      this[$markLoaded]();\n      this[$onModelLoad]();\n      this.updateComplete.then(() => {\n        this.dispatchEvent(new CustomEvent('before-render'));\n      });\n      // Wait for shaders to compile and pixels to be drawn.\n      await new Promise(resolve => {\n        requestAnimationFrame(() => {\n          requestAnimationFrame(() => {\n            this.dispatchEvent(new CustomEvent('load', {\n              detail: {\n                url: source\n              }\n            }));\n            resolve();\n          });\n        });\n      });\n    } catch (error) {\n      this.dispatchEvent(new CustomEvent('error', {\n        detail: {\n          type: 'loadfailure',\n          sourceError: error\n        }\n      }));\n    } finally {\n      updateSourceProgress(1.0);\n    }\n  }\n}\n__decorate$4([n$8({\n  type: String\n})], ModelViewerElementBase.prototype, \"alt\", void 0);\n__decorate$4([n$8({\n  type: String\n})], ModelViewerElementBase.prototype, \"src\", void 0);\n__decorate$4([n$8({\n  type: Boolean,\n  attribute: 'with-credentials'\n})], ModelViewerElementBase.prototype, \"withCredentials\", void 0);\n__decorate$4([n$8({\n  type: Boolean,\n  attribute: 'generate-schema'\n})], ModelViewerElementBase.prototype, \"generateSchema\", void 0);\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate$3 = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nconst MILLISECONDS_PER_SECOND = 1000.0;\nconst $changeAnimation = Symbol('changeAnimation');\nconst $paused = Symbol('paused');\nconst DEFAULT_PLAY_OPTIONS = {\n  repetitions: Infinity,\n  pingpong: false\n};\nconst AnimationMixin = ModelViewerElement => {\n  var _a;\n  class AnimationModelViewerElement extends ModelViewerElement {\n    constructor(...args) {\n      super(args);\n      this.autoplay = false;\n      this.animationName = undefined;\n      this.animationCrossfadeDuration = 300;\n      this[_a] = true;\n      this[$scene].subscribeMixerEvent('loop', e => {\n        const count = e.action._loopCount;\n        this.dispatchEvent(new CustomEvent('loop', {\n          detail: {\n            count\n          }\n        }));\n      });\n      this[$scene].subscribeMixerEvent('finished', () => {\n        this[$paused] = true;\n        this.dispatchEvent(new CustomEvent('finished'));\n      });\n    }\n    /**\n     * Returns an array\n     */\n    get availableAnimations() {\n      if (this.loaded) {\n        return this[$scene].animationNames;\n      }\n      return [];\n    }\n    get duration() {\n      return this[$scene].duration;\n    }\n    get paused() {\n      return this[$paused];\n    }\n    get currentTime() {\n      return this[$scene].animationTime;\n    }\n    set currentTime(value) {\n      this[$scene].animationTime = value;\n      this[$needsRender]();\n    }\n    get timeScale() {\n      return this[$scene].animationTimeScale;\n    }\n    set timeScale(value) {\n      this[$scene].animationTimeScale = value;\n    }\n    pause() {\n      if (this[$paused]) {\n        return;\n      }\n      this[$paused] = true;\n      this.dispatchEvent(new CustomEvent('pause'));\n    }\n    play(options) {\n      if (this.availableAnimations.length > 0) {\n        this[$paused] = false;\n        this[$changeAnimation](options);\n        this.dispatchEvent(new CustomEvent('play'));\n      }\n    }\n    [(_a = $paused, $onModelLoad)]() {\n      super[$onModelLoad]();\n      this[$paused] = true;\n      if (this.animationName != null) {\n        this[$changeAnimation]();\n      }\n      if (this.autoplay) {\n        this.play();\n      }\n    }\n    [$tick](_time, delta) {\n      super[$tick](_time, delta);\n      if (this[$paused] || !this[$getModelIsVisible]() && !this[$renderer].isPresenting) {\n        return;\n      }\n      this[$scene].updateAnimation(delta / MILLISECONDS_PER_SECOND);\n      this[$needsRender]();\n    }\n    updated(changedProperties) {\n      super.updated(changedProperties);\n      if (changedProperties.has('autoplay') && this.autoplay) {\n        this.play();\n      }\n      if (changedProperties.has('animationName')) {\n        this[$changeAnimation]();\n      }\n    }\n    [$changeAnimation](options = DEFAULT_PLAY_OPTIONS) {\n      var _b;\n      const repetitions = (_b = options.repetitions) !== null && _b !== void 0 ? _b : Infinity;\n      const mode = options.pingpong ? LoopPingPong : repetitions === 1 ? LoopOnce : LoopRepeat;\n      this[$scene].playAnimation(this.animationName, this.animationCrossfadeDuration / MILLISECONDS_PER_SECOND, mode, repetitions);\n      // If we are currently paused, we need to force a render so that\n      // the scene updates to the first frame of the new animation\n      if (this[$paused]) {\n        this[$scene].updateAnimation(0);\n        this[$needsRender]();\n      }\n    }\n  }\n  __decorate$3([n$8({\n    type: Boolean\n  })], AnimationModelViewerElement.prototype, \"autoplay\", void 0);\n  __decorate$3([n$8({\n    type: String,\n    attribute: 'animation-name'\n  })], AnimationModelViewerElement.prototype, \"animationName\", void 0);\n  __decorate$3([n$8({\n    type: Number,\n    attribute: 'animation-crossfade-duration'\n  })], AnimationModelViewerElement.prototype, \"animationCrossfadeDuration\", void 0);\n  return AnimationModelViewerElement;\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst $hotspotMap = Symbol('hotspotMap');\nconst $mutationCallback = Symbol('mutationCallback');\nconst $observer = Symbol('observer');\nconst $addHotspot = Symbol('addHotspot');\nconst $removeHotspot = Symbol('removeHotspot');\nconst worldToModel = new Matrix4();\n/**\n * AnnotationMixin implements a declarative API to add hotspots and annotations.\n * Child elements of the <model-viewer> element that have a slot name that\n * begins with \"hotspot\" and data-position and data-normal attributes in\n * the format of the camera-target attribute will be added to the scene and\n * track the specified model coordinates.\n */\nconst AnnotationMixin = ModelViewerElement => {\n  var _a, _b, _c;\n  class AnnotationModelViewerElement extends ModelViewerElement {\n    constructor() {\n      super(...arguments);\n      this[_a] = new Map();\n      this[_b] = mutations => {\n        mutations.forEach(mutation => {\n          // NOTE: Be wary that in ShadyDOM cases, the MutationRecord\n          // only has addedNodes and removedNodes (and no other details).\n          if (!(mutation instanceof MutationRecord) || mutation.type === 'childList') {\n            mutation.addedNodes.forEach(node => {\n              this[$addHotspot](node);\n            });\n            mutation.removedNodes.forEach(node => {\n              this[$removeHotspot](node);\n            });\n            this[$needsRender]();\n          }\n        });\n      };\n      this[_c] = new MutationObserver(this[$mutationCallback]);\n    }\n    connectedCallback() {\n      super.connectedCallback();\n      for (let i = 0; i < this.children.length; ++i) {\n        this[$addHotspot](this.children[i]);\n      }\n      const {\n        ShadyDOM\n      } = self;\n      if (ShadyDOM == null) {\n        this[$observer].observe(this, {\n          childList: true\n        });\n      } else {\n        this[$observer] = ShadyDOM.observeChildren(this, this[$mutationCallback]);\n      }\n    }\n    disconnectedCallback() {\n      super.disconnectedCallback();\n      const {\n        ShadyDOM\n      } = self;\n      if (ShadyDOM == null) {\n        this[$observer].disconnect();\n      } else {\n        ShadyDOM.unobserveChildren(this[$observer]);\n      }\n    }\n    [(_a = $hotspotMap, _b = $mutationCallback, _c = $observer, $onModelLoad)]() {\n      super[$onModelLoad]();\n      const scene = this[$scene];\n      scene.forHotspots(hotspot => {\n        scene.updateSurfaceHotspot(hotspot);\n      });\n    }\n    [$tick](time, delta) {\n      super[$tick](time, delta);\n      const scene = this[$scene];\n      const {\n        annotationRenderer\n      } = scene;\n      const camera = scene.getCamera();\n      if (scene.shouldRender()) {\n        scene.animateSurfaceHotspots();\n        scene.updateHotspotsVisibility(camera.position);\n        annotationRenderer.domElement.style.display = '';\n        annotationRenderer.render(scene, camera);\n      }\n    }\n    /**\n     * Since the data-position and data-normal attributes are not observed, use\n     * this method to move a hotspot. Keep in mind that all hotspots with the\n     * same slot name use a single location and the first definition takes\n     * precedence, until updated with this method.\n     */\n    updateHotspot(config) {\n      const hotspot = this[$hotspotMap].get(config.name);\n      if (hotspot == null) {\n        return;\n      }\n      hotspot.updatePosition(config.position);\n      hotspot.updateNormal(config.normal);\n      hotspot.surface = config.surface;\n      this[$scene].updateSurfaceHotspot(hotspot);\n      this[$needsRender]();\n    }\n    /**\n     * This method returns in-scene data about a requested hotspot including\n     * its position in screen (canvas) space and its current visibility.\n     */\n    queryHotspot(name) {\n      const hotspot = this[$hotspotMap].get(name);\n      if (hotspot == null) {\n        return null;\n      }\n      const position = toVector3D(hotspot.position);\n      const normal = toVector3D(hotspot.normal);\n      const facingCamera = hotspot.facingCamera;\n      const scene = this[$scene];\n      const camera = scene.getCamera();\n      const vector = new Vector3();\n      vector.setFromMatrixPosition(hotspot.matrixWorld);\n      vector.project(camera);\n      const widthHalf = scene.width / 2;\n      const heightHalf = scene.height / 2;\n      vector.x = vector.x * widthHalf + widthHalf;\n      vector.y = -(vector.y * heightHalf) + heightHalf;\n      const canvasPosition = toVector3D(new Vector3(vector.x, vector.y, vector.z));\n      if (!Number.isFinite(canvasPosition.x) || !Number.isFinite(canvasPosition.y)) {\n        return null;\n      }\n      return {\n        position,\n        normal,\n        canvasPosition,\n        facingCamera\n      };\n    }\n    /**\n     * This method returns the model position, normal and texture coordinate\n     * of the point on the mesh corresponding to the input pixel coordinates\n     * given relative to the model-viewer element. The position and normal\n     * are returned as strings in the format suitable for putting in a\n     * hotspot's data-position and data-normal attributes. If the mesh is\n     * not hit, the result is null.\n     */\n    positionAndNormalFromPoint(pixelX, pixelY) {\n      const scene = this[$scene];\n      const ndcPosition = scene.getNDC(pixelX, pixelY);\n      const hit = scene.positionAndNormalFromPoint(ndcPosition);\n      if (hit == null) {\n        return null;\n      }\n      worldToModel.copy(scene.target.matrixWorld).invert();\n      const position = toVector3D(hit.position.applyMatrix4(worldToModel));\n      const normal = toVector3D(hit.normal.transformDirection(worldToModel));\n      let uv = null;\n      if (hit.uv != null) {\n        uv = toVector2D(hit.uv);\n      }\n      return {\n        position: position,\n        normal: normal,\n        uv: uv\n      };\n    }\n    /**\n     * This method returns a dynamic hotspot ID string of the point on the mesh\n     * corresponding to the input pixel coordinates given relative to the\n     * model-viewer element. The ID string can be used in the data-surface\n     * attribute of the hotspot to make it follow this point on the surface even\n     * as the model animates. If the mesh is not hit, the result is null.\n     */\n    surfaceFromPoint(pixelX, pixelY) {\n      const scene = this[$scene];\n      const ndcPosition = scene.getNDC(pixelX, pixelY);\n      return scene.surfaceFromPoint(ndcPosition);\n    }\n    [$addHotspot](node) {\n      if (!(node instanceof HTMLElement && node.slot.indexOf('hotspot') === 0)) {\n        return;\n      }\n      let hotspot = this[$hotspotMap].get(node.slot);\n      if (hotspot != null) {\n        hotspot.increment();\n      } else {\n        hotspot = new Hotspot({\n          name: node.slot,\n          position: node.dataset.position,\n          normal: node.dataset.normal,\n          surface: node.dataset.surface\n        });\n        this[$hotspotMap].set(node.slot, hotspot);\n        this[$scene].addHotspot(hotspot);\n      }\n      this[$scene].queueRender();\n    }\n    [$removeHotspot](node) {\n      if (!(node instanceof HTMLElement)) {\n        return;\n      }\n      const hotspot = this[$hotspotMap].get(node.slot);\n      if (!hotspot) {\n        return;\n      }\n      if (hotspot.decrement()) {\n        this[$scene].removeHotspot(hotspot);\n        this[$hotspotMap].delete(node.slot);\n      }\n      this[$scene].queueRender();\n    }\n  }\n  return AnnotationModelViewerElement;\n};\n\n/*!\nfflate - fast JavaScript compression/decompression\n<https://101arrowz.github.io/fflate>\nLicensed under MIT. https://github.com/101arrowz/fflate/blob/master/LICENSE\nversion 0.8.2\n*/\n\n// aliases for shorter compressed code (most minifers don't do this)\nvar u8 = Uint8Array,\n  u16 = Uint16Array,\n  i32 = Int32Array;\n// fixed length extra bits\nvar fleb = new u8([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 0, /* unused */0, 0, /* impossible */0]);\n// fixed distance extra bits\nvar fdeb = new u8([0, 0, 0, 0, 1, 1, 2, 2, 3, 3, 4, 4, 5, 5, 6, 6, 7, 7, 8, 8, 9, 9, 10, 10, 11, 11, 12, 12, 13, 13, /* unused */0, 0]);\n// code length index map\nvar clim = new u8([16, 17, 18, 0, 8, 7, 9, 6, 10, 5, 11, 4, 12, 3, 13, 2, 14, 1, 15]);\n// get base, reverse index map from extra bits\nvar freb = function (eb, start) {\n  var b = new u16(31);\n  for (var i = 0; i < 31; ++i) {\n    b[i] = start += 1 << eb[i - 1];\n  }\n  // numbers here are at max 18 bits\n  var r = new i32(b[30]);\n  for (var i = 1; i < 30; ++i) {\n    for (var j = b[i]; j < b[i + 1]; ++j) {\n      r[j] = j - b[i] << 5 | i;\n    }\n  }\n  return {\n    b: b,\n    r: r\n  };\n};\nvar _a = freb(fleb, 2),\n  fl = _a.b,\n  revfl = _a.r;\n// we can ignore the fact that the other numbers are wrong; they never happen anyway\nfl[28] = 258, revfl[258] = 28;\nvar _b = freb(fdeb, 0),\n  revfd = _b.r;\n// map of value to reverse (assuming 16 bits)\nvar rev = new u16(32768);\nfor (var i = 0; i < 32768; ++i) {\n  // reverse table algorithm from SO\n  var x = (i & 0xAAAA) >> 1 | (i & 0x5555) << 1;\n  x = (x & 0xCCCC) >> 2 | (x & 0x3333) << 2;\n  x = (x & 0xF0F0) >> 4 | (x & 0x0F0F) << 4;\n  rev[i] = ((x & 0xFF00) >> 8 | (x & 0x00FF) << 8) >> 1;\n}\n// create huffman tree from u8 \"map\": index -> code length for code index\n// mb (max bits) must be at most 15\n// TODO: optimize/split up?\nvar hMap = function (cd, mb, r) {\n  var s = cd.length;\n  // index\n  var i = 0;\n  // u16 \"map\": index -> # of codes with bit length = index\n  var l = new u16(mb);\n  // length of cd must be 288 (total # of codes)\n  for (; i < s; ++i) {\n    if (cd[i]) ++l[cd[i] - 1];\n  }\n  // u16 \"map\": index -> minimum code for bit length = index\n  var le = new u16(mb);\n  for (i = 1; i < mb; ++i) {\n    le[i] = le[i - 1] + l[i - 1] << 1;\n  }\n  var co;\n  if (r) {\n    // u16 \"map\": index -> number of actual bits, symbol for code\n    co = new u16(1 << mb);\n    // bits to remove for reverser\n    var rvb = 15 - mb;\n    for (i = 0; i < s; ++i) {\n      // ignore 0 lengths\n      if (cd[i]) {\n        // num encoding both symbol and bits read\n        var sv = i << 4 | cd[i];\n        // free bits\n        var r_1 = mb - cd[i];\n        // start value\n        var v = le[cd[i] - 1]++ << r_1;\n        // m is end value\n        for (var m = v | (1 << r_1) - 1; v <= m; ++v) {\n          // every 16 bit value starting with the code yields the same result\n          co[rev[v] >> rvb] = sv;\n        }\n      }\n    }\n  } else {\n    co = new u16(s);\n    for (i = 0; i < s; ++i) {\n      if (cd[i]) {\n        co[i] = rev[le[cd[i] - 1]++] >> 15 - cd[i];\n      }\n    }\n  }\n  return co;\n};\n// fixed length tree\nvar flt = new u8(288);\nfor (var i = 0; i < 144; ++i) flt[i] = 8;\nfor (var i = 144; i < 256; ++i) flt[i] = 9;\nfor (var i = 256; i < 280; ++i) flt[i] = 7;\nfor (var i = 280; i < 288; ++i) flt[i] = 8;\n// fixed distance tree\nvar fdt = new u8(32);\nfor (var i = 0; i < 32; ++i) fdt[i] = 5;\n// fixed length map\nvar flm = /*#__PURE__*/hMap(flt, 9, 0);\n// fixed distance map\nvar fdm = /*#__PURE__*/hMap(fdt, 5, 0);\n// get end of byte\nvar shft = function (p) {\n  return (p + 7) / 8 | 0;\n};\n// typed array slice - allows garbage collector to free original reference,\n// while being more compatible than .slice\nvar slc = function (v, s, e) {\n  if (s == null || s < 0) s = 0;\n  if (e == null || e > v.length) e = v.length;\n  // can't use .constructor in case user-supplied\n  return new u8(v.subarray(s, e));\n};\n// error codes\nvar ec = ['unexpected EOF', 'invalid block type', 'invalid length/literal', 'invalid distance', 'stream finished', 'no stream handler',, 'no callback', 'invalid UTF-8 data', 'extra field too long', 'date not in range 1980-2099', 'filename too long', 'stream finishing', 'invalid zip data'\n// determined by unknown compression method\n];\nvar err = function (ind, msg, nt) {\n  var e = new Error(msg || ec[ind]);\n  e.code = ind;\n  if (Error.captureStackTrace) Error.captureStackTrace(e, err);\n  if (!nt) throw e;\n  return e;\n};\n// starting at p, write the minimum number of bits that can hold v to d\nvar wbits = function (d, p, v) {\n  v <<= p & 7;\n  var o = p / 8 | 0;\n  d[o] |= v;\n  d[o + 1] |= v >> 8;\n};\n// starting at p, write the minimum number of bits (>8) that can hold v to d\nvar wbits16 = function (d, p, v) {\n  v <<= p & 7;\n  var o = p / 8 | 0;\n  d[o] |= v;\n  d[o + 1] |= v >> 8;\n  d[o + 2] |= v >> 16;\n};\n// creates code lengths from a frequency table\nvar hTree = function (d, mb) {\n  // Need extra info to make a tree\n  var t = [];\n  for (var i = 0; i < d.length; ++i) {\n    if (d[i]) t.push({\n      s: i,\n      f: d[i]\n    });\n  }\n  var s = t.length;\n  var t2 = t.slice();\n  if (!s) return {\n    t: et,\n    l: 0\n  };\n  if (s == 1) {\n    var v = new u8(t[0].s + 1);\n    v[t[0].s] = 1;\n    return {\n      t: v,\n      l: 1\n    };\n  }\n  t.sort(function (a, b) {\n    return a.f - b.f;\n  });\n  // after i2 reaches last ind, will be stopped\n  // freq must be greater than largest possible number of symbols\n  t.push({\n    s: -1,\n    f: 25001\n  });\n  var l = t[0],\n    r = t[1],\n    i0 = 0,\n    i1 = 1,\n    i2 = 2;\n  t[0] = {\n    s: -1,\n    f: l.f + r.f,\n    l: l,\n    r: r\n  };\n  // efficient algorithm from UZIP.js\n  // i0 is lookbehind, i2 is lookahead - after processing two low-freq\n  // symbols that combined have high freq, will start processing i2 (high-freq,\n  // non-composite) symbols instead\n  // see https://reddit.com/r/photopea/comments/ikekht/uzipjs_questions/\n  while (i1 != s - 1) {\n    l = t[t[i0].f < t[i2].f ? i0++ : i2++];\n    r = t[i0 != i1 && t[i0].f < t[i2].f ? i0++ : i2++];\n    t[i1++] = {\n      s: -1,\n      f: l.f + r.f,\n      l: l,\n      r: r\n    };\n  }\n  var maxSym = t2[0].s;\n  for (var i = 1; i < s; ++i) {\n    if (t2[i].s > maxSym) maxSym = t2[i].s;\n  }\n  // code lengths\n  var tr = new u16(maxSym + 1);\n  // max bits in tree\n  var mbt = ln(t[i1 - 1], tr, 0);\n  if (mbt > mb) {\n    // more algorithms from UZIP.js\n    // TODO: find out how this code works (debt)\n    //  ind    debt\n    var i = 0,\n      dt = 0;\n    //    left            cost\n    var lft = mbt - mb,\n      cst = 1 << lft;\n    t2.sort(function (a, b) {\n      return tr[b.s] - tr[a.s] || a.f - b.f;\n    });\n    for (; i < s; ++i) {\n      var i2_1 = t2[i].s;\n      if (tr[i2_1] > mb) {\n        dt += cst - (1 << mbt - tr[i2_1]);\n        tr[i2_1] = mb;\n      } else break;\n    }\n    dt >>= lft;\n    while (dt > 0) {\n      var i2_2 = t2[i].s;\n      if (tr[i2_2] < mb) dt -= 1 << mb - tr[i2_2]++ - 1;else ++i;\n    }\n    for (; i >= 0 && dt; --i) {\n      var i2_3 = t2[i].s;\n      if (tr[i2_3] == mb) {\n        --tr[i2_3];\n        ++dt;\n      }\n    }\n    mbt = mb;\n  }\n  return {\n    t: new u8(tr),\n    l: mbt\n  };\n};\n// get the max length and assign length codes\nvar ln = function (n, l, d) {\n  return n.s == -1 ? Math.max(ln(n.l, l, d + 1), ln(n.r, l, d + 1)) : l[n.s] = d;\n};\n// length codes generation\nvar lc = function (c) {\n  var s = c.length;\n  // Note that the semicolon was intentional\n  while (s && !c[--s]);\n  var cl = new u16(++s);\n  //  ind      num         streak\n  var cli = 0,\n    cln = c[0],\n    cls = 1;\n  var w = function (v) {\n    cl[cli++] = v;\n  };\n  for (var i = 1; i <= s; ++i) {\n    if (c[i] == cln && i != s) ++cls;else {\n      if (!cln && cls > 2) {\n        for (; cls > 138; cls -= 138) w(32754);\n        if (cls > 2) {\n          w(cls > 10 ? cls - 11 << 5 | 28690 : cls - 3 << 5 | 12305);\n          cls = 0;\n        }\n      } else if (cls > 3) {\n        w(cln), --cls;\n        for (; cls > 6; cls -= 6) w(8304);\n        if (cls > 2) w(cls - 3 << 5 | 8208), cls = 0;\n      }\n      while (cls--) w(cln);\n      cls = 1;\n      cln = c[i];\n    }\n  }\n  return {\n    c: cl.subarray(0, cli),\n    n: s\n  };\n};\n// calculate the length of output from tree, code lengths\nvar clen = function (cf, cl) {\n  var l = 0;\n  for (var i = 0; i < cl.length; ++i) l += cf[i] * cl[i];\n  return l;\n};\n// writes a fixed block\n// returns the new bit pos\nvar wfblk = function (out, pos, dat) {\n  // no need to write 00 as type: TypedArray defaults to 0\n  var s = dat.length;\n  var o = shft(pos + 2);\n  out[o] = s & 255;\n  out[o + 1] = s >> 8;\n  out[o + 2] = out[o] ^ 255;\n  out[o + 3] = out[o + 1] ^ 255;\n  for (var i = 0; i < s; ++i) out[o + i + 4] = dat[i];\n  return (o + 4 + s) * 8;\n};\n// writes a block\nvar wblk = function (dat, out, final, syms, lf, df, eb, li, bs, bl, p) {\n  wbits(out, p++, final);\n  ++lf[256];\n  var _a = hTree(lf, 15),\n    dlt = _a.t,\n    mlb = _a.l;\n  var _b = hTree(df, 15),\n    ddt = _b.t,\n    mdb = _b.l;\n  var _c = lc(dlt),\n    lclt = _c.c,\n    nlc = _c.n;\n  var _d = lc(ddt),\n    lcdt = _d.c,\n    ndc = _d.n;\n  var lcfreq = new u16(19);\n  for (var i = 0; i < lclt.length; ++i) ++lcfreq[lclt[i] & 31];\n  for (var i = 0; i < lcdt.length; ++i) ++lcfreq[lcdt[i] & 31];\n  var _e = hTree(lcfreq, 7),\n    lct = _e.t,\n    mlcb = _e.l;\n  var nlcc = 19;\n  for (; nlcc > 4 && !lct[clim[nlcc - 1]]; --nlcc);\n  var flen = bl + 5 << 3;\n  var ftlen = clen(lf, flt) + clen(df, fdt) + eb;\n  var dtlen = clen(lf, dlt) + clen(df, ddt) + eb + 14 + 3 * nlcc + clen(lcfreq, lct) + 2 * lcfreq[16] + 3 * lcfreq[17] + 7 * lcfreq[18];\n  if (bs >= 0 && flen <= ftlen && flen <= dtlen) return wfblk(out, p, dat.subarray(bs, bs + bl));\n  var lm, ll, dm, dl;\n  wbits(out, p, 1 + (dtlen < ftlen)), p += 2;\n  if (dtlen < ftlen) {\n    lm = hMap(dlt, mlb, 0), ll = dlt, dm = hMap(ddt, mdb, 0), dl = ddt;\n    var llm = hMap(lct, mlcb, 0);\n    wbits(out, p, nlc - 257);\n    wbits(out, p + 5, ndc - 1);\n    wbits(out, p + 10, nlcc - 4);\n    p += 14;\n    for (var i = 0; i < nlcc; ++i) wbits(out, p + 3 * i, lct[clim[i]]);\n    p += 3 * nlcc;\n    var lcts = [lclt, lcdt];\n    for (var it = 0; it < 2; ++it) {\n      var clct = lcts[it];\n      for (var i = 0; i < clct.length; ++i) {\n        var len = clct[i] & 31;\n        wbits(out, p, llm[len]), p += lct[len];\n        if (len > 15) wbits(out, p, clct[i] >> 5 & 127), p += clct[i] >> 12;\n      }\n    }\n  } else {\n    lm = flm, ll = flt, dm = fdm, dl = fdt;\n  }\n  for (var i = 0; i < li; ++i) {\n    var sym = syms[i];\n    if (sym > 255) {\n      var len = sym >> 18 & 31;\n      wbits16(out, p, lm[len + 257]), p += ll[len + 257];\n      if (len > 7) wbits(out, p, sym >> 23 & 31), p += fleb[len];\n      var dst = sym & 31;\n      wbits16(out, p, dm[dst]), p += dl[dst];\n      if (dst > 3) wbits16(out, p, sym >> 5 & 8191), p += fdeb[dst];\n    } else {\n      wbits16(out, p, lm[sym]), p += ll[sym];\n    }\n  }\n  wbits16(out, p, lm[256]);\n  return p + ll[256];\n};\n// deflate options (nice << 13) | chain\nvar deo = /*#__PURE__*/new i32([65540, 131080, 131088, 131104, 262176, 1048704, 1048832, 2114560, 2117632]);\n// empty\nvar et = /*#__PURE__*/new u8(0);\n// compresses data into a raw DEFLATE buffer\nvar dflt = function (dat, lvl, plvl, pre, post, st) {\n  var s = st.z || dat.length;\n  var o = new u8(pre + s + 5 * (1 + Math.ceil(s / 7000)) + post);\n  // writing to this writes to the output buffer\n  var w = o.subarray(pre, o.length - post);\n  var lst = st.l;\n  var pos = (st.r || 0) & 7;\n  if (lvl) {\n    if (pos) w[0] = st.r >> 3;\n    var opt = deo[lvl - 1];\n    var n = opt >> 13,\n      c = opt & 8191;\n    var msk_1 = (1 << plvl) - 1;\n    //    prev 2-byte val map    curr 2-byte val map\n    var prev = st.p || new u16(32768),\n      head = st.h || new u16(msk_1 + 1);\n    var bs1_1 = Math.ceil(plvl / 3),\n      bs2_1 = 2 * bs1_1;\n    var hsh = function (i) {\n      return (dat[i] ^ dat[i + 1] << bs1_1 ^ dat[i + 2] << bs2_1) & msk_1;\n    };\n    // 24576 is an arbitrary number of maximum symbols per block\n    // 424 buffer for last block\n    var syms = new i32(25000);\n    // length/literal freq   distance freq\n    var lf = new u16(288),\n      df = new u16(32);\n    //  l/lcnt  exbits  index          l/lind  waitdx          blkpos\n    var lc_1 = 0,\n      eb = 0,\n      i = st.i || 0,\n      li = 0,\n      wi = st.w || 0,\n      bs = 0;\n    for (; i + 2 < s; ++i) {\n      // hash value\n      var hv = hsh(i);\n      // index mod 32768    previous index mod\n      var imod = i & 32767,\n        pimod = head[hv];\n      prev[imod] = pimod;\n      head[hv] = imod;\n      // We always should modify head and prev, but only add symbols if\n      // this data is not yet processed (\"wait\" for wait index)\n      if (wi <= i) {\n        // bytes remaining\n        var rem = s - i;\n        if ((lc_1 > 7000 || li > 24576) && (rem > 423 || !lst)) {\n          pos = wblk(dat, w, 0, syms, lf, df, eb, li, bs, i - bs, pos);\n          li = lc_1 = eb = 0, bs = i;\n          for (var j = 0; j < 286; ++j) lf[j] = 0;\n          for (var j = 0; j < 30; ++j) df[j] = 0;\n        }\n        //  len    dist   chain\n        var l = 2,\n          d = 0,\n          ch_1 = c,\n          dif = imod - pimod & 32767;\n        if (rem > 2 && hv == hsh(i - dif)) {\n          var maxn = Math.min(n, rem) - 1;\n          var maxd = Math.min(32767, i);\n          // max possible length\n          // not capped at dif because decompressors implement \"rolling\" index population\n          var ml = Math.min(258, rem);\n          while (dif <= maxd && --ch_1 && imod != pimod) {\n            if (dat[i + l] == dat[i + l - dif]) {\n              var nl = 0;\n              for (; nl < ml && dat[i + nl] == dat[i + nl - dif]; ++nl);\n              if (nl > l) {\n                l = nl, d = dif;\n                // break out early when we reach \"nice\" (we are satisfied enough)\n                if (nl > maxn) break;\n                // now, find the rarest 2-byte sequence within this\n                // length of literals and search for that instead.\n                // Much faster than just using the start\n                var mmd = Math.min(dif, nl - 2);\n                var md = 0;\n                for (var j = 0; j < mmd; ++j) {\n                  var ti = i - dif + j & 32767;\n                  var pti = prev[ti];\n                  var cd = ti - pti & 32767;\n                  if (cd > md) md = cd, pimod = ti;\n                }\n              }\n            }\n            // check the previous match\n            imod = pimod, pimod = prev[imod];\n            dif += imod - pimod & 32767;\n          }\n        }\n        // d will be nonzero only when a match was found\n        if (d) {\n          // store both dist and len data in one int32\n          // Make sure this is recognized as a len/dist with 28th bit (2^28)\n          syms[li++] = 268435456 | revfl[l] << 18 | revfd[d];\n          var lin = revfl[l] & 31,\n            din = revfd[d] & 31;\n          eb += fleb[lin] + fdeb[din];\n          ++lf[257 + lin];\n          ++df[din];\n          wi = i + l;\n          ++lc_1;\n        } else {\n          syms[li++] = dat[i];\n          ++lf[dat[i]];\n        }\n      }\n    }\n    for (i = Math.max(i, wi); i < s; ++i) {\n      syms[li++] = dat[i];\n      ++lf[dat[i]];\n    }\n    pos = wblk(dat, w, lst, syms, lf, df, eb, li, bs, i - bs, pos);\n    if (!lst) {\n      st.r = pos & 7 | w[pos / 8 | 0] << 3;\n      // shft(pos) now 1 less if pos & 7 != 0\n      pos -= 7;\n      st.h = head, st.p = prev, st.i = i, st.w = wi;\n    }\n  } else {\n    for (var i = st.w || 0; i < s + lst; i += 65535) {\n      // end\n      var e = i + 65535;\n      if (e >= s) {\n        // write final block\n        w[pos / 8 | 0] = lst;\n        e = s;\n      }\n      pos = wfblk(w, pos + 1, dat.subarray(i, e));\n    }\n    st.i = s;\n  }\n  return slc(o, 0, pre + shft(pos) + post);\n};\n// CRC32 table\nvar crct = /*#__PURE__*/function () {\n  var t = new Int32Array(256);\n  for (var i = 0; i < 256; ++i) {\n    var c = i,\n      k = 9;\n    while (--k) c = (c & 1 && -306674912) ^ c >>> 1;\n    t[i] = c;\n  }\n  return t;\n}();\n// CRC32\nvar crc = function () {\n  var c = -1;\n  return {\n    p: function (d) {\n      // closures have awful performance\n      var cr = c;\n      for (var i = 0; i < d.length; ++i) cr = crct[cr & 255 ^ d[i]] ^ cr >>> 8;\n      c = cr;\n    },\n    d: function () {\n      return ~c;\n    }\n  };\n};\n// deflate with opts\nvar dopt = function (dat, opt, pre, post, st) {\n  if (!st) {\n    st = {\n      l: 1\n    };\n    if (opt.dictionary) {\n      var dict = opt.dictionary.subarray(-32768);\n      var newDat = new u8(dict.length + dat.length);\n      newDat.set(dict);\n      newDat.set(dat, dict.length);\n      dat = newDat;\n      st.w = dict.length;\n    }\n  }\n  return dflt(dat, opt.level == null ? 6 : opt.level, opt.mem == null ? st.l ? Math.ceil(Math.max(8, Math.min(13, Math.log(dat.length))) * 1.5) : 20 : 12 + opt.mem, pre, post, st);\n};\n// Walmart object spread\nvar mrg = function (a, b) {\n  var o = {};\n  for (var k in a) o[k] = a[k];\n  for (var k in b) o[k] = b[k];\n  return o;\n};\n// write bytes\nvar wbytes = function (d, b, v) {\n  for (; v; ++b) d[b] = v, v >>>= 8;\n};\n/**\n * Compresses data with DEFLATE without any wrapper\n * @param data The data to compress\n * @param opts The compression options\n * @returns The deflated version of the data\n */\nfunction deflateSync(data, opts) {\n  return dopt(data, opts || {}, 0, 0);\n}\n// flatten a directory structure\nvar fltn = function (d, p, t, o) {\n  for (var k in d) {\n    var val = d[k],\n      n = p + k,\n      op = o;\n    if (Array.isArray(val)) op = mrg(o, val[1]), val = val[0];\n    if (val instanceof u8) t[n] = [val, op];else {\n      t[n += '/'] = [new u8(0), op];\n      fltn(val, n, t, o);\n    }\n  }\n};\n// text encoder\nvar te = typeof TextEncoder != 'undefined' && /*#__PURE__*/new TextEncoder();\n// text decoder\nvar td = typeof TextDecoder != 'undefined' && /*#__PURE__*/new TextDecoder();\n// text decoder stream\nvar tds = 0;\ntry {\n  td.decode(et, {\n    stream: true\n  });\n  tds = 1;\n} catch (e) {}\n/**\n * Converts a string into a Uint8Array for use with compression/decompression methods\n * @param str The string to encode\n * @param latin1 Whether or not to interpret the data as Latin-1. This should\n *               not need to be true unless decoding a binary string.\n * @returns The string encoded in UTF-8/Latin-1 binary\n */\nfunction strToU8(str, latin1) {\n  if (latin1) {\n    var ar_1 = new u8(str.length);\n    for (var i = 0; i < str.length; ++i) ar_1[i] = str.charCodeAt(i);\n    return ar_1;\n  }\n  if (te) return te.encode(str);\n  var l = str.length;\n  var ar = new u8(str.length + (str.length >> 1));\n  var ai = 0;\n  var w = function (v) {\n    ar[ai++] = v;\n  };\n  for (var i = 0; i < l; ++i) {\n    if (ai + 5 > ar.length) {\n      var n = new u8(ai + 8 + (l - i << 1));\n      n.set(ar);\n      ar = n;\n    }\n    var c = str.charCodeAt(i);\n    if (c < 128 || latin1) w(c);else if (c < 2048) w(192 | c >> 6), w(128 | c & 63);else if (c > 55295 && c < 57344) c = 65536 + (c & 1023 << 10) | str.charCodeAt(++i) & 1023, w(240 | c >> 18), w(128 | c >> 12 & 63), w(128 | c >> 6 & 63), w(128 | c & 63);else w(224 | c >> 12), w(128 | c >> 6 & 63), w(128 | c & 63);\n  }\n  return slc(ar, 0, ai);\n}\n// extra field length\nvar exfl = function (ex) {\n  var le = 0;\n  if (ex) {\n    for (var k in ex) {\n      var l = ex[k].length;\n      if (l > 65535) err(9);\n      le += l + 4;\n    }\n  }\n  return le;\n};\n// write zip header\nvar wzh = function (d, b, f, fn, u, c, ce, co) {\n  var fl = fn.length,\n    ex = f.extra,\n    col = co && co.length;\n  var exl = exfl(ex);\n  wbytes(d, b, ce != null ? 0x2014B50 : 0x4034B50), b += 4;\n  if (ce != null) d[b++] = 20, d[b++] = f.os;\n  d[b] = 20, b += 2; // spec compliance? what's that?\n  d[b++] = f.flag << 1 | (c < 0 && 8), d[b++] = u && 8;\n  d[b++] = f.compression & 255, d[b++] = f.compression >> 8;\n  var dt = new Date(f.mtime == null ? Date.now() : f.mtime),\n    y = dt.getFullYear() - 1980;\n  if (y < 0 || y > 119) err(10);\n  wbytes(d, b, y << 25 | dt.getMonth() + 1 << 21 | dt.getDate() << 16 | dt.getHours() << 11 | dt.getMinutes() << 5 | dt.getSeconds() >> 1), b += 4;\n  if (c != -1) {\n    wbytes(d, b, f.crc);\n    wbytes(d, b + 4, c < 0 ? -c - 2 : c);\n    wbytes(d, b + 8, f.size);\n  }\n  wbytes(d, b + 12, fl);\n  wbytes(d, b + 14, exl), b += 16;\n  if (ce != null) {\n    wbytes(d, b, col);\n    wbytes(d, b + 6, f.attrs);\n    wbytes(d, b + 10, ce), b += 14;\n  }\n  d.set(fn, b);\n  b += fl;\n  if (exl) {\n    for (var k in ex) {\n      var exf = ex[k],\n        l = exf.length;\n      wbytes(d, b, +k);\n      wbytes(d, b + 2, l);\n      d.set(exf, b + 4), b += 4 + l;\n    }\n  }\n  if (col) d.set(co, b), b += col;\n  return b;\n};\n// write zip footer (end of central directory)\nvar wzf = function (o, b, c, d, e) {\n  wbytes(o, b, 0x6054B50); // skip disk\n  wbytes(o, b + 8, c);\n  wbytes(o, b + 10, c);\n  wbytes(o, b + 12, d);\n  wbytes(o, b + 16, e);\n};\n/**\n * Synchronously creates a ZIP file. Prefer using `zip` for better performance\n * with more than one file.\n * @param data The directory structure for the ZIP archive\n * @param opts The main options, merged with per-file options\n * @returns The generated ZIP archive\n */\nfunction zipSync(data, opts) {\n  if (!opts) opts = {};\n  var r = {};\n  var files = [];\n  fltn(data, '', r, opts);\n  var o = 0;\n  var tot = 0;\n  for (var fn in r) {\n    var _a = r[fn],\n      file = _a[0],\n      p = _a[1];\n    var compression = p.level == 0 ? 0 : 8;\n    var f = strToU8(fn),\n      s = f.length;\n    var com = p.comment,\n      m = com && strToU8(com),\n      ms = m && m.length;\n    var exl = exfl(p.extra);\n    if (s > 65535) err(11);\n    var d = compression ? deflateSync(file, p) : file,\n      l = d.length;\n    var c = crc();\n    c.p(file);\n    files.push(mrg(p, {\n      size: file.length,\n      crc: c.d(),\n      c: d,\n      f: f,\n      m: m,\n      u: s != fn.length || m && com.length != ms,\n      o: o,\n      compression: compression\n    }));\n    o += 30 + s + exl + l;\n    tot += 76 + 2 * (s + exl) + (ms || 0) + l;\n  }\n  var out = new u8(tot + 22),\n    oe = o,\n    cdl = tot - o;\n  for (var i = 0; i < files.length; ++i) {\n    var f = files[i];\n    wzh(out, f.o, f, f.f, f.u, f.c.length);\n    var badd = 30 + f.f.length + exfl(f.extra);\n    out.set(f.c, f.o + badd);\n    wzh(out, o, f, f.f, f.u, f.c.length, f.o, f.m), o += 16 + badd + (f.m ? f.m.length : 0);\n  }\n  wzf(out, o, files.length, cdl, oe);\n  return out;\n}\nclass USDZExporter {\n  parse(scene, onDone, onError, options) {\n    this.parseAsync(scene, options).then(onDone).catch(onError);\n  }\n  async parseAsync(scene, options = {}) {\n    options = Object.assign({\n      ar: {\n        anchoring: {\n          type: 'plane'\n        },\n        planeAnchoring: {\n          alignment: 'horizontal'\n        }\n      },\n      includeAnchoringProperties: true,\n      quickLookCompatible: false,\n      maxTextureSize: 1024\n    }, options);\n    const files = {};\n    const modelFileName = 'model.usda';\n\n    // model file should be first in USDZ archive so we init it here\n    files[modelFileName] = null;\n    let output = buildHeader();\n    output += buildSceneStart(options);\n    const materials = {};\n    const textures = {};\n    scene.traverseVisible(object => {\n      if (object.isMesh) {\n        const geometry = object.geometry;\n        const material = object.material;\n        if (material.isMeshStandardMaterial) {\n          const geometryFileName = 'geometries/Geometry_' + geometry.id + '.usda';\n          if (!(geometryFileName in files)) {\n            const meshObject = buildMeshObject(geometry);\n            files[geometryFileName] = buildUSDFileAsString(meshObject);\n          }\n          if (!(material.uuid in materials)) {\n            materials[material.uuid] = material;\n          }\n          output += buildXform(object, geometry, material);\n        } else {\n          console.warn('THREE.USDZExporter: Unsupported material type (USDZ only supports MeshStandardMaterial)', object);\n        }\n      } else if (object.isCamera) {\n        output += buildCamera(object);\n      }\n    });\n    output += buildSceneEnd();\n    output += buildMaterials(materials, textures, options.quickLookCompatible);\n    files[modelFileName] = strToU8(output);\n    output = null;\n    for (const id in textures) {\n      let texture = textures[id];\n      if (texture.isCompressedTexture === true) {\n        texture = decompress(texture);\n      }\n      const canvas = imageToCanvas(texture.image, texture.flipY, options.maxTextureSize);\n      const blob = await new Promise(resolve => canvas.toBlob(resolve, 'image/png', 1));\n      files[`textures/Texture_${id}.png`] = new Uint8Array(await blob.arrayBuffer());\n    }\n\n    // 64 byte alignment\n    // https://github.com/101arrowz/fflate/issues/39#issuecomment-777263109\n\n    let offset = 0;\n    for (const filename in files) {\n      const file = files[filename];\n      const headerSize = 34 + filename.length;\n      offset += headerSize;\n      const offsetMod64 = offset & 63;\n      if (offsetMod64 !== 4) {\n        const padLength = 64 - offsetMod64;\n        const padding = new Uint8Array(padLength);\n        files[filename] = [file, {\n          extra: {\n            12345: padding\n          }\n        }];\n      }\n      offset = file.length;\n    }\n    return zipSync(files, {\n      level: 0\n    });\n  }\n}\nfunction imageToCanvas(image, flipY, maxTextureSize) {\n  if (typeof HTMLImageElement !== 'undefined' && image instanceof HTMLImageElement || typeof HTMLCanvasElement !== 'undefined' && image instanceof HTMLCanvasElement || typeof OffscreenCanvas !== 'undefined' && image instanceof OffscreenCanvas || typeof ImageBitmap !== 'undefined' && image instanceof ImageBitmap) {\n    const scale = maxTextureSize / Math.max(image.width, image.height);\n    const canvas = document.createElement('canvas');\n    canvas.width = image.width * Math.min(1, scale);\n    canvas.height = image.height * Math.min(1, scale);\n    const context = canvas.getContext('2d');\n\n    // TODO: We should be able to do this in the UsdTransform2d?\n\n    if (flipY === true) {\n      context.translate(0, canvas.height);\n      context.scale(1, -1);\n    }\n    context.drawImage(image, 0, 0, canvas.width, canvas.height);\n    return canvas;\n  } else {\n    throw new Error('THREE.USDZExporter: No valid image data found. Unable to process texture.');\n  }\n}\n\n//\n\nconst PRECISION = 7;\nfunction buildHeader() {\n  return `#usda 1.0\n(\n\tcustomLayerData = {\n\t\tstring creator = \"Three.js USDZExporter\"\n\t}\n\tdefaultPrim = \"Root\"\n\tmetersPerUnit = 1\n\tupAxis = \"Y\"\n)\n\n`;\n}\nfunction buildSceneStart(options) {\n  const alignment = options.includeAnchoringProperties === true ? `\n\t\ttoken preliminary:anchoring:type = \"${options.ar.anchoring.type}\"\n\t\ttoken preliminary:planeAnchoring:alignment = \"${options.ar.planeAnchoring.alignment}\"\n\t` : '';\n  return `def Xform \"Root\"\n{\n\tdef Scope \"Scenes\" (\n\t\tkind = \"sceneLibrary\"\n\t)\n\t{\n\t\tdef Xform \"Scene\" (\n\t\t\tcustomData = {\n\t\t\t\tbool preliminary_collidesWithEnvironment = 0\n\t\t\t\tstring sceneName = \"Scene\"\n\t\t\t}\n\t\t\tsceneName = \"Scene\"\n\t\t)\n\t\t{${alignment}\n`;\n}\nfunction buildSceneEnd() {\n  return `\n\t\t}\n\t}\n}\n\n`;\n}\nfunction buildUSDFileAsString(dataToInsert) {\n  let output = buildHeader();\n  output += dataToInsert;\n  return strToU8(output);\n}\n\n// Xform\n\nfunction buildXform(object, geometry, material) {\n  const name = 'Object_' + object.id;\n  const transform = buildMatrix(object.matrixWorld);\n  if (object.matrixWorld.determinant() < 0) {\n    console.warn('THREE.USDZExporter: USDZ does not support negative scales', object);\n  }\n  return `def Xform \"${name}\" (\n\tprepend references = @./geometries/Geometry_${geometry.id}.usda@</Geometry>\n\tprepend apiSchemas = [\"MaterialBindingAPI\"]\n)\n{\n\tmatrix4d xformOp:transform = ${transform}\n\tuniform token[] xformOpOrder = [\"xformOp:transform\"]\n\n\trel material:binding = </Materials/Material_${material.id}>\n}\n\n`;\n}\nfunction buildMatrix(matrix) {\n  const array = matrix.elements;\n  return `( ${buildMatrixRow(array, 0)}, ${buildMatrixRow(array, 4)}, ${buildMatrixRow(array, 8)}, ${buildMatrixRow(array, 12)} )`;\n}\nfunction buildMatrixRow(array, offset) {\n  return `(${array[offset + 0]}, ${array[offset + 1]}, ${array[offset + 2]}, ${array[offset + 3]})`;\n}\n\n// Mesh\n\nfunction buildMeshObject(geometry) {\n  const mesh = buildMesh(geometry);\n  return `\ndef \"Geometry\"\n{\n${mesh}\n}\n`;\n}\nfunction buildMesh(geometry) {\n  const name = 'Geometry';\n  const attributes = geometry.attributes;\n  const count = attributes.position.count;\n  return `\n\tdef Mesh \"${name}\"\n\t{\n\t\tint[] faceVertexCounts = [${buildMeshVertexCount(geometry)}]\n\t\tint[] faceVertexIndices = [${buildMeshVertexIndices(geometry)}]\n\t\tnormal3f[] normals = [${buildVector3Array(attributes.normal, count)}] (\n\t\t\tinterpolation = \"vertex\"\n\t\t)\n\t\tpoint3f[] points = [${buildVector3Array(attributes.position, count)}]\n${buildPrimvars(attributes)}\n\t\tuniform token subdivisionScheme = \"none\"\n\t}\n`;\n}\nfunction buildMeshVertexCount(geometry) {\n  const count = geometry.index !== null ? geometry.index.count : geometry.attributes.position.count;\n  return Array(count / 3).fill(3).join(', ');\n}\nfunction buildMeshVertexIndices(geometry) {\n  const index = geometry.index;\n  const array = [];\n  if (index !== null) {\n    for (let i = 0; i < index.count; i++) {\n      array.push(index.getX(i));\n    }\n  } else {\n    const length = geometry.attributes.position.count;\n    for (let i = 0; i < length; i++) {\n      array.push(i);\n    }\n  }\n  return array.join(', ');\n}\nfunction buildVector3Array(attribute, count) {\n  if (attribute === undefined) {\n    console.warn('USDZExporter: Normals missing.');\n    return Array(count).fill('(0, 0, 0)').join(', ');\n  }\n  const array = [];\n  for (let i = 0; i < attribute.count; i++) {\n    const x = attribute.getX(i);\n    const y = attribute.getY(i);\n    const z = attribute.getZ(i);\n    array.push(`(${x.toPrecision(PRECISION)}, ${y.toPrecision(PRECISION)}, ${z.toPrecision(PRECISION)})`);\n  }\n  return array.join(', ');\n}\nfunction buildVector2Array(attribute) {\n  const array = [];\n  for (let i = 0; i < attribute.count; i++) {\n    const x = attribute.getX(i);\n    const y = attribute.getY(i);\n    array.push(`(${x.toPrecision(PRECISION)}, ${1 - y.toPrecision(PRECISION)})`);\n  }\n  return array.join(', ');\n}\nfunction buildPrimvars(attributes) {\n  let string = '';\n  for (let i = 0; i < 4; i++) {\n    const id = i > 0 ? i : '';\n    const attribute = attributes['uv' + id];\n    if (attribute !== undefined) {\n      string += `\n\t\ttexCoord2f[] primvars:st${id} = [${buildVector2Array(attribute)}] (\n\t\t\tinterpolation = \"vertex\"\n\t\t)`;\n    }\n  }\n\n  // vertex colors\n\n  const colorAttribute = attributes.color;\n  if (colorAttribute !== undefined) {\n    const count = colorAttribute.count;\n    string += `\n\tcolor3f[] primvars:displayColor = [${buildVector3Array(colorAttribute, count)}] (\n\t\tinterpolation = \"vertex\"\n\t\t)`;\n  }\n  return string;\n}\n\n// Materials\n\nfunction buildMaterials(materials, textures, quickLookCompatible = false) {\n  const array = [];\n  for (const uuid in materials) {\n    const material = materials[uuid];\n    array.push(buildMaterial(material, textures, quickLookCompatible));\n  }\n  return `def \"Materials\"\n{\n${array.join('')}\n}\n\n`;\n}\nfunction buildMaterial(material, textures, quickLookCompatible = false) {\n  // https://graphics.pixar.com/usd/docs/UsdPreviewSurface-Proposal.html\n\n  const pad = '\t\t\t';\n  const inputs = [];\n  const samplers = [];\n  function buildTexture(texture, mapType, color) {\n    const id = texture.source.id + '_' + texture.flipY;\n    textures[id] = texture;\n    const uv = texture.channel > 0 ? 'st' + texture.channel : 'st';\n    const WRAPPINGS = {\n      1000: 'repeat',\n      // RepeatWrapping\n      1001: 'clamp',\n      // ClampToEdgeWrapping\n      1002: 'mirror' // MirroredRepeatWrapping\n    };\n    const repeat = texture.repeat.clone();\n    const offset = texture.offset.clone();\n    const rotation = texture.rotation;\n\n    // rotation is around the wrong point. after rotation we need to shift offset again so that we're rotating around the right spot\n    const xRotationOffset = Math.sin(rotation);\n    const yRotationOffset = Math.cos(rotation);\n\n    // texture coordinates start in the opposite corner, need to correct\n    offset.y = 1 - offset.y - repeat.y;\n\n    // turns out QuickLook is buggy and interprets texture repeat inverted/applies operations in a different order.\n    // Apple Feedback: \tFB10036297 and FB11442287\n    if (quickLookCompatible) {\n      // This is NOT correct yet in QuickLook, but comes close for a range of models.\n      // It becomes more incorrect the bigger the offset is\n\n      offset.x = offset.x / repeat.x;\n      offset.y = offset.y / repeat.y;\n      offset.x += xRotationOffset / repeat.x;\n      offset.y += yRotationOffset - 1;\n    } else {\n      // results match glTF results exactly. verified correct in usdview.\n      offset.x += xRotationOffset * repeat.x;\n      offset.y += (1 - yRotationOffset) * repeat.y;\n    }\n    return `\n\t\tdef Shader \"PrimvarReader_${mapType}\"\n\t\t{\n\t\t\tuniform token info:id = \"UsdPrimvarReader_float2\"\n\t\t\tfloat2 inputs:fallback = (0.0, 0.0)\n\t\t\ttoken inputs:varname = \"${uv}\"\n\t\t\tfloat2 outputs:result\n\t\t}\n\n\t\tdef Shader \"Transform2d_${mapType}\"\n\t\t{\n\t\t\tuniform token info:id = \"UsdTransform2d\"\n\t\t\ttoken inputs:in.connect = </Materials/Material_${material.id}/PrimvarReader_${mapType}.outputs:result>\n\t\t\tfloat inputs:rotation = ${(rotation * (180 / Math.PI)).toFixed(PRECISION)}\n\t\t\tfloat2 inputs:scale = ${buildVector2(repeat)}\n\t\t\tfloat2 inputs:translation = ${buildVector2(offset)}\n\t\t\tfloat2 outputs:result\n\t\t}\n\n\t\tdef Shader \"Texture_${texture.id}_${mapType}\"\n\t\t{\n\t\t\tuniform token info:id = \"UsdUVTexture\"\n\t\t\tasset inputs:file = @textures/Texture_${id}.png@\n\t\t\tfloat2 inputs:st.connect = </Materials/Material_${material.id}/Transform2d_${mapType}.outputs:result>\n\t\t\t${color !== undefined ? 'float4 inputs:scale = ' + buildColor4(color) : ''}\n\t\t\ttoken inputs:sourceColorSpace = \"${texture.colorSpace === NoColorSpace ? 'raw' : 'sRGB'}\"\n\t\t\ttoken inputs:wrapS = \"${WRAPPINGS[texture.wrapS]}\"\n\t\t\ttoken inputs:wrapT = \"${WRAPPINGS[texture.wrapT]}\"\n\t\t\tfloat outputs:r\n\t\t\tfloat outputs:g\n\t\t\tfloat outputs:b\n\t\t\tfloat3 outputs:rgb\n\t\t\t${material.transparent || material.alphaTest > 0.0 ? 'float outputs:a' : ''}\n\t\t}`;\n  }\n  if (material.side === DoubleSide) {\n    console.warn('THREE.USDZExporter: USDZ does not support double sided materials', material);\n  }\n  if (material.map !== null) {\n    inputs.push(`${pad}color3f inputs:diffuseColor.connect = </Materials/Material_${material.id}/Texture_${material.map.id}_diffuse.outputs:rgb>`);\n    if (material.transparent) {\n      inputs.push(`${pad}float inputs:opacity.connect = </Materials/Material_${material.id}/Texture_${material.map.id}_diffuse.outputs:a>`);\n    } else if (material.alphaTest > 0.0) {\n      inputs.push(`${pad}float inputs:opacity.connect = </Materials/Material_${material.id}/Texture_${material.map.id}_diffuse.outputs:a>`);\n      inputs.push(`${pad}float inputs:opacityThreshold = ${material.alphaTest}`);\n    }\n    samplers.push(buildTexture(material.map, 'diffuse', material.color));\n  } else {\n    inputs.push(`${pad}color3f inputs:diffuseColor = ${buildColor(material.color)}`);\n  }\n  if (material.emissiveMap !== null) {\n    inputs.push(`${pad}color3f inputs:emissiveColor.connect = </Materials/Material_${material.id}/Texture_${material.emissiveMap.id}_emissive.outputs:rgb>`);\n    samplers.push(buildTexture(material.emissiveMap, 'emissive', new Color(material.emissive.r * material.emissiveIntensity, material.emissive.g * material.emissiveIntensity, material.emissive.b * material.emissiveIntensity)));\n  } else if (material.emissive.getHex() > 0) {\n    inputs.push(`${pad}color3f inputs:emissiveColor = ${buildColor(material.emissive)}`);\n  }\n  if (material.normalMap !== null) {\n    inputs.push(`${pad}normal3f inputs:normal.connect = </Materials/Material_${material.id}/Texture_${material.normalMap.id}_normal.outputs:rgb>`);\n    samplers.push(buildTexture(material.normalMap, 'normal'));\n  }\n  if (material.aoMap !== null) {\n    inputs.push(`${pad}float inputs:occlusion.connect = </Materials/Material_${material.id}/Texture_${material.aoMap.id}_occlusion.outputs:r>`);\n    samplers.push(buildTexture(material.aoMap, 'occlusion', new Color(material.aoMapIntensity, material.aoMapIntensity, material.aoMapIntensity)));\n  }\n  if (material.roughnessMap !== null) {\n    inputs.push(`${pad}float inputs:roughness.connect = </Materials/Material_${material.id}/Texture_${material.roughnessMap.id}_roughness.outputs:g>`);\n    samplers.push(buildTexture(material.roughnessMap, 'roughness', new Color(material.roughness, material.roughness, material.roughness)));\n  } else {\n    inputs.push(`${pad}float inputs:roughness = ${material.roughness}`);\n  }\n  if (material.metalnessMap !== null) {\n    inputs.push(`${pad}float inputs:metallic.connect = </Materials/Material_${material.id}/Texture_${material.metalnessMap.id}_metallic.outputs:b>`);\n    samplers.push(buildTexture(material.metalnessMap, 'metallic', new Color(material.metalness, material.metalness, material.metalness)));\n  } else {\n    inputs.push(`${pad}float inputs:metallic = ${material.metalness}`);\n  }\n  if (material.alphaMap !== null) {\n    inputs.push(`${pad}float inputs:opacity.connect = </Materials/Material_${material.id}/Texture_${material.alphaMap.id}_opacity.outputs:r>`);\n    inputs.push(`${pad}float inputs:opacityThreshold = 0.0001`);\n    samplers.push(buildTexture(material.alphaMap, 'opacity'));\n  } else {\n    inputs.push(`${pad}float inputs:opacity = ${material.opacity}`);\n  }\n  if (material.isMeshPhysicalMaterial) {\n    if (material.clearcoatMap !== null) {\n      inputs.push(`${pad}float inputs:clearcoat.connect = </Materials/Material_${material.id}/Texture_${material.clearcoatMap.id}_clearcoat.outputs:r>`);\n      samplers.push(buildTexture(material.clearcoatMap, 'clearcoat', new Color(material.clearcoat, material.clearcoat, material.clearcoat)));\n    } else {\n      inputs.push(`${pad}float inputs:clearcoat = ${material.clearcoat}`);\n    }\n    if (material.clearcoatRoughnessMap !== null) {\n      inputs.push(`${pad}float inputs:clearcoatRoughness.connect = </Materials/Material_${material.id}/Texture_${material.clearcoatRoughnessMap.id}_clearcoatRoughness.outputs:g>`);\n      samplers.push(buildTexture(material.clearcoatRoughnessMap, 'clearcoatRoughness', new Color(material.clearcoatRoughness, material.clearcoatRoughness, material.clearcoatRoughness)));\n    } else {\n      inputs.push(`${pad}float inputs:clearcoatRoughness = ${material.clearcoatRoughness}`);\n    }\n    inputs.push(`${pad}float inputs:ior = ${material.ior}`);\n  }\n  return `\n\tdef Material \"Material_${material.id}\"\n\t{\n\t\tdef Shader \"PreviewSurface\"\n\t\t{\n\t\t\tuniform token info:id = \"UsdPreviewSurface\"\n${inputs.join('\\n')}\n\t\t\tint inputs:useSpecularWorkflow = 0\n\t\t\ttoken outputs:surface\n\t\t}\n\n\t\ttoken outputs:surface.connect = </Materials/Material_${material.id}/PreviewSurface.outputs:surface>\n\n${samplers.join('\\n')}\n\n\t}\n`;\n}\nfunction buildColor(color) {\n  return `(${color.r}, ${color.g}, ${color.b})`;\n}\nfunction buildColor4(color) {\n  return `(${color.r}, ${color.g}, ${color.b}, 1.0)`;\n}\nfunction buildVector2(vector) {\n  return `(${vector.x}, ${vector.y})`;\n}\nfunction buildCamera(camera) {\n  const name = camera.name ? camera.name : 'Camera_' + camera.id;\n  const transform = buildMatrix(camera.matrixWorld);\n  if (camera.matrixWorld.determinant() < 0) {\n    console.warn('THREE.USDZExporter: USDZ does not support negative scales', camera);\n  }\n  if (camera.isOrthographicCamera) {\n    return `def Camera \"${name}\"\n\t\t{\n\t\t\tmatrix4d xformOp:transform = ${transform}\n\t\t\tuniform token[] xformOpOrder = [\"xformOp:transform\"]\n\n\t\t\tfloat2 clippingRange = (${camera.near.toPrecision(PRECISION)}, ${camera.far.toPrecision(PRECISION)})\n\t\t\tfloat horizontalAperture = ${((Math.abs(camera.left) + Math.abs(camera.right)) * 10).toPrecision(PRECISION)}\n\t\t\tfloat verticalAperture = ${((Math.abs(camera.top) + Math.abs(camera.bottom)) * 10).toPrecision(PRECISION)}\n\t\t\ttoken projection = \"orthographic\"\n\t\t}\n\t\n\t`;\n  } else {\n    return `def Camera \"${name}\"\n\t\t{\n\t\t\tmatrix4d xformOp:transform = ${transform}\n\t\t\tuniform token[] xformOpOrder = [\"xformOp:transform\"]\n\n\t\t\tfloat2 clippingRange = (${camera.near.toPrecision(PRECISION)}, ${camera.far.toPrecision(PRECISION)})\n\t\t\tfloat focalLength = ${camera.getFocalLength().toPrecision(PRECISION)}\n\t\t\tfloat focusDistance = ${camera.focus.toPrecision(PRECISION)}\n\t\t\tfloat horizontalAperture = ${camera.getFilmWidth().toPrecision(PRECISION)}\n\t\t\ttoken projection = \"perspective\"\n\t\t\tfloat verticalAperture = ${camera.getFilmHeight().toPrecision(PRECISION)}\n\t\t}\n\t\n\t`;\n  }\n}\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n/**\n * For our purposes, an enumeration is a fixed set of CSS-expression-compatible\n * names. When serialized, a selected subset of the members may be specified as\n * whitespace-separated strings. An enumeration deserializer is a function that\n * parses a serialized subset of an enumeration and returns any members that are\n * found as a Set.\n *\n * The following example will produce a deserializer for the days of the\n * week:\n *\n * const deserializeDaysOfTheWeek = enumerationDeserializer([\n *   'Monday',\n *   'Tuesday',\n *   'Wednesday',\n *   'Thursday',\n *   'Friday',\n *   'Saturday',\n *   'Sunday'\n * ]);\n */\nconst enumerationDeserializer = allowedNames => valueString => {\n  try {\n    const expressions = parseExpressions(valueString);\n    const names = (expressions.length ? expressions[0].terms : []).filter(valueNode => valueNode && valueNode.type === 'ident').map(valueNode => valueNode.value).filter(name => allowedNames.indexOf(name) > -1);\n    return new Set(names);\n  } catch (_error) {}\n  return new Set();\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate$2 = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nlet isWebXRBlocked = false;\nlet isSceneViewerBlocked = false;\nconst noArViewerSigil = '#model-viewer-no-ar-fallback';\nconst deserializeARModes = enumerationDeserializer(['quick-look', 'scene-viewer', 'webxr', 'none']);\nconst DEFAULT_AR_MODES = 'webxr scene-viewer quick-look';\nconst ARMode = {\n  QUICK_LOOK: 'quick-look',\n  SCENE_VIEWER: 'scene-viewer',\n  WEBXR: 'webxr',\n  NONE: 'none'\n};\nconst $arButtonContainer = Symbol('arButtonContainer');\nconst $enterARWithWebXR = Symbol('enterARWithWebXR');\nconst $openSceneViewer = Symbol('openSceneViewer');\nconst $openIOSARQuickLook = Symbol('openIOSARQuickLook');\nconst $canActivateAR = Symbol('canActivateAR');\nconst $arMode = Symbol('arMode');\nconst $arModes = Symbol('arModes');\nconst $arAnchor = Symbol('arAnchor');\nconst $preload = Symbol('preload');\nconst $onARButtonContainerClick = Symbol('onARButtonContainerClick');\nconst $onARStatus = Symbol('onARStatus');\nconst $onARTracking = Symbol('onARTracking');\nconst $onARTap = Symbol('onARTap');\nconst $selectARMode = Symbol('selectARMode');\nconst $triggerLoad = Symbol('triggerLoad');\nconst ARMixin = ModelViewerElement => {\n  var _a, _b, _c, _d, _e, _f, _g, _h, _j, _k;\n  class ARModelViewerElement extends ModelViewerElement {\n    constructor() {\n      super(...arguments);\n      this.ar = false;\n      this.arScale = 'auto';\n      this.arPlacement = 'floor';\n      this.arModes = DEFAULT_AR_MODES;\n      this.iosSrc = null;\n      this.xrEnvironment = false;\n      this[_a] = false;\n      // TODO: Add this to the shadow root as part of this mixin's\n      // implementation:\n      this[_b] = this.shadowRoot.querySelector('.ar-button');\n      this[_c] = document.createElement('a');\n      this[_d] = new Set();\n      this[_e] = ARMode.NONE;\n      this[_f] = false;\n      this[_g] = event => {\n        event.preventDefault();\n        this.activateAR();\n      };\n      this[_h] = ({\n        status\n      }) => {\n        if (status === ARStatus.NOT_PRESENTING || this[$renderer].arRenderer.presentedScene === this[$scene]) {\n          this.setAttribute('ar-status', status);\n          this.dispatchEvent(new CustomEvent('ar-status', {\n            detail: {\n              status\n            }\n          }));\n          if (status === ARStatus.NOT_PRESENTING) {\n            this.removeAttribute('ar-tracking');\n          } else if (status === ARStatus.SESSION_STARTED) {\n            this.setAttribute('ar-tracking', ARTracking.TRACKING);\n          }\n        }\n      };\n      this[_j] = ({\n        status\n      }) => {\n        this.setAttribute('ar-tracking', status);\n        this.dispatchEvent(new CustomEvent('ar-tracking', {\n          detail: {\n            status\n          }\n        }));\n      };\n      this[_k] = event => {\n        if (event.data == '_apple_ar_quicklook_button_tapped') {\n          this.dispatchEvent(new CustomEvent('quick-look-button-tapped'));\n        }\n      };\n    }\n    get canActivateAR() {\n      return this[$arMode] !== ARMode.NONE;\n    }\n    connectedCallback() {\n      super.connectedCallback();\n      this[$renderer].arRenderer.addEventListener('status', this[$onARStatus]);\n      this.setAttribute('ar-status', ARStatus.NOT_PRESENTING);\n      this[$renderer].arRenderer.addEventListener('tracking', this[$onARTracking]);\n      this[$arAnchor].addEventListener('message', this[$onARTap]);\n    }\n    disconnectedCallback() {\n      super.disconnectedCallback();\n      this[$renderer].arRenderer.removeEventListener('status', this[$onARStatus]);\n      this[$renderer].arRenderer.removeEventListener('tracking', this[$onARTracking]);\n      this[$arAnchor].removeEventListener('message', this[$onARTap]);\n    }\n    update(changedProperties) {\n      super.update(changedProperties);\n      if (changedProperties.has('arScale')) {\n        this[$scene].canScale = this.arScale !== 'fixed';\n      }\n      if (changedProperties.has('arPlacement')) {\n        this[$scene].updateShadow();\n        this[$needsRender]();\n      }\n      if (changedProperties.has('arModes')) {\n        this[$arModes] = deserializeARModes(this.arModes);\n      }\n      if (changedProperties.has('ar') || changedProperties.has('arModes') || changedProperties.has('src') || changedProperties.has('iosSrc')) {\n        this[$selectARMode]();\n      }\n    }\n    /**\n     * Activates AR. Note that for any mode that is not WebXR-based, this\n     * method most likely has to be called synchronous from a user\n     * interaction handler. Otherwise, attempts to activate modes that\n     * require user interaction will most likely be ignored.\n     */\n    async activateAR() {\n      switch (this[$arMode]) {\n        case ARMode.QUICK_LOOK:\n          await this[$openIOSARQuickLook]();\n          break;\n        case ARMode.WEBXR:\n          await this[$enterARWithWebXR]();\n          break;\n        case ARMode.SCENE_VIEWER:\n          this[$openSceneViewer]();\n          break;\n        default:\n          console.warn('No AR Mode can be activated. This is probably due to missing \\\nconfiguration or device capabilities');\n          break;\n      }\n    }\n    async [(_a = $canActivateAR, _b = $arButtonContainer, _c = $arAnchor, _d = $arModes, _e = $arMode, _f = $preload, _g = $onARButtonContainerClick, _h = $onARStatus, _j = $onARTracking, _k = $onARTap, $selectARMode)]() {\n      var _l;\n      let arMode = ARMode.NONE;\n      if (this.ar) {\n        if (this.src != null) {\n          for (const value of this[$arModes]) {\n            if (value === 'webxr' && IS_WEBXR_AR_CANDIDATE && !isWebXRBlocked && (await this[$renderer].arRenderer.supportsPresentation())) {\n              arMode = ARMode.WEBXR;\n              break;\n            }\n            if (value === 'scene-viewer' && !isSceneViewerBlocked && (IS_SCENEVIEWER_CANDIDATE || navigator.userAgentData && navigator.userAgentData.getHighEntropyValues && ((_l = (await navigator.userAgentData.getHighEntropyValues(['formFactor'])).formFactor) === null || _l === void 0 ? void 0 : _l.includes('XR')))) {\n              arMode = ARMode.SCENE_VIEWER;\n              break;\n            }\n            if (value === 'quick-look' && IS_AR_QUICKLOOK_CANDIDATE) {\n              arMode = ARMode.QUICK_LOOK;\n              break;\n            }\n          }\n        }\n        // The presence of ios-src overrides the absence of quick-look\n        // ar-mode.\n        if (arMode === ARMode.NONE && this.iosSrc != null && IS_AR_QUICKLOOK_CANDIDATE) {\n          arMode = ARMode.QUICK_LOOK;\n        }\n      }\n      if (arMode !== ARMode.NONE) {\n        this[$arButtonContainer].classList.add('enabled');\n        this[$arButtonContainer].addEventListener('click', this[$onARButtonContainerClick]);\n      } else if (this[$arButtonContainer].classList.contains('enabled')) {\n        this[$arButtonContainer].removeEventListener('click', this[$onARButtonContainerClick]);\n        this[$arButtonContainer].classList.remove('enabled');\n        // If AR went from working to not, notify the element.\n        const status = ARStatus.FAILED;\n        this.setAttribute('ar-status', status);\n        this.dispatchEvent(new CustomEvent('ar-status', {\n          detail: {\n            status\n          }\n        }));\n      }\n      this[$arMode] = arMode;\n    }\n    async [$enterARWithWebXR]() {\n      console.log('Attempting to present in AR with WebXR...');\n      await this[$triggerLoad]();\n      try {\n        this[$arButtonContainer].removeEventListener('click', this[$onARButtonContainerClick]);\n        const {\n          arRenderer\n        } = this[$renderer];\n        arRenderer.placeOnWall = this.arPlacement === 'wall';\n        await arRenderer.present(this[$scene], this.xrEnvironment);\n      } catch (error) {\n        console.warn('Error while trying to present in AR with WebXR');\n        console.error(error);\n        await this[$renderer].arRenderer.stopPresenting();\n        isWebXRBlocked = true;\n        console.warn('Falling back to next ar-mode');\n        await this[$selectARMode]();\n        this.activateAR();\n      } finally {\n        this[$selectARMode]();\n      }\n    }\n    async [$triggerLoad]() {\n      if (!this.loaded) {\n        this[$preload] = true;\n        this[$updateSource]();\n        await waitForEvent(this, 'load');\n        this[$preload] = false;\n      }\n    }\n    [$shouldAttemptPreload]() {\n      return super[$shouldAttemptPreload]() || this[$preload];\n    }\n    /**\n     * Takes a URL and a title string, and attempts to launch Scene Viewer on\n     * the current device.\n     */\n    [$openSceneViewer]() {\n      const location = self.location.toString();\n      const locationUrl = new URL(location);\n      const modelUrl = new URL(this.src, location);\n      if (modelUrl.hash) modelUrl.hash = '';\n      const params = new URLSearchParams(modelUrl.search);\n      locationUrl.hash = noArViewerSigil;\n      // modelUrl can contain title/link/sound etc.\n      params.set('mode', 'ar_preferred');\n      if (!params.has('disable_occlusion')) {\n        params.set('disable_occlusion', 'true');\n      }\n      if (this.arScale === 'fixed') {\n        params.set('resizable', 'false');\n      }\n      if (this.arPlacement === 'wall') {\n        params.set('enable_vertical_placement', 'true');\n      }\n      if (params.has('sound')) {\n        const soundUrl = new URL(params.get('sound'), location);\n        params.set('sound', soundUrl.toString());\n      }\n      if (params.has('link')) {\n        const linkUrl = new URL(params.get('link'), location);\n        params.set('link', linkUrl.toString());\n      }\n      const intent = `intent://arvr.google.com/scene-viewer/1.2?${params.toString() + '&file=' + encodeURIComponent(modelUrl.toString())}#Intent;scheme=https;package=com.google.android.googlequicksearchbox;action=android.intent.action.VIEW;S.browser_fallback_url=${encodeURIComponent(locationUrl.toString())};end;`;\n      const undoHashChange = () => {\n        if (self.location.hash === noArViewerSigil) {\n          isSceneViewerBlocked = true;\n          // The new history will be the current URL with a new hash.\n          // Go back one step so that we reset to the expected URL.\n          // NOTE(cdata): this should not invoke any browser-level navigation\n          // because hash-only changes modify the URL in-place without\n          // navigating:\n          self.history.back();\n          console.warn('Error while trying to present in AR with Scene Viewer');\n          console.warn('Falling back to next ar-mode');\n          this[$selectARMode]();\n          // Would be nice to activateAR() here, but webXR fails due to not\n          // seeing a user activation.\n        }\n      };\n      self.addEventListener('hashchange', undoHashChange, {\n        once: true\n      });\n      this[$arAnchor].setAttribute('href', intent);\n      console.log('Attempting to present in AR with Scene Viewer...');\n      this[$arAnchor].click();\n    }\n    /**\n     * Takes a URL to a USDZ file and sets the appropriate fields so that\n     * Safari iOS can intent to their AR Quick Look.\n     */\n    async [$openIOSARQuickLook]() {\n      const generateUsdz = !this.iosSrc;\n      this[$arButtonContainer].classList.remove('enabled');\n      const objectURL = generateUsdz ? await this.prepareUSDZ() : this.iosSrc;\n      const modelUrl = new URL(objectURL, self.location.toString());\n      if (generateUsdz) {\n        const location = self.location.toString();\n        const locationUrl = new URL(location);\n        const srcUrl = new URL(this.src, locationUrl);\n        if (srcUrl.hash) {\n          modelUrl.hash = srcUrl.hash;\n        }\n      }\n      if (this.arScale === 'fixed') {\n        if (modelUrl.hash) {\n          modelUrl.hash += '&';\n        }\n        modelUrl.hash += 'allowsContentScaling=0';\n      }\n      const anchor = this[$arAnchor];\n      anchor.setAttribute('rel', 'ar');\n      const img = document.createElement('img');\n      anchor.appendChild(img);\n      anchor.setAttribute('href', modelUrl.toString());\n      if (generateUsdz) {\n        anchor.setAttribute('download', 'model.usdz');\n      }\n      // attach anchor to shadow DOM to ensure iOS16 ARQL banner click message\n      // event propagation\n      anchor.style.display = 'none';\n      if (!anchor.isConnected) this.shadowRoot.appendChild(anchor);\n      console.log('Attempting to present in AR with Quick Look...');\n      anchor.click();\n      anchor.removeChild(img);\n      if (generateUsdz) {\n        URL.revokeObjectURL(objectURL);\n      }\n      this[$arButtonContainer].classList.add('enabled');\n    }\n    async prepareUSDZ() {\n      const updateSourceProgress = this[$progressTracker].beginActivity('usdz-conversion');\n      await this[$triggerLoad]();\n      const {\n        model,\n        shadow,\n        target\n      } = this[$scene];\n      if (model == null) {\n        return '';\n      }\n      let visible = false;\n      // Remove shadow from export\n      if (shadow != null) {\n        visible = shadow.visible;\n        shadow.visible = false;\n      }\n      updateSourceProgress(0.2);\n      const exporter = new USDZExporter();\n      target.remove(model);\n      model.position.copy(target.position);\n      model.updateWorldMatrix(false, true);\n      const arraybuffer = await exporter.parseAsync(model);\n      model.position.set(0, 0, 0);\n      target.add(model);\n      const blob = new Blob([arraybuffer], {\n        type: 'model/vnd.usdz+zip'\n      });\n      const url = URL.createObjectURL(blob);\n      updateSourceProgress(1);\n      if (shadow != null) {\n        shadow.visible = visible;\n      }\n      return url;\n    }\n  }\n  __decorate$2([n$8({\n    type: Boolean,\n    attribute: 'ar'\n  })], ARModelViewerElement.prototype, \"ar\", void 0);\n  __decorate$2([n$8({\n    type: String,\n    attribute: 'ar-scale'\n  })], ARModelViewerElement.prototype, \"arScale\", void 0);\n  __decorate$2([n$8({\n    type: String,\n    attribute: 'ar-placement'\n  })], ARModelViewerElement.prototype, \"arPlacement\", void 0);\n  __decorate$2([n$8({\n    type: String,\n    attribute: 'ar-modes'\n  })], ARModelViewerElement.prototype, \"arModes\", void 0);\n  __decorate$2([n$8({\n    type: String,\n    attribute: 'ios-src'\n  })], ARModelViewerElement.prototype, \"iosSrc\", void 0);\n  __decorate$2([n$8({\n    type: Boolean,\n    attribute: 'xr-environment'\n  })], ARModelViewerElement.prototype, \"xrEnvironment\", void 0);\n  return ARModelViewerElement;\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate$1 = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\nconst PROGRESS_BAR_UPDATE_THRESHOLD = 100;\nconst DEFAULT_DRACO_DECODER_LOCATION = 'https://www.gstatic.com/draco/versioned/decoders/1.5.6/';\nconst DEFAULT_KTX2_TRANSCODER_LOCATION = 'https://www.gstatic.com/basis-universal/versioned/2021-04-15-ba1c3e4/';\nconst DEFAULT_LOTTIE_LOADER_LOCATION = 'https://cdn.jsdelivr.net/npm/three@0.149.0/examples/jsm/loaders/LottieLoader.js';\nconst RevealStrategy = {\n  AUTO: 'auto',\n  MANUAL: 'manual'\n};\nconst LoadingStrategy = {\n  AUTO: 'auto',\n  LAZY: 'lazy',\n  EAGER: 'eager'\n};\nconst $defaultProgressBarElement = Symbol('defaultProgressBarElement');\nconst $posterContainerElement = Symbol('posterContainerElement');\nconst $defaultPosterElement = Symbol('defaultPosterElement');\nconst $shouldDismissPoster = Symbol('shouldDismissPoster');\nconst $hidePoster = Symbol('hidePoster');\nconst $modelIsRevealed = Symbol('modelIsRevealed');\nconst $updateProgressBar = Symbol('updateProgressBar');\nconst $ariaLabelCallToAction = Symbol('ariaLabelCallToAction');\nconst $onProgress = Symbol('onProgress');\n/**\n * LoadingMixin implements features related to lazy loading, as well as\n * presentation details related to the pre-load / pre-render presentation of a\n * <model-viewer>\n *\n * This mixin implements support for models with DRACO-compressed meshes.\n * The DRACO decoder will be loaded on-demand if a glTF that uses the DRACO mesh\n * compression extension is encountered.\n *\n * By default, the DRACO decoder will be loaded from a Google CDN. It is\n * possible to customize where the decoder is loaded from by defining a global\n * configuration option for `<model-viewer>` like so:\n *\n * ```html\n * <script>\n * self.ModelViewerElement = self.ModelViewerElement || {};\n * self.ModelViewerElement.dracoDecoderLocation =\n *     'http://example.com/location/of/draco/decoder/files/';\n * </script>\n * ```\n *\n * Note that the above configuration strategy must be performed *before* the\n * first `<model-viewer>` element is created in the browser. The configuration\n * can be done anywhere, but the easiest way to ensure it is done at the right\n * time is to do it in the `<head>` of the HTML document. This is the\n * recommended way to set the location because it is most compatible with\n * scenarios where the `<model-viewer>` library is lazily loaded.\n *\n * If you absolutely have to set the DRACO decoder location *after* the first\n * `<model-viewer>` element is created, you can do it this way:\n *\n * ```html\n * <script>\n * const ModelViewerElement = customElements.get('model-viewer');\n * ModelViewerElement.dracoDecoderLocation =\n *     'http://example.com/location/of/draco/decoder/files/';\n * </script>\n * ```\n *\n * Note that the above configuration approach will not work until *after*\n * `<model-viewer>` is defined in the browser. Also note that this configuration\n * *must* be set *before* the first DRACO model is fully loaded.\n *\n * It is recommended that users who intend to take advantage of DRACO mesh\n * compression consider whether or not it is acceptable for their use case to\n * have code side-loaded from a Google CDN. If it is not acceptable, then the\n * location must be customized before loading any DRACO models in order to cause\n * the decoder to be loaded from an alternative, acceptable location.\n */\nconst LoadingMixin = ModelViewerElement => {\n  var _a, _b, _c, _d, _e, _f, _g, _h;\n  class LoadingModelViewerElement extends ModelViewerElement {\n    constructor(...args) {\n      super(...args);\n      /**\n       * A URL pointing to the image to use as a poster in scenarios where the\n       * <model-viewer> is not ready to reveal a rendered model to the viewer.\n       */\n      this.poster = null;\n      /**\n       * An enumerable attribute describing under what conditions the\n       * <model-viewer> should reveal a model to the viewer.\n       *\n       * The default value is \"auto\". The only supported alternative values is\n       * \"manual\".\n       */\n      this.reveal = RevealStrategy.AUTO;\n      /**\n       * An enumerable attribute describing under what conditions the\n       * <model-viewer> should preload a model.\n       *\n       * The default value is \"auto\". The only supported alternative values are\n       * \"lazy\" and \"eager\". Auto is equivalent to lazy, which loads the model\n       * when it is near the viewport for reveal = \"auto\", and when interacted\n       * with for reveal = \"interaction\". Eager loads the model immediately.\n       */\n      this.loading = LoadingStrategy.AUTO;\n      this[_a] = false;\n      this[_b] = false;\n      // TODO: Add this to the shadow root as part of this mixin's\n      // implementation:\n      this[_c] = this.shadowRoot.querySelector('.slot.poster');\n      this[_d] = this.shadowRoot.querySelector('#default-poster');\n      this[_e] = this.shadowRoot.querySelector('#default-progress-bar > .bar');\n      this[_f] = this[$defaultPosterElement].getAttribute('aria-label');\n      this[_g] = throttle(progress => {\n        const parentNode = this[$defaultProgressBarElement].parentNode;\n        requestAnimationFrame(() => {\n          this[$defaultProgressBarElement].style.transform = `scaleX(${progress})`;\n          if (progress === 0) {\n            // NOTE(cdata): We remove and re-append the progress bar in this\n            // condition so that the progress bar does not appear to\n            // transition backwards from the right when we reset to 0 (or\n            // otherwise <1) progress after having already reached 1 progress\n            // previously.\n            parentNode.removeChild(this[$defaultProgressBarElement]);\n            parentNode.appendChild(this[$defaultProgressBarElement]);\n          }\n          this[$defaultProgressBarElement].classList.toggle('hide', progress === 1.0);\n        });\n      }, PROGRESS_BAR_UPDATE_THRESHOLD);\n      this[_h] = event => {\n        const progress = event.detail.totalProgress;\n        const reason = event.detail.reason;\n        if (progress === 1.0) {\n          this[$updateProgressBar].flush();\n          if (this.loaded && (this[$shouldDismissPoster] || this.reveal === RevealStrategy.AUTO)) {\n            this[$hidePoster]();\n          }\n        }\n        this[$updateProgressBar](progress);\n        this.dispatchEvent(new CustomEvent('progress', {\n          detail: {\n            totalProgress: progress,\n            reason\n          }\n        }));\n      };\n      const ModelViewerElement = self.ModelViewerElement || {};\n      const dracoDecoderLocation = ModelViewerElement.dracoDecoderLocation || DEFAULT_DRACO_DECODER_LOCATION;\n      CachingGLTFLoader.setDRACODecoderLocation(dracoDecoderLocation);\n      const ktx2TranscoderLocation = ModelViewerElement.ktx2TranscoderLocation || DEFAULT_KTX2_TRANSCODER_LOCATION;\n      CachingGLTFLoader.setKTX2TranscoderLocation(ktx2TranscoderLocation);\n      if (ModelViewerElement.meshoptDecoderLocation) {\n        CachingGLTFLoader.setMeshoptDecoderLocation(ModelViewerElement.meshoptDecoderLocation);\n      }\n      const lottieLoaderLocation = ModelViewerElement.lottieLoaderLocation || DEFAULT_LOTTIE_LOADER_LOCATION;\n      Renderer.singleton.textureUtils.lottieLoaderUrl = lottieLoaderLocation;\n    }\n    static set dracoDecoderLocation(value) {\n      CachingGLTFLoader.setDRACODecoderLocation(value);\n    }\n    static get dracoDecoderLocation() {\n      return CachingGLTFLoader.getDRACODecoderLocation();\n    }\n    static set ktx2TranscoderLocation(value) {\n      CachingGLTFLoader.setKTX2TranscoderLocation(value);\n    }\n    static get ktx2TranscoderLocation() {\n      return CachingGLTFLoader.getKTX2TranscoderLocation();\n    }\n    static set meshoptDecoderLocation(value) {\n      CachingGLTFLoader.setMeshoptDecoderLocation(value);\n    }\n    static get meshoptDecoderLocation() {\n      return CachingGLTFLoader.getMeshoptDecoderLocation();\n    }\n    static set lottieLoaderLocation(value) {\n      Renderer.singleton.textureUtils.lottieLoaderUrl = value;\n    }\n    static get lottieLoaderLocation() {\n      return Renderer.singleton.textureUtils.lottieLoaderUrl;\n    }\n    /**\n     * If provided, the callback will be passed each resource URL before a\n     * request is sent. The callback may return the original URL, or a new URL\n     * to override loading behavior. This behavior can be used to load assets\n     * from .ZIP files, drag-and-drop APIs, and Data URIs.\n     */\n    static mapURLs(callback) {\n      Renderer.singleton.loader[$loader].manager.setURLModifier(callback);\n    }\n    /**\n     * Dismisses the poster, causing the model to load and render if\n     * necessary. This is currently effectively the same as interacting with\n     * the poster via user input.\n     */\n    dismissPoster() {\n      if (this.loaded) {\n        this[$hidePoster]();\n      } else {\n        this[$shouldDismissPoster] = true;\n        this[$updateSource]();\n      }\n    }\n    /**\n     * Displays the poster, hiding the 3D model. If this is called after the 3D\n     * model has been revealed, then it must be dismissed by a call to\n     * dismissPoster().\n     */\n    showPoster() {\n      const posterContainerElement = this[$posterContainerElement];\n      if (posterContainerElement.classList.contains('show')) {\n        return;\n      }\n      posterContainerElement.classList.add('show');\n      this[$userInputElement].classList.remove('show');\n      const defaultPosterElement = this[$defaultPosterElement];\n      defaultPosterElement.removeAttribute('tabindex');\n      defaultPosterElement.removeAttribute('aria-hidden');\n      const oldVisibility = this.modelIsVisible;\n      this[$modelIsRevealed] = false;\n      this[$announceModelVisibility](oldVisibility);\n    }\n    /**\n     * Returns the model's bounding box dimensions in meters, independent of\n     * turntable rotation.\n     */\n    getDimensions() {\n      return toVector3D(this[$scene].size);\n    }\n    getBoundingBoxCenter() {\n      return toVector3D(this[$scene].boundingBox.getCenter(new Vector3()));\n    }\n    connectedCallback() {\n      super.connectedCallback();\n      if (!this.loaded) {\n        this.showPoster();\n      }\n      this[$progressTracker].addEventListener('progress', this[$onProgress]);\n    }\n    disconnectedCallback() {\n      super.disconnectedCallback();\n      this[$progressTracker].removeEventListener('progress', this[$onProgress]);\n    }\n    async updated(changedProperties) {\n      super.updated(changedProperties);\n      if (changedProperties.has('poster') && this.poster != null) {\n        this[$defaultPosterElement].style.backgroundImage = `url(${this.poster})`;\n      }\n      if (changedProperties.has('alt')) {\n        this[$defaultPosterElement].setAttribute('aria-label', this[$altDefaulted]);\n      }\n      if (changedProperties.has('reveal') || changedProperties.has('loading')) {\n        this[$updateSource]();\n      }\n    }\n    [(_a = $modelIsRevealed, _b = $shouldDismissPoster, _c = $posterContainerElement, _d = $defaultPosterElement, _e = $defaultProgressBarElement, _f = $ariaLabelCallToAction, _g = $updateProgressBar, _h = $onProgress, $shouldAttemptPreload)]() {\n      return !!this.src && (this[$shouldDismissPoster] || this.loading === LoadingStrategy.EAGER || this.reveal === RevealStrategy.AUTO && this[$isElementInViewport]);\n    }\n    [$hidePoster]() {\n      this[$shouldDismissPoster] = false;\n      const posterContainerElement = this[$posterContainerElement];\n      if (!posterContainerElement.classList.contains('show')) {\n        return;\n      }\n      posterContainerElement.classList.remove('show');\n      this[$userInputElement].classList.add('show');\n      const oldVisibility = this.modelIsVisible;\n      this[$modelIsRevealed] = true;\n      this[$announceModelVisibility](oldVisibility);\n      const root = this.getRootNode();\n      // If the <model-viewer> is still focused, forward the focus to\n      // the canvas that has just been revealed\n      if (root && root.activeElement === this) {\n        this[$userInputElement].focus();\n      }\n      // Ensure that the poster is no longer focusable or visible to\n      // screen readers\n      const defaultPosterElement = this[$defaultPosterElement];\n      defaultPosterElement.setAttribute('aria-hidden', 'true');\n      defaultPosterElement.tabIndex = -1;\n      this.dispatchEvent(new CustomEvent('poster-dismissed'));\n    }\n    [$getModelIsVisible]() {\n      return super[$getModelIsVisible]() && this[$modelIsRevealed];\n    }\n  }\n  __decorate$1([n$8({\n    type: String\n  })], LoadingModelViewerElement.prototype, \"poster\", void 0);\n  __decorate$1([n$8({\n    type: String\n  })], LoadingModelViewerElement.prototype, \"reveal\", void 0);\n  __decorate$1([n$8({\n    type: String\n  })], LoadingModelViewerElement.prototype, \"loading\", void 0);\n  return LoadingModelViewerElement;\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nvar __decorate = undefined && undefined.__decorate || function (decorators, target, key, desc) {\n  var c = arguments.length,\n    r = c < 3 ? target : desc === null ? desc = Object.getOwnPropertyDescriptor(target, key) : desc,\n    d;\n  if (typeof Reflect === \"object\" && typeof undefined === \"function\") r = undefined(decorators, target, key, desc);else for (var i = decorators.length - 1; i >= 0; i--) if (d = decorators[i]) r = (c < 3 ? d(r) : c > 3 ? d(target, key, r) : d(target, key)) || r;\n  return c > 3 && r && Object.defineProperty(target, key, r), r;\n};\n// How much the model will rotate per\n// second in radians:\nconst DEFAULT_ROTATION_SPEED = Math.PI / 32;\nconst AUTO_ROTATE_DELAY_DEFAULT = 3000;\nconst rotationRateIntrinsics = {\n  basis: [degreesToRadians(numberNode(DEFAULT_ROTATION_SPEED, 'rad'))],\n  keywords: {\n    auto: [null]\n  }\n};\nconst $autoRotateStartTime = Symbol('autoRotateStartTime');\nconst $radiansPerSecond = Symbol('radiansPerSecond');\nconst $syncRotationRate = Symbol('syncRotationRate');\nconst $onCameraChange = Symbol('onCameraChange');\nconst StagingMixin = ModelViewerElement => {\n  var _a, _b, _c;\n  class StagingModelViewerElement extends ModelViewerElement {\n    constructor() {\n      super(...arguments);\n      this.autoRotate = false;\n      this.autoRotateDelay = AUTO_ROTATE_DELAY_DEFAULT;\n      this.rotationPerSecond = 'auto';\n      this[_a] = performance.now();\n      this[_b] = 0;\n      this[_c] = event => {\n        if (!this.autoRotate) {\n          return;\n        }\n        if (event.detail.source === 'user-interaction') {\n          this[$autoRotateStartTime] = performance.now();\n        }\n      };\n    }\n    connectedCallback() {\n      super.connectedCallback();\n      this.addEventListener('camera-change', this[$onCameraChange]);\n      this[$autoRotateStartTime] = performance.now();\n    }\n    disconnectedCallback() {\n      super.disconnectedCallback();\n      this.removeEventListener('camera-change', this[$onCameraChange]);\n      this[$autoRotateStartTime] = performance.now();\n    }\n    updated(changedProperties) {\n      super.updated(changedProperties);\n      if (changedProperties.has('autoRotate')) {\n        this[$autoRotateStartTime] = performance.now();\n      }\n    }\n    [(_a = $autoRotateStartTime, _b = $radiansPerSecond, $syncRotationRate)](style) {\n      this[$radiansPerSecond] = style[0];\n    }\n    [$tick](time, delta) {\n      super[$tick](time, delta);\n      if (!this.autoRotate || !this[$getModelIsVisible]() || this[$renderer].isPresenting) {\n        return;\n      }\n      const rotationDelta = Math.min(delta, time - this[$autoRotateStartTime] - this.autoRotateDelay);\n      if (rotationDelta > 0) {\n        this[$scene].yaw = this.turntableRotation + this[$radiansPerSecond] * rotationDelta * 0.001;\n      }\n    }\n    get turntableRotation() {\n      return this[$scene].yaw;\n    }\n    resetTurntableRotation(theta = 0) {\n      this[$scene].yaw = theta;\n    }\n  }\n  _c = $onCameraChange;\n  __decorate([n$8({\n    type: Boolean,\n    attribute: 'auto-rotate'\n  })], StagingModelViewerElement.prototype, \"autoRotate\", void 0);\n  __decorate([n$8({\n    type: Number,\n    attribute: 'auto-rotate-delay'\n  })], StagingModelViewerElement.prototype, \"autoRotateDelay\", void 0);\n  __decorate([style({\n    intrinsics: rotationRateIntrinsics,\n    updateHandler: $syncRotationRate\n  }), n$8({\n    type: String,\n    attribute: 'rotation-per-second'\n  })], StagingModelViewerElement.prototype, \"rotationPerSecond\", void 0);\n  return StagingModelViewerElement;\n};\n\n/* @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the 'License');\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n *     http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an 'AS IS' BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\nconst ModelViewerElement = AnnotationMixin(SceneGraphMixin(StagingMixin(EnvironmentMixin(ControlsMixin(ARMixin(LoadingMixin(AnimationMixin(ModelViewerElementBase))))))));\ncustomElements.define('model-viewer', ModelViewerElement);\nexport { CanvasTexture, FileLoader, Loader, ModelViewerElement, NearestFilter };\n//# sourceMappingURL=model-viewer.js.map","map":null,"metadata":{},"sourceType":"module","externalDependencies":[]}